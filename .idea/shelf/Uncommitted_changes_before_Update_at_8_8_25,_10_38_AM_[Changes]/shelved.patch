Index: .idea/shelf/Uncommitted_changes_before_Update_at_8_8_25__9_52_AM__Changes_.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25__9_52_AM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25__9_52_AM__Changes_.xml
new file mode 100644
--- /dev/null	(date 1754642300848)
+++ b/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25__9_52_AM__Changes_.xml	(date 1754642300848)
@@ -0,0 +1,209 @@
+<changelist name="Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]" date="1754639536674" recycled="false" toDelete="true">
+  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/shelved.patch" />
+  <option name="DESCRIPTION" value="Uncommitted changes before Update at 8/8/25, 9:52 AM [Changes]" />
+  <binary>
+    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_field_comparison.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/MBE2D.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/SH3D_Comparison_Plot_Modified.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" />
+    <option name="AFTER_PATH" value="SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.h5" />
+    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.h5" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" />
+    <option name="AFTER_PATH" value=".idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/MBE3D_Hybrid.jpg" />
+    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/MBE3D_Hybrid.jpg" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/combined_results.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/SH2D.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" />
+    <option name="AFTER_PATH" value="MBE3D/plots_Data_Physics_TNO3d/MBE3D_Hybrid.jpg" />
+    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/MBE3D_Hybrid1.jpg" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_loss_curve.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison_FINAL.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/combined_results.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison_mixed.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" />
+    <option name="AFTER_PATH" value="SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" />
+    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/SH3D_FNO_field_comparison.png" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/CH3D_random_new.asv" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/middle.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/3d_phase_evolution.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/PFC2D_rand.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_loss_curve_mixed.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" />
+    <option name="AFTER_PATH" value="SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" />
+    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/SH3D_Hybrid_field_comparison.png" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/PFC2D.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/SH3D_rand.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/SH2D_rand.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/CH3D_test.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" />
+    <option name="AFTER_PATH" value=".idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/MBE3D_Hybrid.jpg" />
+    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/MBE3D_Hybrid2.jpg" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/CH3D_Comparison_star_SANO.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/MBE2D_rand.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" />
+    <option name="AFTER_PATH" value=".idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/MBE3D_Hybrid.jpg" />
+    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/MBE3D_Hybrid3.jpg" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_loss_curve_mixed.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/CH3D_random_new.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MBE3D/plots_FNO3d/3d_phase_evolution.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/SH3D_Comparison_Plot_Modified_PIMHNO.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MBE3D/plots_TNO3d/3d_phase_evolution.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/SH3D_SANO_field_comparison.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MBE3D/plots_FNO3d/combined_results.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="MatlabCode/CH3D_rand.m" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+  <binary>
+    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" />
+    <option name="AFTER_PATH" />
+    <option name="SHELVED_PATH" />
+  </binary>
+</changelist>
\ No newline at end of file
Index: .idea/shelf/Uncommitted_changes_before_Update_at_8_8_25__10_09_AM__Changes_.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25__10_09_AM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25__10_09_AM__Changes_.xml
new file mode 100644
--- /dev/null	(date 1754642300862)
+++ b/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25__10_09_AM__Changes_.xml	(date 1754642300862)
@@ -0,0 +1,4 @@
+<changelist name="Uncommitted_changes_before_Update_at_8_8_25,_10_09_AM_[Changes]" date="1754640549687" recycled="false" toDelete="true">
+  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_10_09_AM_[Changes]/shelved.patch" />
+  <option name="DESCRIPTION" value="Uncommitted changes before Update at 8/8/25, 10:09 AM [Changes]" />
+</changelist>
\ No newline at end of file
Index: .idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_10_09_AM_[Changes]/shelved.patch
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_10_09_AM_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_10_09_AM_[Changes]/shelved.patch
new file mode 100644
--- /dev/null	(date 1754640549687)
+++ b/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_10_09_AM_[Changes]/shelved.patch	(date 1754640549687)
@@ -0,0 +1,80 @@
+Index: .idea/workspace.xml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"TNO3d vs FNO3d\">\n      <change afterPath=\"$PROJECT_DIR$/run_inference.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/vcs.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/vcs.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/main.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/main.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/networks.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/networks.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/post_processing.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/post_processing.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/training.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/training.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/utilities.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/utilities.py\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <excluded-from-favorite>\n      <branch-storage>\n        <map>\n          <entry type=\"LOCAL\">\n            <value>\n              <list>\n                <branch-info repo=\"$PROJECT_DIR$\" source=\"master\" />\n              </list>\n            </value>\n          </entry>\n        </map>\n      </branch-storage>\n    </excluded-from-favorite>\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\n      <map>\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\n      </map>\n    </option>\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n    <option name=\"ROOT_SYNC\" value=\"DONT_SYNC\" />\n  </component>\n  <component name=\"GitHubPullRequestSearchHistory\">{\n  &quot;lastFilter&quot;: {\n    &quot;state&quot;: &quot;OPEN&quot;,\n    &quot;assignee&quot;: &quot;MBamdad&quot;\n  }\n}</component>\n  <component name=\"GithubPullRequestsUISettings\">{\n  &quot;selectedUrlAndAccountId&quot;: {\n    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,\n    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;\n  }\n}</component>\n  <component name=\"ProjectColorInfo\">{\n  &quot;associatedIndex&quot;: 1\n}</component>\n  <component name=\"ProjectId\" id=\"2p11NySvsgjZ8eu9d53SI84567l\" />\n  <component name=\"ProjectReloadState\">\n    <option name=\"STATE\" value=\"1\" />\n  </component>\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">{\n  &quot;keyToString&quot;: {\n    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.main.executor&quot;: &quot;Run&quot;,\n    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.networks.executor&quot;: &quot;Run&quot;,\n    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,\n    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,\n    &quot;Python.test1.executor&quot;: &quot;Run&quot;,\n    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,\n    &quot;git-widget-placeholder&quot;: &quot;main&quot;,\n    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,\n    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,\n    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,\n    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,\n    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,\n    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,\n    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,\n    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;\n  },\n  &quot;keyToStringList&quot;: {\n    &quot;ChangesTree.GroupingKeys&quot;: [\n      &quot;directory&quot;\n    ]\n  }\n}</component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$/configs\" />\n      <recent name=\"$PROJECT_DIR$/AC2Dtest/models\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code/AC2D\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code\" />\n    </key>\n    <key name=\"MoveFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.AC3D_TNO3d\">\n    <configuration name=\"AC3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_TNO3d_hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"MBE3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d_Hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <list>\n      <item itemvalue=\"Python.AC3D_TNO3d\" />\n      <item itemvalue=\"Python.AC3d_FNO3d\" />\n      <item itemvalue=\"Python.AC3d_TNO3d_hybrid\" />\n      <item itemvalue=\"Python.CH3D_TNO3d\" />\n      <item itemvalue=\"Python.MBE3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_FNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d_Hybrid\" />\n    </list>\n  </component>\n  <component name=\"SharedIndexes\">\n    <attachedChunks>\n      <set>\n        <option value=\"bundled-js-predefined-1d06a55b98c1-0b3e54e931b4-JavaScript-PY-241.18034.82\" />\n        <option value=\"bundled-python-sdk-975db3bf15a3-2767605e8bc2-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-241.18034.82\" />\n      </set>\n    </attachedChunks>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"\" />\n      <created>1731918731711</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1731918731711</updated>\n      <workItem from=\"1731918732726\" duration=\"17070000\" />\n      <workItem from=\"1732010735784\" duration=\"777000\" />\n      <workItem from=\"1732011520582\" duration=\"8000\" />\n      <workItem from=\"1732011538945\" duration=\"13153000\" />\n      <workItem from=\"1732106481018\" duration=\"3721000\" />\n      <workItem from=\"1732480846034\" duration=\"2889000\" />\n      <workItem from=\"1732483872465\" duration=\"14926000\" />\n      <workItem from=\"1732567216112\" duration=\"964000\" />\n      <workItem from=\"1732765090621\" duration=\"5000\" />\n      <workItem from=\"1732765102609\" duration=\"12000\" />\n      <workItem from=\"1732765345288\" duration=\"10000\" />\n      <workItem from=\"1732903897716\" duration=\"3074000\" />\n      <workItem from=\"1732911303920\" duration=\"27201000\" />\n      <workItem from=\"1732999179592\" duration=\"8241000\" />\n      <workItem from=\"1733039613684\" duration=\"6792000\" />\n      <workItem from=\"1733095843263\" duration=\"10000\" />\n      <workItem from=\"1733140600841\" duration=\"6993000\" />\n      <workItem from=\"1733150993229\" duration=\"184000\" />\n      <workItem from=\"1733151279786\" duration=\"6000\" />\n      <workItem from=\"1733151296310\" duration=\"16875000\" />\n      <workItem from=\"1733233230739\" duration=\"5172000\" />\n      <workItem from=\"1733246997923\" duration=\"15986000\" />\n      <workItem from=\"1733349590652\" duration=\"1949000\" />\n      <workItem from=\"1733352121741\" duration=\"6332000\" />\n      <workItem from=\"1733405466233\" duration=\"12731000\" />\n      <workItem from=\"1733557048829\" duration=\"5541000\" />\n      <workItem from=\"1733583489891\" duration=\"16419000\" />\n      <workItem from=\"1733859258781\" duration=\"7356000\" />\n      <workItem from=\"1733995059967\" duration=\"7899000\" />\n      <workItem from=\"1734011167665\" duration=\"991000\" />\n      <workItem from=\"1734029966470\" duration=\"25769000\" />\n      <workItem from=\"1734205412700\" duration=\"7689000\" />\n      <workItem from=\"1734644992163\" duration=\"5017000\" />\n      <workItem from=\"1734788130789\" duration=\"2312000\" />\n      <workItem from=\"1734863751114\" duration=\"9000\" />\n      <workItem from=\"1734863775073\" duration=\"9221000\" />\n      <workItem from=\"1734880034791\" duration=\"57000\" />\n      <workItem from=\"1734880213539\" duration=\"15000\" />\n      <workItem from=\"1734880329890\" duration=\"30000\" />\n      <workItem from=\"1734880369064\" duration=\"31312000\" />\n      <workItem from=\"1734983129135\" duration=\"55000\" />\n      <workItem from=\"1735034212628\" duration=\"2274000\" />\n      <workItem from=\"1735049036048\" duration=\"5309000\" />\n      <workItem from=\"1735126261413\" duration=\"75000\" />\n      <workItem from=\"1735356723104\" duration=\"1208000\" />\n      <workItem from=\"1735422837186\" duration=\"1387000\" />\n      <workItem from=\"1735719009558\" duration=\"561000\" />\n      <workItem from=\"1736101930735\" duration=\"570000\" />\n      <workItem from=\"1736102511675\" duration=\"4000\" />\n      <workItem from=\"1736161159525\" duration=\"7670000\" />\n      <workItem from=\"1736237907904\" duration=\"111000\" />\n      <workItem from=\"1736519480236\" duration=\"1867000\" />\n      <workItem from=\"1737577034938\" duration=\"3945000\" />\n      <workItem from=\"1737590448155\" duration=\"6145000\" />\n      <workItem from=\"1738310597042\" duration=\"2502000\" />\n      <workItem from=\"1738316162773\" duration=\"726000\" />\n      <workItem from=\"1738326887364\" duration=\"4500000\" />\n      <workItem from=\"1738586797583\" duration=\"600000\" />\n      <workItem from=\"1738663690532\" duration=\"4505000\" />\n      <workItem from=\"1738668267214\" duration=\"5368000\" />\n      <workItem from=\"1738685509837\" duration=\"74000\" />\n      <workItem from=\"1738703726377\" duration=\"1677000\" />\n      <workItem from=\"1738774383038\" duration=\"2249000\" />\n      <workItem from=\"1738787637783\" duration=\"7013000\" />\n      <workItem from=\"1738962434877\" duration=\"1153000\" />\n      <workItem from=\"1738967049524\" duration=\"782000\" />\n      <workItem from=\"1739275350614\" duration=\"312000\" />\n      <workItem from=\"1739464522072\" duration=\"12498000\" />\n      <workItem from=\"1739572784568\" duration=\"1228000\" />\n      <workItem from=\"1739626528163\" duration=\"5778000\" />\n      <workItem from=\"1739689815626\" duration=\"10399000\" />\n      <workItem from=\"1739812786805\" duration=\"48519000\" />\n      <workItem from=\"1740212626723\" duration=\"1263000\" />\n      <workItem from=\"1740213932190\" duration=\"644000\" />\n      <workItem from=\"1741475492994\" duration=\"40894000\" />\n      <workItem from=\"1741690305204\" duration=\"339000\" />\n      <workItem from=\"1741705983516\" duration=\"604000\" />\n      <workItem from=\"1741713165753\" duration=\"1198000\" />\n      <workItem from=\"1741861318912\" duration=\"2286000\" />\n      <workItem from=\"1742201562752\" duration=\"618000\" />\n      <workItem from=\"1742209067924\" duration=\"383000\" />\n      <workItem from=\"1742226300133\" duration=\"2432000\" />\n      <workItem from=\"1743071528350\" duration=\"9513000\" />\n      <workItem from=\"1743490058046\" duration=\"9000\" />\n      <workItem from=\"1743587112942\" duration=\"1188000\" />\n      <workItem from=\"1748900986740\" duration=\"1771000\" />\n      <workItem from=\"1748931928220\" duration=\"446000\" />\n      <workItem from=\"1748932436127\" duration=\"20890000\" />\n      <workItem from=\"1748970706276\" duration=\"3719000\" />\n      <workItem from=\"1748988822181\" duration=\"59000\" />\n      <workItem from=\"1749200290051\" duration=\"680000\" />\n      <workItem from=\"1749203502833\" duration=\"1349000\" />\n      <workItem from=\"1749213099437\" duration=\"3082000\" />\n      <workItem from=\"1750057109660\" duration=\"10453000\" />\n      <workItem from=\"1750070416210\" duration=\"46415000\" />\n    </task>\n    <task id=\"LOCAL-00001\" summary=\"Initial Commit\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732484343908</created>\n      <option name=\"number\" value=\"00001\" />\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732484343908</updated>\n    </task>\n    <task id=\"LOCAL-00002\" summary=\"added TransformerFNO\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732497990642</created>\n      <option name=\"number\" value=\"00002\" />\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732497990642</updated>\n    </task>\n    <task id=\"LOCAL-00003\" summary=\"added the connection between time steps - the model development is finished\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732910153380</created>\n      <option name=\"number\" value=\"00003\" />\n      <option name=\"presentableId\" value=\"LOCAL-00003\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732910153380</updated>\n    </task>\n    <task id=\"LOCAL-00004\" summary=\"Finished Allen-Cahn Problem\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733176021525</created>\n      <option name=\"number\" value=\"00004\" />\n      <option name=\"presentableId\" value=\"LOCAL-00004\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733176021525</updated>\n    </task>\n    <task id=\"LOCAL-00005\" summary=\"Added Allen-Cahn 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733583274023</created>\n      <option name=\"number\" value=\"00005\" />\n      <option name=\"presentableId\" value=\"LOCAL-00005\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733583274023</updated>\n    </task>\n    <task id=\"LOCAL-00006\" summary=\"added save_vtk\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733995237535</created>\n      <option name=\"number\" value=\"00006\" />\n      <option name=\"presentableId\" value=\"LOCAL-00006\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733995237535</updated>\n    </task>\n    <task id=\"LOCAL-00007\" summary=\"added MATLAB codes for creating database\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1734788540933</created>\n      <option name=\"number\" value=\"00007\" />\n      <option name=\"presentableId\" value=\"LOCAL-00007\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1734788540933</updated>\n    </task>\n    <task id=\"LOCAL-00008\" summary=\"added CH2DNL\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735126332032</created>\n      <option name=\"number\" value=\"00008\" />\n      <option name=\"presentableId\" value=\"LOCAL-00008\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735126332032</updated>\n    </task>\n    <task id=\"LOCAL-00009\" summary=\"added SH2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735719422931</created>\n      <option name=\"number\" value=\"00009\" />\n      <option name=\"presentableId\" value=\"LOCAL-00009\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735719422931</updated>\n    </task>\n    <task id=\"LOCAL-00010\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1736237977029</created>\n      <option name=\"number\" value=\"00010\" />\n      <option name=\"presentableId\" value=\"LOCAL-00010\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1736237977029</updated>\n    </task>\n    <task id=\"LOCAL-00011\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738788849261</created>\n      <option name=\"number\" value=\"00011\" />\n      <option name=\"presentableId\" value=\"LOCAL-00011\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738788849261</updated>\n    </task>\n    <task id=\"LOCAL-00012\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738789326593</created>\n      <option name=\"number\" value=\"00012\" />\n      <option name=\"presentableId\" value=\"LOCAL-00012\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738789326593</updated>\n    </task>\n    <task id=\"LOCAL-00013\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738796104012</created>\n      <option name=\"number\" value=\"00013\" />\n      <option name=\"presentableId\" value=\"LOCAL-00013\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738796104012</updated>\n    </task>\n    <task id=\"LOCAL-00014\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962464719</created>\n      <option name=\"number\" value=\"00014\" />\n      <option name=\"presentableId\" value=\"LOCAL-00014\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962464719</updated>\n    </task>\n    <task id=\"LOCAL-00015\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962748829</created>\n      <option name=\"number\" value=\"00015\" />\n      <option name=\"presentableId\" value=\"LOCAL-00015\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962748829</updated>\n    </task>\n    <task id=\"LOCAL-00016\" summary=\"Turn Nx to 64\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738967163754</created>\n      <option name=\"number\" value=\"00016\" />\n      <option name=\"presentableId\" value=\"LOCAL-00016\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738967163754</updated>\n    </task>\n    <task id=\"LOCAL-00017\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275401458</created>\n      <option name=\"number\" value=\"00017\" />\n      <option name=\"presentableId\" value=\"LOCAL-00017\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275401458</updated>\n    </task>\n    <task id=\"LOCAL-00018\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275433418</created>\n      <option name=\"number\" value=\"00018\" />\n      <option name=\"presentableId\" value=\"LOCAL-00018\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275433418</updated>\n    </task>\n    <task id=\"LOCAL-00019\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690373369</created>\n      <option name=\"number\" value=\"00019\" />\n      <option name=\"presentableId\" value=\"LOCAL-00019\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690373369</updated>\n    </task>\n    <task id=\"LOCAL-00020\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690420059</created>\n      <option name=\"number\" value=\"00020\" />\n      <option name=\"presentableId\" value=\"LOCAL-00020\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690420059</updated>\n    </task>\n    <task id=\"LOCAL-00021\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1743587271259</created>\n      <option name=\"number\" value=\"00021\" />\n      <option name=\"presentableId\" value=\"LOCAL-00021\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1743587271259</updated>\n    </task>\n    <option name=\"localTasksCounter\" value=\"22\" />\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"Vcs.Log.Tabs.Properties\">\n    <option name=\"RECENT_FILTERS\">\n      <map>\n        <entry key=\"Branch\">\n          <value>\n            <list>\n              <RecentGroup>\n                <option name=\"FILTER_VALUES\">\n                  <option value=\"main\" />\n                </option>\n              </RecentGroup>\n            </list>\n          </value>\n        </entry>\n      </map>\n    </option>\n    <option name=\"TAB_STATES\">\n      <map>\n        <entry key=\"MAIN\">\n          <value>\n            <State>\n              <option name=\"FILTERS\">\n                <map>\n                  <entry key=\"branch\">\n                    <value>\n                      <list>\n                        <option value=\"main\" />\n                      </list>\n                    </value>\n                  </entry>\n                </map>\n              </option>\n            </State>\n          </value>\n        </entry>\n      </map>\n    </option>\n  </component>\n  <component name=\"VcsManagerConfiguration\">\n    <MESSAGE value=\"Initial Commit\" />\n    <MESSAGE value=\"added TransformerFNO\" />\n    <MESSAGE value=\"added the connection between time steps - the model development is finished\" />\n    <MESSAGE value=\"refactored\" />\n    <MESSAGE value=\"Finished Allen-Cahn Problem\" />\n    <MESSAGE value=\"Added Allen-Cahn 3D\" />\n    <MESSAGE value=\"added save_vtk\" />\n    <MESSAGE value=\"added MATLAB codes for creating database\" />\n    <MESSAGE value=\"seperated the number of layers in fourier part and convolutional part\" />\n    <MESSAGE value=\"added CH2DNL\" />\n    <MESSAGE value=\"added SH2D\" />\n    <MESSAGE value=\"added PFC2D\" />\n    <MESSAGE value=\"Turn Nx to 64\" />\n    <MESSAGE value=\"update to 3D\" />\n    <MESSAGE value=\"TNO3d vs FNO3d\" />\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"TNO3d vs FNO3d\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>142</line>\n          <option name=\"timeStamp\" value=\"17\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>163</line>\n          <option name=\"timeStamp\" value=\"18\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>134</line>\n          <option name=\"timeStamp\" value=\"19\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>327</line>\n          <option name=\"timeStamp\" value=\"20\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>243</line>\n          <option name=\"timeStamp\" value=\"21\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_2.py</url>\n          <line>333</line>\n          <option name=\"timeStamp\" value=\"27\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>\n          <line>371</line>\n          <option name=\"timeStamp\" value=\"44\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>\n          <line>338</line>\n          <option name=\"timeStamp\" value=\"54\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>53</line>\n          <option name=\"timeStamp\" value=\"128\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>30</line>\n          <option name=\"timeStamp\" value=\"129\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>25</line>\n          <option name=\"timeStamp\" value=\"133\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>18</line>\n          <option name=\"timeStamp\" value=\"135\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>\n          <line>44</line>\n          <option name=\"timeStamp\" value=\"138\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test2.py</url>\n          <line>16</line>\n          <option name=\"timeStamp\" value=\"144\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/utilities.py</url>\n          <line>98</line>\n          <option name=\"timeStamp\" value=\"170\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/main.py</url>\n          <line>157</line>\n          <option name=\"timeStamp\" value=\"177\" />\n        </line-breakpoint>\n      </breakpoints>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n  </component>\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test3.coverage\" NAME=\"Test3 Coverage Results\" MODIFIED=\"1739273938386\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage\" NAME=\"config_AC2D_FNO3d Coverage Results\" MODIFIED=\"1733233385695\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1743065376798\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_2.coverage\" NAME=\"AC2D_Net2D_2 Coverage Results\" MODIFIED=\"1732904114403\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$test2.coverage\" NAME=\"test2 Coverage Results\" MODIFIED=\"1742889074336\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1741561715014\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage\" NAME=\"config_SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254757455\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$backend_interagg.coverage\" NAME=\"backend_interagg Coverage Results\" MODIFIED=\"1737630366471\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript3.coverage\" NAME=\"RunScript3 Coverage Results\" MODIFIED=\"1736368081257\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_2.coverage\" NAME=\"AC2D_2 Coverage Results\" MODIFIED=\"1732483323689\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1733086051390\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main_TF.coverage\" NAME=\"main_TF Coverage Results\" MODIFIED=\"1738704014479\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1741538869064\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$THFNO.coverage\" NAME=\"THFNO Coverage Results\" MODIFIED=\"1732911474644\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/networks\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1740088478224\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$PFC3D.coverage\" NAME=\"PFC3D Coverage Results\" MODIFIED=\"1740083613128\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1741603428589\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$run_inference.coverage\" NAME=\"run_inference Coverage Results\" MODIFIED=\"1750323709039\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1738663765959\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$post_processing.coverage\" NAME=\"post_processing Coverage Results\" MODIFIED=\"1733557098801\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage\" NAME=\"config_CH2D_TNO2d Coverage Results\" MODIFIED=\"1734086207850\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1748933697533\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1750255151255\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript2.coverage\" NAME=\"RunScript2 Coverage Results\" MODIFIED=\"1736369209710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1742215946758\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_3.coverage\" NAME=\"AC2D_Net2D_3 Coverage Results\" MODIFIED=\"1732974697103\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_FNO3d.coverage\" NAME=\"AC3d_FNO3d Coverage Results\" MODIFIED=\"1749017845623\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D.coverage\" NAME=\"AC2D Coverage Results\" MODIFIED=\"1733088640665\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/Archive_Code\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D.coverage\" NAME=\"AC2D_Net2D Coverage Results\" MODIFIED=\"1732567473230\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1740054182408\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage\" NAME=\"MBE3D_TNO3d Coverage Results\" MODIFIED=\"1741562061391\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_AC3D_TNO3d.coverage\" NAME=\"config_AC3D_TNO3d Coverage Results\" MODIFIED=\"1737644605063\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D.coverage\" NAME=\"MBE3D Coverage Results\" MODIFIED=\"1739283566145\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1741605347375\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1743071672425\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1736268192289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage\" NAME=\"PFC3D_TNO3d Coverage Results\" MODIFIED=\"1741564210973\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage\" NAME=\"config_CH2DNL_TNO2d Coverage Results\" MODIFIED=\"1735052490996\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$MBE2D.coverage\" NAME=\"MBE2D Coverage Results\" MODIFIED=\"1732278526731\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1739914172084\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test_Run.coverage\" NAME=\"Test_Run Coverage Results\" MODIFIED=\"1738945320139\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1741561294310\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741861381348\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1743081225414\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage\" NAME=\"PFV3D_FNO3d Coverage Results\" MODIFIED=\"1741564487710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript1.coverage\" NAME=\"RunScript1 Coverage Results\" MODIFIED=\"1736368790622\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$SH2D.coverage\" NAME=\"SH2D Coverage Results\" MODIFIED=\"1732347080402\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$PFC2D.coverage\" NAME=\"PFC2D Coverage Results\" MODIFIED=\"1732278679485\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$CH2D.coverage\" NAME=\"CH2D Coverage Results\" MODIFIED=\"1732347055915\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_FNO3d.coverage\" NAME=\"AC3D_FNO3d Coverage Results\" MODIFIED=\"1741561435127\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D.coverage\" NAME=\"SH3D Coverage Results\" MODIFIED=\"1739044808411\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test.coverage\" NAME=\"Test Coverage Results\" MODIFIED=\"1739459206236\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741547133078\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage\" NAME=\"config_AC2D_FNO2d Coverage Results\" MODIFIED=\"1733393903488\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$AC3D.coverage\" NAME=\"AC3D Coverage Results\" MODIFIED=\"1740041515520\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_CH3D_TNO3d.coverage\" NAME=\"config_CH3D_TNO3d Coverage Results\" MODIFIED=\"1738089807566\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test2.coverage\" NAME=\"Test2 Coverage Results\" MODIFIED=\"1739283715182\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_FNO3d.coverage\" NAME=\"CH3D_FNO3d Coverage Results\" MODIFIED=\"1741628529142\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage\" NAME=\"AC3d_TNO3d_hybrid Coverage Results\" MODIFIED=\"1748989478372\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1737899062785\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D.coverage\" NAME=\"config_AC2D Coverage Results\" MODIFIED=\"1733087276180\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_1.coverage\" NAME=\"AC2D_Net2D_1 Coverage Results\" MODIFIED=\"1732535211383\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1736520700819\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$fourier_3d.coverage\" NAME=\"fourier_3d Coverage Results\" MODIFIED=\"1732221600628\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1750254767095\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage\" NAME=\"SH3D_TNO3d_Hybrid Coverage Results\" MODIFIED=\"1749216389646\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1748990262244\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$test1.coverage\" NAME=\"test1 Coverage Results\" MODIFIED=\"1733413325318\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_2.coverage\" NAME=\"CH3D_2 Coverage Results\" MODIFIED=\"1739918355289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254975290\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage\" NAME=\"config_MBE2D_TNO2d Coverage Results\" MODIFIED=\"1736261397712\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n  </component>\n</project>
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/.idea/workspace.xml b/.idea/workspace.xml
+--- a/.idea/workspace.xml	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/.idea/workspace.xml	(date 1754640545561)
+@@ -4,32 +4,7 @@
+     <option name="autoReloadType" value="SELECTIVE" />
+   </component>
+   <component name="ChangeListManager">
+-    <list default="true" id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="TNO3d vs FNO3d">
+-      <change afterPath="$PROJECT_DIR$/run_inference.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/.idea/vcs.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/main.py" beforeDir="false" afterPath="$PROJECT_DIR$/main.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/networks.py" beforeDir="false" afterPath="$PROJECT_DIR$/networks.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/post_processing.py" beforeDir="false" afterPath="$PROJECT_DIR$/post_processing.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/training.py" beforeDir="false" afterPath="$PROJECT_DIR$/training.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/utilities.py" beforeDir="false" afterPath="$PROJECT_DIR$/utilities.py" afterDir="false" />
+-    </list>
++    <list default="true" id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="update main file" />
+     <option name="SHOW_DIALOG" value="false" />
+     <option name="HIGHLIGHT_CONFLICTS" value="true" />
+     <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
+@@ -56,6 +31,7 @@
+         </map>
+       </branch-storage>
+     </excluded-from-favorite>
++    <option name="PUSH_AUTO_UPDATE" value="true" />
+     <option name="RECENT_BRANCH_BY_REPOSITORY">
+       <map>
+         <entry key="$PROJECT_DIR$" value="main" />
+@@ -688,6 +664,17 @@
+   <component name="TypeScriptGeneratedFilesManager">
+     <option name="version" value="3" />
+   </component>
++  <component name="Vcs.Log.History.Properties">
++    <option name="COLUMN_ID_ORDER">
++      <list>
++        <option value="Default.Root" />
++        <option value="Default.Author" />
++        <option value="Default.Date" />
++        <option value="Default.Subject" />
++        <option value="GitHub.CommitStatus" />
++      </list>
++    </option>
++  </component>
+   <component name="Vcs.Log.Tabs.Properties">
+     <option name="RECENT_FILTERS">
+       <map>
+@@ -742,7 +729,8 @@
+     <MESSAGE value="Turn Nx to 64" />
+     <MESSAGE value="update to 3D" />
+     <MESSAGE value="TNO3d vs FNO3d" />
+-    <option name="LAST_COMMIT_MESSAGE" value="TNO3d vs FNO3d" />
++    <MESSAGE value="update main file" />
++    <option name="LAST_COMMIT_MESSAGE" value="update main file" />
+   </component>
+   <component name="XDebuggerManager">
+     <breakpoint-manager>
Index: PFC3D/.idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PFC3D/.idea/workspace.xml b/PFC3D/.idea/workspace.xml
new file mode 100644
--- /dev/null	(date 1752127452580)
+++ b/PFC3D/.idea/workspace.xml	(date 1752127452580)
@@ -0,0 +1,77 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="ChangeListManager">
+    <list default="true" id="425971b0-b981-4d27-9b46-07a66a7c7527" name="Changes" comment="">
+      <change beforePath="$PROJECT_DIR$/../.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/../.idea/workspace.xml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/../AC3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../AC3D/plots_FNO3d/Error_subplots.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../AC3D/plots_FNO3d/Exact Solution_subplots.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../AC3D/plots_FNO3d/Predicted Solution_subplots.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../AC3D/plots_FNO3d/combined_results.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../AC3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../AC3D/plots_TNO3d/Error_subplots.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../AC3D/plots_TNO3d/Exact Solution_subplots.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../AC3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../AC3D/plots_TNO3d/combined_results.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/../configs/config_AC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/../configs/config_AC3D_FNO3d.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/../configs/config_AC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/../configs/config_AC3D_TNO3d.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/../configs/config_CH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/../configs/config_CH3D_TNO3d.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/../configs/config_SH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/../configs/config_SH3D_TNO3d.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/../main.py" beforeDir="false" afterPath="$PROJECT_DIR$/../main.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/../run_interface3.py" beforeDir="false" afterPath="$PROJECT_DIR$/../run_interface3.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/../training.py" beforeDir="false" afterPath="$PROJECT_DIR$/../training.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/../utilities.py" beforeDir="false" afterPath="$PROJECT_DIR$/../utilities.py" afterDir="false" />
+    </list>
+    <option name="SHOW_DIALOG" value="false" />
+    <option name="HIGHLIGHT_CONFLICTS" value="true" />
+    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
+    <option name="LAST_RESOLUTION" value="IGNORE" />
+  </component>
+  <component name="Git.Settings">
+    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$/.." />
+  </component>
+  <component name="ProjectColorInfo"><![CDATA[{
+  "associatedIndex": 0
+}]]></component>
+  <component name="ProjectId" id="2zfgCKW6RyD5tU2JetMLDnbUD8L" />
+  <component name="ProjectViewState">
+    <option name="hideEmptyMiddlePackages" value="true" />
+    <option name="showLibraryContents" value="true" />
+  </component>
+  <component name="PropertiesComponent"><![CDATA[{
+  "keyToString": {
+    "RunOnceActivity.ShowReadmeOnStart": "true",
+    "git-widget-placeholder": "main",
+    "last_opened_file_path": "/scratch/noqu8762/phase_field_equations_4d/PFC3D",
+    "nodejs_package_manager_path": "npm",
+    "vue.rearranger.settings.migration": "true"
+  }
+}]]></component>
+  <component name="SharedIndexes">
+    <attachedChunks>
+      <set>
+        <option value="bundled-js-predefined-1d06a55b98c1-0b3e54e931b4-JavaScript-PY-241.18034.82" />
+        <option value="bundled-python-sdk-975db3bf15a3-2767605e8bc2-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-241.18034.82" />
+      </set>
+    </attachedChunks>
+  </component>
+  <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
+  <component name="TaskManager">
+    <task active="true" id="Default" summary="Default task">
+      <changelist id="425971b0-b981-4d27-9b46-07a66a7c7527" name="Changes" comment="" />
+      <created>1752127412427</created>
+      <option name="number" value="Default" />
+      <option name="presentableId" value="Default" />
+      <updated>1752127412427</updated>
+      <workItem from="1752127413453" duration="40000" />
+    </task>
+    <servers />
+  </component>
+  <component name="TypeScriptGeneratedFilesManager">
+    <option name="version" value="3" />
+  </component>
+</project>
\ No newline at end of file
Index: .idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/shelved.patch
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/shelved.patch
new file mode 100644
--- /dev/null	(date 1754639536674)
+++ b/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/shelved.patch	(date 1754639536674)
@@ -0,0 +1,27062 @@
+Index: training.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>import torch\nimport torch.nn.functional as F\nfrom timeit import default_timer\nfrom tqdm import tqdm\n\ndef train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,\n              optimizer, scheduler, normalized, normalizer, device):\n    train_mse_log = []\n    train_l2_log = []\n    test_l2_log = []\n\n    if normalized:\n        # a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        # a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n        train_mse = 0\n        train_l2 = 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            #print(\"x shape\", x.shape)\n            out = model(x)\n            #print(f\"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}\")\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            train_mse += mse.item()\n            train_l2 += loss.item()\n\n        model.eval()\n        test_l2 = 0.0\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                #test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n\n        train_mse /= len(train_loader)\n        train_l2 /= (batch_size * len(train_loader))\n        test_l2 /= (batch_size * len(test_loader))\n\n        train_mse_log.append(train_mse)\n        train_l2_log.append(train_l2)\n        test_l2_log.append(test_l2)\n\n        # Update the learning rate based on the test_l2 metric\n        #scheduler.step(test_l2) ##\n\n\n        t2 = default_timer()\n        #print(ep, t2 - t1, train_mse, train_l2, test_l2)\n        if ep == 0:  # Print the header row once\n            print(\"No. Epoch   Time (s)       Train MSE      Train L2       Test L2\")\n\n        print(f\"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}\")\n\n    return model, train_mse_log, train_l2_log, test_l2_log\n\ndef train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,\n                   optimizer, scheduler, normalized, normalizer, device):\n    ntrain = len(train_loader) * train_loader.batch_size\n    ntest = len(test_loader) * test_loader.batch_size\n    train_mse_log = []\n    train_l2_log = []\n    test_l2_log = []\n    step = 1\n    if normalized:\n        a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n        train_l2_step = 0\n        train_l2_full = 0\n        for xx, yy in train_loader:\n            loss = 0\n            xx = xx.to(device)\n            yy = yy.to(device)\n            T = yy.shape[-1]\n            #print(f\" T : {T}\")\n            #print(f\"target shape: {yy.shape}\")\n            #print(f\"Input shape: {xx.shape}, y (target): {yy.shape}\")\n            for t in range(0, T, step):\n                y = yy[..., t:t + step]\n                im = model(xx)\n                #print(f\"Input shape: {xx.shape}, y (target): {y.shape}, prediction (model output): {im.shape}\")\n                #print(f\"target shape 2: {yy.shape}\")\n                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n\n                if t == 0:\n                    pred = im\n                else:\n                    pred = torch.cat((pred, im), -1)\n                xx = torch.cat((xx[..., step:], im), dim=-1)\n\n            train_l2_step += loss.item()\n            l2_full = myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1))\n            train_l2_full += l2_full.item()\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n        test_l2_step = 0\n        test_l2_full = 0\n        with torch.no_grad():\n            for xx, yy in test_loader:\n                loss = 0\n                xx = xx.to(device)\n                yy = yy.to(device)\n\n                for t in range(0, T, step):\n                    y = yy[..., t:t + step]\n                    im = model(xx)\n                    loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n\n                    if t == 0:\n                        pred = im\n                    else:\n                        pred = torch.cat((pred, im), -1)\n\n                    xx = torch.cat((xx[..., step:], im), dim=-1)\n\n                test_l2_step += loss.item()\n                test_l2_full += myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1)).item()\n\n        t2 = default_timer()\n        train_mse = train_l2_step / ntrain / (T / step)\n        train_l2 = train_l2_full / ntrain\n        test_l2 = test_l2_full / ntest\n\n        # Log the loss values\n        train_l2_log.append(train_l2_step / ntrain / (T / step))\n        test_l2_log.append(test_l2_step / ntest / (T / step))\n\n        if ep == 0:  # Print the header row once\n            print(\"No. Epoch   Time (s)       Train MSE      Train L2       Test L2\")\n\n        print(f\"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}\")\n\n    return model, train_l2_log, test_l2_log\n\n\n\n########################\n########################\n\ndef calculate_pde_residual(u_phys, grid_info, epsilon, problem, device):\n    \"\"\"\n    Calculates the residual for a specified 3D PDE on PHYSICAL data.\n    u_phys shape: (batch, Nx, Ny, Nz, T_out) - Denormalized data\n    grid_info: Dictionary containing Nx, Ny, Nz, Lx, Ly, Lz, dt_model, T_out\n    pde_params: Dictionary containing PDE-specific parameters\n    problem_name: String identifier for the PDE (e.g., 'SH3D', 'AC3D', 'CH3D', 'MBE3D', 'PFC3D')\n    device: PyTorch device\n    \"\"\"\n    batch_size, Nx, Ny, Nz, T_out = u_phys.shape\n    Lx, Ly, Lz = grid_info['Lx'], grid_info['Ly'], grid_info['Lz']\n    dt_model = grid_info['dt_model']\n\n    if T_out <= 1:\n        print(f\"Warning: T_out ({T_out}) <= 1 for problem {problem}. PDE loss requires T_out > 1. Returning zero loss.\")\n        return torch.zeros(1, device=device, requires_grad=True)\n\n    # --- Calculate Time Derivative (u/t) ---\n    du_dt = torch.zeros_like(u_phys)\n    du_dt[..., 0] = (u_phys[..., 1] - u_phys[..., 0]) / dt_model\n    du_dt[..., -1] = (u_phys[..., -1] - u_phys[..., -2]) / dt_model\n    if T_out > 2:\n       du_dt[..., 1:-1] = (u_phys[..., 2:] - u_phys[..., :-2]) / (2 * dt_model)\n\n    # --- Common Spectral Derivative Setup ---\n    _kx = torch.fft.fftfreq(Nx, d=Lx/Nx) * 2 * torch.pi\n    _ky = torch.fft.fftfreq(Ny, d=Ly/Ny) * 2 * torch.pi\n    _kz = torch.fft.fftfreq(Nz, d=Lz/Nz) * 2 * torch.pi\n\n    ikx_m, iky_m, ikz_m = torch.meshgrid(1j * _kx, 1j * _ky, 1j * _kz, indexing='ij')\n    ikx_m = ikx_m.to(device)\n    iky_m = iky_m.to(device)\n    ikz_m = ikz_m.to(device)\n\n    k2x_m, k2y_m, k2z_m = torch.meshgrid(_kx**2, _ky**2, _kz**2, indexing='ij')\n    # k2_m is kx^2 + ky^2 + kz^2. In Fourier space, laplacian is -k2_m\n    k2_m = (k2x_m + k2y_m + k2z_m).to(device)\n\n    u_hat = torch.fft.fftn(u_phys, dim=[1, 2, 3])\n\n    pde_residual = None\n\n    if problem == 'SH3D':\n        epsilon_sh = epsilon # pde_params.get('epsilon_sh')\n        if epsilon_sh is None: raise ValueError(\"Parameter 'epsilon_sh' not provided for SH3D.\")\n        k4_m = k2_m**2\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n        rhs_sh3d = -(u_phys**3) - (1 - epsilon_sh) * u_phys - biharm_u - 2 * lap_u\n        pde_residual = du_dt - rhs_sh3d\n\n    elif problem == 'AC3D':\n        Cahn_ac = epsilon # pde_params.get('Cahn_ac')\n        if Cahn_ac is None: raise ValueError(\"Parameter 'Cahn_ac' not provided for AC3D.\")\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        f_prime_u = u_phys**3 - u_phys\n        rhs_ac3d = Cahn_ac * lap_u - f_prime_u\n        pde_residual = du_dt - rhs_ac3d\n\n    elif problem == 'CH3D':\n        Cahn_ch = epsilon #  pde_params.get('Cahn_ch')\n        if Cahn_ch is None: raise ValueError(\"Parameter 'Cahn_ch' not provided for CH3D.\")\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        #mu_terms = (u_phys**3 - 3 * u_phys) - Cahn_ch * lap_u\n        mu_terms = (u_phys ** 3 -  u_phys) - Cahn_ch * lap_u\n        mu_terms_hat = torch.fft.fftn(mu_terms, dim=[1, 2, 3])\n        lap_mu_terms_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * mu_terms_hat\n        lap_mu_terms = torch.fft.ifftn(lap_mu_terms_hat, dim=[1, 2, 3]).real\n        rhs_ch3d = lap_mu_terms\n        pde_residual = du_dt - rhs_ch3d\n\n    elif problem == 'MBE3D':\n        epsilon_mbe = epsilon #  pde_params.get('epsilon_mbe')\n        if epsilon_mbe is None: raise ValueError(\"Parameter 'epsilon_mbe' not provided for MBE3D.\")\n        du_dx_hat = ikx_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dy_hat = iky_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dz_hat = ikz_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dx = torch.fft.ifftn(du_dx_hat, dim=[1, 2, 3]).real\n        du_dy = torch.fft.ifftn(du_dy_hat, dim=[1, 2, 3]).real\n        du_dz = torch.fft.ifftn(du_dz_hat, dim=[1, 2, 3]).real\n        grad_u_sq = du_dx**2 + du_dy**2 + du_dz**2\n        f1 = grad_u_sq * du_dx\n        f2 = grad_u_sq * du_dy\n        f3 = grad_u_sq * du_dz\n        f1_hat = torch.fft.fftn(f1, dim=[1, 2, 3])\n        f2_hat = torch.fft.fftn(f2, dim=[1, 2, 3])\n        f3_hat = torch.fft.fftn(f3, dim=[1, 2, 3])\n        div_term_hat = (ikx_m.unsqueeze(0).unsqueeze(-1) * f1_hat +\n                        iky_m.unsqueeze(0).unsqueeze(-1) * f2_hat +\n                        ikz_m.unsqueeze(0).unsqueeze(-1) * f3_hat)\n        div_term = torch.fft.ifftn(div_term_hat, dim=[1, 2, 3]).real\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        k4_m = k2_m**2\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term\n        pde_residual = du_dt - rhs_mbe3d\n\n    elif problem == 'PFC3D':\n        epsilon_pfc = epsilon # pde_params.get('epsilon_pfc') # Parameter 'r' in PFC, often -(epsilon)\n        if epsilon_pfc is None: raise ValueError(\"Parameter 'epsilon_pfc' not provided for PFC3D.\")\n\n        # Calculate necessary derivatives\n        # -u  (term1_spatial_operator * u)\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n\n        # u   (term2_spatial_operator * u)\n        k4_m = k2_m**2\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n\n        # -u  (term3_spatial_operator * u)\n        k6_m = k2_m**3 # Be careful with sign if k2_m is just kx^2+ky^2+kz^2\n                      # Since k^6 in Fourier space corresponds to (-^2)^3 = -^6 if direct multiplication\n                      # Or (i k)^6 = -k^6.\n                      # The MATLAB denominator (1/dt + (1-eps)k^2 + k^6) implies the k^6 term is positive.\n                      # So in real space, this corresponds to -u (because -(-)^3 u = u is not what we want)\n                      # A positive k^6 in Fourier space means we multiply by k^6, which is (-(laplacian_operator))^3,\n                      # this will become -laplacian_operator^3 which is -.\n                      # The MATLAB form `(pp2+qq2+rr2).^3` is `(k^2)^3 = k^6`.\n                      # So this term becomes `k^6 * u_hat` -> `u` (with a negative sign from implicit to explicit)\n        # Or, if (pp2+qq2+rr2) is k^2, then (pp2+qq2+rr2)^3 is k^6.\n        # The term in the denominator is `+ k^6`, so when moved to RHS it's `-k^6 u_hat`.\n        # `-k^6 u_hat` corresponds to `u` in real space.\n        triharm_u_hat = -k6_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        triharm_u = torch.fft.ifftn(triharm_u_hat, dim=[1, 2, 3]).real\n\n\n        # (u)\n        u_cubed = u_phys**3\n        u_cubed_hat = torch.fft.fftn(u_cubed, dim=[1, 2, 3])\n        lap_u_cubed_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_cubed_hat\n        lap_u_cubed = torch.fft.ifftn(lap_u_cubed_hat, dim=[1, 2, 3]).real\n\n        # PDE: u/t + (1-)u + 2u + u + (u) = 0\n        # RHS = - ( (1-_pfc)u + 2u + u + (u) )\n        # Let's use the parameter `epsilon` from PFC MATLAB as `r` (undercooling param)\n        # A common PFC form is du/dt = nabla^2 * ( (r)u + u^3 - (1+nabla^2)^2 u )\n        # du/dt = nabla^2 * ( ru + u^3 - (1 + 2 nabla^2 + nabla^4)u )\n        # du/dt = r nabla^2 u + nabla^2(u^3) - nabla^2 u - 2 nabla^4 u - nabla^6 u\n        # du/dt = (r-1) nabla^2 u - 2 nabla^4 u - nabla^6 u + nabla^2(u^3)\n        # Here 'r' from literature is often called 'epsilon' in PFC code.\n        # Let's match the form derived from MATLAB:\n        # u/t = -(1-)u - 2u - u - (u)\n        # Residual: du_dt - [-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed]\n\n        term1_spatial = (1 - epsilon_pfc) * lap_u # (1-eps)(-nabla^2 u) -> (eps-1)nabla^2 u\n        term2_spatial = 2 * biharm_u             # 2 nabla^4 u\n        term3_spatial = triharm_u                # nabla^6 u\n        term4_nonlinear = lap_u_cubed            # nabla^2 (u^3)\n\n        # According to the derived form: u/t = -(1-)u - 2u - u - (u)\n        # residual = du_dt - (-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed)\n        rhs_pfc3d = -(1 - epsilon_pfc) * lap_u - 2 * biharm_u - triharm_u - lap_u_cubed\n        pde_residual = du_dt - rhs_pfc3d\n\n    else:\n        raise ValueError(f\"Unknown problem_name: {problem}. PDE residual not defined.\")\n\n    if pde_residual is not None:\n        loss_pde = F.mse_loss(pde_residual, torch.zeros_like(pde_residual))\n    else:\n        loss_pde = torch.zeros(1, device=device, requires_grad=True)\n\n    return loss_pde\n\n\ndef train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,\n                    optimizer, scheduler, normalized, normalizer, device, pde_weight, grid_info, epsilon, problem, pde_loss_scaler=1.0, can_compute_pde = True):\n    train_mse_hybrid_log = []\n    train_l2_hybrid_log = []\n\n    test_mse_hybrid_log = []\n    test_loss_hybrid_log = []\n\n\n    train_data_log = []\n    test_data_log = []\n\n    train_pde_scaled_log = []\n    train_pde_raw_log = []\n\n    test_pde_loss_scaled_log = []\n    test_pde_loss_raw_log = []\n\n\n    if normalized:\n        # a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        # a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n\n        train_mse_hybrid = 0\n        train_l2_hybrid = 0\n\n        train_data = 0.0\n        train_pde_scaled = 0.0\n        train_pde_raw = 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            # print(\"x shape\", x.shape)\n            out = model(x)\n            # print(f\"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}\")\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n\n            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n            loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n            # --- PDE Loss Calculation (on physical scale) ---\n            if can_compute_pde:\n                # loss_pde_raw = calculate_pde_residual_sh3d(pred_phys, grid_info, epsilon, device)\n                #loss_pde_raw = calculate_pde_residual_sh3d(out, grid_info, epsilon, device)\n                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                loss_pde_scaled = loss_pde_raw * pde_loss_scaler  # Apply scaling\n\n            loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled\n            mse_hybrid = (1.0 - pde_weight) * mse_data + pde_weight * loss_pde_scaled\n\n\n            loss_hybrid.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # Hybrid\n            train_mse_hybrid += mse_hybrid.item()\n            train_l2_hybrid += loss_hybrid.item()\n            ##\n            train_data += loss_data.item()\n            train_pde_scaled += loss_pde_scaled.item()\n            train_pde_raw += loss_pde_raw.item()\n\n\n        model.eval()\n        test_data= 0.0 # data\n        test_mse_data = 0.0\n        test_pde_loss_scaled = 0.0\n        test_pde_loss_raw = 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                # test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n                test_mse_data += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n                test_data += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n\n                # PDE Loss\n                if can_compute_pde:\n                    #loss_pde_test_raw = calculate_pde_residual_sh3d(out, grid_info, epsilon, device)\n                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n\n                test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()\n                test_pde_loss_raw += loss_pde_test_raw.item()\n\n            test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled\n            test_mse_hybrid = (1.0 - pde_weight) * test_mse_data + pde_weight * test_pde_loss_scaled\n\n        # Train Hybrid\n        train_mse_hybrid /= len(train_loader)\n        train_l2_hybrid /= (batch_size * len(train_loader))\n\n        # Test Hybrid\n        test_mse_hybrid /= len(test_loader)\n        test_loss_hybrid /= (batch_size * len(test_loader))\n\n        # train data\n        train_data /= (batch_size * len(train_loader))\n        # test data\n        test_data /= (batch_size * len(test_loader))\n        # train pde\n        train_pde_scaled /= (batch_size * len(train_loader))\n        train_pde_raw /= (batch_size * len(train_loader))\n        # test pde\n        test_pde_loss_scaled /= (batch_size * len(test_loader))\n        test_pde_loss_raw /= (batch_size * len(test_loader))\n\n\n\n\n        # train Hybrid\n        train_mse_hybrid_log.append(train_mse_hybrid)\n        train_l2_hybrid_log.append(train_l2_hybrid)\n\n        # Test Hybrid\n        test_mse_hybrid_log.append(test_mse_hybrid)\n        test_loss_hybrid_log.append(test_loss_hybrid)\n\n        # train data\n        train_data_log.append(train_data)\n        # test data\n        test_data_log.append(test_data)\n        # train pde\n        train_pde_scaled_log.append(train_pde_scaled)\n        train_pde_raw_log.append(train_pde_raw)\n        # test pde\n        test_pde_loss_scaled_log.append(test_pde_loss_scaled)\n        test_pde_loss_raw_log.append(test_pde_loss_raw)\n\n        # Update the learning rate based on the test_l2 metric\n        # scheduler.step(test_l2) ##\n\n        t2 = default_timer()\n\n        if ep == 0:\n            # Update header to reflect spectral raw PDE loss\n            print(\"No. Epoch | Time (s)   | Train MSE Hyb  | Train L2 Hyb  | test L2 Hyb | Test L2 data        | test_pde scl.   | test_pde_raw \")\n            print(\"---------------------------------------------------------------------------------------------\")\n        # Update print statement\n        print(f\"{ep:<9}  {t2 - t1:<10.4f}   {train_mse_hybrid:<10.6e}     {train_l2_hybrid:<10.6e} {test_loss_hybrid:<10.6e}  {test_data:<24.6e} {test_pde_loss_scaled:<24.6e} {test_pde_loss_raw:<24.6e} \")\n\n    return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log\n\n\ndef compute_initial_loss_scaler(model, loader, myloss, normalized, normalizer, device, grid_info, epsilon, problem):\n    \"\"\"\n    Computes the scaling factor to balance data and PDE losses.\n    \"\"\"\n    model.eval()\n\n    # Get one batch from the loader\n    x, y = next(iter(loader))\n    x, y = x.to(device), y.to(device)\n\n    with torch.no_grad():\n        out = model(x)\n        if normalized:\n            y_normalizer = normalizer[1].to(device)\n            out = y_normalizer.decode(out)\n            y = y_normalizer.decode(y)\n\n        # Calculate initial data loss\n        initial_loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n        # Calculate initial raw PDE loss\n        initial_loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n\n        # Handle case where PDE loss is zero to avoid division by zero\n        if initial_loss_pde_raw.item() < 1e-12:\n            scaler = 1.0\n            print(\"Warning: Initial PDE loss is near zero. Setting scaler to 1.0.\")\n        else:\n            # The scaler is the ratio of the two losses\n            scaler = initial_loss_data.item() / initial_loss_pde_raw.item()\n            print(f\"Computed initial loss scaler: {scaler:.4f}\")\n            print(f\"  - Initial Data Loss: {initial_loss_data.item():.6f}\")\n            print(f\"  - Initial PDE Loss (raw): {initial_loss_pde_raw.item():.6f}\")\n\n    model.train()  # Set model back to training mode\n    return scaler\n\n\n''''\ndef train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,\n                 optimizer, scheduler, normalized, normalizer, device, pde_weight,\n                 grid_info, epsilon, problem, pde_loss_scaler='auto', can_compute_pde=True):\n    # --- Logging Lists ---\n    train_mse_hybrid_log, train_l2_hybrid_log = [], []\n    test_mse_hybrid_log, test_loss_hybrid_log = [], []\n    train_data_log, test_data_log = [], []\n    train_pde_scaled_log, train_pde_raw_log = [], []\n    test_pde_loss_scaled_log, test_pde_loss_raw_log = [], []\n\n    if normalized:\n        y_normalizer = normalizer[1].to(device)\n    else:\n        y_normalizer = None\n\n    # ====================================================================================\n    # Automatic PDE Loss Scaler Calculation\n    # ====================================================================================\n    if pde_loss_scaler == 'auto' and can_compute_pde and pde_weight > 0:\n        print(\"--- Calibrating PDE loss scaler automatically ---\")\n        model.eval()\n        total_data_loss_for_scaling = 0.0\n        total_pde_loss_for_scaling = 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n                out = model(x)\n\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                # Calculate data loss for this batch\n                data_loss_batch = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n                total_data_loss_for_scaling += data_loss_batch.item()\n\n                # Calculate raw PDE loss for this batch\n                pde_loss_batch_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                total_pde_loss_for_scaling += pde_loss_batch_raw.item()\n\n        # Calculate the average losses\n        avg_data_loss = total_data_loss_for_scaling / len(test_loader)\n        avg_pde_loss = total_pde_loss_for_scaling / len(test_loader)\n\n        # Compute the scaler\n        if avg_pde_loss > 1e-8:  # Avoid division by zero\n            pde_loss_scaler = avg_data_loss / avg_pde_loss\n        else:\n            pde_loss_scaler = 1.0  # Default to 1 if PDE loss is negligible\n\n        print(f\"Initial Avg Data Loss: {avg_data_loss:.6e}\")\n        print(f\"Initial Avg Raw PDE Loss: {avg_pde_loss:.6e}\")\n        print(f\"Calculated pde_loss_scaler: {pde_loss_scaler:.6f}\")\n        print(\"---------------------------------------------\")\n\n    elif not can_compute_pde or pde_weight == 0:\n        pde_loss_scaler = 0.0  # No scaling needed if PDE is not used\n    elif isinstance(pde_loss_scaler, str):  # Handle cases like 'auto' when PDE is off\n        pde_loss_scaler = 1.0\n\n    # --- Main Training Loop ---\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n\n        # Initialize epoch-level accumulators\n        train_mse_hybrid, train_l2_hybrid = 0.0, 0.0\n        train_data, train_pde_scaled, train_pde_raw = 0.0, 0.0, 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            optimizer.zero_grad()\n\n            out = model(x)\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n\n            # --- Loss Calculation ---\n            loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n\n            loss_pde_scaled = torch.tensor(0.0, device=device)\n            loss_pde_raw = torch.tensor(0.0, device=device)\n\n            if can_compute_pde and pde_weight > 0:\n                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                loss_pde_scaled = loss_pde_raw * pde_loss_scaler\n\n            # Combine losses\n            loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled\n            mse_hybrid = (1.0 - pde_weight) * mse_data + pde_weight * loss_pde_scaled\n\n            loss_hybrid.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # --- Accumulate Metrics ---\n            train_mse_hybrid += mse_hybrid.item()\n            train_l2_hybrid += loss_hybrid.item()\n            train_data += loss_data.item()\n            train_pde_scaled += loss_pde_scaled.item()\n            train_pde_raw += loss_pde_raw.item()\n\n        # --- Evaluation ---\n        model.eval()\n        test_data, test_mse_data = 0.0, 0.0\n        test_pde_loss_scaled, test_pde_loss_raw = 0.0, 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                test_data += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n                test_mse_data += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean').item()\n\n                if can_compute_pde and pde_weight > 0:\n                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                    test_pde_loss_raw += loss_pde_test_raw.item()\n                    test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()\n\n        # --- Normalize and Log Metrics ---\n        # Note: We divide by len(loader) because item() gives the mean loss for the batch.\n        # This computes the average of the batch means.\n\n        # Averages for training set\n        train_mse_hybrid /= len(train_loader)\n        train_l2_hybrid /= len(train_loader)\n        train_data /= len(train_loader)\n        train_pde_scaled /= len(train_loader)\n        train_pde_raw /= len(train_loader)\n\n        # Averages for test set\n        test_mse_data /= len(test_loader)\n        test_data /= len(test_loader)\n        test_pde_loss_scaled /= len(test_loader)\n        test_pde_loss_raw /= len(test_loader)\n\n        # Calculate final hybrid test losses from averages\n        test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled\n        test_mse_hybrid = (1.0 - pde_weight) * test_mse_data + pde_weight * test_pde_loss_scaled\n\n        # Append to logs\n        train_mse_hybrid_log.append(train_mse_hybrid)\n        train_l2_hybrid_log.append(train_l2_hybrid)\n        test_mse_hybrid_log.append(test_mse_hybrid)\n        test_loss_hybrid_log.append(test_loss_hybrid)\n        train_data_log.append(train_data)\n        test_data_log.append(test_data)\n        train_pde_scaled_log.append(train_pde_scaled)\n        train_pde_raw_log.append(train_pde_raw)\n        test_pde_loss_scaled_log.append(test_pde_loss_scaled)\n        test_pde_loss_raw_log.append(test_pde_loss_raw)\n\n        t2 = default_timer()\n\n        if ep == 0:\n            print(\"--- Starting Training ---\")\n            print(f\"PDE Loss Scaler is set to: {pde_loss_scaler:.6f}\")\n            print(\n                \"No. Epoch | Time (s)   | Train MSE Hyb  | Train L2 Hyb   | Test L2 Hyb    | Test L2 data   | Test PDE Scl.  | Test PDE Raw\")\n            print(\n                \"-------------------------------------------------------------------------------------------------------------------------\")\n\n        # CORRECTED PRINT STATEMENT:\n        print(\n            f\"{ep:<9} | {t2 - t1:<10.4f} | {train_mse_hybrid:<14.6e} | {train_l2_hybrid:<14.6e} | {test_loss_hybrid:<14.6e} | {test_data:<14.6e} | {test_pde_loss_scaled:<14.6e} | {test_pde_loss_raw:<14.6e}\")\n\n    return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log\n'''
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/training.py b/training.py
+--- a/training.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/training.py	(date 1754547783919)
+@@ -1,8 +1,10 @@
+ import torch
+ import torch.nn.functional as F
+ from timeit import default_timer
++import numpy as np
+ from tqdm import tqdm
+ 
++'''
+ def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
+               optimizer, scheduler, normalized, normalizer, device):
+     train_mse_log = []
+@@ -65,7 +67,6 @@
+         # Update the learning rate based on the test_l2 metric
+         #scheduler.step(test_l2) ##
+ 
+-
+         t2 = default_timer()
+         #print(ep, t2 - t1, train_mse, train_l2, test_l2)
+         if ep == 0:  # Print the header row once
+@@ -75,6 +76,347 @@
+ 
+     return model, train_mse_log, train_l2_log, test_l2_log
+ 
++'''
++
++
++# Make sure SobolevLoss is imported or defined before this function is called
++# so that isinstance() can work correctly.
++# from your_utilities import SobolevLoss
++
++def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
++              optimizer, scheduler, normalized, normalizer, device):
++    # This is a placeholder for the real import.
++    # In your actual code, you must import SobolevLoss from utilities.py
++    from utilities import SobolevLoss
++
++    train_mse_log = []
++    train_l2_log = []
++    test_l2_log = []
++
++    if normalized:
++        y_normalizer = normalizer[1].to(device)
++    else:
++        y_normalizer = None
++
++    for ep in range(epochs):
++        model.train()
++        t1 = default_timer()
++        train_mse = 0
++        train_l2 = 0
++        for x, y in train_loader:
++            x, y = x.to(device), y.to(device)
++
++            optimizer.zero_grad()
++            out = model(x)
++
++            if normalized:
++                out = y_normalizer.decode(out)
++                y = y_normalizer.decode(y)
++
++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
++
++            # --- THIS IS THE FIX ---
++            # If the loss is SobolevLoss, pass the original multi-dimensional tensors.
++            # Otherwise, for losses like LpLoss, pass the flattened tensors.
++            if isinstance(myloss, SobolevLoss):
++                loss = myloss(out, y)  # Pass the un-flattened tensor
++            else:
++                loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))  # The original behavior
++            # --- END OF FIX ---
++
++            loss.backward()
++            optimizer.step()
++            scheduler.step()
++            train_mse += mse.item()
++            train_l2 += loss.item()
++
++        model.eval()
++        test_l2 = 0.0
++        with torch.no_grad():
++            for x, y in test_loader:
++                x, y = x.to(device), y.to(device)
++
++                out = model(x)
++                if normalized:
++                    out = y_normalizer.decode(out)
++                    y = y_normalizer.decode(y)
++
++                # --- APPLY THE SAME FIX HERE ---
++                if isinstance(myloss, SobolevLoss):
++                    test_l2 += myloss(out, y).item()
++                else:
++                    test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()
++                # --- END OF FIX ---
++
++        train_mse /= len(train_loader)
++        train_l2 /= (batch_size * len(train_loader))
++        test_l2 /= (batch_size * len(test_loader))
++
++        train_mse_log.append(train_mse)
++        train_l2_log.append(train_l2)
++        test_l2_log.append(test_l2)
++
++        t2 = default_timer()
++        if ep == 0:
++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
++
++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
++
++    return model, train_mse_log, train_l2_log, test_l2_log
++''''
++def train_fno4d(model, myloss, epochs, batch_size, train_loader, test_loader,
++              optimizer, scheduler, normalized, normalizer, device):
++    train_mse_log = []
++    train_l2_log = []
++    #val_mse_log = []  # New
++    #val_l2_log = []  # New
++    test_l2_log = []
++    test_mse_log = []
++
++    # --- Early Stopping Parameters (Optional) ---
++    #best_val_loss = float('inf')
++    #patience_counter = 0
++    #patience_epochs = 5 # 10  # Example: stop if no improvement for 10 epochs
++    #best_model_state = None
++    # ---
++
++    if normalized:
++        # a_normalizer = normalizer[0].to(device)
++        y_normalizer = normalizer[1].to(device)
++    else:
++        # a_normalizer = None
++        y_normalizer = None
++
++    for ep in range(epochs):
++        model.train()
++        t1 = default_timer()
++        train_mse = 0
++        train_l2 = 0
++        for x, y in train_loader:
++            x, y = x.to(device), y.to(device)
++
++            optimizer.zero_grad()
++            #print("x shape", x.shape)
++            out = model(x)
++            print(f"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}")
++            if normalized:
++                out = y_normalizer.decode(out)
++                #print("out shape1:", out.shape)
++                y = y_normalizer.decode(y)
++            print("out shape2 :", out.shape)
++            print("y shape:", y.shape)
++
++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
++            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
++
++            loss.backward()
++            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Adjust max_norm if needed
++            optimizer.step()
++            scheduler.step()
++            train_mse += mse.item()
++            train_l2 += loss.item()
++
++        # Test
++
++        model.eval()
++        test_l2 = 0.0
++        test_mse = 0.0
++        with torch.no_grad():
++            for x, y in test_loader:
++                x, y = x.to(device), y.to(device)
++
++                out = model(x)
++                if normalized:
++                    out = y_normalizer.decode(out)
++                    y = y_normalizer.decode(y)
++
++                #test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()
++                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()
++                test_mse += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
++
++
++        test_l2 /= (batch_size * len(test_loader))
++        test_mse /= (batch_size * len(test_loader))
++
++        test_l2_log.append(test_l2)
++        test_mse_log.append(test_mse)
++        # Update the learning rate based on the test_l2 metric
++        #scheduler.step(test_l2) ##
++
++
++        t2 = default_timer()
++        #print(ep, t2 - t1, train_mse, train_l2, test_l2)
++
++
++        if ep == 0:
++            # Update header to reflect spectral raw PDE loss
++            print("No. Epoch | Time (s)   | Train MSE     | Test mse     | Train L2      |  Test L2 ")
++            print("---------------------------------------------------------------------------------------")
++        # Update print statement
++        print(f"{ep:<9} | {t2 - t1:<10.4f} | {train_mse:<10.6e} | {test_mse:<10.6e} | {train_l2:<10.6e} | {test_l2:<24.6e} ")
++
++
++    return model, train_mse_log, train_l2_log, test_l2_log, test_mse_log
++'''
++
++
++def train_fno4d(model, myloss, epochs, batch_size, train_loader, test_loader,
++                optimizer, scheduler, normalized, normalizer, device):
++    """Training function for FNO4d model."""
++    ntrain = len(train_loader) * train_loader.batch_size
++    ntest = len(test_loader) * test_loader.batch_size
++
++    train_mse_log = []
++    train_l2_log = []
++    test_l2_log = []
++    test_mse_log = []
++
++    if normalized:
++        y_normalizer = normalizer[1].to(device)
++    else:
++        y_normalizer = None
++
++    for ep in range(epochs):
++        model.train()
++        t1 = default_timer()
++        train_mse = 0
++        train_l2 = 0
++
++        for x, y in train_loader:
++            x, y = x.to(device), y.to(device)
++
++            optimizer.zero_grad()
++            out = model(x)
++
++            if normalized:
++                out = y_normalizer.decode(out)
++                y = y_normalizer.decode(y)
++
++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
++            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
++
++            loss.backward()
++            optimizer.step()
++            scheduler.step()
++
++            train_mse += mse.item()
++            train_l2 += loss.item() / batch_size  # Normalize by batch size
++
++        model.eval()
++        test_l2 = 0
++        test_mse = 0
++        with torch.no_grad():
++            for x, y in test_loader:
++                x, y = x.to(device), y.to(device)
++
++                out = model(x)
++                if normalized:
++                    out = y_normalizer.decode(out)
++                    y = y_normalizer.decode(y)
++
++                test_mse += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean').item()
++                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item() / batch_size  # Normalize here too
++
++        # Average over number of batches
++        train_mse /= len(train_loader)
++        train_l2 /= len(train_loader)
++        test_mse /= len(test_loader)
++        test_l2 /= len(test_loader)
++
++        train_mse_log.append(train_mse)
++        train_l2_log.append(train_l2)
++        test_l2_log.append(test_l2)
++        test_mse_log.append(test_mse)
++
++        t2 = default_timer()
++
++        if ep == 0:
++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test MSE       Test L2")
++
++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_mse:<13.10f} {test_l2:<13.10f}")
++
++    return model, train_mse_log, train_l2_log, test_l2_log
++
++
++
++import torch
++import torch.nn.functional as F
++from timeit import default_timer
++
++'''
++def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
++              optimizer, scheduler, normalized, normalizer, device):
++    train_mse_log = []
++    train_l2_log = []
++    test_l2_log = []
++
++    if normalized:
++        y_normalizer = normalizer[1].to(device)
++    else:
++        y_normalizer = None
++
++    for ep in range(epochs):
++        model.train()
++        t1 = default_timer()
++        train_mse = 0
++        train_l2 = 0
++        for x, y in train_loader:
++            x, y = x.to(device), y.to(device)
++
++            optimizer.zero_grad()
++            out = model(x)
++
++            if normalized:
++                out = y_normalizer.decode(out)
++                y = y_normalizer.decode(y)
++
++            # This MSE is kept for logging the data-only error
++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
++
++            # --- MINIMAL CHANGE HERE ---
++            # The loss function now receives the UN-FLATTENED tensors
++            # so it can compute spatial gradients for the Sobolev loss.
++            loss = myloss(out, y)
++
++            loss.backward()
++            optimizer.step()
++            scheduler.step()
++            train_mse += mse.item()
++            train_l2 += loss.item()
++
++        model.eval()
++        test_l2 = 0.0
++        with torch.no_grad():
++            for x, y in test_loader:
++                x, y = x.to(device), y.to(device)
++
++                out = model(x)
++                if normalized:
++                    out = y_normalizer.decode(out)
++                    y = y_normalizer.decode(y)
++
++                # --- MINIMAL CHANGE HERE ---
++                # Also pass the un-flattened tensors during evaluation.
++                test_l2 += myloss(out, y).item()
++
++        train_mse /= len(train_loader)
++        train_l2 /= (batch_size * len(train_loader))  # Kept original scaling
++        test_l2 /= (batch_size * len(test_loader))  # Kept original scaling
++
++        train_mse_log.append(train_mse)
++        train_l2_log.append(train_l2)
++        test_l2_log.append(test_l2)
++
++        t2 = default_timer()
++        if ep == 0:  # Print the header row once
++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
++
++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
++
++    return model, train_mse_log, train_l2_log, test_l2_log
++'''
++
++
+ def train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,
+                    optimizer, scheduler, normalized, normalizer, device):
+     ntrain = len(train_loader) * train_loader.batch_size
+@@ -164,7 +506,110 @@
+ 
+     return model, train_l2_log, test_l2_log
+ 
++'''
++def train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,
++                   optimizer, scheduler, normalized, normalizer, device):
++    ntrain = len(train_loader) * train_loader.batch_size
++    ntest = len(test_loader) * test_loader.batch_size
++    train_l2_log = []
++    test_l2_log = []
++    step = 1
++
++    # Normalizer setup is unchanged
++    if normalized:
++        y_normalizer = normalizer[1].to(device)
++    else:
++        y_normalizer = None
++
++    for ep in range(epochs):
++        model.train()
++        t1 = default_timer()
++        train_l2_step = 0
++        train_l2_full = 0
++        for xx, yy in train_loader:
++            loss = 0
++            xx = xx.to(device)
++            yy = yy.to(device)
++            T = yy.shape[-1]
++
++            # The auto-regressive loop for one-step-ahead prediction
++            for t in range(0, T, step):
++                y = yy[..., t:t + step]
++                im = model(xx)
++
++                # --- MINIMAL CHANGE #1 ---
++                # Pass the un-flattened tensors (im, y) to myloss.
++                # Both have shape (batch, s, s, s, 1) here.
++                loss += myloss(im, y)
++
++                if t == 0:
++                    pred = im
++                else:
++                    pred = torch.cat((pred, im), -1)
++
++                # Update input for next time step
++                xx = torch.cat((xx[..., step:], im), dim=-1)
++
++            train_l2_step += loss.item()
++
++            # --- MINIMAL CHANGE #2 ---
++            # Also pass the un-flattened full tensors (pred, yy) to myloss.
++            # Both have shape (batch, s, s, s, T_out) here.
++            l2_full = myloss(pred, yy)
++            train_l2_full += l2_full.item()
++
++            optimizer.zero_grad()
++            loss.backward()
++            optimizer.step()
++            scheduler.step()
++
++        # Evaluation loop
++        test_l2_step = 0
++        test_l2_full = 0
++        with torch.no_grad():
++            for xx, yy in test_loader:
++                loss = 0
++                xx = xx.to(device)
++                yy = yy.to(device)
++                T = yy.shape[-1]  # T is defined inside the loop for safety
++
++                for t in range(0, T, step):
++                    y = yy[..., t:t + step]
++                    im = model(xx)
++
++                    # --- MINIMAL CHANGE #3 ---
++                    loss += myloss(im, y)
++
++                    if t == 0:
++                        pred = im
++                    else:
++                        pred = torch.cat((pred, im), -1)
++
++                    xx = torch.cat((xx[..., step:], im), dim=-1)
++
++                test_l2_step += loss.item()
++
++                # --- MINIMAL CHANGE #4 ---
++                test_l2_full += myloss(pred, yy).item()
+ 
++        t2 = default_timer()
++        # The meaning of these metrics is slightly different now, but the calculation is kept
++        train_mse = train_l2_step / ntrain / (T / step)
++        train_l2 = train_l2_full / ntrain
++        test_l2 = test_l2_full / ntest
++
++        # Log the loss values
++        train_l2_log.append(train_l2_step / ntrain / (T / step))
++        test_l2_log.append(test_l2_step / ntest / (T / step))
++
++        if ep == 0:  # Print the header row once
++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
++
++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
++
++    # Returning the logs for the one-step-ahead loss
++    return model, train_l2_log, test_l2_log
++'''
+ 
+ ########################
+ ########################
+@@ -227,12 +672,15 @@
+         if Cahn_ac is None: raise ValueError("Parameter 'Cahn_ac' not provided for AC3D.")
+         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
+         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
+-        f_prime_u = u_phys**3 - u_phys
+-        rhs_ac3d = Cahn_ac * lap_u - f_prime_u
++        #f_prime_u = u_phys**3 - u_phys
++        #rhs_ac3d = Cahn_ac * lap_u - f_prime_u ##
++        f_prime_u = (1/Cahn_ac) * (u_phys ** 3 - u_phys)
++        rhs_ac3d = lap_u - f_prime_u  ##
++
+         pde_residual = du_dt - rhs_ac3d
+ 
+     elif problem == 'CH3D':
+-        Cahn_ch = epsilon #  pde_params.get('Cahn_ch')
++        Cahn_ch = epsilon**2 #  pde_params.get('Cahn_ch')
+         if Cahn_ch is None: raise ValueError("Parameter 'Cahn_ch' not provided for CH3D.")
+         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
+         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
+@@ -269,66 +717,39 @@
+         k4_m = k2_m**2
+         biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat
+         biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real
+-        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term
++        #rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term
++        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u + div_term
+         pde_residual = du_dt - rhs_mbe3d
+ 
+     elif problem == 'PFC3D':
+-        epsilon_pfc = epsilon # pde_params.get('epsilon_pfc') # Parameter 'r' in PFC, often -(epsilon)
++        epsilon_pfc = epsilon
+         if epsilon_pfc is None: raise ValueError("Parameter 'epsilon_pfc' not provided for PFC3D.")
+-
+-        # Calculate necessary derivatives
+-        # -u  (term1_spatial_operator * u)
++        # Calculate necessary spatial derivatives using Fourier transforms
++        # u (Laplacian)
+         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
+         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
+ 
+-        # u   (term2_spatial_operator * u)
+-        k4_m = k2_m**2
++        # u (Biharmonic)
++        k4_m = k2_m ** 2
+         biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat
+         biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real
+ 
+-        # -u  (term3_spatial_operator * u)
+-        k6_m = k2_m**3 # Be careful with sign if k2_m is just kx^2+ky^2+kz^2
+-                      # Since k^6 in Fourier space corresponds to (-^2)^3 = -^6 if direct multiplication
+-                      # Or (i k)^6 = -k^6.
+-                      # The MATLAB denominator (1/dt + (1-eps)k^2 + k^6) implies the k^6 term is positive.
+-                      # So in real space, this corresponds to -u (because -(-)^3 u = u is not what we want)
+-                      # A positive k^6 in Fourier space means we multiply by k^6, which is (-(laplacian_operator))^3,
+-                      # this will become -laplacian_operator^3 which is -.
+-                      # The MATLAB form `(pp2+qq2+rr2).^3` is `(k^2)^3 = k^6`.
+-                      # So this term becomes `k^6 * u_hat` -> `u` (with a negative sign from implicit to explicit)
+-        # Or, if (pp2+qq2+rr2) is k^2, then (pp2+qq2+rr2)^3 is k^6.
+-        # The term in the denominator is `+ k^6`, so when moved to RHS it's `-k^6 u_hat`.
+-        # `-k^6 u_hat` corresponds to `u` in real space.
++        # u (Triharmonic)
++        k6_m = k2_m ** 3
++        # In Fourier space, multiplying by -k^6 corresponds to the  operator
+         triharm_u_hat = -k6_m.unsqueeze(0).unsqueeze(-1) * u_hat
+         triharm_u = torch.fft.ifftn(triharm_u_hat, dim=[1, 2, 3]).real
+ 
+-
+         # (u)
+-        u_cubed = u_phys**3
++        u_cubed = u_phys ** 3
+         u_cubed_hat = torch.fft.fftn(u_cubed, dim=[1, 2, 3])
+         lap_u_cubed_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_cubed_hat
+         lap_u_cubed = torch.fft.ifftn(lap_u_cubed_hat, dim=[1, 2, 3]).real
+ 
+-        # PDE: u/t + (1-)u + 2u + u + (u) = 0
+-        # RHS = - ( (1-_pfc)u + 2u + u + (u) )
+-        # Let's use the parameter `epsilon` from PFC MATLAB as `r` (undercooling param)
+-        # A common PFC form is du/dt = nabla^2 * ( (r)u + u^3 - (1+nabla^2)^2 u )
+-        # du/dt = nabla^2 * ( ru + u^3 - (1 + 2 nabla^2 + nabla^4)u )
+-        # du/dt = r nabla^2 u + nabla^2(u^3) - nabla^2 u - 2 nabla^4 u - nabla^6 u
+-        # du/dt = (r-1) nabla^2 u - 2 nabla^4 u - nabla^6 u + nabla^2(u^3)
+-        # Here 'r' from literature is often called 'epsilon' in PFC code.
+-        # Let's match the form derived from MATLAB:
+-        # u/t = -(1-)u - 2u - u - (u)
+-        # Residual: du_dt - [-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed]
+-
+-        term1_spatial = (1 - epsilon_pfc) * lap_u # (1-eps)(-nabla^2 u) -> (eps-1)nabla^2 u
+-        term2_spatial = 2 * biharm_u             # 2 nabla^4 u
+-        term3_spatial = triharm_u                # nabla^6 u
+-        term4_nonlinear = lap_u_cubed            # nabla^2 (u^3)
+-
+-        # According to the derived form: u/t = -(1-)u - 2u - u - (u)
+-        # residual = du_dt - (-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed)
+-        rhs_pfc3d = -(1 - epsilon_pfc) * lap_u - 2 * biharm_u - triharm_u - lap_u_cubed
++        # Construct the Right-Hand Side (RHS) of the PDE to match the MATLAB code
++        # PDE: u/t = (1-)u + 2u + u + (u)
++        rhs_pfc3d = (1 - epsilon_pfc) * lap_u + 2 * biharm_u + triharm_u + lap_u_cubed
++        # The residual is the difference between the time derivative and the RHS
+         pde_residual = du_dt - rhs_pfc3d
+ 
+     else:
+@@ -503,42 +924,117 @@
+     return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log
+ 
+ 
+-def compute_initial_loss_scaler(model, loader, myloss, normalized, normalizer, device, grid_info, epsilon, problem):
+-    """
+-    Computes the scaling factor to balance data and PDE losses.
+-    """
+-    model.eval()
++'''
++
++def train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,
++                 optimizer, scheduler, normalized, normalizer, device, pde_weight, grid_info, epsilon, problem,
++                 pde_loss_scaler=1.0, can_compute_pde=True):
++    train_mse_hybrid_log = []
++    train_l2_hybrid_log = []
++    test_loss_hybrid_log = []
++    train_data_log = []
++    test_data_log = []
++    train_pde_scaled_log = []
++    test_pde_loss_scaled_log = []
++
++    if normalized:
++        y_normalizer = normalizer[1].to(device)
++    else:
++        y_normalizer = None
++
++    for ep in range(epochs):
++        model.train()
++        t1 = default_timer()
++
++        train_mse_hybrid = 0
++        train_l2_hybrid = 0
++        train_data = 0.0
++        train_pde_scaled = 0.0
++
++        for x, y in train_loader:
++            x, y = x.to(device), y.to(device)
++
++            optimizer.zero_grad()
++            out = model(x)
++            if normalized:
++                out = y_normalizer.decode(out)
++                y = y_normalizer.decode(y)
++
++            # --- MINIMAL CHANGE #1 ---
++            # Pass the UN-FLATTENED tensors to myloss.
++            loss_data = myloss(out, y)
++
++            # Kept for logging purposes
++            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
++
++            if can_compute_pde and pde_weight > 0:
++                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
++                loss_pde_scaled = loss_pde_raw * pde_loss_scaler
++                loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled
++            else:
++                loss_pde_scaled = torch.tensor(0.0)  # For logging
++                loss_hybrid = loss_data
++
++            loss_hybrid.backward()
++            optimizer.step()
++            scheduler.step()
++
++            train_l2_hybrid += loss_hybrid.item()
++            train_data += loss_data.item()
++            train_pde_scaled += loss_pde_scaled.item()
++
++        model.eval()
++        test_data = 0.0
++        test_pde_loss_scaled = 0.0
+ 
+-    # Get one batch from the loader
+-    x, y = next(iter(loader))
+-    x, y = x.to(device), y.to(device)
++        with torch.no_grad():
++            for x, y in test_loader:
++                x, y = x.to(device), y.to(device)
+ 
+-    with torch.no_grad():
+-        out = model(x)
+-        if normalized:
+-            y_normalizer = normalizer[1].to(device)
+-            out = y_normalizer.decode(out)
+-            y = y_normalizer.decode(y)
++                out = model(x)
++                if normalized:
++                    out = y_normalizer.decode(out)
++                    y = y_normalizer.decode(y)
+ 
+-        # Calculate initial data loss
+-        initial_loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
++                # --- MINIMAL CHANGE #2 ---
++                # Pass the UN-FLATTENED tensors here as well.
++                test_data += myloss(out, y).item()
++
++                if can_compute_pde and pde_weight > 0:
++                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
++                    test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()
++
++        # Normalize losses
++        train_l2_hybrid /= len(train_loader)
++        train_data /= len(train_loader)
++        train_pde_scaled /= len(train_loader)
++
++        test_data /= len(test_loader)
++        test_pde_loss_scaled /= len(test_loader)
+ 
+-        # Calculate initial raw PDE loss
+-        initial_loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
++        test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled
+ 
+-        # Handle case where PDE loss is zero to avoid division by zero
+-        if initial_loss_pde_raw.item() < 1e-12:
+-            scaler = 1.0
+-            print("Warning: Initial PDE loss is near zero. Setting scaler to 1.0.")
+-        else:
+-            # The scaler is the ratio of the two losses
+-            scaler = initial_loss_data.item() / initial_loss_pde_raw.item()
+-            print(f"Computed initial loss scaler: {scaler:.4f}")
+-            print(f"  - Initial Data Loss: {initial_loss_data.item():.6f}")
+-            print(f"  - Initial PDE Loss (raw): {initial_loss_pde_raw.item():.6f}")
++        # Append logs
++        train_l2_hybrid_log.append(train_l2_hybrid)
++        test_loss_hybrid_log.append(test_loss_hybrid)
++        train_data_log.append(train_data)
++        test_data_log.append(test_data)
++        train_pde_scaled_log.append(train_pde_scaled)
++        test_pde_loss_scaled_log.append(test_pde_loss_scaled)
+ 
+-    model.train()  # Set model back to training mode
+-    return scaler
++        t2 = default_timer()
++
++        if ep == 0:
++            print("No. Epoch | Time (s)   | Train L2 Hyb  | Test L2 Hyb   | Test L2 data  | Test PDE Scaled")
++            print("---------------------------------------------------------------------------------------")
++
++        print(
++            f"{ep:<9} | {t2 - t1:<10.4f} | {train_l2_hybrid:<13.6e} | {test_loss_hybrid:<13.6e} | {test_data:<13.6e} | {test_pde_loss_scaled:<13.6e}")
++
++    # Simplified return statement
++    return model, train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log
++'''''
++
+ 
+ 
+ ''''
+Index: main1.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>import os\nimport importlib\nimport torch\nimport inspect\nimport numpy as np\nimport matplotlib\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom training import train_fno, train_fno_time, train_hybrid\nfrom torch.utils.data import DataLoader, random_split\nfrom utilities import ImportDataset, count_params, LpLoss, ModelEvaluator\nfrom post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, make_video, save_vtk, plot_xy_plane_subplots\nimport time  # Import the time module at the beginning of the script\nfrom torch_optimizer import Lamb\nimport scipy.io\n\n################################################################\n# Problem Definition\n################################################################\n# problem = 'AC2D'\n#problem = 'AC3D'\n# problem = 'CH2DNL'\n# problem = 'SH2D'\nproblem = 'SH3D'\n# problem = 'PFC2D'\n#problem = 'PFC3D'\n#problem = 'MBE2D'\n#problem = 'MBE3D'\n# problem = 'CH2D'\n#problem = 'CH3D'\n\n#network_name = 'TNO2d'\n# network_name = 'FNO2d'\n#network_name = 'FNO3d'\nnetwork_name = 'TNO3d'\n\nPINN_MODE = False # True # False #\n\nprint(f\"problem = {problem}\")\nprint(f\"network = {network_name}\")\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\") # configuration file\n# above line means: import configs.config_PFC3D_TNO3d as cf\nnetwork = getattr(importlib.import_module('networks'), network_name) # from networks import TNO3d\ntorch.manual_seed(cf.torch_seed)\nnp.random.seed(cf.numpy_seed)\n#device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')\ndevice = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)\n# --- Define Output Directory ---\n\n\nPDE_WEIGHT = cf.pde_weight\nPDE_LOSS_SCALER = cf.pde_loss_scaler\n\nif PINN_MODE:\n    run_descriptor = f\"PINN_w{int(PDE_WEIGHT * 100)}\"\n    output_subdir = f\"plots_Data_Physics_{network_name}\"  # Specific PINN output\nelse:\n    run_descriptor = \"DataDriven\"\n    output_subdir = f\"plots_{network_name}\"  # Original data-driven output\n\n#model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'\nmodel_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}.pt'\nmodel_dir = os.path.join(problem, 'models') # models_smpooth\nmodel_name = f'{model_run_name}'\nmodel_path = os.path.join(model_dir, model_name)\n\nplot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir\nos.makedirs(model_dir, exist_ok=True)\nos.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists\n\nprint(f\"Model Run Name: {model_run_name}\")\nprint(f\"Model Path: {model_path}\")\nprint(f\"Plot Directory: {plot_dir}\")\n\n# width_q = 32\nstart_time = time.time()\n\n################################################################\n# load data and data normalization\n################################################################\n#model_dir = problem + '/models'\n\nprint(f\"model = {model_name}\")\nprint(f\"number of epoch = {cf.epochs}\")\nprint(f\"batch size = {cf.batch_size}\")\nprint(f\"nTrain = {cf.nTrain}\")\nprint(f\"nTest = {cf.nTest}\")\nprint(f\"learning_rate = {cf.learning_rate}\")\nprint(f\"n_layers = {cf.n_layers}\")\nprint(f\"width_q = {cf.width_q}\")\nprint(f\"width_h = {cf.width_h}\")\n\nmodel_path = os.path.join(model_dir, model_name)\nos.makedirs(model_dir, exist_ok=True)\n# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\ntrain_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])\n# to see train_dataset values: print(\"train_dataset subset:\", [train_dataset[i] for i in range(len(train_dataset))])\nnormalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)\n\n################################################################\n# training and evaluation\n################################################################\nsig = inspect.signature(network.__init__)\nrequired_args = [param.name for param in sig.parameters.values()\n                 if param.default == inspect.Parameter.empty and param.name != \"self\"]\nif network_name == 'FNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'FNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelse:\n    raise Exception(\"network_name is not correct\")\n\nprint(count_params(model))      # Print model parameters\ntrain_mse_log, train_l2_log, test_l2_log = [], [], []       # Initialize logs\n\n# Load the entire model and logs\nif os.path.exists(model_path) and cf.load_model:\n    print(f\"Loading pre-trained model from {model_path}\")\n    checkpoint = torch.load(model_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict']) # Use this line if you only save state_dict\n    #model = checkpoint['model'] # Use this line if you save the entire model object\n    train_mse_log = checkpoint.get('train_mse_log', [])\n    train_l2_log = checkpoint.get('train_l2_log', [])\n    test_l2_log = checkpoint.get('test_l2_log', [])\nelse:\n    print(\"No pre-trained model loaded. Initializing a new model.\")\n\n# Define optimizer, scheduler, and loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)\nmyloss = LpLoss(size_average=False)\n\n###\n\n# Train the model\nif cf.training:\n    print(\"\\n--- Starting Training ---\")\n    if PINN_MODE:\n        grid_info = {\n            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,\n            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,\n            'dt_model': cf.dt_model,\n            'T_out': cf.T_out\n        }\n\n        if PDE_WEIGHT == 0.0:\n            print(\"Running PINN training loop with pde_weight=0 (Data-Driven only loss).\")\n        else:\n            print(\n                f\"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {PDE_LOSS_SCALER:.2e}\")\n\n        model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (\n            train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                         optimizer, scheduler, cf.normalized, normalizers, device,\n                         PDE_WEIGHT, grid_info, cf.epsilon, problem,\n                         pde_loss_scaler=PDE_LOSS_SCALER)\n        )\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'train_mse_log': train_mse_hybrid_log,\n            'train_l2_log': train_l2_hybrid_log,\n            'test_l2_log': test_data_log,\n            'test_pde_scaled_log': test_pde_loss_scaled_log,\n            'train_data_log': train_data_log,\n            'train_pde_scaled_log': train_pde_scaled_log,\n            'test_loss_hybrid_log': test_loss_hybrid_log\n        }, model_path)\n\n    else:\n        if network_name in ['FNO2d', 'FNO3d']:\n            model, train_l2_log, test_l2_log = (\n                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                               optimizer, scheduler, cf.normalized, normalizers, device))\n            train_mse_log = []\n        else:\n            model, train_mse_log, train_l2_log, test_l2_log = (\n               train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                           optimizer, scheduler, cf.normalized, normalizers, device))\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'train_mse_log': train_mse_log,\n            'train_l2_log': train_l2_log,\n            'test_l2_log': test_l2_log\n        }, model_path)\n\n\nend_time = time.time()\nFinal_time = round(end_time - start_time, 2)\nprint(f\"Total Execution Time: {Final_time} seconds\")\n\nevaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,\n                           time_history=(network_name in ['FNO2d', 'FNO3d']))\n\nresults = evaluator.evaluate(loss_fn=myloss)\ninp = results['input']\npred = results['prediction']\nexact = results['exact']\ntest_l2_avg = results[\"average\"]\n\nif PINN_MODE:\n    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log]\n    labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\nelse:\n    losses = [train_l2_log, test_l2_log]\n    labels = ['Train L2', 'Test L2']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\n\n\n################################################################\n# post-processing\n################################################################\na_ind = inp[cf.index]\nu_pred = pred[cf.index]\nu_exact = exact[cf.index]\nerror = u_pred - u_exact\n\nplot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]\nprint(f\"Field shape: {u_exact.shape}\")\n\nselected_time_steps = [0, 2, 4, 6, 8, 9]\n\n# Plot exact solution\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=u_exact,\n                      field_name='Exact Solution',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[0],\n                      problem=problem,\n                      network_name=network_name)\n\n# Plot predicted solution\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=u_pred,\n                      field_name='Predicted Solution',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[1],\n                      problem=problem,\n                      network_name=network_name)\n\n# Plot error\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=error,\n                      field_name='Error',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[2],\n                      problem=problem,\n                      network_name=network_name)\n\n\n# ==============================================================================\n# NEW SECTION: PREDICT AND VISUALIZE A SINGLE TRAJECTORY EVOLUTION\n# ==============================================================================\nprint(\"\\n--- Generating Visualization for a Single Predicted Trajectory ---\")\n\n# Ensure dt_simulation is defined in the config file.\nif not hasattr(cf, 'dt_simulation'):\n    raise AttributeError(\"Configuration file is missing 'dt_simulation'. Please add it (e.g., dt_simulation = 0.00002).\")\n\npredicted_trajectory = u_pred # Shape: (s, s, s, T_out)\n\n# 1. Choose 4 suitable time frames for visualization from the predicted steps.\nnum_time_frames_to_plot = 4\ntotal_predicted_steps = predicted_trajectory.shape[-1]  # This is T_out\n\nif total_predicted_steps < 1:\n    print(\"No time steps to plot in the predicted trajectory.\")\nelse:\n    # Select 4 evenly spaced indices from the available time steps.\n    time_indices_to_plot = np.linspace(0, total_predicted_steps - 1, num_time_frames_to_plot, dtype=int).tolist()\n\n    print(f\"Selected time indices for plotting: {time_indices_to_plot}\")\n\n    # 2. Create the subplot (1 row, 4 columns) and save it.\n    fig, axes = plt.subplots(1, num_time_frames_to_plot, figsize=(5 * num_time_frames_to_plot, 5), squeeze=False)\n    axes = axes.flatten()\n\n    vmin = predicted_trajectory.cpu().numpy().min()\n    vmax = predicted_trajectory.cpu().numpy().max()\n    s = cf.s\n    slice_index = s // 2  # Middle slice in the Z-direction\n\n    for i, t_idx in enumerate(time_indices_to_plot):\n        # 3. Calculate the correct physical time for the label.\n        # The prediction starts after T_in steps.\n        physical_time = (cf.T_in + t_idx) * cf.dt_simulation\n\n        slice_2d = predicted_trajectory[:, :, slice_index, t_idx].cpu().numpy()\n\n        ax = axes[i]\n        im = ax.imshow(slice_2d, cmap='viridis', vmin=vmin, vmax=vmax,\n                       extent=[0, cf.Lx, 0, cf.Ly], origin='lower', interpolation='bicubic')\n        ax.set_title(f'Predicted t={physical_time:.2e}') # Use scientific notation for time\n        ax.set_xlabel('x')\n        if i == 0:\n            ax.set_ylabel('y')\n\n    fig.colorbar(im, ax=axes.tolist(), orientation='vertical', pad=0.02)\n    z_coord = cf.Lx / s * (slice_index - s / 2)\n    fig.suptitle(f'Predicted Evolution (Z-slice at z={z_coord:.2f})', fontsize=16)\n    fig.tight_layout(rect=[0, 0, 1, 0.95])\n\n    subplot_filename = os.path.join(plot_dir, f'{model_run_name}_single_trajectory_subplot.png')\n    plt.savefig(subplot_filename, dpi=300, bbox_inches='tight')\n    print(f\"Trajectory subplot saved to {subplot_filename}\")\n    plt.close(fig)\n\n# END OF NEW SECTION\n# ==============================================================================\n\n# The p=2 explicitly specifies the L2 norm.\nl2_norm_error = torch.norm(u_pred - u_exact, p=2)\n\n# Calculate the L2 norm of the exact solution\nl2_norm_exact = torch.norm(u_exact, p=2)\n\n# Calculate the relative L2 norm error\nepsilon = 1e-8\nif l2_norm_exact.item() > epsilon:\n    relative_l2_error = l2_norm_error / l2_norm_exact\nelse:\n    if l2_norm_error.item() < epsilon:\n        relative_l2_error = torch.tensor(0.0, device=u_pred.device, dtype=u_pred.dtype)\n    else:\n        print(f\"Warning: L2 norm of exact solution is {l2_norm_exact.item()}, which is close to zero. L2 norm of error is {l2_norm_error.item()}.\")\n        relative_l2_error = torch.tensor(float('inf'), device=u_pred.device, dtype=u_pred.dtype)\n\nprint(f\"L2 norm of error: {l2_norm_error.item()}\")\nprint(f\"L2 norm of exact solution: {l2_norm_exact.item()}\")\nprint(f\"Relative L2 norm error: {relative_l2_error.item()}\")\nrelative_l2_error_percentage = (relative_l2_error * 100)\nprint(f\"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%\")\n\n###\nplot_combined_results(\n    domain=cf.domain,\n    u_exact=u_exact,\n    u_pred=u_pred,\n    error=error,\n    plot_ranges=[\n        [-1.2, 1.2],\n        [-1.2, 1.2],\n        [-1.2, 1.2]\n    ],\n    problem=problem,\n    network_name=network_name,\n    plot_dir = plot_dir,\n    pde_weight = PDE_WEIGHT\n)\n\nplot_combined_results_3d(\n    domain=cf.domain,\n    u_exact=u_exact,\n    u_pred=u_pred,\n    error=error,\n    plot_ranges=[\n        [-1.2, 1.2],\n        [-1.2, 1.2],\n        [-1.2, 1.2]\n    ],\n    problem=problem,\n    network_name=network_name,\n    plot_dir = plot_dir,\n    pde_weight = PDE_WEIGHT\n)\n\n################################################################\n# Save Results to MATLAB .mat file\n################################################################\nprint(\"\\n--- Saving Results to .mat File ---\")\n\nmat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')\n\nif PINN_MODE:\n    try:\n        results_dict = {\n            'train_mse_log': train_mse_hybrid_log,\n            'train_hybrid_loss': np.array(train_l2_hybrid_log),\n            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),\n            'train_data_log': np.array(train_data_log),\n            'test_data_log': np.array(test_data_log),\n            'train_pde_scaled_log': np.array(train_pde_scaled_log),\n            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,\n            'config_pde_loss_scaler': PDE_LOSS_SCALER if PINN_MODE else 0.0,\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\nelse:\n    try:\n        results_dict = {\n            'train_mse_log': np.array(train_mse_log),\n            'train_l2_log': np.array(train_l2_log),\n            'test_l2_log': np.array(test_l2_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\n\nprint(\"\\n--- Script Finished ---\")
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/main1.py b/main1.py
+--- a/main1.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/main1.py	(date 1754547783948)
+@@ -1,111 +1,128 @@
++
+ import os
+ import importlib
+ import torch
+ import inspect
+ import numpy as np
+ import matplotlib
++import h5py  # MODIFIED: Added h5py import
++import scipy.io
++
+ matplotlib.use('TkAgg')
+ import matplotlib.pyplot as plt
+ import torch.nn.functional as F
+-from training import train_fno, train_fno_time, train_hybrid
++from training import train_fno, train_fno_time, train_hybrid, train_fno4d
+ from torch.utils.data import DataLoader, random_split
+-from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator
+-from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, make_video, save_vtk, plot_xy_plane_subplots
+-import time  # Import the time module at the beginning of the script
++from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator, SobolevLoss
++from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \
++    make_video, save_vtk, plot_xy_plane_subplots
++import time
+ from torch_optimizer import Lamb
+-import scipy.io
++
++################################################################
++# Problem Definition
++################################################################
+ 
+ ################################################################
+ # Problem Definition
+ ################################################################
+ # problem = 'AC2D'
+-#problem = 'AC3D'
++problem = 'AC3D'
+ # problem = 'CH2DNL'
+ # problem = 'SH2D'
+-problem = 'SH3D'
++#problem = 'SH3D'
+ # problem = 'PFC2D'
+ #problem = 'PFC3D'
+-#problem = 'MBE2D'
++# problem = 'MBE2D'
+ #problem = 'MBE3D'
+ # problem = 'CH2D'
+ #problem = 'CH3D'
+ 
+-#network_name = 'TNO2d'
++# network_name = 'TNO2d'
+ # network_name = 'FNO2d'
+ #network_name = 'FNO3d'
++#network_name = 'FNO4d'
+ network_name = 'TNO3d'
+ 
+-PINN_MODE = False # True # False #
++PINN_MODE =  False # True #  True #  False #  True #   True #    True #
++#  False #    True # False #  False  # False #
+ 
+ print(f"problem = {problem}")
+ print(f"network = {network_name}")
+ os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
+-cf = importlib.import_module(f"configs.config_{problem}_{network_name}") # configuration file
+-# above line means: import configs.config_PFC3D_TNO3d as cf
+-network = getattr(importlib.import_module('networks'), network_name) # from networks import TNO3d
++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
++network = getattr(importlib.import_module('networks'), network_name)
+ torch.manual_seed(cf.torch_seed)
+ np.random.seed(cf.numpy_seed)
+-#device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')
+-device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")
++device = torch.device("cuda:2" if torch.cuda.is_available() else "cpu")
+ print("Device: ", device)
+-# --- Define Output Directory ---
+-
+ 
+ PDE_WEIGHT = cf.pde_weight
+-PDE_LOSS_SCALER = cf.pde_loss_scaler
++pde_loss_scaler = cf.pde_loss_scaler
+ 
+ if PINN_MODE:
+     run_descriptor = f"PINN_w{int(PDE_WEIGHT * 100)}"
+-    output_subdir = f"plots_Data_Physics_{network_name}"  # Specific PINN output
++    output_subdir = f"plots_Data_Physics_{network_name}"
++    model_run_name = f'{network_name}_{problem}_Hybrid_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
+ else:
+     run_descriptor = "DataDriven"
+-    output_subdir = f"plots_{network_name}"  # Original data-driven output
++    output_subdir = f"plots_{network_name}"
++    model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
+ 
+-#model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'
+-model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}.pt'
+-model_dir = os.path.join(problem, 'models') # models_smpooth
++model_dir = os.path.join(problem, 'models')
+ model_name = f'{model_run_name}'
+ model_path = os.path.join(model_dir, model_name)
+-
+-plot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir
++plot_dir = os.path.join(problem, output_subdir)
+ os.makedirs(model_dir, exist_ok=True)
+-os.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists
++os.makedirs(plot_dir, exist_ok=True)
+ 
+ print(f"Model Run Name: {model_run_name}")
+ print(f"Model Path: {model_path}")
+ print(f"Plot Directory: {plot_dir}")
+ 
+-# width_q = 32
+ start_time = time.time()
+ 
+ ################################################################
+ # load data and data normalization
+ ################################################################
+-#model_dir = problem + '/models'
+-
+-print(f"model = {model_name}")
+-print(f"number of epoch = {cf.epochs}")
+-print(f"batch size = {cf.batch_size}")
+-print(f"nTrain = {cf.nTrain}")
+-print(f"nTest = {cf.nTest}")
+-print(f"learning_rate = {cf.learning_rate}")
+-print(f"n_layers = {cf.n_layers}")
+-print(f"width_q = {cf.width_q}")
+-print(f"width_h = {cf.width_h}")
+-
+-model_path = os.path.join(model_dir, model_name)
+-os.makedirs(model_dir, exist_ok=True)
+-# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf
+-dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
++# MODIFIED: Added special handling for SH3D dataset loading
++try:
++    dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
++    if problem == 'SH3D':
++        print("SH3D dataset detected - applying special handling")
++        # Verify dataset sizes
++        sample = dataset[0][0]  # Get first sample
++        print(f"SH3D sample shape: {sample.shape}, dtype: {sample.dtype}")
++        print(f"SH3D stats - mean: {sample.mean():.4f}, std: {sample.std():.4f}")
++except Exception as e:
++    print(f"Error loading dataset: {e}")
++    raise
+ 
+ train_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])
+-# to see train_dataset values: print("train_dataset subset:", [train_dataset[i] for i in range(len(train_dataset))])
+ normalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None
+ 
+-train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
+-test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
++train_loader = DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
++test_loader = DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
++
+ 
+-################################################################
++# ==================== CODE TO INSPECT BATCH SHAPE ====================
++print("\n" + "="*50)
++print("Inspecting DataLoader Batch Shapes")
++print("="*50)
++# Get one batch of data from the train_loader
++try:
++    x_batch, y_batch = next(iter(train_loader))
++    # Print the shape of the batch
++    # This will be (batch_size, S, S, S, T_in) for input
++    # and (batch_size, S, S, S, T_out) for target
++    print(f"Shape of an input batch from DataLoader: {x_batch.shape}")
++    print(f"Shape of a target batch from DataLoader: {y_batch.shape}")
++except StopIteration:
++    print("Train loader is empty. Cannot retrieve a batch.")
++print("="*50 + "\n")
++# =======================================================================
++
++############AA####################################################
+ # training and evaluation
+ ################################################################
+ sig = inspect.signature(network.__init__)
+@@ -118,19 +135,32 @@
+ elif network_name == 'FNO3d':
+     model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)
+ elif network_name == 'TNO3d':
+-    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)
++    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(
++        device)
++elif network_name == 'FNO4d':
++    model = network(
++        modes1=cf.modes,
++        modes2=cf.modes,
++        modes3=cf.modes,
++        modes4_internal =1, # cf.modes_t, # MUST BE 1
++        width=cf.width,
++        width_q=cf.width_q,
++        T_in_channels=cf.T_in,
++        n_layers=cf.n_layers
++    ).to(device)
++
++
+ else:
+     raise Exception("network_name is not correct")
+ 
+-print(count_params(model))      # Print model parameters
+-train_mse_log, train_l2_log, test_l2_log = [], [], []       # Initialize logs
++print(count_params(model))  # Print model parameters
++train_mse_log, train_l2_log, test_l2_log = [], [], []  # Initialize logs
+ 
+ # Load the entire model and logs
+ if os.path.exists(model_path) and cf.load_model:
+     print(f"Loading pre-trained model from {model_path}")
+     checkpoint = torch.load(model_path, map_location=device)
+-    model.load_state_dict(checkpoint['model_state_dict']) # Use this line if you only save state_dict
+-    #model = checkpoint['model'] # Use this line if you save the entire model object
++    model = checkpoint['model']
+     train_mse_log = checkpoint.get('train_mse_log', [])
+     train_l2_log = checkpoint.get('train_l2_log', [])
+     test_l2_log = checkpoint.get('test_l2_log', [])
+@@ -140,14 +170,19 @@
+ # Define optimizer, scheduler, and loss function
+ optimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)
+ scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)
+-myloss = LpLoss(size_average=False)
++myloss = LpLoss(p=2, l1_weight=0.1, size_average=False) # size_average=True # False
++# NEW: Instantiate SobolevLoss instead of LpLoss
++# You can tune grad_weight. A good starting point is 0.1 or 1.0.
++#myloss = SobolevLoss(d=3, p=2, grad_weight=0.1)
+ 
+-###
++# COMPUTE THE DYNAMIC SCALER
++# Use the train_loader to get a representative batch
++
+ 
+ # Train the model
+ if cf.training:
+     print("\n--- Starting Training ---")
+-    if PINN_MODE:
++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
+         grid_info = {
+             'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
+             'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
+@@ -159,18 +194,18 @@
+             print("Running PINN training loop with pde_weight=0 (Data-Driven only loss).")
+         else:
+             print(
+-                f"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {PDE_LOSS_SCALER:.2e}")
++                f"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {pde_loss_scaler:.2e}")
+ 
+         model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (
+             train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+                          optimizer, scheduler, cf.normalized, normalizers, device,
+                          PDE_WEIGHT, grid_info, cf.epsilon, problem,
+-                         pde_loss_scaler=PDE_LOSS_SCALER)
++                         pde_loss_scaler=pde_loss_scaler)
+         )
+ 
+         print(f"Saving model and logs to {model_path}")
+         torch.save({
+-            'model_state_dict': model.state_dict(),
++            'model': model,
+             'train_mse_log': train_mse_hybrid_log,
+             'train_l2_log': train_l2_hybrid_log,
+             'test_l2_log': test_data_log,
+@@ -180,32 +215,134 @@
+             'test_loss_hybrid_log': test_loss_hybrid_log
+         }, model_path)
+ 
+-    else:
+-        if network_name in ['FNO2d', 'FNO3d']:
++    else:  # Original Data-Driven Mode
++        if network_name == 'FNO2d' or network_name == 'FNO3d':
++            model, train_l2_log, test_l2_log = (
++                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                               optimizer, scheduler, cf.normalized, normalizers, device))
++            train_mse_log = []
++        elif network_name == 'FNO4d':
++
++            model, train_mse_log, train_l2_log, test_l2_log = (  # Add val logs
++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                          optimizer, scheduler, cf.normalized, normalizers, device))
++
++            # train_fno4d = train_fno
++        else:
++            model, train_mse_log, train_l2_log, test_l2_log = (
++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                          optimizer, scheduler, cf.normalized, normalizers, device))
++
++    print(f"Saving model and logs to {model_path}")
++    torch.save({
++        'model': model,
++        'train_mse_log': train_mse_log,
++        'train_l2_log': train_l2_log,
++        'test_l2_log': test_l2_log
++    }, model_path)
++
++
++'''
++# Train the model
++if cf.training:
++    print("\n--- Starting Training ---")
++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
++        grid_info = {
++            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
++            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
++            'dt_model': cf.dt_model,
++            'T_out': cf.T_out
++        }
++
++        # --- NEW: Define the two stages for the training curriculum ---
++        epochs_stage1 = 10
++        scaler_stage1 = 1e-4
++
++        # Calculate remaining epochs for stage 2
++        epochs_stage2 = cf.epochs - epochs_stage1
++        scaler_stage2 = 1e-6
++
++        # --- Stage 1 Training ---
++        print("\n--- Starting Training Stage 1 ---")
++        print(f"Epochs: {epochs_stage1}, PDE Scaler: {scaler_stage1:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
++
++        # Note: The 'model' object is updated in-place by the function call
++        model, train_mse_s1, train_l2_s1, test_data_s1, test_pde_s1, train_data_s1, train_pde_scl_s1, test_loss_s1 = (
++            train_hybrid(model, myloss, epochs_stage1, cf.batch_size, train_loader, test_loader,
++                         optimizer, scheduler, cf.normalized, normalizers, device,
++                         PDE_WEIGHT, grid_info, cf.epsilon, problem,
++                         pde_loss_scaler=scaler_stage1)
++        )
++
++        # --- Stage 2 Training (if there are remaining epochs) ---
++        if epochs_stage2 > 0:
++            print("\n--- Starting Training Stage 2 ---")
++            print(f"Epochs: {epochs_stage2}, PDE Scaler: {scaler_stage2:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
++
++            model, train_mse_s2, train_l2_s2, test_data_s2, test_pde_s2, train_data_s2, train_pde_scl_s2, test_loss_s2 = (
++                train_hybrid(model, myloss, epochs_stage2, cf.batch_size, train_loader, test_loader,
++                             optimizer, scheduler, cf.normalized, normalizers, device,
++                             PDE_WEIGHT, grid_info, cf.epsilon, problem,
++                             pde_loss_scaler=scaler_stage2)
++            )
++
++            # Combine the logs from both stages for plotting and saving
++            train_mse_hybrid_log = train_mse_s1 + train_mse_s2
++            train_l2_hybrid_log = train_l2_s1 + train_l2_s2
++            test_data_log = test_data_s1 + test_data_s2
++            test_pde_loss_scaled_log = test_pde_s1 + test_pde_s2
++            train_data_log = train_data_s1 + train_data_s2
++            train_pde_scaled_log = train_pde_scl_s1 + train_pde_scl_s2
++            test_loss_hybrid_log = test_loss_s1 + test_loss_s2
++        else:
++            # If only stage 1 was run, the final logs are just the stage 1 logs
++            train_mse_hybrid_log = train_mse_s1
++            train_l2_hybrid_log = train_l2_s1
++            test_data_log = test_data_s1
++            test_pde_loss_scaled_log = test_pde_s1
++            train_data_log = train_data_s1
++            train_pde_scaled_log = train_pde_scl_s1
++            test_loss_hybrid_log = test_loss_s1
++
++        print(f"\n--- Training Finished. Saving model and logs to {model_path} ---")
++        # The torch.save call remains the same, as the log variables have been correctly prepared
++        torch.save({
++            'model': model,
++            'train_mse_log': train_mse_hybrid_log,
++            'train_l2_log': train_l2_hybrid_log,
++            'test_l2_log': test_data_log, # 'test_l2_log' is used by evaluator, it should contain data loss
++            'test_pde_scaled_log': test_pde_loss_scaled_log,
++            'train_data_log': train_data_log,
++            'train_pde_scaled_log': train_pde_scaled_log,
++            'test_loss_hybrid_log': test_loss_hybrid_log
++        }, model_path)
++
++    else:  # Original Data-Driven Mode (This part remains unchanged)
++        if network_name == 'FNO2d' or network_name == 'FNO3d':
+             model, train_l2_log, test_l2_log = (
+                 train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+                                optimizer, scheduler, cf.normalized, normalizers, device))
+             train_mse_log = []
+         else:
+             model, train_mse_log, train_l2_log, test_l2_log = (
+-               train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+-                           optimizer, scheduler, cf.normalized, normalizers, device))
++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                          optimizer, scheduler, cf.normalized, normalizers, device))
+ 
+         print(f"Saving model and logs to {model_path}")
+         torch.save({
+-            'model_state_dict': model.state_dict(),
++            'model': model,
+             'train_mse_log': train_mse_log,
+             'train_l2_log': train_l2_log,
+             'test_l2_log': test_l2_log
+         }, model_path)
+-
++'''
+ 
+ end_time = time.time()
+ Final_time = round(end_time - start_time, 2)
+ print(f"Total Execution Time: {Final_time} seconds")
+ 
+ evaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,
+-                           time_history=(network_name in ['FNO2d', 'FNO3d']))
++                           time_history=(network_name == 'FNO2d'))
+ 
+ results = evaluator.evaluate(loss_fn=myloss)
+ inp = results['input']
+@@ -214,7 +351,8 @@
+ test_l2_avg = results["average"]
+ 
+ if PINN_MODE:
+-    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log]
++    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log,
++              train_pde_scaled_log]
+     labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']
+     plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)
+ else:
+@@ -222,7 +360,6 @@
+     labels = ['Train L2', 'Test L2']
+     plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)
+ 
+-
+ ################################################################
+ # post-processing
+ ################################################################
+@@ -231,115 +368,202 @@
+ u_exact = exact[cf.index]
+ error = u_pred - u_exact
+ 
++print(f"DEBUG: Shape of u_exact passed to plotting function: {u_exact.shape}")
++print(f"DEBUG: Shape of u_pred passed to plotting function: {u_pred.shape}")
++
+ plot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]
+-print(f"Field shape: {u_exact.shape}")
++
++# =========================================================================================
++# ===                START OF MODIFIED PLOTTING PREPARATION BLOCK                      ===
++# =========================================================================================
++
++# 1. Get the initial condition (t=0) data for the chosen sample index
++a_ind = inp[cf.index]
++print(f"Shape of initial condition (t=0) data 'a_ind': {a_ind.shape}")
++
++# 2. Separate desired times into t=0 vs. future predictions
++desired_times = cf.time_steps
++future_times_to_plot = []
++has_initial_condition = (0 in desired_times)
++for t in desired_times:
++    if t > 0:
++        future_times_to_plot.append(t)
++
++# 3. Translate the FUTURE times to array indices
++indices_to_plot = []
++valid_future_times = []
++for t in future_times_to_plot:
++    if t <= cf.T_out:
++        indices_to_plot.append(t - 1)
++        valid_future_times.append(t)
++    else:
++        print(f"Warning: Time t={t} is out of valid prediction range. Skipping.")
++print(f"Plotting for future times: {valid_future_times} --> which correspond to array indices: {indices_to_plot}")
++
++# 4. MOVE ALL DATA TO THE TARGET DEVICE BEFORE OPERATIONS
++t0_data_cpu = a_ind
++u_exact_cpu = u_exact
++u_pred_cpu = u_pred
++error_cpu = error
++
++t0_data_gpu = t0_data_cpu.to(device)
++u_exact_gpu = u_exact_cpu.to(device)
++u_pred_gpu = u_pred_cpu.to(device)
++error_gpu = error_cpu.to(device)
++indices_tensor_gpu = torch.tensor(indices_to_plot, device=device)
++
++# 5. PREPARE COMBINED TENSORS FOR PLOTTING on the GPU
++if has_initial_condition:
++    # --- ### FIXED DIMENSION HANDLING ### ---
++    # `a_ind` has shape (sx, sy, sz, 1) where the last dim is a channel.
++    # `u_exact_gpu` has shape (sx, sy, sz, T) where the last dim is time.
++    # They are both 4D, so we can concatenate them directly if the last dimension is treated as the time dimension.
++    # We don't need to do any reshaping. `t0_data_gpu` is already correct.
++    t0_for_concat = t0_data_gpu
++
++    # Select the future time slices from the GPU tensors
++    u_exact_selected = u_exact_gpu.index_select(-1, indices_tensor_gpu)
++    u_pred_selected = u_pred_gpu.index_select(-1, indices_tensor_gpu)
++    error_selected = error_gpu.index_select(-1, indices_tensor_gpu)
++
++    # Combine t=0 data with the selected future steps
++    u_exact_for_plot = torch.cat((t0_for_concat, u_exact_selected), dim=-1)
++    u_pred_for_plot = torch.cat((t0_for_concat, u_pred_selected), dim=-1)
++
++    # The error for t=0 is zero by definition
++    error_t0 = torch.zeros_like(t0_for_concat)
++    error_for_plot = torch.cat((error_t0, error_selected), dim=-1)
+ 
+-selected_time_steps = [0, 2, 4, 6, 8, 9]
++    final_indices = list(range(len(desired_times)))
++    final_labels = desired_times
++else:
++    u_exact_for_plot = u_exact_gpu
++    u_pred_for_plot = u_pred_gpu
++    error_for_plot = error_gpu
++    final_indices = indices_to_plot
++    final_labels = valid_future_times
+ 
+-# Plot exact solution
++print(f"Final data prepared for plotting with shape: {u_exact_for_plot.shape}")
++print(f"Final indices for plotting: {final_indices}")
++print(f"Final labels for plotting: {final_labels}")
++
++
++# =========================================================================================
++# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===
++# =========================================================================================
++
++################################################################
++# Save Results to MATLAB .mat file
++################################################################
++print("\n--- Saving Results to .mat File ---")
++mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
++
++# MODIFIED: Enhanced saving logic with fallbacks
++def save_results(mat_filename, results_dict):
++    try:
++        # First try standard save
++        scipy.io.savemat(mat_filename, results_dict)
++        print(f"Saved with standard format to {mat_filename}")
++    except ValueError as e:
++        if "Format should be '4' or '5'" in str(e):
++            print("Large data detected, trying v7.3 format...")
++            try:
++                scipy.io.savemat(mat_filename, results_dict, format='v7.3')
++                print(f"Saved with v7.3 format to {mat_filename}")
++            except Exception as e:
++                print(f"v7.3 failed: {e}")
++                # Fallback to HDF5
++                h5_filename = mat_filename.replace('.mat', '.h5')
++                with h5py.File(h5_filename, 'w') as f:
++                    for k, v in results_dict.items():
++                        f.create_dataset(k, data=v, compression='gzip')
++                print(f"Saved as HDF5 to {h5_filename}")
++        else:
++            raise
++
++if PINN_MODE:
++    results_dict = {
++        'train_mse_log': np.array(train_mse_hybrid_log, dtype=np.float32),  # MODIFIED: Added dtype
++        'train_hybrid_loss': np.array(train_l2_hybrid_log, dtype=np.float32),
++        'test_loss_hybrid_log': np.array(test_loss_hybrid_log, dtype=np.float32),
++        'train_data_log': np.array(train_data_log, dtype=np.float32),
++        'test_data_log': np.array(test_data_log, dtype=np.float32),
++        'train_pde_scaled_log': np.array(train_pde_scaled_log, dtype=np.float32),
++        'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log, dtype=np.float32),
++        'test_input': inp.cpu().numpy().astype(np.float32),  # MODIFIED: Added astype
++        'test_prediction': pred.cpu().numpy().astype(np.float32),
++        'test_exact': exact.cpu().numpy().astype(np.float32),
++        'config_pde_weight': np.float32(PDE_WEIGHT),
++        'config_pde_loss_scaler': np.float32(pde_loss_scaler),
++        'config_epochs': np.int32(cf.epochs),
++        'config_lr': np.float32(cf.learning_rate),
++        'config_T_in': np.int32(cf.T_in),
++        'config_T_out': np.int32(cf.T_out),
++        'config_s': np.int32(cf.s),
++        'config_Lx': np.float32(cf.Lx),
++        'final_exec_time_s': np.float32(Final_time),
++    }
++else:
++    results_dict = {
++        'train_mse_log': np.array(train_mse_log, dtype=np.float32),
++        'train_l2_log': np.array(train_l2_log, dtype=np.float32),
++        'test_l2_log': np.array(test_l2_log, dtype=np.float32),
++        'test_input': inp.cpu().numpy().astype(np.float32),
++        'test_prediction': pred.cpu().numpy().astype(np.float32),
++        'test_exact': exact.cpu().numpy().astype(np.float32),
++        'config_epochs': np.int32(cf.epochs),
++        'config_lr': np.float32(cf.learning_rate),
++        'config_T_in': np.int32(cf.T_in),
++        'config_T_out': np.int32(cf.T_out),
++        'config_s': np.int32(cf.s),
++        'config_Lx': np.float32(cf.Lx),
++        'final_exec_time_s': np.float32(Final_time),
++    }
++
++# MODIFIED: Use the new save function
++save_results(mat_filename, results_dict)
++
++# Plot XY-plane for the "Exact" solution trajectory (includes t=0)
++
++'''
+ plot_xy_plane_subplots(domain=cf.domain,
+-                      field=u_exact,
+-                      field_name='Exact Solution',
+-                      time_steps=selected_time_steps,
+-                      plot_range=plot_range[0],
+-                      problem=problem,
+-                      network_name=network_name)
++                       field=u_exact_for_plot,
++                       field_name='Exact Solution',
++                       time_steps=final_indices,
++                       desired_times=final_labels,
++                       plot_range=plot_range[0],
++                       problem=problem,
++                       network_name=network_name)
+ 
+-# Plot predicted solution
++# Plot XY-plane for the "Predicted" solution trajectory (includes t=0 from input)
+ plot_xy_plane_subplots(domain=cf.domain,
+-                      field=u_pred,
+-                      field_name='Predicted Solution',
+-                      time_steps=selected_time_steps,
+-                      plot_range=plot_range[1],
+-                      problem=problem,
+-                      network_name=network_name)
++                       field=u_pred_for_plot,
++                       field_name='Predicted Solution',
++                       time_steps=final_indices,
++                       desired_times=final_labels,
++                       plot_range=plot_range[1],
++                       problem=problem,
++                       network_name=network_name)
+ 
+-# Plot error
++# Plot XY-plane for the "Error" (error is 0 at t=0)
+ plot_xy_plane_subplots(domain=cf.domain,
+-                      field=error,
+-                      field_name='Error',
+-                      time_steps=selected_time_steps,
+-                      plot_range=plot_range[2],
+-                      problem=problem,
+-                      network_name=network_name)
+-
+-
+-# ==============================================================================
+-# NEW SECTION: PREDICT AND VISUALIZE A SINGLE TRAJECTORY EVOLUTION
+-# ==============================================================================
+-print("\n--- Generating Visualization for a Single Predicted Trajectory ---")
+-
+-# Ensure dt_simulation is defined in the config file.
+-if not hasattr(cf, 'dt_simulation'):
+-    raise AttributeError("Configuration file is missing 'dt_simulation'. Please add it (e.g., dt_simulation = 0.00002).")
+-
+-predicted_trajectory = u_pred # Shape: (s, s, s, T_out)
+-
+-# 1. Choose 4 suitable time frames for visualization from the predicted steps.
+-num_time_frames_to_plot = 4
+-total_predicted_steps = predicted_trajectory.shape[-1]  # This is T_out
+-
+-if total_predicted_steps < 1:
+-    print("No time steps to plot in the predicted trajectory.")
+-else:
+-    # Select 4 evenly spaced indices from the available time steps.
+-    time_indices_to_plot = np.linspace(0, total_predicted_steps - 1, num_time_frames_to_plot, dtype=int).tolist()
+-
+-    print(f"Selected time indices for plotting: {time_indices_to_plot}")
++                       field=error_for_plot,
++                       field_name='Error',
++                       time_steps=final_indices,
++                       desired_times=final_labels,
++                       plot_range=plot_range[2],
++                       problem=problem,
++                       network_name=network_name)
++'''
+ 
+-    # 2. Create the subplot (1 row, 4 columns) and save it.
+-    fig, axes = plt.subplots(1, num_time_frames_to_plot, figsize=(5 * num_time_frames_to_plot, 5), squeeze=False)
+-    axes = axes.flatten()
+-
+-    vmin = predicted_trajectory.cpu().numpy().min()
+-    vmax = predicted_trajectory.cpu().numpy().max()
+-    s = cf.s
+-    slice_index = s // 2  # Middle slice in the Z-direction
+-
+-    for i, t_idx in enumerate(time_indices_to_plot):
+-        # 3. Calculate the correct physical time for the label.
+-        # The prediction starts after T_in steps.
+-        physical_time = (cf.T_in + t_idx) * cf.dt_simulation
+-
+-        slice_2d = predicted_trajectory[:, :, slice_index, t_idx].cpu().numpy()
+-
+-        ax = axes[i]
+-        im = ax.imshow(slice_2d, cmap='viridis', vmin=vmin, vmax=vmax,
+-                       extent=[0, cf.Lx, 0, cf.Ly], origin='lower', interpolation='bicubic')
+-        ax.set_title(f'Predicted t={physical_time:.2e}') # Use scientific notation for time
+-        ax.set_xlabel('x')
+-        if i == 0:
+-            ax.set_ylabel('y')
+-
+-    fig.colorbar(im, ax=axes.tolist(), orientation='vertical', pad=0.02)
+-    z_coord = cf.Lx / s * (slice_index - s / 2)
+-    fig.suptitle(f'Predicted Evolution (Z-slice at z={z_coord:.2f})', fontsize=16)
+-    fig.tight_layout(rect=[0, 0, 1, 0.95])
+-
+-    subplot_filename = os.path.join(plot_dir, f'{model_run_name}_single_trajectory_subplot.png')
+-    plt.savefig(subplot_filename, dpi=300, bbox_inches='tight')
+-    print(f"Trajectory subplot saved to {subplot_filename}")
+-    plt.close(fig)
+-
+-# END OF NEW SECTION
+-# ==============================================================================
+-
+-# The p=2 explicitly specifies the L2 norm.
++# Calculate L2 norm on original full prediction
+ l2_norm_error = torch.norm(u_pred - u_exact, p=2)
+-
+-# Calculate the L2 norm of the exact solution
+ l2_norm_exact = torch.norm(u_exact, p=2)
+-
+-# Calculate the relative L2 norm error
+ epsilon = 1e-8
+ if l2_norm_exact.item() > epsilon:
+     relative_l2_error = l2_norm_error / l2_norm_exact
+ else:
+-    if l2_norm_error.item() < epsilon:
+-        relative_l2_error = torch.tensor(0.0, device=u_pred.device, dtype=u_pred.dtype)
+-    else:
+-        print(f"Warning: L2 norm of exact solution is {l2_norm_exact.item()}, which is close to zero. L2 norm of error is {l2_norm_error.item()}.")
+-        relative_l2_error = torch.tensor(float('inf'), device=u_pred.device, dtype=u_pred.dtype)
++    relative_l2_error = torch.tensor(0.0) if l2_norm_error.item() < epsilon else torch.tensor(float('inf'))
+ 
+ print(f"L2 norm of error: {l2_norm_error.item()}")
+ print(f"L2 norm of exact solution: {l2_norm_exact.item()}")
+@@ -347,93 +571,33 @@
+ relative_l2_error_percentage = (relative_l2_error * 100)
+ print(f"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%")
+ 
+-###
++# Call the combined results plots with the prepared data
+ plot_combined_results(
+     domain=cf.domain,
+-    u_exact=u_exact,
+-    u_pred=u_pred,
+-    error=error,
+-    plot_ranges=[
+-        [-1.2, 1.2],
+-        [-1.2, 1.2],
+-        [-1.2, 1.2]
+-    ],
++    u_exact=u_exact_for_plot,
++    u_pred=u_pred_for_plot,
++    error=error_for_plot,
++    plot_ranges=plot_range,
+     problem=problem,
+     network_name=network_name,
+-    plot_dir = plot_dir,
+-    pde_weight = PDE_WEIGHT
++    plot_dir=plot_dir,
++    pde_weight=PDE_WEIGHT,
++    time_steps_indices=final_indices,
++    desired_times=final_labels
+ )
+ 
+ plot_combined_results_3d(
+     domain=cf.domain,
+-    u_exact=u_exact,
+-    u_pred=u_pred,
+-    error=error,
+-    plot_ranges=[
+-        [-1.2, 1.2],
+-        [-1.2, 1.2],
+-        [-1.2, 1.2]
+-    ],
++    u_exact=u_exact_for_plot,
++    u_pred=u_pred_for_plot,
++    error=error_for_plot,
++    plot_ranges=plot_range,
+     problem=problem,
+     network_name=network_name,
+-    plot_dir = plot_dir,
+-    pde_weight = PDE_WEIGHT
++    plot_dir=plot_dir,
++    pde_weight=PDE_WEIGHT,
++    time_steps_indices=final_indices,
++    desired_times=final_labels
+ )
+ 
+-################################################################
+-# Save Results to MATLAB .mat file
+-################################################################
+-print("\n--- Saving Results to .mat File ---")
+-
+-mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
+-
+-if PINN_MODE:
+-    try:
+-        results_dict = {
+-            'train_mse_log': train_mse_hybrid_log,
+-            'train_hybrid_loss': np.array(train_l2_hybrid_log),
+-            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),
+-            'train_data_log': np.array(train_data_log),
+-            'test_data_log': np.array(test_data_log),
+-            'train_pde_scaled_log': np.array(train_pde_scaled_log),
+-            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),
+-            'test_input': inp.cpu().numpy(),
+-            'test_prediction': pred.cpu().numpy(),
+-            'test_exact': exact.cpu().numpy(),
+-            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,
+-            'config_pde_loss_scaler': PDE_LOSS_SCALER if PINN_MODE else 0.0,
+-            'config_epochs': cf.epochs,
+-            'config_lr': cf.learning_rate,
+-            'config_T_in': cf.T_in,
+-            'config_T_out': cf.T_out,
+-            'config_s': cf.s,
+-            'config_Lx': cf.Lx,
+-            'final_exec_time_s': Final_time,
+-        }
+-        scipy.io.savemat(mat_filename, results_dict)
+-        print(f"Results saved successfully to: {mat_filename}")
+-    except Exception as e:
+-        print(f"Error saving results to .mat file: {e}")
+-else:
+-    try:
+-        results_dict = {
+-            'train_mse_log': np.array(train_mse_log),
+-            'train_l2_log': np.array(train_l2_log),
+-            'test_l2_log': np.array(test_l2_log),
+-            'test_input': inp.cpu().numpy(),
+-            'test_prediction': pred.cpu().numpy(),
+-            'test_exact': exact.cpu().numpy(),
+-            'config_epochs': cf.epochs,
+-            'config_lr': cf.learning_rate,
+-            'config_T_in': cf.T_in,
+-            'config_T_out': cf.T_out,
+-            'config_s': cf.s,
+-            'config_Lx': cf.Lx,
+-            'final_exec_time_s': Final_time,
+-        }
+-        scipy.io.savemat(mat_filename, results_dict)
+-        print(f"Results saved successfully to: {mat_filename}")
+-    except Exception as e:
+-        print(f"Error saving results to .mat file: {e}")
+-
+ print("\n--- Script Finished ---")
+\ No newline at end of file
+Index: networks.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef get_grid_2d(shape, device):\n    batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n    gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n    gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n    return torch.cat((gridx, gridy), dim=-1).to(device)\n\n\ndef get_grid_3d(shape, device):\n    batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n    gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n    gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n    gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n    return torch.cat((gridx, gridy, gridz), dim=-1).to(device)\n\n\n# Complex multiplication\ndef compl_mul2d(inp, weights):\n    # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n    return torch.einsum(\"bixy,ioxy->boxy\", inp, weights)\n\n\ndef compl_mul3d(inp, weights):\n    # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n    return torch.einsum(\"bixyz,ioxyz->boxyz\", inp, weights)\n\n\nclass SpectralConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, modes1, modes2):\n        super(SpectralConv2d, self).__init__()\n\n        \"\"\"\n        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n        \"\"\"\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n        self.modes2 = modes2\n\n        self.scale = (1 / (in_channels * out_channels))\n        self.weights1 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n        self.weights2 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n\n    def forward(self, x):\n        batchsize = x.shape[0]\n        # Compute Fourier coefficients --  1. Compute Fourier Transform\n        # Now, instead of working with raw pixel/grid values, we work with frequency components\\\n        # Suppose the input x has shape (batch, in_channels, H, W)\n        # x_ft has shape: batchin_channelsH(W/2+1)\n        x_ft = torch.fft.rfft2(x) # 2D Fast Fourier Transform (FFT) --> v0 = F(v0)\n\n        # Multiply relevant Fourier modes -- 2. Apply Spectral Convolution\n        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat,\n                             device=x.device)\n        # v1(k1,k2)= W(k1,k2).v0(k1,k2) --> W(k1,k2) are learnable parameters that control how much each frequency mode contributes\n        out_ft[:, :, :self.modes1, :self.modes2] = \\\n            compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n            compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n\n        # Return to physical space\n        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1))) # Apply Inverse Fourier Transform (iFFT) --> v1(x,y) = F^(-1)[v1(k1,k2)]\n        return x\n\n\nclass SpectralConv3d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n        super(SpectralConv3d, self).__init__()\n\n        \"\"\"\n        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n        \"\"\"\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n        self.modes2 = modes2\n        self.modes3 = modes3\n\n        self.scale = (1 / (in_channels * out_channels))\n        self.weights1 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights2 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights3 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights4 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n\n    def forward(self, x):\n        batchsize = x.shape[0]\n        # Compute Fourier coefficients up to factor of e^(- something constant)\n        x_ft = torch.fft.rfftn(x, dim=[-3, -2, -1])\n\n        # Multiply relevant Fourier modes\n        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1) // 2 + 1,\n                             dtype=torch.cfloat, device=x.device)\n        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n\n        # Return to physical space\n        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n        return x\n\n\nclass MLP2d(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels, T=1, num_layers=2):\n        \"\"\"\n        Initialize the MLP2d class.\n        Parameters:\n        - in_channels: Number of input channels.\n        - out_channels: Number of output channels.\n        - mid_channels: Number of intermediate channels.\n        - T: Number of blocks (default=1).\n        - num_layers: Number of layers in each block (default=2).\n        \"\"\"\n        super(MLP2d, self).__init__()\n\n        self.num_layers = num_layers\n        self.layers = nn.ModuleList()\n\n        for _ in range(T):\n            self.layers.append(nn.Conv2d(in_channels, mid_channels, 1))\n            for _ in range(self.num_layers - 2):\n                self.layers.append(nn.Conv2d(mid_channels, mid_channels, 1))\n            self.layers.append(nn.Conv2d(mid_channels, out_channels, 1))\n\n    def forward(self, x, t=0):\n        start = t * self.num_layers\n        end = start + self.num_layers\n        for i in range(start, end - 1):\n            x = F.gelu(self.layers[i](x))\n        x = self.layers[end - 1](x)\n        return x\n\n\nclass MLP3d(MLP2d):\n    def __init__(self, in_channels, out_channels, mid_channels, T=1, num_layers=2):\n        super(MLP3d, self).__init__(in_channels, out_channels, mid_channels, T, num_layers)\n\n        self.layers = nn.ModuleList()\n        for _ in range(T):\n            self.layers.append(nn.Conv3d(in_channels, mid_channels, 1))\n            # After (3x3x3 kernel)\n            #self.layers.append(nn.Conv3d(in_channels, mid_channels, 3, padding=1))  ## Changed from 1*1*1 to 3*3*3\n            for _ in range(self.num_layers - 2):\n                self.layers.append(nn.Conv3d(mid_channels, mid_channels, 1))\n                #self.layers.append(nn.Conv3d(mid_channels, mid_channels, 3, padding=1))  ## Changed from 1 to 3\n            self.layers.append(nn.Conv3d(mid_channels, out_channels, 1))\n            #self.layers.append(nn.Conv3d(mid_channels, out_channels, 3, padding=1))  ## Changed from 1 to 3\n\n\nclass FNO2d(nn.Module):\n    def __init__(self, modes1, modes2, width, width_q, T_in, T_out, n_layers):\n        super(FNO2d, self).__init__()\n\n        \"\"\"\n        The overall network. It contains 4 layers of the Fourier layer.\n        1. Lift the input to the desire channel dimension by self.fc0 .\n        2. 4 layers of the integral operators u' = (W + K)(u).\n            W defined by self.w; K defined by self.conv .\n        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n\n        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n        input shape: (batchsize, x=64, y=64, c=12)\n        output: the solution of the next timestep\n        output shape: (batchsize, x=64, y=64, c=1)\n        \"\"\"\n\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.width = width\n        self.width_q = width_q\n        self.T_in = T_in\n        self.T_out = T_out\n        self.padding = 8  # pad the domain if input is non-periodic\n        self.n_layers = n_layers\n\n        self.p = nn.Linear(T_in + 2, self.width)  # We start with an input x == u(x,y) of shape (batch,x,y,c), We lift it to a higher-dimensional space using a linear layer\n        # v0(x,y) = p(x=u)\n        self.convs = nn.ModuleList(\n            [SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(n_layers)]) # 2D Fast Fourier Transform (FFT) --> v0 = F(v0)\n        self.mlps = nn.ModuleList([MLP2d(self.width, self.width, self.width) for _ in range(n_layers)])\n        self.ws = nn.ModuleList([nn.Conv2d(self.width, self.width, 1) for _ in range(n_layers)]) # Pointwise convolution layers\n        self.norm = nn.InstanceNorm2d(self.width)\n        self.q = MLP2d(self.width, 1, self.width_q)  # output channel is 1: u(x, y)\n\n    def forward(self, x):\n        grid = get_grid_2d(x.shape, x.device)\n        x = torch.cat((x, grid), dim=-1)\n        x = self.p(x)\n        x = x.permute(0, 3, 1, 2)\n        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            '''\n            x1 = self.mlps[i](x1): Local Mixing Using MLP: Since the Fourier convolution captures global dependencies,\n             we still need local interactions --> v_i+1 = sigma(W.vi  +  b), \n             which W and b are learnable parameters, and  is the activation function.\n            '''\n            x2 = self.ws[i](x)\n            '''\n             x2 = self.ws[i](x): applies a pointwise convolution (11 convolution) to the input tensor x.\n                self.ws is a list (nn.ModuleList) of 11 convolutional layers.\n                Each self.ws[i] is a 2D convolution layer (nn.Conv2d) with a kernel size of 1x1.\n                The purpose of these layers is to perform a linear transformation of the feature maps \n                without mixing spatial locations.\n\n            '''\n            x = x1 + x2 #  Merge Global and Local Representations\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n        x = self.q(x)\n        '''\n         Output Projection back to the desired shape using another MLP\n        v_out = Q.v_final(x,y)\n        Q is a learnable projection.\n\n        '''\n        x = x.permute(0, 2, 3, 1)\n        #The final shape of x is (batch,x,y,1), which represents the predicted function value at each spatial location.\n        return x\n\n\nclass TNO2d(FNO2d):\n    def __init__(self, modes1, modes2, width, width_q, width_h, T_in, T_out, n_layers, n_layers_q=2, n_layers_h=4):\n        super(TNO2d, self).__init__(modes1, modes2, width, width_q, T_in, T_out, n_layers)\n        '''\n         TNO2d extends FNO2d. It introduces temporal modeling by adding two MLP layers:\n        self.q  projects the Fourier features to output over time.\n        self.h  handles temporal dependencies between consecutive time steps.\n        New parameters added:\n        width_h  controls temporal memory features.\n        n_layers_q  depth of self.q (output MLP).\n        n_layers_h  depth of self.h (temporal evolution MLP).\n        '''\n        self.width_h = width_h\n        #self.q = MLP2d(self.width, 1, self.width, T_out) # for AC\n        #self.q2 = MLP2d(1, 1, self.width // 4, T_out - 1)\n        #self.q = MLP2d(self.width, 1, 2 * self.width, T_out)  # for CH\n        #self.q2 = MLP2d(1, 1, self.width, T_out - 1)\n        self.q = MLP2d(self.width, 1, self.width_q, T_out, n_layers_q)  # for CHNL\n        self.h = MLP2d(1, 1, self.width_h, T_out - 1, n_layers_h)\n\n    def forward(self, x):\n        grid = get_grid_2d(x.shape, x.device)\n        x = torch.cat((x, grid), dim=-1) # a(x) or= x : Input function (e.g., initial condition for a PDE)\n        x = self.p(x) # \tLifts input to a high-dimensional space\n        x = x.permute(0, 3, 1, 2)\n        # x = F.pad(x, [0, self.padding, 0, self.padding])\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x # x=GELU(FourierConv(x)+MLP(x)+PointwiseConv(x)\n\n        # x = x[..., :-self.padding, :-self.padding]\n        '''\n         Temporal Evolution Loop\n        Initial time step prediction:\n        Uses self.q(x) to generate the first time step.\n        Stores result in X[..., 0]\n        '''\n        X = torch.zeros(*grid.shape[:-1], self.T_out, device=x.device)\n        xt = self.q(x)\n        X[..., 0] = xt.permute(0, 2, 3, 1).squeeze(-1)\n\n        for t in range(1, self.T_out):\n            x1 = self.q(x, t) # Predicts the next step using Fourier features.  # Q_n(W_L+ K_L )...P(a(x)), Projects final Fourier features to outpu\n            x2 = self.h(xt, t - 1) # Uses previous output (xt) to refine the next state. # H_nG_ (x,t_(n-1) )(a(x)), Models dependency on past states\n            xt = x1 + x2 #  Solution at time t_n : x_t = G_ (x,t_n )(a(x))\n            X[..., t] = xt.permute(0, 2, 3, 1).squeeze(-1)\n            '''\n             Uses previous output (xt) to refine the next state.\n            Combines both predictions --> x_t=MLP_q(x)+MLP_h[(x t1)]\n            Stores result in X[..., t]\n            '''\n        return X\n\n\nclass FNO3d(nn.Module):\n    def __init__(self, modes1, modes2, modes3, width, width_q, T_in, T_out, n_layers, n_layers_q=2, n_layers_h=2):\n        super(FNO3d, self).__init__()\n\n        \"\"\"\n        The FNO3d class is a deep learning model designed for solving spatiotemporal problems. \n        The overall network. It contains 4 layers of the Fourier layer.\n        1. Lift the input to the desire channel dimension by self.fc0 .\n        2. 4 layers of the integral operators u' = (W + K)(u).\n            W defined by self.w; K defined by self.conv .\n        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n\n        input: the solution of the first 10 time_steps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n        input shape: (batchsize, x=64, y=64, t=40, c=13)\n        output: the solution of the next 40 time_steps\n        output shape: (batchsize, x=64, y=64, t=40, c=1)\n        \"\"\"\n\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.modes3 = modes3\n        self.width = width\n        self.width_q = width_q\n        self.T_in = T_in\n        self.T_out = T_out\n        self.padding = 6  # pad the domain if input is non-periodic\n        self.n_layers = n_layers\n\n        self.p = nn.Linear(self.T_in + 3, self.width)  # Lifting Layer: input channel is 12: the solution of the first 10 time_steps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n\n        self.convs = nn.ModuleList(\n            [SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3) for _ in range(n_layers)])\n        self.mlps = nn.ModuleList([MLP3d(self.width, self.width, self.width) for _ in range(n_layers)])\n        self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 1) for _ in range(n_layers)])\n        #self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 3, padding=1) for _ in range(n_layers)])  ## kernel changed\n        #self.q = MLP3d(self.width, 1, self.width)  # output channel is 1: u(x, y)\n        self.q = MLP3d(self.width, 1, self.width_q)  # output channel is 1: u(x, y)\n\n    def forward(self, x):\n        #x = x.unsqueeze(3).repeat([1, 1, 1, self.T_out, 1])\n        grid = get_grid_3d(x.shape, x.device)\n        #print(' x shape:', x.shape)\n        x = torch.cat((x, grid), dim=-1)\n        #print(' x shape after cat:', x.shape)\n        x = self.p(x)\n        x = x.permute(0, 4, 1, 2, 3)\n        #x = F.pad(x, [0, self.padding])  # pad the domain if input is non-periodic\n        #print(' x shape after permute:', x.shape)\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        #x = x[..., :-self.padding]\n        x = self.q(x)\n        #x = x.permute(0, 2, 3, 4, 1)[..., 0]  # pad the domain if input is non-periodic\n        x = x.permute(0, 2, 3, 4, 1)\n        #print('FNO3d return x shape:', x.shape)\n        return x\n\n\nclass TNO3d(FNO3d):\n    def __init__(self, modes1, modes2, modes3, width, width_q, width_h, T_in, T_out, n_layers):\n        super(TNO3d, self).__init__(modes1, modes2, modes3, width, width_q, T_in, T_out, n_layers)\n        \"\"\"\n        The super() function calls the parent class (FNO3d) constructor to initialize \n        the parameters that are inherited from the parent class.\n        input: the initial condition and locations (a(x, y, z), x, y, z)\n        input shape: (batchsize, x=s, y=s, z=s, c=4)\n        output: the solution \n        output shape: (batchsize, x=s, y=s, z=s, t=T)\n        \"\"\"\n        self.width_h = width_h\n\n        #self.q = MLP3d(self.width, 1, self.width, T_out)\n        #self.q2 = MLP3d(1, 1, self.width // 4, T_out - 1)\n        self.q = MLP3d(self.width, 1, self.width_q, T_out)\n        self.h = MLP3d(1, 1, self.width_h, T_out - 1)\n\n    def forward(self, x):\n        grid = get_grid_3d(x.shape, x.device)\n        #print('x shape: ',x.shape)\n        #print('grid shape: ', grid.shape)\n        x = torch.cat((x, grid), dim=-1)\n        x = self.p(x)\n        x = x.permute(0, 4, 1, 2, 3)\n        # x = F.pad(x, [0, self.padding, 0, self.padding])\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        # x = x[..., :-self.padding, :-self.padding]\n        X = torch.zeros(*grid.shape[:-1], self.T_out, device=x.device)\n        xt = self.q(x)\n        X[..., 0] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)\n        for t in range(1, self.T_out):\n            x1 = self.q(x, t)\n            x2 = self.h(xt, t - 1)\n            xt = x1 + x2\n            X[..., t] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)\n\n        #print('shape X for model TNO: ', X.shape)\n        return X\n\n\ndef compute_spatial_derivatives(field, coordinates):\n    \"\"\"\n    Computes first and second spatial derivatives of a field with respect to coordinates\n\n    Args:\n        field: Tensor of shape [batch, x, y, z]\n        coordinates: Tensor of shape [batch, x, y, z, 3] (must require grad)\n\n    Returns:\n        laplacian: Tensor of shape [batch, x, y, z] containing \n    \"\"\"\n    # Ensure we can compute gradients\n    field = field.clone().requires_grad_(True)\n    coordinates = coordinates.clone().requires_grad_(True)\n\n    # Compute first derivatives\n    grad_outputs = torch.ones_like(field)\n    grad_x, grad_y, grad_z = torch.autograd.grad(\n        outputs=field,\n        inputs=coordinates,\n        grad_outputs=grad_outputs,\n        create_graph=True,\n        retain_graph=True,\n        allow_unused=False\n    )[0].unbind(dim=-1)\n\n    # Compute second derivatives\n    laplacian = 0.0\n    for grad in [grad_x, grad_y, grad_z]:\n        grad_outputs = torch.ones_like(grad)\n        d2phi = torch.autograd.grad(\n            outputs=grad,\n            inputs=coordinates,\n            grad_outputs=grad_outputs,\n            create_graph=True,\n            retain_graph=True,\n            allow_unused=False\n        )[0].unbind(dim=-1)[0]  # Take derivative along same axis\n        laplacian += d2phi\n\n    return laplacian\ndef compute_allen_cahn_loss(predictions, coordinates, epsilon=0.05, delta_t=0.01):\n    \"\"\"\n    Robust physics loss calculation for Allen-Cahn equation\n\n    Args:\n        predictions: Model outputs [batch, x, y, z, time]\n        coordinates: Spatial coordinates [batch, x, y, z, 3]\n        epsilon: Interface width parameter\n        delta_t: Time step size\n\n    Returns:\n        pde_loss: PDE residual loss\n        bc_loss: Boundary condition loss\n    \"\"\"\n    batch_size = predictions.shape[0]\n    pde_loss = 0.0\n    bc_loss = 0.0\n\n    # Compute for each time step\n    for t in range(predictions.shape[-1]):\n        phi_t = predictions[..., t]\n\n        # Compute Laplacian\n        laplacian = compute_spatial_derivatives(phi_t, coordinates)\n\n        # Compute time derivative (finite difference)\n        if t == 0:\n            dt = (predictions[..., t + 1] - predictions[..., t]) / delta_t\n        elif t == predictions.shape[-1] - 1:\n            dt = (predictions[..., t] - predictions[..., t - 1]) / delta_t\n        else:\n            dt = (predictions[..., t + 1] - predictions[..., t - 1]) / (2 * delta_t)\n\n        # Allen-Cahn residual\n        residual = dt - (laplacian - (1 / epsilon ** 2) * (phi_t ** 3 - phi_t))\n        pde_loss += torch.mean(residual ** 2)\n\n        # Periodic boundary conditions\n        bc_loss += torch.mean((phi_t[..., 0, :, :] - phi_t[..., -1, :, :]) ** 2)\n        bc_loss += torch.mean((phi_t[..., :, 0, :] - phi_t[..., :, -1, :]) ** 2)\n        bc_loss += torch.mean((phi_t[..., :, :, 0] - phi_t[..., :, :, -1]) ** 2)\n\n    return pde_loss / predictions.shape[-1], bc_loss / (3 * predictions.shape[-1])
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/networks.py b/networks.py
+--- a/networks.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/networks.py	(date 1754547783963)
+@@ -410,8 +410,9 @@
+         xt = self.q(x)
+         X[..., 0] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)
+         for t in range(1, self.T_out):
+-            x1 = self.q(x, t)
+-            x2 = self.h(xt, t - 1)
++            #  two special MLPs (self.q and self.h) to generate the forecast step-by-step.
++            x1 = self.q(x, t) # A new prediction based on the original initial state.
++            x2 = self.h(xt, t - 1) #  A "correction" or "update" based on the prediction from the previous step (Time=1).
+             xt = x1 + x2
+             X[..., t] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)
+ 
+@@ -419,87 +420,150 @@
+         return X
+ 
+ 
+-def compute_spatial_derivatives(field, coordinates):
+-    """
+-    Computes first and second spatial derivatives of a field with respect to coordinates
++###############
++###############
++
++
++# Add to networks.py
++''''
++def get_grid_4d(shape, device):
++    batchsize, size_x, size_y, size_z, size_t = shape[0], shape[1], shape[2], shape[3], shape[4]
++    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
++    gridx = gridx.reshape(1, size_x, 1, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, size_t, 1])
++    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
++    gridy = gridy.reshape(1, 1, size_y, 1, 1, 1).repeat([batchsize, size_x, 1, size_z, size_t, 1])
++    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
++    gridz = gridz.reshape(1, 1, 1, size_z, 1, 1).repeat([batchsize, size_x, size_y, 1, size_t, 1])
++    gridt = torch.tensor(np.linspace(0, 1, size_t), dtype=torch.float)
++    gridt = gridt.reshape(1, 1, 1, 1, size_t, 1).repeat([batchsize, size_x, size_y, size_z, 1, 1])
++    return torch.cat((gridx, gridy, gridz, gridt), dim=-1).to(device)
++'''
++
++def get_grid_4d(shape, device):
++    batchsize, size_x, size_y, size_z, _ = shape  # Note: last dim is channels, not time
++    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
++    gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])
++    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
++    gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])
++    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
++    gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])
++    return torch.cat((gridx, gridy, gridz), dim=-1).to(device)  # Returns (batch, x, y, z, 3)
++
++
++def compl_mul4d(inp, weights):
++    # (batch, in_channel, x,y,z,t), (in_channel, out_channel, x,y,z,t) -> (batch, out_channel, x,y,z,t)
++    return torch.einsum("bixyzt,ioxyzt->boxyzt", inp, weights)
++
++
++class SpectralConv4d(nn.Module):
++    def __init__(self, in_channels, out_channels, modes1, modes2, modes3, modes4):
++        super(SpectralConv4d, self).__init__()
+ 
+-    Args:
+-        field: Tensor of shape [batch, x, y, z]
+-        coordinates: Tensor of shape [batch, x, y, z, 3] (must require grad)
++        self.in_channels = in_channels
++        self.out_channels = out_channels
++        self.modes1 = modes1  # Number of Fourier modes to multiply
++        self.modes2 = modes2
++        self.modes3 = modes3
++        self.modes4 = modes4
+ 
+-    Returns:
+-        laplacian: Tensor of shape [batch, x, y, z] containing 
+-    """
+-    # Ensure we can compute gradients
+-    field = field.clone().requires_grad_(True)
+-    coordinates = coordinates.clone().requires_grad_(True)
++        self.scale = (1 / (in_channels * out_channels))
++        # We'll use 8 weights for 4D (similar to how 3D uses 4 weights)
++        self.weights1 = nn.Parameter(
++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
++                                    dtype=torch.cfloat))
++        self.weights2 = nn.Parameter(
++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
++                                    dtype=torch.cfloat))
++        self.weights3 = nn.Parameter(
++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
++                                    dtype=torch.cfloat))
++        self.weights4 = nn.Parameter(
++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
++                                    dtype=torch.cfloat))
++        self.weights5 = nn.Parameter(
++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
++                                    dtype=torch.cfloat))
++        self.weights6 = nn.Parameter(
++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
++                                    dtype=torch.cfloat))
++        self.weights7 = nn.Parameter(
++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
++                                    dtype=torch.cfloat))
++        self.weights8 = nn.Parameter(
++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
++                                    dtype=torch.cfloat))
+ 
+-    # Compute first derivatives
+-    grad_outputs = torch.ones_like(field)
+-    grad_x, grad_y, grad_z = torch.autograd.grad(
+-        outputs=field,
+-        inputs=coordinates,
+-        grad_outputs=grad_outputs,
+-        create_graph=True,
+-        retain_graph=True,
+-        allow_unused=False
+-    )[0].unbind(dim=-1)
++    def forward(self, x):
++        batchsize = x.shape[0]
++        # Compute Fourier coefficients
++        x_ft = torch.fft.rfftn(x, dim=[-4, -3, -2, -1])  # FFT over spatial and time dimensions
+ 
+-    # Compute second derivatives
+-    laplacian = 0.0
+-    for grad in [grad_x, grad_y, grad_z]:
+-        grad_outputs = torch.ones_like(grad)
+-        d2phi = torch.autograd.grad(
+-            outputs=grad,
+-            inputs=coordinates,
+-            grad_outputs=grad_outputs,
+-            create_graph=True,
+-            retain_graph=True,
+-            allow_unused=False
+-        )[0].unbind(dim=-1)[0]  # Take derivative along same axis
+-        laplacian += d2phi
++        # Multiply relevant Fourier modes
++        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-4), x.size(-3), x.size(-2), x.size(-1) // 2 + 1,
++                             dtype=torch.cfloat, device=x.device)
+ 
+-    return laplacian
+-def compute_allen_cahn_loss(predictions, coordinates, epsilon=0.05, delta_t=0.01):
+-    """
+-    Robust physics loss calculation for Allen-Cahn equation
++        # Handle all combinations of modes
++        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3, :self.modes4] = \
++            compl_mul4d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3, :self.modes4], self.weights1)
++        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3, :self.modes4] = \
++            compl_mul4d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3, :self.modes4], self.weights2)
++        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3, :self.modes4] = \
++            compl_mul4d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3, :self.modes4], self.weights3)
++        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3, :self.modes4] = \
++            compl_mul4d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3, :self.modes4], self.weights4)
++        out_ft[:, :, :self.modes1, :self.modes2, -self.modes3:, :self.modes4] = \
++            compl_mul4d(x_ft[:, :, :self.modes1, :self.modes2, -self.modes3:, :self.modes4], self.weights5)
++        out_ft[:, :, -self.modes1:, :self.modes2, -self.modes3:, :self.modes4] = \
++            compl_mul4d(x_ft[:, :, -self.modes1:, :self.modes2, -self.modes3:, :self.modes4], self.weights6)
++        out_ft[:, :, :self.modes1, -self.modes2:, -self.modes3:, :self.modes4] = \
++            compl_mul4d(x_ft[:, :, :self.modes1, -self.modes2:, -self.modes3:, :self.modes4], self.weights7)
++        out_ft[:, :, -self.modes1:, -self.modes2:, -self.modes3:, :self.modes4] = \
++            compl_mul4d(x_ft[:, :, -self.modes1:, -self.modes2:, -self.modes3:, :self.modes4], self.weights8)
+ 
+-    Args:
+-        predictions: Model outputs [batch, x, y, z, time]
+-        coordinates: Spatial coordinates [batch, x, y, z, 3]
+-        epsilon: Interface width parameter
+-        delta_t: Time step size
++        # Return to physical space
++        x = torch.fft.irfftn(out_ft, s=(x.size(-4), x.size(-3), x.size(-2), x.size(-1)))
++        return x
+ 
+-    Returns:
+-        pde_loss: PDE residual loss
+-        bc_loss: Boundary condition loss
+-    """
+-    batch_size = predictions.shape[0]
+-    pde_loss = 0.0
+-    bc_loss = 0.0
+ 
+-    # Compute for each time step
+-    for t in range(predictions.shape[-1]):
+-        phi_t = predictions[..., t]
++class FNO4d(nn.Module):
++    def __init__(self, modes1, modes2, modes3, modes4_internal, width, width_q, T_in_channels, n_layers):
++        super(FNO4d, self).__init__()
+ 
+-        # Compute Laplacian
+-        laplacian = compute_spatial_derivatives(phi_t, coordinates)
++        self.modes1 = modes1
++        self.modes2 = modes2
++        self.modes3 = modes3
++        self.modes4 = modes4_internal
++        self.width = width
++        self.width_q = width_q
++        self.T_in = T_in_channels
++        self.n_layers = n_layers
++        self.padding = 6
+ 
+-        # Compute time derivative (finite difference)
+-        if t == 0:
+-            dt = (predictions[..., t + 1] - predictions[..., t]) / delta_t
+-        elif t == predictions.shape[-1] - 1:
+-            dt = (predictions[..., t] - predictions[..., t - 1]) / delta_t
+-        else:
+-            dt = (predictions[..., t + 1] - predictions[..., t - 1]) / (2 * delta_t)
++        # Input is (x,y,z) + time channels (t_in_channels) + 3 spatial coordinates
++        self.p = nn.Linear(self.T_in + 3, self.width)  # +3 for (x,y,z) coordinates
+ 
+-        # Allen-Cahn residual
+-        residual = dt - (laplacian - (1 / epsilon ** 2) * (phi_t ** 3 - phi_t))
+-        pde_loss += torch.mean(residual ** 2)
++        self.convs = nn.ModuleList([
++            SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)
++            for _ in range(n_layers)
++        ])
++        self.mlps = nn.ModuleList([MLP3d(self.width, self.width, self.width) for _ in range(n_layers)])
++        self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 1) for _ in range(n_layers)])
++        self.q = MLP3d(self.width, 1, self.width_q)  # Output channel is 1
+ 
+-        # Periodic boundary conditions
+-        bc_loss += torch.mean((phi_t[..., 0, :, :] - phi_t[..., -1, :, :]) ** 2)
+-        bc_loss += torch.mean((phi_t[..., :, 0, :] - phi_t[..., :, -1, :]) ** 2)
+-        bc_loss += torch.mean((phi_t[..., :, :, 0] - phi_t[..., :, :, -1]) ** 2)
++    def forward(self, x):
++        # Input shape: (batch, x, y, z, t_in_channels)
++        grid = get_grid_4d(x.shape, x.device)
++        x = torch.cat((x, grid), dim=-1)  # This is the key step where "time" is handled.  Now both are 5D: (batch, x, y, z, t_in_channels + 3)
++        x = self.p(x)  # Lift to higher dimension
++        x = x.permute(0, 4, 1, 2, 3)  # (batch, channels, x, y, z)
+ 
+-    return pde_loss / predictions.shape[-1], bc_loss / (3 * predictions.shape[-1])
+\ No newline at end of file
++        for i in range(self.n_layers):
++            x1 = self.convs[i](x)
++            x1 = self.mlps[i](x1)
++            x2 = self.ws[i](x)
++            x = x1 + x2
++            x = F.gelu(x) if i < self.n_layers - 1 else x
++
++        x = self.q(x)
++        x = x.permute(0, 2, 3, 4, 1)  # (batch, x, y, z, 1)
++        return x
+\ No newline at end of file
+Index: configs/config_PFC3D_TNO3d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>\"\"\"\nDevice:  cuda:0\nmodel = TNO2d_PFC2D_S64_T1to100_width32_modes12_q32_h16.pt\nnumber of epoch = 1000\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n2539703\n\nThe average testing error is 0.027059923857450485\nStd. deviation of testing error is 0.01980009116232395\n----------------------------------------------\nmodel = TNO2d_PFC2D_S64_T1to50_width16_modes12_q32_h16.pt\nnumber of epoch = 200\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n651059\n\nThe average testing error is 0.005057875066995621\nStd. deviation of testing error is 0.0021678071934729815\n----------------------------------------------\n\n\n\"\"\"\n\nimport numpy as np\n\n# General SettingnTrain = 1200 # 5250 # 7500\n\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200\nnTest = 300\nbatch_size = 50 # 100\nlearning_rate = 0.005\nweight_decay = 1e-4 # 1e-4\nepochs = 50\niterations = epochs * (nTrain // batch_size)\nmodes = 14 #12\nwidth = 12 # 16 # 32\nwidth_q = width # 32\nwidth_h = width//2 # 16\nn_layers = 4\n\n'''\ntau = 315;\nalpha = 115; \n'''\n\n# Discretization\ns = 32 # 64 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # True\nload_model = False # True # False # True  # False\n\n# Database\nparent_dir = './data/'\nmatlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 200  # 110  # 200\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n# time_steps = [0, 2, 4, 6, 8, 9]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_PFC3D_TNO3d.py b/configs/config_PFC3D_TNO3d.py
+--- a/configs/config_PFC3D_TNO3d.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/configs/config_PFC3D_TNO3d.py	(date 1754636119253)
+@@ -1,36 +1,3 @@
+-"""
+-Device:  cuda:0
+-model = TNO2d_PFC2D_S64_T1to100_width32_modes12_q32_h16.pt
+-number of epoch = 1000
+-batch size = 100
+-nTrain = 4000
+-nTest = 400
+-learning_rate = 0.005
+-n_layers = 4
+-width_q = 32
+-width_h = 16
+-2539703
+-
+-The average testing error is 0.027059923857450485
+-Std. deviation of testing error is 0.01980009116232395
+-----------------------------------------------
+-model = TNO2d_PFC2D_S64_T1to50_width16_modes12_q32_h16.pt
+-number of epoch = 200
+-batch size = 100
+-nTrain = 4000
+-nTest = 400
+-learning_rate = 0.005
+-n_layers = 4
+-width_q = 32
+-width_h = 16
+-651059
+-
+-The average testing error is 0.005057875066995621
+-Std. deviation of testing error is 0.0021678071934729815
+-----------------------------------------------
+-
+-
+-"""
+ 
+ import numpy as np
+ 
+@@ -43,26 +10,21 @@
+ # Network Parameters
+ nTrain = 1200
+ nTest = 300
+-batch_size = 50 # 100
+-learning_rate = 0.005
++batch_size = 20 #50# 100
++learning_rate = 0.001 # 0.005
+ weight_decay = 1e-4 # 1e-4
+-epochs = 50
++epochs = 30 # 20 # 50
+ iterations = epochs * (nTrain // batch_size)
+ modes = 14 #12
+ width = 12 # 16 # 32
+ width_q = width # 32
+ width_h = width//2 # 16
+-n_layers = 4
+-
+-'''
+-tau = 315;
+-alpha = 115; 
+-'''
++n_layers = 2 # 4
+ 
+ # Discretization
+ s = 32 # 64 # 64
+ T_in = 1
+-T_out = 20 # 100
++T_out = 100 # 20 # 100
+ 
+ # Training Setting
+ normalized = True
+@@ -71,14 +33,44 @@
+ 
+ # Database
+ parent_dir = './data/'
+-matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
++
+ # Plotting
+-index = 200  # 110  # 200
+-domain = [-np.pi, np.pi]
++index = 69  # 110  # 200
++Lx = 10*np.pi
++domain = [-5*np.pi, 5*np.pi]
+ # time_steps = [29, 35, 39, 45, 49]
+ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+ # time_steps = [0, 2, 4, 6, 8, 9]
+ #time_steps = [39, 59, 79]
+-time_steps = [0, 9, 19]
+\ No newline at end of file
++time_steps = [0, 50, 90]
++
++
++
++#############
++
++# Time Discretization Parameters (from AC3D MATLAB)
++dt_sim = 0.005 # 0.1     # Time step in the MATLAB simulation
++Nt_sim = 50        # Total number of simulation steps in MATLAB
++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
++# PDE Parameters for Allen-Cahn (AC3D)
++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
++# The PDE implemented in calculate_pde_residual was:
++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++# PINN Specific Settings (if PINN_MODE is True in main.py)
++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++
++pde_loss_scaler = 1e-4
+\ No newline at end of file
+Index: run_interface2.py
+===================================================================
+diff --git a/run_interface2.py b/run_interface2.py
+deleted file mode 100644
+--- a/run_interface2.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ /dev/null	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
+@@ -1,115 +0,0 @@
+-import torch
+-import numpy as np
+-import importlib
+-import matplotlib
+-matplotlib.use('TkAgg')
+-import matplotlib.pyplot as plt
+-from mpl_toolkits.mplot3d import Axes3D
+-from mpl_toolkits.mplot3d.art3d import Poly3DCollection
+-from skimage import measure
+-
+-# --- Model and Normalizer Loading (Unchanged) ---
+-device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")
+-model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models_smooth/TNO3d_SH3D_S32_T1to100_width12_modes16_q12_h6.pt'
+-
+-try:
+-    from networks import TNO3d
+-    torch.serialization.add_safe_globals([TNO3d])
+-    checkpoint = torch.load(model_path, map_location=device, weights_only=True)
+-except Exception as e:
+-    print(f"Secure loading failed: {e}\nFalling back to weights_only=False")
+-    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
+-
+-model = checkpoint['model']
+-model.eval()
+-
+-problem = 'SH3D'
+-network_name = 'TNO3d'
+-cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+-
+-# 1. Load the actual dataset the model was trained/tested on
+-dataset_path = './data/SH3D_1500_Nt_101_Nx_32_random.pt'
+-print(f"Loading ground truth dataset from: {dataset_path}")
+-full_dataset = torch.load(dataset_path)
+-
+-if isinstance(full_dataset, dict) and 'data' in full_dataset:
+-    data_tensor = full_dataset['data']
+-else:
+-    raise ValueError("Loaded dataset is not in the expected format.")
+-
+-print(f"Original data tensor shape: {data_tensor.shape}")
+-permuted_tensor = data_tensor.permute(0, 2, 3, 4, 1)
+-print(f"Permuted data tensor shape: {permuted_tensor.shape}")
+-
+-data_x = permuted_tensor[..., 0:1]
+-data_y = permuted_tensor[..., 1:]
+-
+-print(f"Split into input 'x' shape: {data_x.shape}")
+-print(f"Split into output 'y' shape: {data_y.shape}")
+-
+-# 2. Pick a single sample to test
+-sample_idx = 10
+-print(f"Using sample index: {sample_idx}")
+-
+-# 3. Separate the input and the ground truth for our chosen sample
+-input_ic = data_x[sample_idx].unsqueeze(0).to(device)
+-ground_truth_evolution = data_y[sample_idx].to(device)
+-
+-# IMPORTANT: We still need the normalizer
+-dataset_loader = importlib.import_module('utilities').ImportDataset
+-normalizer = dataset_loader(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out).normalizer_x
+-normalizer.mean = normalizer.mean.to(device)
+-normalizer.std = normalizer.std.to(device)
+-
+-# Normalize the input before feeding it to the model
+-normalized_input = normalizer.encode(input_ic)
+-
+-# 4. Run the model to get the prediction
+-with torch.no_grad():
+-    prediction_normalized = model(normalized_input)
+-    prediction = normalizer.decode(prediction_normalized)
+-
+-# Squeeze the batch dimension for easier plotting
+-prediction = prediction.squeeze(0)
+-
+-# 5. Compare the prediction with the ground truth
+-# --- MODIFIED: AVOID THE LAST FRAME (t=100) AS IT IS CORRUPT IN THE DATA FILE ---
+-# We will plot t=99 (model index 98) instead.
+-selected_frames_model_idx = [0, 49, 98]
+-selected_frames_true_time = [1, 50, 99]
+-
+-fig = plt.figure(figsize=(15, 8))
+-fig.suptitle(f'Model Validation on Sample {sample_idx}', fontsize=16)
+-
+-# Plot Ground Truth
+-for i, t_idx in enumerate(selected_frames_model_idx):
+-    ax = fig.add_subplot(2, 3, i + 1, projection='3d')
+-    frame_data = ground_truth_evolution[..., t_idx].cpu().numpy()
+-    print(f"Ground Truth (t={selected_frames_true_time[i]}): min={np.min(frame_data):.4f}, max={np.max(frame_data):.4f}")
+-    try:
+-        verts, faces, _, _ = measure.marching_cubes(frame_data, level=0.0)
+-        mesh = Poly3DCollection(verts[faces], facecolors='blue', edgecolor='none', alpha=0.9)
+-        ax.add_collection3d(mesh)
+-        ax.set_title(f'Ground Truth (t={selected_frames_true_time[i]})')
+-    except (ValueError, RuntimeError):
+-        ax.set_title(f'Ground Truth (t={selected_frames_true_time[i]})\n(No Isosurface)')
+-    ax.set_box_aspect([1, 1, 1]); ax.view_init(elev=30, azim=45)
+-    ax.grid(False); ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])
+-
+-# Plot Model Prediction
+-for i, t_idx in enumerate(selected_frames_model_idx):
+-    ax = fig.add_subplot(2, 3, i + 4, projection='3d')
+-    frame_data = prediction[..., t_idx].cpu().numpy()
+-    print(f"Model Prediction (t={selected_frames_true_time[i]}): min={np.min(frame_data):.4f}, max={np.max(frame_data):.4f}")
+-    try:
+-        verts, faces, _, _ = measure.marching_cubes(frame_data, level=0.0)
+-        mesh = Poly3DCollection(verts[faces], facecolors='red', edgecolor='none', alpha=0.9)
+-        ax.add_collection3d(mesh)
+-        ax.set_title(f'Model Prediction (t={selected_frames_true_time[i]})')
+-    except (ValueError, RuntimeError):
+-        ax.set_title(f'Model Prediction (t={selected_frames_true_time[i]})\n(No Isosurface)')
+-    ax.set_box_aspect([1, 1, 1]); ax.view_init(elev=30, azim=45)
+-    ax.grid(False); ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])
+-
+-plt.tight_layout(rect=[0, 0, 1, 0.95])
+-plt.show()
+\ No newline at end of file
+Index: run_inference.py
+===================================================================
+diff --git a/run_inference.py b/run_inference.py
+deleted file mode 100644
+--- a/run_inference.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ /dev/null	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
+@@ -1,166 +0,0 @@
+-import os
+-import numpy as np
+-import matplotlib.pyplot as plt
+-from mpl_toolkits.mplot3d.art3d import Poly3DCollection
+-from skimage import measure
+-import matplotlib
+-matplotlib.use('TkAgg')
+-# --- 0. Setup Output Directory ---
+-plot_dir = 'DNS_Results'
+-os.makedirs(plot_dir, exist_ok=True)
+-print(f"Figures will be saved in the '{plot_dir}' directory.")
+-
+-# --- 1. Parameter Initialization (Matching MATLAB Script) ---
+-
+-# Spatial Parameters
+-Nx = 32  # Grid size in x direction
+-Ny = Nx  # Grid size in y direction
+-Nz = Nx  # Grid size in z direction
+-Lx = 10.0  # Domain size in x direction
+-Ly = 10.0  # Domain size in y direction
+-Lz = 10.0  # Domain size in z direction
+-hx = Lx / Nx
+-hy = Ly / Ny
+-hz = Lz / Nz
+-
+-# Create the grid
+-x = np.linspace(-0.5 * Lx, 0.5 * Lx - hx, Nx)
+-y = np.linspace(-0.5 * Ly, 0.5 * Ly - hy, Ny)
+-z = np.linspace(-0.5 * Lz, 0.5 * Lz - hz, Nz)
+-xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')
+-
+-# Constant for the PDE
+-epsilon_pde = 0.15
+-
+-# Discrete Fourier Transform Setup (using np.fft.fftfreq for precision)
+-kx = 2 * np.pi * np.fft.fftfreq(Nx, d=hx)
+-ky = 2 * np.pi * np.fft.fftfreq(Ny, d=hy)
+-kz = 2 * np.pi * np.fft.fftfreq(Nz, d=hz)
+-kxx, kyy, kzz = np.meshgrid(kx ** 2, ky ** 2, kz ** 2, indexing='ij')
+-
+-# Time Discretization
+-dt = 0.05  # Time step
+-Nt = 100  # Total number of time steps
+-
+-# --- 2. Simulation for a Single, Specific Initial Condition ---
+-print('Starting direct numerical simulation for a single sphere...')
+-
+-# Create the specific SMOOTH sphere initial condition
+-radius = 2.0
+-epsilon_interface = 0.1
+-distance = np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)
+-u = np.tanh((radius - distance) / epsilon_interface)
+-
+-# Initialize storage for solutions at specific time frames
+-u_t0 = u.copy()  # Store initial condition (Time Frame 0)
+-u_t50 = np.zeros((Nx, Ny, Nz))
+-u_t100 = np.zeros((Nx, Ny, Nz))
+-
+-# --- 3. Time Evolution Loop (Directly solving the PDE) ---
+-for iter in range(1, Nt + 1):
+-    # Time evolution of the SH3D equation using a spectral method
+-    u_hat = np.fft.fftn(u)
+-    u3_hat = np.fft.fftn(u ** 3)
+-
+-    # Equation in Fourier space
+-    s_hat = u_hat / dt - u3_hat + 2 * (kxx + kyy + kzz) * u_hat
+-    v_hat = s_hat / (1.0 / dt + (1 - epsilon_pde) + (kxx + kyy + kzz) ** 2)
+-
+-    # Transform back to real space
+-    u = np.real(np.fft.ifftn(v_hat))
+-
+-    # Store solutions at specified time frames
+-    if iter == 50:
+-        u_t50 = u.copy()
+-        print('Captured data at Time Frame 50.')
+-    elif iter == 100:
+-        u_t100 = u.copy()
+-        print('Captured data at Time Frame 100.')
+-
+-print('Simulation complete.')
+-
+-# --- 4. Plotting Results (Replicating MATLAB Style) ---
+-
+-# Set a professional plotting style
+-plt.style.use('seaborn-v0_8-whitegrid')
+-plt.rcParams.update({'font.size': 12, 'axes.labelsize': 14, 'axes.titlesize': 16})
+-
+-# --- Plot 1: 3D Subplot of Phase Evolution ---
+-print("Generating 3D evolution plot...")
+-fig_3d = plt.figure(figsize=(20, 6))
+-time_data = [(u_t0, 'Time Frame: 0', '#0072BD'),
+-             (u_t50, 'Time Frame: 50', '#D95319'),
+-             (u_t100, 'Time Frame: 100', '#77AC30')]
+-
+-for i, (data, title, color) in enumerate(time_data):
+-    ax = fig_3d.add_subplot(1, 3, i + 1, projection='3d')
+-
+-    try:
+-        verts, faces, _, _ = measure.marching_cubes(data, level=0.0, spacing=(hx, hy, hz))
+-        verts -= np.array([Lx / 2, Ly / 2, Lz / 2])
+-
+-        mesh = Poly3DCollection(verts[faces])
+-        mesh.set_facecolor(color)
+-        mesh.set_edgecolor('none')
+-        ax.add_collection3d(mesh)
+-
+-        ax.set_xlabel("x")
+-        ax.set_ylabel("y")
+-        ax.set_zlabel("z")
+-
+-        ax.set_xlim([-Lx / 2, Lx / 2])
+-        ax.set_ylim([-Ly / 2, Ly / 2])
+-        ax.set_zlim([-Lx / 2, Lz / 2])
+-
+-        ax.set_box_aspect([Lx, Ly, Lz])
+-
+-        ax.set_title(title)
+-        ax.view_init(elev=30, azim=45)
+-        ax.set_proj_type('ortho')
+-
+-    except (ValueError, RuntimeError) as e:
+-        ax.text(0, 0, 0, "No isosurface found", ha='center', va='center')
+-        ax.set_title(title)
+-        print(f"Could not generate isosurface for '{title}': {e}")
+-
+-fig_3d.tight_layout()
+-
+-# <<< --- SAVE THE 3D FIGURE --- >>>
+-save_path_3d = os.path.join(plot_dir, 'SH3D_DNS_Evolution_3D.png')
+-fig_3d.savefig(save_path_3d, dpi=300, bbox_inches='tight')
+-print(f"3D plot saved to: {save_path_3d}")
+-# <<< ------------------------ >>>
+-
+-plt.show()
+-
+-# --- Plot 2: 1D Profile Plot ---
+-print("Generating 1D profile plot...")
+-fig_1d, ax_1d = plt.subplots(figsize=(12, 7))
+-
+-# Extract 1D profile along the x-axis (where y=0 and z=0)
+-mid_idx_y = Nx // 2
+-mid_idx_z = Nz // 2
+-
+-profile_t0 = u_t0[:, mid_idx_y, mid_idx_z]
+-profile_t50 = u_t50[:, mid_idx_y, mid_idx_z]
+-profile_t100 = u_t100[:, mid_idx_y, mid_idx_z]
+-
+-# Plotting with styles matching MATLAB
+-ax_1d.plot(x, profile_t0, color='#0072BD', linewidth=2.5, label='Time Frame: 0')
+-ax_1d.plot(x, profile_t50, color='#D95319', linewidth=2.5, label='Time Frame: 50')
+-ax_1d.plot(x, profile_t100, color='#EDB120', linewidth=2.5, label='Time Frame: 100')
+-
+-ax_1d.set_title('1D Profile of Phase Field u along x-axis (y=0, z=0)')
+-ax_1d.set_xlabel('x')
+-ax_1d.set_ylabel('u(x, y=0, z=0)')
+-ax_1d.legend(loc='best')
+-ax_1d.set_ylim([-1.1, 1.1])
+-ax_1d.grid(True, which='both', linestyle='--', linewidth=0.7)
+-
+-# <<< --- SAVE THE 1D FIGURE --- >>>
+-save_path_1d = os.path.join(plot_dir, 'SH3D_DNS_Profile_1D.png')
+-fig_1d.savefig(save_path_1d, dpi=300, bbox_inches='tight')
+-print(f"1D plot saved to: {save_path_1d}")
+-# <<< ------------------------ >>>
+-
+-plt.show()
+\ No newline at end of file
+Index: run_interface3.py
+===================================================================
+diff --git a/run_interface3.py b/run_interface3.py
+deleted file mode 100644
+--- a/run_interface3.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ /dev/null	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
+@@ -1,163 +0,0 @@
+-import torch
+-import numpy as np
+-import importlib
+-from utilities import ImportDataset
+-import matplotlib
+-matplotlib.use('TkAgg')
+-import matplotlib.pyplot as plt
+-from mpl_toolkits.mplot3d import Axes3D
+-from mpl_toolkits.mplot3d.art3d import Poly3DCollection
+-from skimage import measure
+-from matplotlib.colors import LightSource
+-
+-# Load model
+-device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")
+-
+-#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6.pt'
+-
+-model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+-
+-# Option 1 (Recommended secure approach)
+-try:
+-    from networks import TNO3d  # Import your custom network class
+-    torch.serialization.add_safe_globals([TNO3d])
+-    checkpoint = torch.load(model_path, map_location=device, weights_only=True)
+-except Exception as e:
+-    print(f"Secure loading failed: {e}\nFalling back to weights_only=False")
+-    # Option 2 (Less secure fallback)
+-    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
+-
+-model = checkpoint['model']
+-model.eval()
+-
+-# Load dataset for normalization
+-problem = 'SH3D'
+-network_name = 'TNO3d'
+-cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+-dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+-
+-# Move normalizer parameters to device
+-dataset.normalizer_x.mean = dataset.normalizer_x.mean.to(device)
+-dataset.normalizer_x.std = dataset.normalizer_x.std.to(device)
+-dataset.normalizer_y.mean = dataset.normalizer_y.mean.to(device)
+-dataset.normalizer_y.std = dataset.normalizer_y.std.to(device)
+-
+-
+-# Create spherical initial condition
+-def create_sharp_sphere_initial_condition(N=32, radius=2, L=10):
+-    x = np.linspace(-L / 2, L / 2, N)
+-    y = np.linspace(-L / 2, L / 2, N)
+-    z = np.linspace(-L / 2, L / 2, N)
+-    xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')
+-
+-    r = np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)
+-    sphere = np.ones((N, N, N), dtype=np.float32)  # Use float32 for consistency
+-
+-    # Perfectly sharp transition (no smoothing)
+-    outer_mask = r > radius
+-    sphere[outer_mask] = -1.0
+-
+-    # Force exact values (no floating point artifacts)
+-    sphere = np.where(r <= radius, 1.0, -1.0)
+-
+-    return sphere
+-# Create initial condition with perfect sharp interface
+-sphere_ic = create_sharp_sphere_initial_condition()
+-
+-input_tensor = torch.from_numpy(sphere_ic).float().unsqueeze(0).unsqueeze(-1).to(device)
+-input_tensor = dataset.normalizer_x.encode(input_tensor)
+-
+-# Run prediction
+-with torch.no_grad():
+-    prediction = model(input_tensor)  # Shape [1, 32, 32, 32, 10]
+-    prediction = dataset.normalizer_y.decode(prediction)
+-
+-# Define your custom frames to display
+-selected_frames = [0, 50, 90]  # Adjusted for T_out=10
+-num_frames = len(selected_frames)
+-
+-# Create figure with two subplots: 3D views and 1D profile
+-fig = plt.figure(figsize=(20, 10))
+-grid = plt.GridSpec(2, num_frames, hspace=0.3, wspace=0.2)
+-
+-# 1. Plot 3D isosurfaces for selected frames
+-for i, t in enumerate(selected_frames):
+-    ax = fig.add_subplot(grid[0, i], projection='3d')
+-    frame_data = prediction[0, ..., t].cpu().numpy()
+-
+-    # Print data range for debugging
+-    print(f"Frame {t}: min={np.min(frame_data):.3f}, max={np.max(frame_data):.3f}")
+-
+-    # Determine appropriate level
+-    data_min, data_max = np.min(frame_data), np.max(frame_data)
+-    if data_min > 0 or data_max < 0:
+-        level = (data_max + data_min) / 2  # Midpoint if zero is outside range
+-    else:
+-        level = 0.0  # Default level
+-
+-    try:
+-        # Extract smooth isosurface with adjusted level
+-        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level)
+-
+-        # Apply lighting and coloring
+-        ls = LightSource(azdeg=135, altdeg=45)
+-        rgb = ls.shade_normals(verts[faces], fraction=0.8)
+-
+-        mesh = Poly3DCollection(verts[faces],
+-                                facecolors=rgb,
+-                                edgecolor='none',
+-                                alpha=0.9)
+-
+-        ax.add_collection3d(mesh)
+-        plot_success = True
+-    except ValueError as e:
+-        print(f"Could not generate isosurface for frame {t}: {e}")
+-        plot_success = False
+-        # Display empty plot with error message
+-        ax.text(0.5, 0.5, 0.5, f"No isosurface\nat level={level:.2f}",
+-                ha='center', va='center', fontsize=10)
+-
+-    # Set viewing parameters
+-    ax.set_xlim(0, frame_data.shape[0])
+-    ax.set_ylim(0, frame_data.shape[1])
+-    ax.set_zlim(0, frame_data.shape[2])
+-    ax.set_title(f'Time = {t}\nLevel = {level:.2f}', pad=10)
+-    ax.grid(False)
+-    ax.set_xticks([])
+-    ax.set_yticks([])
+-    ax.set_zticks([])
+-    if plot_success:
+-        ax.view_init(elev=30, azim=45)
+-
+-# 2. Plot 1D profile through center for all time steps
+-ax_profile = fig.add_subplot(grid[1, :])
+-L = 10  # Domain size
+-x = np.linspace(-L / 2, L / 2, prediction.shape[1])
+-center_idx = prediction.shape[1] // 2  # Middle of the domain
+-
+-# Plot profiles for the same custom frames in the profile plot
+-for t in selected_frames:
+-    profile = prediction[0, :, center_idx, center_idx, t].cpu().numpy()
+-    ax_profile.plot(x, profile, label=f't={t}', alpha=0.8, linewidth=1.5)
+-
+-# Format profile plot
+-ax_profile.set_xlabel('Position along x-axis', fontsize=12)
+-ax_profile.set_ylabel('Field value', fontsize=12)
+-ax_profile.set_title('1D Profile Evolution Through Domain Center', pad=15)
+-ax_profile.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
+-ax_profile.grid(True, alpha=0.3)
+-ax_profile.set_ylim([-1.2, 1.5])  # Match MATLAB y-limits
+-
+-plt.tight_layout()
+-plt.show()
+-
+-# After getting predictions in Python
+-prediction_np = prediction.cpu().numpy()  # Convert to numpy array
+-
+-# Save to .mat file
+-from scipy.io import savemat
+-savemat('SH3D_python_predictions.mat', {
+-    'python_pred': prediction_np,
+-    'selected_frames': np.array(selected_frames),
+-    'x': x  # Spatial coordinates
+-})
+\ No newline at end of file
+Index: configs/config_SH3D_FNO3d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:2'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 # 5250 # 7500\nnTest = 300 # 2250 #500\nbatch_size = 10 # 50 # 50\nlearning_rate = 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-4\nepochs = 30 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 16\nwidth =  12 #32\nwidth_q =   width # width # 2 * width #\nwidth_h = width//2  # width//4 # width #\nn_layers = 2 # 8\n\n# Discretization\ns = 32 # 32 # 64\nT_in = 1\nT_out = 91 # 100 # 100\n\n# Training Setting\nnormalized = True # False #True\ntraining = True # False  # True\nload_model = False # False #True\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results\n\n# Plotting\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\nLx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\nLy =Lx\nLz= Lx\n\nindex = 62  # 24 # 62\n#domain = [-np.pi, np.pi]  ######\ndomain = [-Lx/2, Lx/2]\n\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 50, 90]\n\n\n### Hybrid method\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\n#Lx = np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\n# domain = [-Lx/2, Lx/2] # Assuming centered domain\n\n# Time Discretization (from MATLAB)\ndt_sim = 0.0000002 # Simulation time step\nNt = 100 # Total simulation steps\nnum_saved_steps = 101 # Number of saved steps (includes t=0)\nns = Nt / (num_saved_steps - 1) # Interval between saved steps\ndt_model = ns * dt_sim # Effective time step between model outputs\n\n# PDE Parameters\nepsilon = 0.15\n#pde_weight = 0.3 # Example: 30% physics loss\npde_weight = 0.0 # Example: 70% physics loss\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\npde_loss_scaler = 1e-11\n###########################\n# ... rest of config ...
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_SH3D_FNO3d.py b/configs/config_SH3D_FNO3d.py
+--- a/configs/config_SH3D_FNO3d.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/configs/config_SH3D_FNO3d.py	(date 1754547783975)
+@@ -33,12 +33,12 @@
+ parent_dir = './data/'
+ #matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'
+ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
+-matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+-
++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
+ # Plotting
+ 
+ # In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
+-Lx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
++Lx = 15 # 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+ Ly =Lx
+ Lz= Lx
+ 
+@@ -62,7 +62,7 @@
+ # domain = [-Lx/2, Lx/2] # Assuming centered domain
+ 
+ # Time Discretization (from MATLAB)
+-dt_sim = 0.0000002 # Simulation time step
++dt_sim = 0.0002 # Simulation time step
+ Nt = 100 # Total simulation steps
+ num_saved_steps = 101 # Number of saved steps (includes t=0)
+ ns = Nt / (num_saved_steps - 1) # Interval between saved steps
+@@ -75,6 +75,6 @@
+ # Learning Rate Scheduler Parameters (for StepLR)
+ scheduler_step = 20  # Decay learning rate every 20 epochs
+ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+-pde_loss_scaler = 1e-11
++pde_loss_scaler = 1e-0
+ ###########################
+ # ... rest of config ...
+\ No newline at end of file
+Index: configs/config_CH3D_TNO3d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500\nnTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500\nbatch_size = 20 # 50 # 3 # 20 # 50 # 5 # 50\nlearning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-3 # 1e-4\nepochs = 100 # 500 # 1000 # 25 # 100 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 10 #12 # 14 # 16 # 10 # 16\nwidth = 12 # 8 #12 #14 # 12 # 16 # 32\nwidth_q = width # 2 * width #\nwidth_h = width//2 # width//4 # width #\nn_layers = 4 # 4 # 5 # 5 # 8\n\n# Discretization\n\ns = 64 # 64 #32 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False # True # False  # True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'\n\n\n# Plotting\nindex = 62  # 24 # 62\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_CH3D_TNO3d.py b/configs/config_CH3D_TNO3d.py
+--- a/configs/config_CH3D_TNO3d.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/configs/config_CH3D_TNO3d.py	(date 1754547783990)
+@@ -6,24 +6,24 @@
+ numpy_seed = 0
+ 
+ # Network Parameters
+-nTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+-nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
+-batch_size = 20 # 50 # 3 # 20 # 50 # 5 # 50
++nTrain = 1200 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
++nTest =  300 # 300 # 100 # 2000 # 4000 #300 # 300 #500
++batch_size = 20 # 15 # 50 # 3 # 20 # 50 # 5 # 50
+ learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
+ weight_decay = 1e-4 # 1e-3 # 1e-4
+-epochs = 100 # 500 # 1000 # 25 # 100 # 1000
++epochs = 50 # 50 # 50 # 100 # 500 # 1000 # 25 # 100 # 1000
+ iterations = epochs * (nTrain // batch_size)
+-modes = 14 # 10 #12 # 14 # 16 # 10 # 16
+-width = 12 # 8 #12 #14 # 12 # 16 # 32
++modes = 14 # 14 # 12 # 14 # 10 #12 # 14 # 16 # 10 # 16
++width = 12 # 12 # 8 #12 #14 # 12 # 16 # 32
+ width_q = width # 2 * width #
+ width_h = width//2 # width//4 # width #
+-n_layers = 4 # 4 # 5 # 5 # 8
++n_layers = 3 # 4 # 5 # 5 # 8
+ 
+ # Discretization
+ 
+-s = 64 # 64 #32 # 64
++s = 32 # 64 # 64 #32 # 64
+ T_in = 1
+-T_out = 20 # 100
++T_out = 100 # 20 # 100
+ 
+ # Training Setting
+ normalized = True
+@@ -33,16 +33,46 @@
+ # Database
+ parent_dir = './data/'
+ #matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
+-matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+-
+-
++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
++#matlab_dataset = 'CH3D_800_Nt_101_Nx_32.mat'
++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
+ # Plotting
+ index = 62  # 24 # 62
+-domain = [-np.pi, np.pi]
++Lx = 2 # np.pi            # Domain size from MATLAB
++#domain = [-np.pi, np.pi]
++domain = [-Lx/2, Lx/2]
++
++#domain = [-np.pi, np.pi]
+ # time_steps = [29, 35, 39, 45, 49]
+ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+ #time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+ #time_steps = [39, 49, 59, 69, 79, 89, 99]
+ #time_steps = [39, 59, 79]
+-time_steps = [0, 9, 19]
+\ No newline at end of file
++time_steps = [0, 50, 90]
++
++
++#############
++
++# Time Discretization Parameters (from AC3D MATLAB)
++dt_sim = 0.0005     # Time step in the MATLAB simulation
++Nt_sim = 50        # Total number of simulation steps in MATLAB
++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
++# PDE Parameters for Allen-Cahn (AC3D)
++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
++# The PDE implemented in calculate_pde_residual was:
++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++epsilon = 0.05 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++# PINN Specific Settings (if PINN_MODE is True in main.py)
++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++
++pde_loss_scaler = 1e-6
+\ No newline at end of file
+Index: configs/config_MBE3D_FNO4d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_MBE3D_FNO4d.py b/configs/config_MBE3D_FNO4d.py
+new file mode 100644
+--- /dev/null	(date 1754547784000)
++++ b/configs/config_MBE3D_FNO4d.py	(date 1754547784000)
+@@ -0,0 +1,75 @@
++
++import numpy as np
++
++# General Setting
++gpu_number = 'cuda:1'  # 'cuda:1'
++torch_seed = 0
++numpy_seed = 0
++
++# Network Parameters
++nTrain = 1200 #1600 # 4000
++nTest = 300  # 400
++batch_size = 50 # 10 # 20 # 50# 25 #100
++learning_rate = 0.001
++weight_decay = 1e-4
++epochs = 30 # 50 # 1000
++iterations = epochs * (nTrain // batch_size)
++modes = 14 # 12
++width = 12 #32
++width_q = width #32
++width_h = width // 2 # width # 32
++n_layers = 2 # 4
++
++# Discretization
++s = 32
++T_in = 1
++T_out = 91 #20 #91 # 20 # 100
++
++# Training Setting
++normalized = True
++training = True  # True  # True
++load_model = False #True  # False  # False
++
++# Database
++parent_dir = './data/'
++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat'
++
++# Plotting
++# Plotting
++index = 62  # 72
++#domain = [-np.pi, np.pi]
++Lx = 2* np.pi  #10 # np.pi            # Domain size from MATLAB
++domain = [-Lx/2, Lx/2]
++# time_steps = [29, 35, 39, 45, 49]
++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++#time_steps = [39, 59, 79]
++#time_steps = [39, 59, 79]
++time_steps = [0, 50, 90]
++
++
++#############
++
++# Time Discretization Parameters (from AC3D MATLAB)
++dt_sim = 0.1     # Time step in the MATLAB simulation
++Nt_sim = 50        # Total number of simulation steps in MATLAB
++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
++# PDE Parameters for Allen-Cahn (AC3D)
++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
++# The PDE implemented in calculate_pde_residual was:
++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++epsilon = 0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++# PINN Specific Settings (if PINN_MODE is True in main.py)
++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++
++pde_loss_scaler = 1e-6
+\ No newline at end of file
+Index: PFC3D/.idea/PFC3D.iml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/PFC3D/.idea/PFC3D.iml b/PFC3D/.idea/PFC3D.iml
+new file mode 100644
+--- /dev/null	(date 1754547784034)
++++ b/PFC3D/.idea/PFC3D.iml	(date 1754547784034)
+@@ -0,0 +1,8 @@
++<?xml version="1.0" encoding="UTF-8"?>
++<module type="PYTHON_MODULE" version="4">
++  <component name="NewModuleRootManager">
++    <content url="file://$MODULE_DIR$" />
++    <orderEntry type="inheritedJdk" />
++    <orderEntry type="sourceFolder" forTests="false" />
++  </component>
++</module>
+\ No newline at end of file
+Index: configs/config_CH3D_FNO4d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_CH3D_FNO4d.py b/configs/config_CH3D_FNO4d.py
+new file mode 100644
+--- /dev/null	(date 1754547784009)
++++ b/configs/config_CH3D_FNO4d.py	(date 1754547784009)
+@@ -0,0 +1,77 @@
++import numpy as np
++
++# General Setting
++gpu_number = 'cuda:3'  # 'cuda:1'
++torch_seed = 0
++numpy_seed = 0
++
++# Network Parameters
++nTrain = 1300 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
++nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
++batch_size = 20 # 10 # 20 # 20 # 50 # 3 # 20 # 50 # 5 # 50
++learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
++weight_decay = 1e-4 # 1e-3 # 1e-4
++epochs = 50 # 100 # 500 # 1000 # 25 # 100 # 1000
++iterations = epochs * (nTrain // batch_size)
++modes = 14 # 10 #12 # 14 # 16 # 10 # 16
++width = 12 # 8 #12 #14 # 12 # 16 # 32
++width_q = width # 2 * width #
++width_h = width//2 # width//4 # width #
++n_layers = 3 # 2 # 4 # 5 # 5 # 8
++
++# Discretization
++
++s = 32 # 64 # 32 # 64 #32 # 64
++T_in = 1
++T_out = 91 # 20 # 100
++
++# Training Setting
++normalized = True
++training = True # False # True # False  # True
++load_model = False # True # False # False #True
++
++# Database
++parent_dir = './data/'
++
++#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++# Plotting
++index = 62  # 24 # 62
++#domain = [-np.pi, np.pi]
++Lx = 2 # np.pi            # Domain size from MATLAB
++#domain = [-np.pi, np.pi]
++domain = [-Lx/2, Lx/2]
++# time_steps = [29, 35, 39, 45, 49]
++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++#time_steps = [39, 49, 59, 69, 79, 89, 99]
++#time_steps = [39, 59, 79]
++time_steps = [0, 50, 90]
++
++
++#############
++
++# Time Discretization Parameters (from AC3D MATLAB)
++dt_sim = 0.0005     # Time step in the MATLAB simulation
++Nt_sim = 50        # Total number of simulation steps in MATLAB
++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
++# PDE Parameters for Allen-Cahn (AC3D)
++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
++# The PDE implemented in calculate_pde_residual was:
++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++epsilon = 0.05  # The epsilon from your AC3D MATLAB script, PDE parameter
++# PINN Specific Settings (if PINN_MODE is True in main.py)
++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++
++pde_loss_scaler = 1e-4
+\ No newline at end of file
+Index: run_interface.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/run_interface.py b/run_interface.py
+new file mode 100644
+--- /dev/null	(date 1754551855013)
++++ b/run_interface.py	(date 1754551855013)
+@@ -0,0 +1,452 @@
++import torch
++import numpy as np
++import importlib
++from utilities import ImportDataset
++import matplotlib
++
++matplotlib.use('TkAgg')
++import matplotlib.pyplot as plt
++from mpl_toolkits.mplot3d import Axes3D
++from mpl_toolkits.mplot3d.art3d import Poly3DCollection
++from skimage import measure
++from matplotlib.colors import LightSource
++from scipy.io import savemat
++
++# ============================================================================
++# 1. CHOOSE INITIAL CONDITION
++# ============================================================================
++# Options: 'sphere', 'dumbbell', 'star', separation, torus, 'heart'
++initial_condition_type = 'star'  # <-- CHANGE THIS VALUE TO RUN A DIFFERENT SIMULATION
++print(f"Running simulation for Initial Condition: {initial_condition_type.upper()}")
++
++# ============================================================================
++# 2. MODEL AND DATASET LOADING
++# ============================================================================
++# Load model
++device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")
++
++# SH3D
++#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
++#model_path = '/SH3D/models/TNO3d_SH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d_valid_old.pt'
++#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
++
++# AC3D
++#model_path = '/scratch/noqu8762/phase_field_equations_4d/AC3D/models/TNO3d_AC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt' # AC3D
++#model_path = '/scratch/noqu8762/phase_field_equations_4d/AC3D/models/TNO3d_AC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt' # AC3D
++
++# CH3D
++#model_path = '/scratch/noqu8762/phase_field_equations_4d/CH3D/models/TNO3d_CH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
++#model_path = '/scratch/noqu8762/phase_field_equations_4d/CH3D/models/TNO3d_CH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
++
++
++# mixed MBE3d#
++#model_path = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
++#model_path = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
++
++
++# PFC (we plotted this)
++#model_path = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/models/TNO3d_PFC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
++model_path = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/models/TNO3d_PFC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt' # reduce weight for PDE loss
++#model_path = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/models/TNO3d_PFC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d_valid.pt'
++
++
++
++try:
++    from networks import TNO3d  # Assuming networks.py and TNO3d are available
++
++    # Add builtins.set to safe globals for robust loading
++    torch.serialization.add_safe_globals([set])
++    torch.serialization.add_safe_globals([TNO3d])  # Add TNO3d if it's part of the global scope during saving
++
++    checkpoint = torch.load(model_path, map_location=device, weights_only=True)
++except Exception as e:
++    print(f"Secure loading failed: {e}\nFalling back to weights_only=False")
++    # It's good practice to ensure the safe globals are added even for fallback
++    torch.serialization.add_safe_globals([set])
++    torch.serialization.add_safe_globals([TNO3d])
++    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
++
++model = checkpoint['model']
++model.eval()
++
++# Load dataset for normalization AND EXTRACT PROBLEM NAME
++key_directory = 'phase_field_equations_4d'
++problem = ''
++try:
++    parts = model_path.split('/')
++    index = parts.index(key_directory)
++    problem = parts[index + 1]  # This gets the directory name (e.g., 'AC3D')
++except (ValueError, IndexError):
++    print(f"Could not automatically determine problem name. Set manually if needed.")
++
++print(f"Problem Name Determined: {problem}")
++network_name = 'TNO3d'
++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")  # Assuming configs module is available
++dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
++
++dataset.normalizer_x.mean = dataset.normalizer_x.mean.to(device)
++dataset.normalizer_x.std = dataset.normalizer_x.std.to(device)
++dataset.normalizer_y.mean = dataset.normalizer_y.mean.to(device)
++dataset.normalizer_y.std = dataset.normalizer_y.std.to(device)
++
++
++# ============================================================================
++# 3. CREATE INITIAL CONDITION
++# ============================================================================
++def create_initial_condition(ic_type='sphere'):
++    Nx, Ny, Nz = 0, 0, 0
++    Lx, Ly, Lz = 0, 0, 0
++    epsilon = 0
++    Nt = 0
++    selected_frames = []
++    u = None
++    dt = 0
++
++    if ic_type == 'sphere':
++        Nx = 32;
++        Ny = 32;
++        Nz = 32
++        # Lx = 10*np.pi; # PFC3D
++        Lx = 5 # AC3D
++        #Lx = 15  # SH3D
++        Ly = Lx;
++        Lz = Lx
++        # epsilon = 0.5 # PFC3D
++        #epsilon = 0.15 # SH3d
++        epsilon = 0.1 # AC3d
++        # dt = 0.0005
++        dt = 0.05  # SH3D
++        Nt = 100
++        selected_frames = [0, 70, 90]
++
++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++
++        # radius = 6 # PFC3D
++        radius = 0.5 # AC3D
++        #radius = 2.0  # SH3D
++        interface_width = np.sqrt(2) * epsilon
++        u = np.tanh((radius - np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)) / interface_width)
++
++    elif ic_type == 'dumbbell':
++        Nx = 32;
++        Ny = 32;
++        Nz = 32
++        Lx = 40;
++        Ly = 20;
++        Lz = 20
++        epsilon = 0.005
++        dt = 0.01
++        Nt = 100
++        selected_frames = [0, 50, 90]
++
++        x_grid = np.linspace(0, Lx, Nx)
++        y_grid = np.linspace(0, Ly, Ny)
++        z_grid = np.linspace(0, Lz, Nz)
++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++
++        R0 = 0.25
++        interface_width = np.sqrt(2) * epsilon
++
++        r1 = np.sqrt((xx - (0.3 * Lx)) ** 2 + (yy - (0.5 * Ly)) ** 2 + (zz - (0.5 * Lz)) ** 2)
++        r2 = np.sqrt((xx - (1.7 * Lx)) ** 2 + (yy - (0.5 * Ly)) ** 2 + (zz - (0.5 * Lz)) ** 2)
++        u_spheres = np.tanh((R0 - r1) / interface_width) + np.tanh((R0 - r2) / interface_width) + 1
++
++        bar_mask = (xx > (0.4 * Lx)) & (xx < (1.6 * Lx)) & \
++                   (yy > (0.4 * Ly)) & (yy < (0.6 * Ly)) & \
++                   (zz > (0.4 * Lz)) & (zz < (0.6 * Lz))
++        u = u_spheres
++        u[bar_mask] = 1.0
++        u = np.clip(u, -1.0, 1.0)
++
++    elif ic_type == 'star':
++        Nx = 32;
++        Ny = 32;
++        Nz = 32
++        #Lx = 5 # AC3D,
++        Lx = 10 * np.pi  # --> PFC3D
++        #Lx = 2  # CH3D
++        Ly = Lx;
++        Lz = Lx
++        epsilon = 0.5  # PFC3D
++        #epsilon = 0.05 # CH3d
++        dt = 0.005
++        Nt = 100
++        selected_frames = [0, 50, 90]
++
++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++
++        interface_width = np.sqrt(2.0) * epsilon
++        theta = np.arctan2(zz, xx)
++        R_theta = 5.0 + 1.0 * np.cos(6 * theta)  # PFC3D
++        # R_theta = 0.7 + 0.2 * np.cos(6 * theta)  # AC3D
++        #R_theta = 0.7 + 0.2 * np.cos(6 * theta)  # CH3D
++        dist = np.sqrt(xx ** 2 + 2 * yy ** 2 + zz ** 2)
++        u = np.tanh((R_theta - dist) / interface_width)
++
++    elif ic_type == 'torus':
++        Nx = 32;
++        Ny = 32;
++        Nz = 32
++        # Lx = 10*np.pi;
++        Lx = 2 * np.pi  # MBE3D
++        Ly = Lx;
++        Lz = Lx
++        # epsilon = 0.5
++        epsilon = 0.1  # MBE3D
++        # dt = 0.005
++        dt = 0.001  # MBE3D
++        Nt = 100
++        selected_frames = [0, 50, 90]
++
++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++
++        # R_major = 5.5
++        # r_minor = 3.5
++        R_major = 2.1  # MBE3D
++        r_minor = 0.7  # MBE3D
++
++        interface_width = np.sqrt(2) * epsilon
++        torus_dist = np.sqrt((np.sqrt(xx ** 2 + yy ** 2) - R_major) ** 2 + zz ** 2)
++        u = np.tanh((r_minor - torus_dist) / interface_width)
++        # u = np.clip(u, -1.0, 1.0)
++
++    elif ic_type == 'separation':
++        Nx = 32;
++        Ny = 32;
++        Nz = 32
++        Lx = 2 * np.pi;
++        Ly = 2 * np.pi;
++        Lz = 2 * np.pi
++        epsilon = 0.5
++        dt = 0.0005
++        Nt = 100
++        selected_frames = [0, 50, 90]
++
++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++
++        interface_width = np.sqrt(2) * epsilon
++
++        r1_dist = np.sqrt((xx + 1) ** 2 + yy ** 2 + zz ** 2)
++        r2_dist = np.sqrt((xx - 1) ** 2 + yy ** 2 + zz ** 2)
++
++        u = np.tanh((1 - r1_dist) / interface_width) + np.tanh((1 - r2_dist) / interface_width)
++        # u = np.clip(u, -1.0, 1.0)
++
++    elif ic_type == 'heart':
++        Nx = 32
++        Ny = 32
++        Nz = 32
++        Lx = 5.0
++        Ly = Lx
++        Lz = Lx
++        epsilon = 0.15
++        dt = 0.005  # Assuming a dt similar to other conditions
++        Nt = 100
++        selected_frames = [0, 50, 90]
++
++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++
++        # Equation from image: phi(x,y,z,0) = tanh( ( (x^2 + 9/4*y^2 + z^2 - 1)^3 - x^2*z^3 - 9/80*y^2*z^3 ) / sqrt(2*epsilon) )
++        denominator = np.sqrt(2 * epsilon)
++        numerator = (xx ** 2 + (9 / 4) * yy ** 2 + zz ** 2 - 1) ** 3 - xx ** 2 * zz ** 3 - (9 / 80) * yy ** 2 * zz ** 3
++        u = np.tanh(numerator / denominator)
++
++    else:
++        raise ValueError(f"Unknown initial condition type: {ic_type}")
++
++    return u, (Lx, Ly, Lz), (Nx, Ny, Nz), Nt, dt, selected_frames
++
++
++# Create the selected initial condition
++initial_condition_field, domain_lengths, grid_sizes, Nt, dt, selected_frames = create_initial_condition(
++    ic_type=initial_condition_type)
++Lx, Ly, Lz = domain_lengths
++Nx, Ny, Nz = grid_sizes
++
++# ============================================================================
++# 4. PREDICTION AND VISUALIZATION
++# ============================================================================
++# Prepare tensor for the model
++input_tensor = torch.from_numpy(initial_condition_field).float().unsqueeze(0).unsqueeze(-1).to(device)
++input_tensor = dataset.normalizer_x.encode(input_tensor)
++
++# Run prediction
++with torch.no_grad():
++    # Start timer
++    start_time = torch.cuda.Event(enable_timing=True)
++    end_time = torch.cuda.Event(enable_timing=True)
++
++    torch.cuda.synchronize()  # Wait for all operations to complete
++    start_time.record()  # Start recording
++
++    prediction = model(input_tensor)
++
++    end_time.record()  # Stop recording
++    torch.cuda.synchronize()  # Wait for all operations to complete
++
++    # ==================== MODIFICATION START ====================
++    # Calculate elapsed time in milliseconds
++    inference_time_ms = start_time.elapsed_time(end_time)
++    # Convert milliseconds to seconds for saving
++    inference_time = inference_time_ms / 1000.0
++    # ===================== MODIFICATION END =====================
++
++    prediction = dataset.normalizer_y.decode(prediction)
++    # Clip the prediction to be within the physical bounds [-1, 1].
++    #prediction = torch.clamp(prediction, min=-1.0, max=1.0) # SH3d
++
++# ==================== MODIFICATION START ====================
++# Updated print statement to show both units
++print(f"Inference time: {inference_time_ms:.3f} milliseconds ({inference_time:.6f} seconds)")
++# ===================== MODIFICATION END =====================
++
++
++# Create figure
++fig = plt.figure(figsize=(20, 10))
++grid = plt.GridSpec(2, len(selected_frames), hspace=0.3, wspace=0.2)
++fig.suptitle(f"TNO Prediction for {initial_condition_type.upper()} Initial Condition ({problem})", fontsize=16)
++
++# Define mesh coordinates for plotting
++if initial_condition_type in ['sphere', 'star', 'torus', 'separation', 'heart']:
++    x_coords = np.linspace(-Lx / 2, Lx / 2, Nx)
++    x_lim_low, x_lim_high = -Lx / 2, Lx / 2
++    y_lim_low, y_lim_high = -Ly / 2, Ly / 2
++    z_lim_low, z_lim_high = -Lz / 2, Lz / 2
++elif initial_condition_type == 'dumbbell':
++    x_coords = np.linspace(0, Lx, Nx)
++    x_lim_low, x_lim_high = 0, Lx
++    y_lim_low, y_lim_high = 0, Ly
++    z_lim_low, z_lim_high = 0, Lz
++
++# 1. Plot 3D isosurfaces
++for i, t in enumerate(selected_frames):
++    ax = fig.add_subplot(grid[0, i], projection='3d')
++
++    # if t == 0:
++    #    frame_data = initial_condition_field
++    #    title_text = f'Initial Condition\nTime = {t}'
++    # else:
++    #    frame_data = prediction[0, ..., t].cpu().numpy()
++    #    title_text = f'Prediction\nTime = {t}'
++
++    frame_data = prediction[0, ..., t].cpu().numpy()
++    title_text = f'Prediction\nTime = {t}'
++
++    level = 0.0
++    try:
++        dx, dy, dz = Lx / (Nx - 1), Ly / (Ny - 1), Lz / (Nz - 1)
++        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level, spacing=(dx, dy, dz))
++
++        if initial_condition_type in ['sphere', 'star', 'torus', 'separation', 'heart']:
++            verts[:, 0] -= Lx / 2
++            verts[:, 1] -= Ly / 2
++            verts[:, 2] -= Lz / 2
++
++        ls = LightSource(azdeg=135, altdeg=45)
++        mesh = Poly3DCollection(verts[faces], facecolors='gray', edgecolor='none', alpha=0.9)
++        ax.add_collection3d(mesh)
++        plot_success = True
++    except ValueError as e:
++        print(f"Could not generate isosurface for frame {t}: {e}")
++        ax.text(0.5, 0.5, 0.5, f"No isosurface\nat level={level:.2f}", ha='center', va='center', transform=ax.transAxes)
++        plot_success = False
++
++    ax.set_xlim(x_lim_low, x_lim_high)
++    ax.set_ylim(y_lim_low, y_lim_high)
++    ax.set_zlim(z_lim_low, z_lim_high)
++    ax.set_title(f'{title_text}\nLevel = {level:.2f}', pad=10)
++    ax.grid(False)
++    ax.set_xticks([])
++    ax.set_yticks([])
++    ax.set_zticks([])
++    if plot_success:
++        ax.view_init(elev=30, azim=45)
++
++# 2. Plot 1D profile
++ax_profile = fig.add_subplot(grid[1, :])
++center_y_idx = Ny // 2
++center_z_idx = Nz // 2
++
++for t in selected_frames:
++    if t == 0:
++        profile = initial_condition_field[:, center_y_idx, center_z_idx]
++        label_text = f't={t} (IC)'
++    else:
++        profile = prediction[0, :, center_y_idx, center_z_idx, t].cpu().numpy()
++        label_text = f't={t}'
++    # profile = prediction[0, :, center_y_idx, center_z_idx, t].cpu().numpy()
++    # label_text = f't={t}'
++
++    ax_profile.plot(x_coords, profile, label=label_text, alpha=0.8, linewidth=1.5)
++
++ax_profile.set_xlabel('Position along x-axis', fontsize=12)
++ax_profile.set_ylabel('Field value', fontsize=12)
++ax_profile.set_title('1D Profile Evolution Through Domain Center', pad=15)
++ax_profile.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
++ax_profile.grid(True, alpha=0.3)
++ax_profile.set_ylim([-1.5, 1.5])
++
++plt.tight_layout(rect=[0, 0, 1, 0.96])
++plt.show()
++
++
++## This is saved the data of initial condition itself
++# ============================================================================
++# 5. SAVE RESULTS TO .MAT FILE
++# ============================================================================
++# Get the raw prediction tensor from the model as a NumPy array
++prediction_np = prediction.cpu().numpy()
++# Create a "hybrid" tensor for saving, ensuring the t=0 slice is the true IC
++final_prediction_to_save = np.copy(prediction_np)
++final_prediction_to_save[0, :, :, :, 0] = initial_condition_field
++# Define the output filename using the 'problem' variable extracted earlier
++# from the model_path. This makes the filename dynamic.
++output_filename = f'{problem}_python_predictions_{initial_condition_type}_PIMHNO.mat'
++
++# ==================== MODIFICATION START ====================
++# Save the corrected data and the inference time to the .mat file
++savemat(output_filename, {
++    'python_pred': final_prediction_to_save,
++    'selected_frames': np.array(selected_frames),
++    'x': x_coords,
++    'inference_time': inference_time  # Add the inference time (in seconds)
++})
++print(f"Corrected prediction (with true IC at t=0) and inference time saved to {output_filename}")
++
++# ===================== MODIFICATION END =====================
++
++'''
++# ============================================================================
++# 5. SAVE RESULTS TO .MAT FILE
++# ============================================================================
++# Get the raw prediction tensor from the model as a NumPy array
++prediction_np = prediction.cpu().numpy()
++# The array to save is now just the raw prediction
++final_prediction_to_save = prediction_np
++# The line that overwrites t=0 has been removed.
++output_filename = f'{problem}_python_predictions_{initial_condition_type}.mat'
++# Save the raw prediction data to the .mat file
++savemat(output_filename, {
++    'python_pred': final_prediction_to_save,
++    'selected_frames': np.array(selected_frames),
++    'x': x_coords,
++    'inference_time': inference_time  # Add the inference time (in seconds)
++})
++print(f"Raw model prediction saved to {output_filename}")
++
++'''
+Index: PFC3D/.idea/misc.xml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/PFC3D/.idea/misc.xml b/PFC3D/.idea/misc.xml
+new file mode 100644
+--- /dev/null	(date 1752127452592)
++++ b/PFC3D/.idea/misc.xml	(date 1752127452592)
+@@ -0,0 +1,4 @@
++<?xml version="1.0" encoding="UTF-8"?>
++<project version="4">
++  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.6" project-jdk-type="Python SDK" />
++</project>
+\ No newline at end of file
+Index: PFC3D/.idea/modules.xml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/PFC3D/.idea/modules.xml b/PFC3D/.idea/modules.xml
+new file mode 100644
+--- /dev/null	(date 1752127452573)
++++ b/PFC3D/.idea/modules.xml	(date 1752127452573)
+@@ -0,0 +1,8 @@
++<?xml version="1.0" encoding="UTF-8"?>
++<project version="4">
++  <component name="ProjectModuleManager">
++    <modules>
++      <module fileurl="file://$PROJECT_DIR$/.idea/PFC3D.iml" filepath="$PROJECT_DIR$/.idea/PFC3D.iml" />
++    </modules>
++  </component>
++</project>
+\ No newline at end of file
+Index: configs/config_SH3D_TNO3d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:2'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 # 5250 # 7500\nnTest = 300 # 2250 #500\nbatch_size = 20 # 50\nlearning_rate = 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-4\nepochs = 30 # 50 # 50 # 50 # 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 16 # 16\nwidth =  12 # 12 #32\nwidth_q =   width # width # 2 * width #\nwidth_h = width//2  # width//4 # width #\nn_layers = 2 # 8\n\n# Discretization\n#s = 32 # 32 # 64\n#T_in = 1\n#T_out = 20 # 100\n# Discretization\ns = 32 # 80         # CRITICAL: Must match Nx, Ny, Nz from MATLAB (which is 80)\nT_in = 1       # CRITICAL: Use the first time step (t=0) as input\nT_out = 100 # 91 # 100 # 20     # CRITICAL: Predict the next 10 time steps. Total steps used = 1+10=11, which matches the data.\n\n# Training Setting\nnormalized = True # False\ntraining = True # False  #   True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_3232.mat' # correct\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results\n# Plotting\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\nLx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\nLy =Lx\nLz= Lx\n\n\nindex = 62  # 24 # 62\n#domain = [-np.pi, np.pi] ######\ndomain = [-Lx/2, Lx/2]\n\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\n#time_steps = [0, 9, 19]\ntime_steps = [0, 50, 90]\n####\n### Hybrid method\n\n\n#domain = [-Lx/2, Lx/2] # Assuming centered domain\n\n# Time Discretization (from MATLAB)\ndt_sim = 0.05 # Simulation time step\ndt_simulation = 0.05\nNt = 100 # Total simulation steps\nnum_saved_steps = 101 # Number of saved steps (includes t=0)\nns = Nt / (num_saved_steps - 1) # Interval between saved steps\ndt_model = ns * dt_sim # Effective time step between model outputs\n\n# PDE Parameters\nepsilon = 0.15\n#pde_weight = 0.3 # Example: 30% physics loss\npde_weight = 0.4 # Example: 70% physics loss\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\npde_loss_scaler = 1e1\n###########################\n# ... rest of config ...
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_SH3D_TNO3d.py b/configs/config_SH3D_TNO3d.py
+--- a/configs/config_SH3D_TNO3d.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/configs/config_SH3D_TNO3d.py	(date 1754547783868)
+@@ -6,18 +6,18 @@
+ numpy_seed = 0
+ 
+ # Network Parameters
+-nTrain = 1200 # 5250 # 7500
+-nTest = 300 # 2250 #500
++nTrain = 1200 # 1600 # 5250 # 7500
++nTest = 300 # 400 # 2250 #500
+ batch_size = 20 # 50
+ learning_rate = 0.001 # 0.005 # 0.001
+ weight_decay = 1e-4 # 1e-4
+-epochs = 30 # 50 # 50 # 50 # 50 # 1000
++epochs = 30 # 50 # 50 # 50 # 50 # 50 # 1000
+ iterations = epochs * (nTrain // batch_size)
+ modes =  14 # 16 # 16
+ width =  12 # 12 #32
+-width_q =   width # width # 2 * width #
++width_q = width # width # 2 * width #
+ width_h = width//2  # width//4 # width #
+-n_layers = 2 # 8
++n_layers = 2 # 4 # 8
+ 
+ # Discretization
+ #s = 32 # 32 # 64
+@@ -38,11 +38,13 @@
+ 
+ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_3232.mat' # correct
+ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
+-matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
++
++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
+ # Plotting
+ 
+ # In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
+-Lx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
++Lx = 15 # 10 # 15 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+ Ly =Lx
+ Lz= Lx
+ 
+@@ -76,11 +78,11 @@
+ # PDE Parameters
+ epsilon = 0.15
+ #pde_weight = 0.3 # Example: 30% physics loss
+-pde_weight = 0.4 # Example: 70% physics loss
++pde_weight = 0.5 # 0.2 # Example: 70% physics loss
+ 
+ # Learning Rate Scheduler Parameters (for StepLR)
+ scheduler_step = 20  # Decay learning rate every 20 epochs
+ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+-pde_loss_scaler = 1e1
++pde_loss_scaler = 1.5e0
+ ###########################
+ # ... rest of config ...
+\ No newline at end of file
+Index: .idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/shelved.patch
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/shelved.patch
+new file mode 100644
+--- /dev/null	(date 1754055605082)
++++ b/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/shelved.patch	(date 1754055605082)
+@@ -0,0 +1,5425 @@
++Index: configs/config_PFC3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\"\"\"\nDevice:  cuda:0\nmodel = TNO2d_PFC2D_S64_T1to100_width32_modes12_q32_h16.pt\nnumber of epoch = 1000\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n2539703\n\nThe average testing error is 0.027059923857450485\nStd. deviation of testing error is 0.01980009116232395\n----------------------------------------------\nmodel = TNO2d_PFC2D_S64_T1to50_width16_modes12_q32_h16.pt\nnumber of epoch = 200\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n651059\n\nThe average testing error is 0.005057875066995621\nStd. deviation of testing error is 0.0021678071934729815\n----------------------------------------------\n\n\n\"\"\"\n\nimport numpy as np\n\n# General SettingnTrain = 1200 # 5250 # 7500\n\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200\nnTest = 300\nbatch_size = 50 # 100\nlearning_rate = 0.005\nweight_decay = 1e-4 # 1e-4\nepochs = 50\niterations = epochs * (nTrain // batch_size)\nmodes = 14 #12\nwidth = 12 # 16 # 32\nwidth_q = width # 32\nwidth_h = width//2 # 16\nn_layers = 4\n\n'''\ntau = 315;\nalpha = 115; \n'''\n\n# Discretization\ns = 32 # 64 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # True\nload_model = False # True # False # True  # False\n\n# Database\nparent_dir = './data/'\nmatlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 200  # 110  # 200\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n# time_steps = [0, 2, 4, 6, 8, 9]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_PFC3D_TNO3d.py b/configs/config_PFC3D_TNO3d.py
++--- a/configs/config_PFC3D_TNO3d.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/configs/config_PFC3D_TNO3d.py	(date 1753601090884)
++@@ -43,26 +43,21 @@
++ # Network Parameters
++ nTrain = 1200
++ nTest = 300
++-batch_size = 50 # 100
++-learning_rate = 0.005
+++batch_size = 20 #50# 100
+++learning_rate = 0.001 # 0.005
++ weight_decay = 1e-4 # 1e-4
++-epochs = 50
+++epochs = 30 # 20 # 50
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 #12
++ width = 12 # 16 # 32
++ width_q = width # 32
++ width_h = width//2 # 16
++-n_layers = 4
++-
++-'''
++-tau = 315;
++-alpha = 115; 
++-'''
+++n_layers = 2 # 4
++ 
++ # Discretization
++ s = 32 # 64 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -71,14 +66,44 @@
++ 
++ # Database
++ parent_dir = './data/'
++-matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
+++
++ # Plotting
++-index = 200  # 110  # 200
++-domain = [-np.pi, np.pi]
+++index = 69  # 110  # 200
+++Lx = 10*np.pi
+++domain = [-5*np.pi, 5*np.pi]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ # time_steps = [0, 2, 4, 6, 8, 9]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.005 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: main.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import os\nimport importlib\nimport torch\nimport inspect\nimport numpy as np\nimport matplotlib\n\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom training import train_fno, train_fno_time, train_hybrid, compute_initial_loss_scaler\nfrom torch.utils.data import DataLoader, random_split\nfrom utilities import ImportDataset, count_params, LpLoss, ModelEvaluator\nfrom post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \\\n    make_video, save_vtk, plot_xy_plane_subplots\nimport time  # Import the time module at the beginning of the script\nfrom torch_optimizer import Lamb\n\n################################################################\n# Problem Definition\n################################################################\n# problem = 'AC2D'\n# problem = 'AC3D'\n# problem = 'CH2DNL'\n# problem = 'SH2D'\nproblem = 'SH3D'\n# problem = 'PFC2D'\n# problem = 'PFC3D'\n# problem = 'MBE2D'\n# problem = 'MBE3D'\n# problem = 'CH2D'\n# problem = 'CH3D'\n\n# network_name = 'TNO2d'\n# network_name = 'FNO2d'\n#network_name = 'FNO3d'\nnetwork_name = 'TNO3d'\n\nPINN_MODE =  True #False #  False #  False  # False #\n\nprint(f\"problem = {problem}\")\nprint(f\"network = {network_name}\")\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\")  # configuration file\n# above line means: import configs.config_PFC3D_TNO3d as cf\nnetwork = getattr(importlib.import_module('networks'), network_name)  # from networks import TNO3d\ntorch.manual_seed(cf.torch_seed)\nnp.random.seed(cf.numpy_seed)\n# device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')\ndevice = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)\n# --- Define Output Directory ---\n\n\nPDE_WEIGHT = cf.pde_weight\n#PDE_LOSS_SCALER = cf.pde_loss_scaler\n\nif PINN_MODE:\n    run_descriptor = f\"PINN_w{int(PDE_WEIGHT * 100)}\"\n    output_subdir = f\"plots_Data_Physics_{network_name}\"  # Specific PINN output\nelse:\n    run_descriptor = \"DataDriven\"\n    output_subdir = f\"plots_{network_name}\"  # Original data-driven output\n\n# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'\n# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_SH3D_random_sphere_finial.pt'\nmodel_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d.pt'\nmodel_dir = os.path.join(problem, 'models')  # models_smpooth\nmodel_name = f'{model_run_name}'\nmodel_path = os.path.join(model_dir, model_name)\n\nplot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir\nos.makedirs(model_dir, exist_ok=True)\nos.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists\n\nprint(f\"Model Run Name: {model_run_name}\")\nprint(f\"Model Path: {model_path}\")\nprint(f\"Plot Directory: {plot_dir}\")\n\n# width_q = 32\nstart_time = time.time()\n\n################################################################\n# load data and data normalization\n################################################################\n# model_dir = problem + '/models'\n\nprint(f\"model = {model_name}\")\nprint(f\"number of epoch = {cf.epochs}\")\nprint(f\"batch size = {cf.batch_size}\")\nprint(f\"nTrain = {cf.nTrain}\")\nprint(f\"nTest = {cf.nTest}\")\nprint(f\"learning_rate = {cf.learning_rate}\")\nprint(f\"n_layers = {cf.n_layers}\")\nprint(f\"width_q = {cf.width_q}\")\nprint(f\"width_h = {cf.width_h}\")\n\nmodel_path = os.path.join(model_dir, model_name)\nos.makedirs(model_dir, exist_ok=True)\n# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\ntrain_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])\n# to see train_dataset values: print(\"train_dataset subset:\", [train_dataset[i] for i in range(len(train_dataset))])\nnormalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)\n\n############AA####################################################\n# training and evaluation\n################################################################\nsig = inspect.signature(network.__init__)\nrequired_args = [param.name for param in sig.parameters.values()\n                 if param.default == inspect.Parameter.empty and param.name != \"self\"]\nif network_name == 'FNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'FNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(\n        device)\nelse:\n    raise Exception(\"network_name is not correct\")\n\nprint(count_params(model))  # Print model parameters\ntrain_mse_log, train_l2_log, test_l2_log = [], [], []  # Initialize logs\n\n# Load the entire model and logs\nif os.path.exists(model_path) and cf.load_model:\n    print(f\"Loading pre-trained model from {model_path}\")\n    checkpoint = torch.load(model_path, map_location=device)\n    model = checkpoint['model']\n    train_mse_log = checkpoint.get('train_mse_log', [])\n    train_l2_log = checkpoint.get('train_l2_log', [])\n    test_l2_log = checkpoint.get('test_l2_log', [])\nelse:\n    print(\"No pre-trained model loaded. Initializing a new model.\")\n\n# Define optimizer, scheduler, and loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)\nmyloss = LpLoss(p=2, l1_weight=0.0, size_average=False)\n\n# COMPUTE THE DYNAMIC SCALER\n# Use the train_loader to get a representative batch\n\n\n# Train the model\nif cf.training:\n    print(\"\\n--- Starting Training ---\")\n    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)\n        grid_info = {\n            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,\n            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,\n            'dt_model': cf.dt_model,\n            'T_out': cf.T_out\n        }\n\n        pde_loss_scaler = compute_initial_loss_scaler(\n            model,\n            train_loader,\n            myloss,\n            cf.normalized,\n            normalizers,\n            device,\n            grid_info,\n            cf.epsilon,\n            problem\n        )\n\n\n        if PDE_WEIGHT == 0.0:\n            print(\"Running PINN training loop with pde_weight=0 (Data-Driven only loss).\")\n        else:\n            print(\n                f\"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {pde_loss_scaler:.2e}\")\n\n        model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (\n            train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                         optimizer, scheduler, cf.normalized, normalizers, device,\n                         PDE_WEIGHT, grid_info, cf.epsilon, problem,\n                         pde_loss_scaler=pde_loss_scaler)\n        )\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model': model,\n            'train_mse_log': train_mse_hybrid_log,\n            'train_l2_log': train_l2_hybrid_log,\n            'test_l2_log': test_data_log,\n            'test_pde_scaled_log': test_pde_loss_scaled_log,\n            'train_data_log': train_data_log,\n            'train_pde_scaled_log': train_pde_scaled_log,\n            'test_loss_hybrid_log': test_loss_hybrid_log\n        }, model_path)\n\n    else:  # Original Data-Driven Mode\n        if network_name == 'FNO2d' or network_name == 'FNO3d':\n            model, train_l2_log, test_l2_log = (\n                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                               optimizer, scheduler, cf.normalized, normalizers, device))\n            train_mse_log = []\n        else:\n            model, train_mse_log, train_l2_log, test_l2_log = (\n                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                          optimizer, scheduler, cf.normalized, normalizers, device))\n\n    print(f\"Saving model and logs to {model_path}\")\n    torch.save({\n        'model': model,\n        'train_mse_log': train_mse_log,\n        'train_l2_log': train_l2_log,\n        'test_l2_log': test_l2_log\n    }, model_path)\n\nend_time = time.time()\nFinal_time = round(end_time - start_time, 2)\nprint(f\"Total Execution Time: {Final_time} seconds\")\n\nevaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,\n                           time_history=(network_name == 'FNO2d'))\n\nresults = evaluator.evaluate(loss_fn=myloss)\ninp = results['input']\npred = results['prediction']\nexact = results['exact']\ntest_l2_avg = results[\"average\"]\n\nif PINN_MODE:\n    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log,\n              train_pde_scaled_log]\n    labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\nelse:\n    losses = [train_l2_log, test_l2_log]\n    labels = ['Train L2', 'Test L2']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\n\n################################################################\n# post-processing\n################################################################\na_ind = inp[cf.index]\nu_pred = pred[cf.index]\nu_exact = exact[cf.index]\nerror = u_pred - u_exact\n\nprint(f\"DEBUG: Shape of u_exact passed to plotting function: {u_exact.shape}\")\nprint(f\"DEBUG: Shape of u_pred passed to plotting function: {u_pred.shape}\")\n\nplot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]\n\n# =========================================================================================\n# ===                START OF MODIFIED PLOTTING PREPARATION BLOCK                      ===\n# =========================================================================================\n\n# 1. Get the initial condition (t=0) data for the chosen sample index\na_ind = inp[cf.index]\nprint(f\"Shape of initial condition (t=0) data 'a_ind': {a_ind.shape}\")\n\n# 2. Separate desired times into t=0 vs. future predictions\ndesired_times = cf.time_steps\nfuture_times_to_plot = []\nhas_initial_condition = (0 in desired_times)\nfor t in desired_times:\n    if t > 0:\n        future_times_to_plot.append(t)\n\n# 3. Translate the FUTURE times to array indices\nindices_to_plot = []\nvalid_future_times = []\nfor t in future_times_to_plot:\n    if t <= cf.T_out:\n        indices_to_plot.append(t - 1)\n        valid_future_times.append(t)\n    else:\n        print(f\"Warning: Time t={t} is out of valid prediction range. Skipping.\")\nprint(f\"Plotting for future times: {valid_future_times} --> which correspond to array indices: {indices_to_plot}\")\n\n# 4. MOVE ALL DATA TO THE TARGET DEVICE BEFORE OPERATIONS\nt0_data_cpu = a_ind\nu_exact_cpu = u_exact\nu_pred_cpu = u_pred\nerror_cpu = error\n\nt0_data_gpu = t0_data_cpu.to(device)\nu_exact_gpu = u_exact_cpu.to(device)\nu_pred_gpu = u_pred_cpu.to(device)\nerror_gpu = error_cpu.to(device)\nindices_tensor_gpu = torch.tensor(indices_to_plot, device=device)\n\n# 5. PREPARE COMBINED TENSORS FOR PLOTTING on the GPU\nif has_initial_condition:\n    # --- ### FIXED DIMENSION HANDLING ### ---\n    # `a_ind` has shape (sx, sy, sz, 1) where the last dim is a channel.\n    # `u_exact_gpu` has shape (sx, sy, sz, T) where the last dim is time.\n    # They are both 4D, so we can concatenate them directly if the last dimension is treated as the time dimension.\n    # We don't need to do any reshaping. `t0_data_gpu` is already correct.\n    t0_for_concat = t0_data_gpu\n\n    # Select the future time slices from the GPU tensors\n    u_exact_selected = u_exact_gpu.index_select(-1, indices_tensor_gpu)\n    u_pred_selected = u_pred_gpu.index_select(-1, indices_tensor_gpu)\n    error_selected = error_gpu.index_select(-1, indices_tensor_gpu)\n\n    # Combine t=0 data with the selected future steps\n    u_exact_for_plot = torch.cat((t0_for_concat, u_exact_selected), dim=-1)\n    u_pred_for_plot = torch.cat((t0_for_concat, u_pred_selected), dim=-1)\n\n    # The error for t=0 is zero by definition\n    error_t0 = torch.zeros_like(t0_for_concat)\n    error_for_plot = torch.cat((error_t0, error_selected), dim=-1)\n\n    final_indices = list(range(len(desired_times)))\n    final_labels = desired_times\nelse:\n    u_exact_for_plot = u_exact_gpu\n    u_pred_for_plot = u_pred_gpu\n    error_for_plot = error_gpu\n    final_indices = indices_to_plot\n    final_labels = valid_future_times\n\nprint(f\"Final data prepared for plotting with shape: {u_exact_for_plot.shape}\")\nprint(f\"Final indices for plotting: {final_indices}\")\nprint(f\"Final labels for plotting: {final_labels}\")\n\n# Plot XY-plane for the \"Exact\" solution trajectory (includes t=0)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=u_exact_for_plot,\n                       field_name='Exact Solution',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[0],\n                       problem=problem,\n                       network_name=network_name)\n\n# Plot XY-plane for the \"Predicted\" solution trajectory (includes t=0 from input)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=u_pred_for_plot,\n                       field_name='Predicted Solution',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[1],\n                       problem=problem,\n                       network_name=network_name)\n\n# Plot XY-plane for the \"Error\" (error is 0 at t=0)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=error_for_plot,\n                       field_name='Error',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[2],\n                       problem=problem,\n                       network_name=network_name)\n\n# Calculate L2 norm on original full prediction\nl2_norm_error = torch.norm(u_pred - u_exact, p=2)\nl2_norm_exact = torch.norm(u_exact, p=2)\nepsilon = 1e-8\nif l2_norm_exact.item() > epsilon:\n    relative_l2_error = l2_norm_error / l2_norm_exact\nelse:\n    relative_l2_error = torch.tensor(0.0) if l2_norm_error.item() < epsilon else torch.tensor(float('inf'))\n\nprint(f\"L2 norm of error: {l2_norm_error.item()}\")\nprint(f\"L2 norm of exact solution: {l2_norm_exact.item()}\")\nprint(f\"Relative L2 norm error: {relative_l2_error.item()}\")\nrelative_l2_error_percentage = (relative_l2_error * 100)\nprint(f\"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%\")\n\n# Call the combined results plots with the prepared data\nplot_combined_results(\n    domain=cf.domain,\n    u_exact=u_exact_for_plot,\n    u_pred=u_pred_for_plot,\n    error=error_for_plot,\n    plot_ranges=plot_range,\n    problem=problem,\n    network_name=network_name,\n    plot_dir=plot_dir,\n    pde_weight=PDE_WEIGHT,\n    time_steps_indices=final_indices,\n    desired_times=final_labels\n)\n\nplot_combined_results_3d(\n    domain=cf.domain,\n    u_exact=u_exact_for_plot,\n    u_pred=u_pred_for_plot,\n    error=error_for_plot,\n    plot_ranges=plot_range,\n    problem=problem,\n    network_name=network_name,\n    plot_dir=plot_dir,\n    pde_weight=PDE_WEIGHT,\n    time_steps_indices=final_indices,\n    desired_times=final_labels\n)\n\n# =========================================================================================\n# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===\n# =========================================================================================\n\n################################################################\n# Save Results to MATLAB .mat file\n################################################################\nprint(\"\\n--- Saving Results to .mat File ---\")\nimport scipy.io\n\nmat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')\n\nif PINN_MODE:\n    try:\n        results_dict = {\n            'train_mse_log': train_mse_hybrid_log,\n            'train_hybrid_loss': np.array(train_l2_hybrid_log),\n            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),\n            'train_data_log': np.array(train_data_log),\n            'test_data_log': np.array(test_data_log),\n            'train_pde_scaled_log': np.array(train_pde_scaled_log),\n            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,\n            'config_pde_loss_scaler': pde_loss_scaler if PINN_MODE else 0.0,\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\nelse:\n    try:\n        results_dict = {\n            'train_mse_log': np.array(train_mse_log),\n            'train_l2_log': np.array(train_l2_log),\n            'test_l2_log': np.array(test_l2_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\n\nprint(\"\\n--- Script Finished ---\")
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/main.py b/main.py
++--- a/main.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/main.py	(date 1753977480572)
++@@ -4,108 +4,122 @@
++ import inspect
++ import numpy as np
++ import matplotlib
+++import h5py  # MODIFIED: Added h5py import
+++import scipy.io
++ 
++ matplotlib.use('TkAgg')
++ import matplotlib.pyplot as plt
++ import torch.nn.functional as F
++-from training import train_fno, train_fno_time, train_hybrid, compute_initial_loss_scaler
+++from training import train_fno, train_fno_time, train_hybrid, train_fno4d
++ from torch.utils.data import DataLoader, random_split
++-from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator
+++from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator, SobolevLoss
++ from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \
++     make_video, save_vtk, plot_xy_plane_subplots
++-import time  # Import the time module at the beginning of the script
+++import time
++ from torch_optimizer import Lamb
++ 
+++################################################################
+++# Problem Definition
+++################################################################
+++
++ ################################################################
++ # Problem Definition
++ ################################################################
++ # problem = 'AC2D'
++-# problem = 'AC3D'
+++problem = 'AC3D'
++ # problem = 'CH2DNL'
++ # problem = 'SH2D'
++-problem = 'SH3D'
+++#problem = 'SH3D'
++ # problem = 'PFC2D'
++-# problem = 'PFC3D'
+++#problem = 'PFC3D'
++ # problem = 'MBE2D'
++-# problem = 'MBE3D'
+++#problem = 'MBE3D'
++ # problem = 'CH2D'
++-# problem = 'CH3D'
+++#problem = 'CH3D'
++ 
++ # network_name = 'TNO2d'
++ # network_name = 'FNO2d'
++ #network_name = 'FNO3d'
+++#network_name = 'FNO4d'
++ network_name = 'TNO3d'
++ 
++-PINN_MODE =  True #False #  False #  False  # False #
+++PINN_MODE =  False # True #  True #  False #  True #   True #    True #
+++#  False #    True # False #  False  # False #
++ 
++ print(f"problem = {problem}")
++ print(f"network = {network_name}")
++ os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
++-cf = importlib.import_module(f"configs.config_{problem}_{network_name}")  # configuration file
++-# above line means: import configs.config_PFC3D_TNO3d as cf
++-network = getattr(importlib.import_module('networks'), network_name)  # from networks import TNO3d
+++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+++network = getattr(importlib.import_module('networks'), network_name)
++ torch.manual_seed(cf.torch_seed)
++ np.random.seed(cf.numpy_seed)
++-# device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')
++-device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
+++device = torch.device("cuda:2" if torch.cuda.is_available() else "cpu")
++ print("Device: ", device)
++-# --- Define Output Directory ---
++-
++ 
++ PDE_WEIGHT = cf.pde_weight
++-#PDE_LOSS_SCALER = cf.pde_loss_scaler
+++pde_loss_scaler = cf.pde_loss_scaler
++ 
++ if PINN_MODE:
++     run_descriptor = f"PINN_w{int(PDE_WEIGHT * 100)}"
++-    output_subdir = f"plots_Data_Physics_{network_name}"  # Specific PINN output
+++    output_subdir = f"plots_Data_Physics_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_Hybrid_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
++ else:
++     run_descriptor = "DataDriven"
++-    output_subdir = f"plots_{network_name}"  # Original data-driven output
+++    output_subdir = f"plots_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
++ 
++-# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'
++-# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_SH3D_random_sphere_finial.pt'
++-model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d.pt'
++-model_dir = os.path.join(problem, 'models')  # models_smpooth
+++model_dir = os.path.join(problem, 'models')
++ model_name = f'{model_run_name}'
++ model_path = os.path.join(model_dir, model_name)
++-
++-plot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir
+++plot_dir = os.path.join(problem, output_subdir)
++ os.makedirs(model_dir, exist_ok=True)
++-os.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists
+++os.makedirs(plot_dir, exist_ok=True)
++ 
++ print(f"Model Run Name: {model_run_name}")
++ print(f"Model Path: {model_path}")
++ print(f"Plot Directory: {plot_dir}")
++ 
++-# width_q = 32
++ start_time = time.time()
++ 
++ ################################################################
++ # load data and data normalization
++ ################################################################
++-# model_dir = problem + '/models'
++-
++-print(f"model = {model_name}")
++-print(f"number of epoch = {cf.epochs}")
++-print(f"batch size = {cf.batch_size}")
++-print(f"nTrain = {cf.nTrain}")
++-print(f"nTest = {cf.nTest}")
++-print(f"learning_rate = {cf.learning_rate}")
++-print(f"n_layers = {cf.n_layers}")
++-print(f"width_q = {cf.width_q}")
++-print(f"width_h = {cf.width_h}")
++-
++-model_path = os.path.join(model_dir, model_name)
++-os.makedirs(model_dir, exist_ok=True)
++-# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf
++-dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++# MODIFIED: Added special handling for SH3D dataset loading
+++try:
+++    dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++    if problem == 'SH3D':
+++        print("SH3D dataset detected - applying special handling")
+++        # Verify dataset sizes
+++        sample = dataset[0][0]  # Get first sample
+++        print(f"SH3D sample shape: {sample.shape}, dtype: {sample.dtype}")
+++        print(f"SH3D stats - mean: {sample.mean():.4f}, std: {sample.std():.4f}")
+++except Exception as e:
+++    print(f"Error loading dataset: {e}")
+++    raise
++ 
++ train_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])
++-# to see train_dataset values: print("train_dataset subset:", [train_dataset[i] for i in range(len(train_dataset))])
++ normalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None
++ 
++-train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
++-test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++train_loader = DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
+++test_loader = DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++
+++
+++# ==================== CODE TO INSPECT BATCH SHAPE ====================
+++print("\n" + "="*50)
+++print("Inspecting DataLoader Batch Shapes")
+++print("="*50)
+++# Get one batch of data from the train_loader
+++try:
+++    x_batch, y_batch = next(iter(train_loader))
+++    # Print the shape of the batch
+++    # This will be (batch_size, S, S, S, T_in) for input
+++    # and (batch_size, S, S, S, T_out) for target
+++    print(f"Shape of an input batch from DataLoader: {x_batch.shape}")
+++    print(f"Shape of a target batch from DataLoader: {y_batch.shape}")
+++except StopIteration:
+++    print("Train loader is empty. Cannot retrieve a batch.")
+++print("="*50 + "\n")
+++# =======================================================================
++ 
++ ############AA####################################################
++ # training and evaluation
++@@ -122,6 +136,19 @@
++ elif network_name == 'TNO3d':
++     model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(
++         device)
+++elif network_name == 'FNO4d':
+++    model = network(
+++        modes1=cf.modes,
+++        modes2=cf.modes,
+++        modes3=cf.modes,
+++        modes4_internal =1, # cf.modes_t, # MUST BE 1
+++        width=cf.width,
+++        width_q=cf.width_q,
+++        T_in_channels=cf.T_in,
+++        n_layers=cf.n_layers
+++    ).to(device)
+++
+++
++ else:
++     raise Exception("network_name is not correct")
++ 
++@@ -142,7 +169,10 @@
++ # Define optimizer, scheduler, and loss function
++ optimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)
++ scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)
++-myloss = LpLoss(p=2, l1_weight=0.0, size_average=False)
+++myloss = LpLoss(p=2, l1_weight=0.1, size_average=False) # size_average=True # False
+++# NEW: Instantiate SobolevLoss instead of LpLoss
+++# You can tune grad_weight. A good starting point is 0.1 or 1.0.
+++#myloss = SobolevLoss(d=3, p=2, grad_weight=0.1)
++ 
++ # COMPUTE THE DYNAMIC SCALER
++ # Use the train_loader to get a representative batch
++@@ -159,19 +189,6 @@
++             'T_out': cf.T_out
++         }
++ 
++-        pde_loss_scaler = compute_initial_loss_scaler(
++-            model,
++-            train_loader,
++-            myloss,
++-            cf.normalized,
++-            normalizers,
++-            device,
++-            grid_info,
++-            cf.epsilon,
++-            problem
++-        )
++-
++-
++         if PDE_WEIGHT == 0.0:
++             print("Running PINN training loop with pde_weight=0 (Data-Driven only loss).")
++         else:
++@@ -203,6 +220,13 @@
++                 train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                                optimizer, scheduler, cf.normalized, normalizers, device))
++             train_mse_log = []
+++        elif network_name == 'FNO4d':
+++
+++            model, train_mse_log, train_l2_log, test_l2_log = (  # Add val logs
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++            # train_fno4d = train_fno
++         else:
++             model, train_mse_log, train_l2_log, test_l2_log = (
++                 train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++@@ -216,14 +240,129 @@
++         'test_l2_log': test_l2_log
++     }, model_path)
++ 
+++
+++'''
+++# Train the model
+++if cf.training:
+++    print("\n--- Starting Training ---")
+++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
+++        grid_info = {
+++            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
+++            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
+++            'dt_model': cf.dt_model,
+++            'T_out': cf.T_out
+++        }
+++
+++        # --- NEW: Define the two stages for the training curriculum ---
+++        epochs_stage1 = 10
+++        scaler_stage1 = 1e-4
+++
+++        # Calculate remaining epochs for stage 2
+++        epochs_stage2 = cf.epochs - epochs_stage1
+++        scaler_stage2 = 1e-6
+++
+++        # --- Stage 1 Training ---
+++        print("\n--- Starting Training Stage 1 ---")
+++        print(f"Epochs: {epochs_stage1}, PDE Scaler: {scaler_stage1:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++        # Note: The 'model' object is updated in-place by the function call
+++        model, train_mse_s1, train_l2_s1, test_data_s1, test_pde_s1, train_data_s1, train_pde_scl_s1, test_loss_s1 = (
+++            train_hybrid(model, myloss, epochs_stage1, cf.batch_size, train_loader, test_loader,
+++                         optimizer, scheduler, cf.normalized, normalizers, device,
+++                         PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                         pde_loss_scaler=scaler_stage1)
+++        )
+++
+++        # --- Stage 2 Training (if there are remaining epochs) ---
+++        if epochs_stage2 > 0:
+++            print("\n--- Starting Training Stage 2 ---")
+++            print(f"Epochs: {epochs_stage2}, PDE Scaler: {scaler_stage2:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++            model, train_mse_s2, train_l2_s2, test_data_s2, test_pde_s2, train_data_s2, train_pde_scl_s2, test_loss_s2 = (
+++                train_hybrid(model, myloss, epochs_stage2, cf.batch_size, train_loader, test_loader,
+++                             optimizer, scheduler, cf.normalized, normalizers, device,
+++                             PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                             pde_loss_scaler=scaler_stage2)
+++            )
+++
+++            # Combine the logs from both stages for plotting and saving
+++            train_mse_hybrid_log = train_mse_s1 + train_mse_s2
+++            train_l2_hybrid_log = train_l2_s1 + train_l2_s2
+++            test_data_log = test_data_s1 + test_data_s2
+++            test_pde_loss_scaled_log = test_pde_s1 + test_pde_s2
+++            train_data_log = train_data_s1 + train_data_s2
+++            train_pde_scaled_log = train_pde_scl_s1 + train_pde_scl_s2
+++            test_loss_hybrid_log = test_loss_s1 + test_loss_s2
+++        else:
+++            # If only stage 1 was run, the final logs are just the stage 1 logs
+++            train_mse_hybrid_log = train_mse_s1
+++            train_l2_hybrid_log = train_l2_s1
+++            test_data_log = test_data_s1
+++            test_pde_loss_scaled_log = test_pde_s1
+++            train_data_log = train_data_s1
+++            train_pde_scaled_log = train_pde_scl_s1
+++            test_loss_hybrid_log = test_loss_s1
+++
+++        print(f"\n--- Training Finished. Saving model and logs to {model_path} ---")
+++        # The torch.save call remains the same, as the log variables have been correctly prepared
+++        torch.save({
+++            'model': model,
+++            'train_mse_log': train_mse_hybrid_log,
+++            'train_l2_log': train_l2_hybrid_log,
+++            'test_l2_log': test_data_log, # 'test_l2_log' is used by evaluator, it should contain data loss
+++            'test_pde_scaled_log': test_pde_loss_scaled_log,
+++            'train_data_log': train_data_log,
+++            'train_pde_scaled_log': train_pde_scaled_log,
+++            'test_loss_hybrid_log': test_loss_hybrid_log
+++        }, model_path)
+++
+++    else:  # Original Data-Driven Mode (This part remains unchanged)
+++        if network_name == 'FNO2d' or network_name == 'FNO3d':
+++            model, train_l2_log, test_l2_log = (
+++                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                               optimizer, scheduler, cf.normalized, normalizers, device))
+++            train_mse_log = []
+++        else:
+++            model, train_mse_log, train_l2_log, test_l2_log = (
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++        print(f"Saving model and logs to {model_path}")
+++        torch.save({
+++            'model': model,
+++            'train_mse_log': train_mse_log,
+++            'train_l2_log': train_l2_log,
+++            'test_l2_log': test_l2_log
+++        }, model_path)
+++'''
+++
++ end_time = time.time()
++ Final_time = round(end_time - start_time, 2)
++ print(f"Total Execution Time: {Final_time} seconds")
++ 
+++# ==================== START: CAPTURE PREDICTION AND EXACT SOLUTION TIMES ====================
+++print("\n--- Evaluating Model and Measuring Prediction Time ---")
++ evaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,
++                            time_history=(network_name == 'FNO2d'))
++ 
+++# Measure the time it takes to get predictions for the entire test set
+++prediction_start_time = time.time()
++ results = evaluator.evaluate(loss_fn=myloss)
+++prediction_end_time = time.time()
+++
+++# Calculate the model's prediction time
+++model_prediction_time = prediction_end_time - prediction_start_time
+++print(f"Model prediction time for the test set: {model_prediction_time:.4f} seconds")
+++
+++# IMPORTANT: Placeholder for the exact solution time.
+++# This value MUST be updated manually with the time it took the numerical
+++# solver to generate the ground truth data for the test set.
+++# The value here is just an example.
+++exact_solution_time = 3600.0  # Placeholder in seconds (e.g., 1 hour)
+++print(f"Using placeholder for exact solution time: {exact_solution_time:.2f} seconds. PLEASE UPDATE THIS VALUE.")
+++# ===================== END: CAPTURE PREDICTION AND EXACT SOLUTION TIMES =====================
+++
+++
++ inp = results['input']
++ pred = results['prediction']
++ exact = results['exact']
++@@ -326,7 +465,89 @@
++ print(f"Final indices for plotting: {final_indices}")
++ print(f"Final labels for plotting: {final_labels}")
++ 
+++
+++# =========================================================================================
+++# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===
+++# =========================================================================================
+++
+++################################################################
+++# Save Results to MATLAB .mat file
+++################################################################
+++print("\n--- Saving Results to .mat File ---")
+++mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
+++
+++# MODIFIED: Enhanced saving logic with fallbacks
+++def save_results(mat_filename, results_dict):
+++    try:
+++        # First try standard save
+++        scipy.io.savemat(mat_filename, results_dict)
+++        print(f"Saved with standard format to {mat_filename}")
+++    except ValueError as e:
+++        if "Format should be '4' or '5'" in str(e):
+++            print("Large data detected, trying v7.3 format...")
+++            try:
+++                scipy.io.savemat(mat_filename, results_dict, format='v7.3')
+++                print(f"Saved with v7.3 format to {mat_filename}")
+++            except Exception as e:
+++                print(f"v7.3 failed: {e}")
+++                # Fallback to HDF5
+++                h5_filename = mat_filename.replace('.mat', '.h5')
+++                with h5py.File(h5_filename, 'w') as f:
+++                    for k, v in results_dict.items():
+++                        f.create_dataset(k, data=v, compression='gzip')
+++                print(f"Saved as HDF5 to {h5_filename}")
+++        else:
+++            raise
+++
+++if PINN_MODE:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_hybrid_log, dtype=np.float32),  # MODIFIED: Added dtype
+++        'train_hybrid_loss': np.array(train_l2_hybrid_log, dtype=np.float32),
+++        'test_loss_hybrid_log': np.array(test_loss_hybrid_log, dtype=np.float32),
+++        'train_data_log': np.array(train_data_log, dtype=np.float32),
+++        'test_data_log': np.array(test_data_log, dtype=np.float32),
+++        'train_pde_scaled_log': np.array(train_pde_scaled_log, dtype=np.float32),
+++        'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),  # MODIFIED: Added astype
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_pde_weight': np.float32(PDE_WEIGHT),
+++        'config_pde_loss_scaler': np.float32(pde_loss_scaler),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++        'model_prediction_time': np.float32(model_prediction_time),  # ADDED
+++        'exact_solution_time': np.float32(exact_solution_time),      # ADDED
+++    }
+++else:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_log, dtype=np.float32),
+++        'train_l2_log': np.array(train_l2_log, dtype=np.float32),
+++        'test_l2_log': np.array(test_l2_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++        'model_prediction_time': np.float32(model_prediction_time),  # ADDED
+++        'exact_solution_time': np.float32(exact_solution_time),      # ADDED
+++    }
+++
+++# MODIFIED: Use the new save function
+++save_results(mat_filename, results_dict)
+++
++ # Plot XY-plane for the "Exact" solution trajectory (includes t=0)
+++
+++'''
++ plot_xy_plane_subplots(domain=cf.domain,
++                        field=u_exact_for_plot,
++                        field_name='Exact Solution',
++@@ -355,6 +576,7 @@
++                        plot_range=plot_range[2],
++                        problem=problem,
++                        network_name=network_name)
+++'''
++ 
++ # Calculate L2 norm on original full prediction
++ l2_norm_error = torch.norm(u_pred - u_exact, p=2)
++@@ -400,65 +622,4 @@
++     desired_times=final_labels
++ )
++ 
++-# =========================================================================================
++-# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===
++-# =========================================================================================
++-
++-################################################################
++-# Save Results to MATLAB .mat file
++-################################################################
++-print("\n--- Saving Results to .mat File ---")
++-import scipy.io
++-
++-mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
++-
++-if PINN_MODE:
++-    try:
++-        results_dict = {
++-            'train_mse_log': train_mse_hybrid_log,
++-            'train_hybrid_loss': np.array(train_l2_hybrid_log),
++-            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),
++-            'train_data_log': np.array(train_data_log),
++-            'test_data_log': np.array(test_data_log),
++-            'train_pde_scaled_log': np.array(train_pde_scaled_log),
++-            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,
++-            'config_pde_loss_scaler': pde_loss_scaler if PINN_MODE else 0.0,
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-else:
++-    try:
++-        results_dict = {
++-            'train_mse_log': np.array(train_mse_log),
++-            'train_l2_log': np.array(train_l2_log),
++-            'test_l2_log': np.array(test_l2_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-
++ print("\n--- Script Finished ---")
++\ No newline at end of file
++Index: run_interface3.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport numpy as np\nimport importlib\nfrom utilities import ImportDataset\nimport matplotlib\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom skimage import measure\nfrom matplotlib.colors import LightSource\n\n# Load model\ndevice = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n\n#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6.pt'\n\nmodel_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'\n\n# Option 1 (Recommended secure approach)\ntry:\n    from networks import TNO3d  # Import your custom network class\n    torch.serialization.add_safe_globals([TNO3d])\n    checkpoint = torch.load(model_path, map_location=device, weights_only=True)\nexcept Exception as e:\n    print(f\"Secure loading failed: {e}\\nFalling back to weights_only=False\")\n    # Option 2 (Less secure fallback)\n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n\nmodel = checkpoint['model']\nmodel.eval()\n\n# Load dataset for normalization\nproblem = 'SH3D'\nnetwork_name = 'TNO3d'\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\")\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\n# Move normalizer parameters to device\ndataset.normalizer_x.mean = dataset.normalizer_x.mean.to(device)\ndataset.normalizer_x.std = dataset.normalizer_x.std.to(device)\ndataset.normalizer_y.mean = dataset.normalizer_y.mean.to(device)\ndataset.normalizer_y.std = dataset.normalizer_y.std.to(device)\n\n\n# Create spherical initial condition\ndef create_sharp_sphere_initial_condition(N=32, radius=2, L=10):\n    x = np.linspace(-L / 2, L / 2, N)\n    y = np.linspace(-L / 2, L / 2, N)\n    z = np.linspace(-L / 2, L / 2, N)\n    xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')\n\n    r = np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)\n    sphere = np.ones((N, N, N), dtype=np.float32)  # Use float32 for consistency\n\n    # Perfectly sharp transition (no smoothing)\n    outer_mask = r > radius\n    sphere[outer_mask] = -1.0\n\n    # Force exact values (no floating point artifacts)\n    sphere = np.where(r <= radius, 1.0, -1.0)\n\n    return sphere\n# Create initial condition with perfect sharp interface\nsphere_ic = create_sharp_sphere_initial_condition()\n\ninput_tensor = torch.from_numpy(sphere_ic).float().unsqueeze(0).unsqueeze(-1).to(device)\ninput_tensor = dataset.normalizer_x.encode(input_tensor)\n\n# Run prediction\nwith torch.no_grad():\n    prediction = model(input_tensor)  # Shape [1, 32, 32, 32, 10]\n    prediction = dataset.normalizer_y.decode(prediction)\n\n# Define your custom frames to display\nselected_frames = [0, 50, 90]  # Adjusted for T_out=10\nnum_frames = len(selected_frames)\n\n# Create figure with two subplots: 3D views and 1D profile\nfig = plt.figure(figsize=(20, 10))\ngrid = plt.GridSpec(2, num_frames, hspace=0.3, wspace=0.2)\n\n# 1. Plot 3D isosurfaces for selected frames\nfor i, t in enumerate(selected_frames):\n    ax = fig.add_subplot(grid[0, i], projection='3d')\n    frame_data = prediction[0, ..., t].cpu().numpy()\n\n    # Print data range for debugging\n    print(f\"Frame {t}: min={np.min(frame_data):.3f}, max={np.max(frame_data):.3f}\")\n\n    # Determine appropriate level\n    data_min, data_max = np.min(frame_data), np.max(frame_data)\n    if data_min > 0 or data_max < 0:\n        level = (data_max + data_min) / 2  # Midpoint if zero is outside range\n    else:\n        level = 0.0  # Default level\n\n    try:\n        # Extract smooth isosurface with adjusted level\n        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level)\n\n        # Apply lighting and coloring\n        ls = LightSource(azdeg=135, altdeg=45)\n        rgb = ls.shade_normals(verts[faces], fraction=0.8)\n\n        mesh = Poly3DCollection(verts[faces],\n                                facecolors=rgb,\n                                edgecolor='none',\n                                alpha=0.9)\n\n        ax.add_collection3d(mesh)\n        plot_success = True\n    except ValueError as e:\n        print(f\"Could not generate isosurface for frame {t}: {e}\")\n        plot_success = False\n        # Display empty plot with error message\n        ax.text(0.5, 0.5, 0.5, f\"No isosurface\\nat level={level:.2f}\",\n                ha='center', va='center', fontsize=10)\n\n    # Set viewing parameters\n    ax.set_xlim(0, frame_data.shape[0])\n    ax.set_ylim(0, frame_data.shape[1])\n    ax.set_zlim(0, frame_data.shape[2])\n    ax.set_title(f'Time = {t}\\nLevel = {level:.2f}', pad=10)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_zticks([])\n    if plot_success:\n        ax.view_init(elev=30, azim=45)\n\n# 2. Plot 1D profile through center for all time steps\nax_profile = fig.add_subplot(grid[1, :])\nL = 10  # Domain size\nx = np.linspace(-L / 2, L / 2, prediction.shape[1])\ncenter_idx = prediction.shape[1] // 2  # Middle of the domain\n\n# Plot profiles for the same custom frames in the profile plot\nfor t in selected_frames:\n    profile = prediction[0, :, center_idx, center_idx, t].cpu().numpy()\n    ax_profile.plot(x, profile, label=f't={t}', alpha=0.8, linewidth=1.5)\n\n# Format profile plot\nax_profile.set_xlabel('Position along x-axis', fontsize=12)\nax_profile.set_ylabel('Field value', fontsize=12)\nax_profile.set_title('1D Profile Evolution Through Domain Center', pad=15)\nax_profile.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nax_profile.grid(True, alpha=0.3)\nax_profile.set_ylim([-1.2, 1.5])  # Match MATLAB y-limits\n\nplt.tight_layout()\nplt.show()\n\n# After getting predictions in Python\nprediction_np = prediction.cpu().numpy()  # Convert to numpy array\n\n# Save to .mat file\nfrom scipy.io import savemat\nsavemat('SH3D_python_predictions.mat', {\n    'python_pred': prediction_np,\n    'selected_frames': np.array(selected_frames),\n    'x': x  # Spatial coordinates\n})
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/run_interface3.py b/run_interface3.py
++--- a/run_interface3.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/run_interface3.py	(date 1754035003634)
++@@ -3,125 +3,374 @@
++ import importlib
++ from utilities import ImportDataset
++ import matplotlib
+++
++ matplotlib.use('TkAgg')
++ import matplotlib.pyplot as plt
++ from mpl_toolkits.mplot3d import Axes3D
++ from mpl_toolkits.mplot3d.art3d import Poly3DCollection
++ from skimage import measure
++ from matplotlib.colors import LightSource
+++from scipy.io import savemat
++ 
+++# ============================================================================
+++# 1. CHOOSE INITIAL CONDITION
+++# ============================================================================
+++# Options: 'sphere', 'dumbbell', 'star', separation, torus, 'heart'
+++initial_condition_type = 'star'  # <-- CHANGE THIS VALUE TO RUN A DIFFERENT SIMULATION
+++print(f"Running simulation for Initial Condition: {initial_condition_type.upper()}")
+++
+++# ============================================================================
+++# 2. MODEL AND DATASET LOADING
+++# ============================================================================
++ # Load model
++ device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")
++ 
++-#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6.pt'
+++# SH3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++
+++# AC3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/AC3D/models/TNO3d_AC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt' # AC3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/AC3D/models/TNO3d_AC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt' # AC3D
+++
+++# CH3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/CH3D/models/TNO3d_CH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++model_path = '/scratch/noqu8762/phase_field_equations_4d/CH3D/models/TNO3d_CH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++
++ 
++-model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++# mixed MBE3d#
+++# model_path = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++# model_path = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
++ 
++-# Option 1 (Recommended secure approach)
+++# No Mixed
+++# model_path ='/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_S32_T1to100_width12_modes14_q12_h6_grf3d_NoMixed.pt'
+++# model_path ='/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d_NoMixed.pt'
+++
+++# PFC (we plotted this)
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/models/TNO3d_PFC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/models/TNO3d_PFC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++
+++
+++
++ try:
++-    from networks import TNO3d  # Import your custom network class
++-    torch.serialization.add_safe_globals([TNO3d])
+++    from networks import TNO3d  # Assuming networks.py and TNO3d are available
+++
+++    # Add builtins.set to safe globals for robust loading
+++    torch.serialization.add_safe_globals([set])
+++    torch.serialization.add_safe_globals([TNO3d])  # Add TNO3d if it's part of the global scope during saving
+++
++     checkpoint = torch.load(model_path, map_location=device, weights_only=True)
++ except Exception as e:
++     print(f"Secure loading failed: {e}\nFalling back to weights_only=False")
++-    # Option 2 (Less secure fallback)
+++    # It's good practice to ensure the safe globals are added even for fallback
+++    torch.serialization.add_safe_globals([set])
+++    torch.serialization.add_safe_globals([TNO3d])
++     checkpoint = torch.load(model_path, map_location=device, weights_only=False)
++ 
++ model = checkpoint['model']
++ model.eval()
++ 
++-# Load dataset for normalization
++-problem = 'SH3D'
+++# Load dataset for normalization AND EXTRACT PROBLEM NAME
+++key_directory = 'phase_field_equations_4d'
+++problem = ''
+++try:
+++    parts = model_path.split('/')
+++    index = parts.index(key_directory)
+++    problem = parts[index + 1]  # This gets the directory name (e.g., 'AC3D')
+++except (ValueError, IndexError):
+++    print(f"Could not automatically determine problem name. Set manually if needed.")
+++
+++print(f"Problem Name Determined: {problem}")
++ network_name = 'TNO3d'
++-cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")  # Assuming configs module is available
++ dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
++ 
++-# Move normalizer parameters to device
++ dataset.normalizer_x.mean = dataset.normalizer_x.mean.to(device)
++ dataset.normalizer_x.std = dataset.normalizer_x.std.to(device)
++ dataset.normalizer_y.mean = dataset.normalizer_y.mean.to(device)
++ dataset.normalizer_y.std = dataset.normalizer_y.std.to(device)
++ 
++ 
++-# Create spherical initial condition
++-def create_sharp_sphere_initial_condition(N=32, radius=2, L=10):
++-    x = np.linspace(-L / 2, L / 2, N)
++-    y = np.linspace(-L / 2, L / 2, N)
++-    z = np.linspace(-L / 2, L / 2, N)
++-    xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')
+++# ============================================================================
+++# 3. CREATE INITIAL CONDITION
+++# ============================================================================
+++def create_initial_condition(ic_type='sphere'):
+++    Nx, Ny, Nz = 0, 0, 0
+++    Lx, Ly, Lz = 0, 0, 0
+++    epsilon = 0
+++    Nt = 0
+++    selected_frames = []
+++    u = None
+++    dt = 0
+++
+++    if ic_type == 'sphere':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        # Lx = 10*np.pi; # PFC3D
+++        #Lx = 5 # AC3D
+++        Lx = 15  # SH3D
+++        Ly = Lx;
+++        Lz = Lx
+++        # epsilon = 0.5 # PFC3D
+++        epsilon = 0.15 # SH3d
+++        #epsilon = 0.1 # AC3d
+++        # dt = 0.0005
+++        dt = 0.05  # SH3D
+++        Nt = 100
+++        selected_frames = [0, 70, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        # radius = 6 # PFC3D
+++        #radius = 0.5 # AC3D
+++        radius = 2.0  # SH3D
+++        interface_width = np.sqrt(2) * epsilon
+++        u = np.tanh((radius - np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)) / interface_width)
+++
+++    elif ic_type == 'dumbbell':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        Lx = 40;
+++        Ly = 20;
+++        Lz = 20
+++        epsilon = 0.005
+++        dt = 0.01
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(0, Lx, Nx)
+++        y_grid = np.linspace(0, Ly, Ny)
+++        z_grid = np.linspace(0, Lz, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        R0 = 0.25
+++        interface_width = np.sqrt(2) * epsilon
+++
+++        r1 = np.sqrt((xx - (0.3 * Lx)) ** 2 + (yy - (0.5 * Ly)) ** 2 + (zz - (0.5 * Lz)) ** 2)
+++        r2 = np.sqrt((xx - (1.7 * Lx)) ** 2 + (yy - (0.5 * Ly)) ** 2 + (zz - (0.5 * Lz)) ** 2)
+++        u_spheres = np.tanh((R0 - r1) / interface_width) + np.tanh((R0 - r2) / interface_width) + 1
+++
+++        bar_mask = (xx > (0.4 * Lx)) & (xx < (1.6 * Lx)) & \
+++                   (yy > (0.4 * Ly)) & (yy < (0.6 * Ly)) & \
+++                   (zz > (0.4 * Lz)) & (zz < (0.6 * Lz))
+++        u = u_spheres
+++        u[bar_mask] = 1.0
+++        u = np.clip(u, -1.0, 1.0)
+++
+++    elif ic_type == 'star':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        #Lx = 5 # AC3D,
+++        #Lx = 10 * np.pi  # --> PFC3D
+++        Lx = 2  # CH3D
+++        Ly = Lx;
+++        Lz = Lx
+++        #epsilon = 0.5  # PFC3D
+++        epsilon = 0.05 # CH3d
+++        dt = 0.005
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++ 
++-    r = np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)
++-    sphere = np.ones((N, N, N), dtype=np.float32)  # Use float32 for consistency
+++        interface_width = np.sqrt(2.0) * epsilon
+++        theta = np.arctan2(zz, xx)
+++        #R_theta = 5.0 + 1.0 * np.cos(6 * theta)  # PFC3D
+++        # R_theta = 0.7 + 0.2 * np.cos(6 * theta)  # AC3D
+++        R_theta = 0.7 + 0.2 * np.cos(6 * theta)  # CH3D
+++        dist = np.sqrt(xx ** 2 + 2 * yy ** 2 + zz ** 2)
+++        u = np.tanh((R_theta - dist) / interface_width)
++ 
++-    # Perfectly sharp transition (no smoothing)
++-    outer_mask = r > radius
++-    sphere[outer_mask] = -1.0
+++    elif ic_type == 'torus':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        # Lx = 10*np.pi;
+++        Lx = 2 * np.pi  # MBE3D
+++        Ly = Lx;
+++        Lz = Lx
+++        # epsilon = 0.5
+++        epsilon = 0.1  # MBE3D
+++        # dt = 0.005
+++        dt = 0.001  # MBE3D
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
++ 
++-    # Force exact values (no floating point artifacts)
++-    sphere = np.where(r <= radius, 1.0, -1.0)
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++ 
++-    return sphere
++-# Create initial condition with perfect sharp interface
++-sphere_ic = create_sharp_sphere_initial_condition()
+++        # R_major = 5.5
+++        # r_minor = 3.5
+++        R_major = 2.1  # MBE3D
+++        r_minor = 0.7  # MBE3D
++ 
++-input_tensor = torch.from_numpy(sphere_ic).float().unsqueeze(0).unsqueeze(-1).to(device)
+++        interface_width = np.sqrt(2) * epsilon
+++        torus_dist = np.sqrt((np.sqrt(xx ** 2 + yy ** 2) - R_major) ** 2 + zz ** 2)
+++        u = np.tanh((r_minor - torus_dist) / interface_width)
+++        # u = np.clip(u, -1.0, 1.0)
+++
+++    elif ic_type == 'separation':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        Lx = 2 * np.pi;
+++        Ly = 2 * np.pi;
+++        Lz = 2 * np.pi
+++        epsilon = 0.5
+++        dt = 0.0005
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        interface_width = np.sqrt(2) * epsilon
+++
+++        r1_dist = np.sqrt((xx + 1) ** 2 + yy ** 2 + zz ** 2)
+++        r2_dist = np.sqrt((xx - 1) ** 2 + yy ** 2 + zz ** 2)
+++
+++        u = np.tanh((1 - r1_dist) / interface_width) + np.tanh((1 - r2_dist) / interface_width)
+++        # u = np.clip(u, -1.0, 1.0)
+++
+++    elif ic_type == 'heart':
+++        Nx = 32
+++        Ny = 32
+++        Nz = 32
+++        Lx = 5.0
+++        Ly = Lx
+++        Lz = Lx
+++        epsilon = 0.15
+++        dt = 0.005  # Assuming a dt similar to other conditions
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        # Equation from image: phi(x,y,z,0) = tanh( ( (x^2 + 9/4*y^2 + z^2 - 1)^3 - x^2*z^3 - 9/80*y^2*z^3 ) / sqrt(2*epsilon) )
+++        denominator = np.sqrt(2 * epsilon)
+++        numerator = (xx ** 2 + (9 / 4) * yy ** 2 + zz ** 2 - 1) ** 3 - xx ** 2 * zz ** 3 - (9 / 80) * yy ** 2 * zz ** 3
+++        u = np.tanh(numerator / denominator)
+++
+++    else:
+++        raise ValueError(f"Unknown initial condition type: {ic_type}")
+++
+++    return u, (Lx, Ly, Lz), (Nx, Ny, Nz), Nt, dt, selected_frames
+++
+++
+++# Create the selected initial condition
+++initial_condition_field, domain_lengths, grid_sizes, Nt, dt, selected_frames = create_initial_condition(
+++    ic_type=initial_condition_type)
+++Lx, Ly, Lz = domain_lengths
+++Nx, Ny, Nz = grid_sizes
+++
+++# ============================================================================
+++# 4. PREDICTION AND VISUALIZATION
+++# ============================================================================
+++# Prepare tensor for the model
+++input_tensor = torch.from_numpy(initial_condition_field).float().unsqueeze(0).unsqueeze(-1).to(device)
++ input_tensor = dataset.normalizer_x.encode(input_tensor)
++ 
++ # Run prediction
++ with torch.no_grad():
++-    prediction = model(input_tensor)  # Shape [1, 32, 32, 32, 10]
+++    # Start timer
+++    start_time = torch.cuda.Event(enable_timing=True)
+++    end_time = torch.cuda.Event(enable_timing=True)
+++
+++    torch.cuda.synchronize()  # Wait for all operations to complete
+++    start_time.record()  # Start recording
+++
+++    prediction = model(input_tensor)
+++
+++    end_time.record()  # Stop recording
+++    torch.cuda.synchronize()  # Wait for all operations to complete
+++
+++    # ==================== MODIFICATION START ====================
+++    # Calculate elapsed time in milliseconds
+++    inference_time_ms = start_time.elapsed_time(end_time)
+++    # Convert milliseconds to seconds for saving
+++    inference_time = inference_time_ms / 1000.0
+++    # ===================== MODIFICATION END =====================
+++
++     prediction = dataset.normalizer_y.decode(prediction)
+++    # Clip the prediction to be within the physical bounds [-1, 1].
+++    #prediction = torch.clamp(prediction, min=-1.0, max=1.0) # SH3d
++ 
++-# Define your custom frames to display
++-selected_frames = [0, 50, 90]  # Adjusted for T_out=10
++-num_frames = len(selected_frames)
+++# ==================== MODIFICATION START ====================
+++# Updated print statement to show both units
+++print(f"Inference time: {inference_time_ms:.3f} milliseconds ({inference_time:.6f} seconds)")
+++# ===================== MODIFICATION END =====================
++ 
++-# Create figure with two subplots: 3D views and 1D profile
+++
+++# Create figure
++ fig = plt.figure(figsize=(20, 10))
++-grid = plt.GridSpec(2, num_frames, hspace=0.3, wspace=0.2)
+++grid = plt.GridSpec(2, len(selected_frames), hspace=0.3, wspace=0.2)
+++fig.suptitle(f"TNO Prediction for {initial_condition_type.upper()} Initial Condition ({problem})", fontsize=16)
++ 
++-# 1. Plot 3D isosurfaces for selected frames
+++# Define mesh coordinates for plotting
+++if initial_condition_type in ['sphere', 'star', 'torus', 'separation', 'heart']:
+++    x_coords = np.linspace(-Lx / 2, Lx / 2, Nx)
+++    x_lim_low, x_lim_high = -Lx / 2, Lx / 2
+++    y_lim_low, y_lim_high = -Ly / 2, Ly / 2
+++    z_lim_low, z_lim_high = -Lz / 2, Lz / 2
+++elif initial_condition_type == 'dumbbell':
+++    x_coords = np.linspace(0, Lx, Nx)
+++    x_lim_low, x_lim_high = 0, Lx
+++    y_lim_low, y_lim_high = 0, Ly
+++    z_lim_low, z_lim_high = 0, Lz
+++
+++# 1. Plot 3D isosurfaces
++ for i, t in enumerate(selected_frames):
++     ax = fig.add_subplot(grid[0, i], projection='3d')
+++
+++    # if t == 0:
+++    #    frame_data = initial_condition_field
+++    #    title_text = f'Initial Condition\nTime = {t}'
+++    # else:
+++    #    frame_data = prediction[0, ..., t].cpu().numpy()
+++    #    title_text = f'Prediction\nTime = {t}'
+++
++     frame_data = prediction[0, ..., t].cpu().numpy()
++-
++-    # Print data range for debugging
++-    print(f"Frame {t}: min={np.min(frame_data):.3f}, max={np.max(frame_data):.3f}")
+++    title_text = f'Prediction\nTime = {t}'
++ 
++-    # Determine appropriate level
++-    data_min, data_max = np.min(frame_data), np.max(frame_data)
++-    if data_min > 0 or data_max < 0:
++-        level = (data_max + data_min) / 2  # Midpoint if zero is outside range
++-    else:
++-        level = 0.0  # Default level
++-
+++    level = 0.0
++     try:
++-        # Extract smooth isosurface with adjusted level
++-        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level)
+++        dx, dy, dz = Lx / (Nx - 1), Ly / (Ny - 1), Lz / (Nz - 1)
+++        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level, spacing=(dx, dy, dz))
++ 
++-        # Apply lighting and coloring
+++        if initial_condition_type in ['sphere', 'star', 'torus', 'separation', 'heart']:
+++            verts[:, 0] -= Lx / 2
+++            verts[:, 1] -= Ly / 2
+++            verts[:, 2] -= Lz / 2
+++
++         ls = LightSource(azdeg=135, altdeg=45)
++-        rgb = ls.shade_normals(verts[faces], fraction=0.8)
++-
++-        mesh = Poly3DCollection(verts[faces],
++-                                facecolors=rgb,
++-                                edgecolor='none',
++-                                alpha=0.9)
++-
+++        mesh = Poly3DCollection(verts[faces], facecolors='gray', edgecolor='none', alpha=0.9)
++         ax.add_collection3d(mesh)
++         plot_success = True
++     except ValueError as e:
++         print(f"Could not generate isosurface for frame {t}: {e}")
+++        ax.text(0.5, 0.5, 0.5, f"No isosurface\nat level={level:.2f}", ha='center', va='center', transform=ax.transAxes)
++         plot_success = False
++-        # Display empty plot with error message
++-        ax.text(0.5, 0.5, 0.5, f"No isosurface\nat level={level:.2f}",
++-                ha='center', va='center', fontsize=10)
++ 
++-    # Set viewing parameters
++-    ax.set_xlim(0, frame_data.shape[0])
++-    ax.set_ylim(0, frame_data.shape[1])
++-    ax.set_zlim(0, frame_data.shape[2])
++-    ax.set_title(f'Time = {t}\nLevel = {level:.2f}', pad=10)
+++    ax.set_xlim(x_lim_low, x_lim_high)
+++    ax.set_ylim(y_lim_low, y_lim_high)
+++    ax.set_zlim(z_lim_low, z_lim_high)
+++    ax.set_title(f'{title_text}\nLevel = {level:.2f}', pad=10)
++     ax.grid(False)
++     ax.set_xticks([])
++     ax.set_yticks([])
++@@ -129,35 +378,76 @@
++     if plot_success:
++         ax.view_init(elev=30, azim=45)
++ 
++-# 2. Plot 1D profile through center for all time steps
+++# 2. Plot 1D profile
++ ax_profile = fig.add_subplot(grid[1, :])
++-L = 10  # Domain size
++-x = np.linspace(-L / 2, L / 2, prediction.shape[1])
++-center_idx = prediction.shape[1] // 2  # Middle of the domain
+++center_y_idx = Ny // 2
+++center_z_idx = Nz // 2
++ 
++-# Plot profiles for the same custom frames in the profile plot
++ for t in selected_frames:
++-    profile = prediction[0, :, center_idx, center_idx, t].cpu().numpy()
++-    ax_profile.plot(x, profile, label=f't={t}', alpha=0.8, linewidth=1.5)
+++    if t == 0:
+++        profile = initial_condition_field[:, center_y_idx, center_z_idx]
+++        label_text = f't={t} (IC)'
+++    else:
+++        profile = prediction[0, :, center_y_idx, center_z_idx, t].cpu().numpy()
+++        label_text = f't={t}'
+++    # profile = prediction[0, :, center_y_idx, center_z_idx, t].cpu().numpy()
+++    # label_text = f't={t}'
++ 
++-# Format profile plot
+++    ax_profile.plot(x_coords, profile, label=label_text, alpha=0.8, linewidth=1.5)
+++
++ ax_profile.set_xlabel('Position along x-axis', fontsize=12)
++ ax_profile.set_ylabel('Field value', fontsize=12)
++ ax_profile.set_title('1D Profile Evolution Through Domain Center', pad=15)
++ ax_profile.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
++ ax_profile.grid(True, alpha=0.3)
++-ax_profile.set_ylim([-1.2, 1.5])  # Match MATLAB y-limits
+++ax_profile.set_ylim([-1.5, 1.5])
++ 
++-plt.tight_layout()
+++plt.tight_layout(rect=[0, 0, 1, 0.96])
++ plt.show()
++ 
++-# After getting predictions in Python
++-prediction_np = prediction.cpu().numpy()  # Convert to numpy array
++ 
++-# Save to .mat file
++-from scipy.io import savemat
++-savemat('SH3D_python_predictions.mat', {
++-    'python_pred': prediction_np,
+++## This is saved the data of initial condition itself
+++# ============================================================================
+++# 5. SAVE RESULTS TO .MAT FILE
+++# ============================================================================
+++# Get the raw prediction tensor from the model as a NumPy array
+++prediction_np = prediction.cpu().numpy()
+++# Create a "hybrid" tensor for saving, ensuring the t=0 slice is the true IC
+++final_prediction_to_save = np.copy(prediction_np)
+++final_prediction_to_save[0, :, :, :, 0] = initial_condition_field
+++# Define the output filename using the 'problem' variable extracted earlier
+++# from the model_path. This makes the filename dynamic.
+++output_filename = f'{problem}_python_predictions_{initial_condition_type}.mat'
+++
+++# ==================== MODIFICATION START ====================
+++# Save the corrected data and the inference time to the .mat file
+++savemat(output_filename, {
+++    'python_pred': final_prediction_to_save,
++     'selected_frames': np.array(selected_frames),
++-    'x': x  # Spatial coordinates
++-})
++\ No newline at end of file
+++    'x': x_coords,
+++    'inference_time': inference_time  # Add the inference time (in seconds)
+++})
+++print(f"Corrected prediction (with true IC at t=0) and inference time saved to {output_filename}")
+++
+++# ===================== MODIFICATION END =====================
+++
+++'''
+++# ============================================================================
+++# 5. SAVE RESULTS TO .MAT FILE
+++# ============================================================================
+++# Get the raw prediction tensor from the model as a NumPy array
+++prediction_np = prediction.cpu().numpy()
+++# The array to save is now just the raw prediction
+++final_prediction_to_save = prediction_np
+++# The line that overwrites t=0 has been removed.
+++output_filename = f'{problem}_python_predictions_{initial_condition_type}.mat'
+++# Save the raw prediction data to the .mat file
+++savemat(output_filename, {
+++    'python_pred': final_prediction_to_save,
+++    'selected_frames': np.array(selected_frames),
+++    'x': x_coords,
+++    'inference_time': inference_time  # Add the inference time (in seconds)
+++})
+++print(f"Raw model prediction saved to {output_filename}")
+++
+++'''
++Index: configs/config_MBE3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\nimport numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 #1600 # 4000\nnTest = 300  # 400\nbatch_size = 50# 25 #100\nlearning_rate = 0.005\nweight_decay = 1e-4\nepochs = 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 12\nwidth = 12 #32\nwidth_q = width #32\nwidth_h = width // 2 # width # 32\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # True  # True\nload_model = False #True  # False  # False\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'\nmatlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 9  # 72\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_MBE3D_TNO3d.py b/configs/config_MBE3D_TNO3d.py
++--- a/configs/config_MBE3D_TNO3d.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/configs/config_MBE3D_TNO3d.py	(date 1753792269011)
++@@ -7,23 +7,23 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 1200 #1600 # 4000
+++nTrain = 1300 #1600 # 4000
++ nTest = 300  # 400
++-batch_size = 50# 25 #100
++-learning_rate = 0.005
+++batch_size = 20 # 50# 25 #100
+++learning_rate = 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 1000
+++epochs =  50 # 25# 50 # 20 # 50 # 1000
++ iterations = epochs * (nTrain // batch_size)
++-modes = 14 # 12
++-width = 12 #32
+++modes = 14 # 14 # 12
+++width = 12 # 12 #32
++ width_q = width #32
++ width_h = width // 2 # width # 32
++-n_layers = 4
+++n_layers = 2 # 4 # 3 # 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -32,14 +32,45 @@
++ 
++ # Database
++ parent_dir = './data/'
++-#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'
++-matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'
+++
+++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat' # I got the result based on this Dataset!! epochs = 50 !! n_layers = 2 pde_loss_scaler = 1e-4 # 1e-3
+++#matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat' # not valid
+++
++ # Plotting
++-index = 9  # 72
++-domain = [-np.pi, np.pi]
+++index = 62  # 72
+++#domain = [-np.pi, np.pi]
+++Lx = 2* np.pi  # 6 # 2* np.pi            # Domain size from MATLAB
+++domain = [-Lx/2, Lx/2]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.001 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.1 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4 # 1e-3
++\ No newline at end of file
++Index: training.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport torch.nn.functional as F\nfrom timeit import default_timer\nfrom tqdm import tqdm\n\ndef train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,\n              optimizer, scheduler, normalized, normalizer, device):\n    train_mse_log = []\n    train_l2_log = []\n    test_l2_log = []\n\n    if normalized:\n        # a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        # a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n        train_mse = 0\n        train_l2 = 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            #print(\"x shape\", x.shape)\n            out = model(x)\n            #print(f\"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}\")\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            train_mse += mse.item()\n            train_l2 += loss.item()\n\n        model.eval()\n        test_l2 = 0.0\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                #test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n\n        train_mse /= len(train_loader)\n        train_l2 /= (batch_size * len(train_loader))\n        test_l2 /= (batch_size * len(test_loader))\n\n        train_mse_log.append(train_mse)\n        train_l2_log.append(train_l2)\n        test_l2_log.append(test_l2)\n\n        # Update the learning rate based on the test_l2 metric\n        #scheduler.step(test_l2) ##\n\n\n        t2 = default_timer()\n        #print(ep, t2 - t1, train_mse, train_l2, test_l2)\n        if ep == 0:  # Print the header row once\n            print(\"No. Epoch   Time (s)       Train MSE      Train L2       Test L2\")\n\n        print(f\"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}\")\n\n    return model, train_mse_log, train_l2_log, test_l2_log\n\ndef train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,\n                   optimizer, scheduler, normalized, normalizer, device):\n    ntrain = len(train_loader) * train_loader.batch_size\n    ntest = len(test_loader) * test_loader.batch_size\n    train_mse_log = []\n    train_l2_log = []\n    test_l2_log = []\n    step = 1\n    if normalized:\n        a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n        train_l2_step = 0\n        train_l2_full = 0\n        for xx, yy in train_loader:\n            loss = 0\n            xx = xx.to(device)\n            yy = yy.to(device)\n            T = yy.shape[-1]\n            #print(f\" T : {T}\")\n            #print(f\"target shape: {yy.shape}\")\n            #print(f\"Input shape: {xx.shape}, y (target): {yy.shape}\")\n            for t in range(0, T, step):\n                y = yy[..., t:t + step]\n                im = model(xx)\n                #print(f\"Input shape: {xx.shape}, y (target): {y.shape}, prediction (model output): {im.shape}\")\n                #print(f\"target shape 2: {yy.shape}\")\n                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n\n                if t == 0:\n                    pred = im\n                else:\n                    pred = torch.cat((pred, im), -1)\n                xx = torch.cat((xx[..., step:], im), dim=-1)\n\n            train_l2_step += loss.item()\n            l2_full = myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1))\n            train_l2_full += l2_full.item()\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n        test_l2_step = 0\n        test_l2_full = 0\n        with torch.no_grad():\n            for xx, yy in test_loader:\n                loss = 0\n                xx = xx.to(device)\n                yy = yy.to(device)\n\n                for t in range(0, T, step):\n                    y = yy[..., t:t + step]\n                    im = model(xx)\n                    loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n\n                    if t == 0:\n                        pred = im\n                    else:\n                        pred = torch.cat((pred, im), -1)\n\n                    xx = torch.cat((xx[..., step:], im), dim=-1)\n\n                test_l2_step += loss.item()\n                test_l2_full += myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1)).item()\n\n        t2 = default_timer()\n        train_mse = train_l2_step / ntrain / (T / step)\n        train_l2 = train_l2_full / ntrain\n        test_l2 = test_l2_full / ntest\n\n        # Log the loss values\n        train_l2_log.append(train_l2_step / ntrain / (T / step))\n        test_l2_log.append(test_l2_step / ntest / (T / step))\n\n        if ep == 0:  # Print the header row once\n            print(\"No. Epoch   Time (s)       Train MSE      Train L2       Test L2\")\n\n        print(f\"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}\")\n\n    return model, train_l2_log, test_l2_log\n\n\n\n########################\n########################\n\ndef calculate_pde_residual(u_phys, grid_info, epsilon, problem, device):\n    \"\"\"\n    Calculates the residual for a specified 3D PDE on PHYSICAL data.\n    u_phys shape: (batch, Nx, Ny, Nz, T_out) - Denormalized data\n    grid_info: Dictionary containing Nx, Ny, Nz, Lx, Ly, Lz, dt_model, T_out\n    pde_params: Dictionary containing PDE-specific parameters\n    problem_name: String identifier for the PDE (e.g., 'SH3D', 'AC3D', 'CH3D', 'MBE3D', 'PFC3D')\n    device: PyTorch device\n    \"\"\"\n    batch_size, Nx, Ny, Nz, T_out = u_phys.shape\n    Lx, Ly, Lz = grid_info['Lx'], grid_info['Ly'], grid_info['Lz']\n    dt_model = grid_info['dt_model']\n\n    if T_out <= 1:\n        print(f\"Warning: T_out ({T_out}) <= 1 for problem {problem}. PDE loss requires T_out > 1. Returning zero loss.\")\n        return torch.zeros(1, device=device, requires_grad=True)\n\n    # --- Calculate Time Derivative (u/t) ---\n    du_dt = torch.zeros_like(u_phys)\n    du_dt[..., 0] = (u_phys[..., 1] - u_phys[..., 0]) / dt_model\n    du_dt[..., -1] = (u_phys[..., -1] - u_phys[..., -2]) / dt_model\n    if T_out > 2:\n       du_dt[..., 1:-1] = (u_phys[..., 2:] - u_phys[..., :-2]) / (2 * dt_model)\n\n    # --- Common Spectral Derivative Setup ---\n    _kx = torch.fft.fftfreq(Nx, d=Lx/Nx) * 2 * torch.pi\n    _ky = torch.fft.fftfreq(Ny, d=Ly/Ny) * 2 * torch.pi\n    _kz = torch.fft.fftfreq(Nz, d=Lz/Nz) * 2 * torch.pi\n\n    ikx_m, iky_m, ikz_m = torch.meshgrid(1j * _kx, 1j * _ky, 1j * _kz, indexing='ij')\n    ikx_m = ikx_m.to(device)\n    iky_m = iky_m.to(device)\n    ikz_m = ikz_m.to(device)\n\n    k2x_m, k2y_m, k2z_m = torch.meshgrid(_kx**2, _ky**2, _kz**2, indexing='ij')\n    # k2_m is kx^2 + ky^2 + kz^2. In Fourier space, laplacian is -k2_m\n    k2_m = (k2x_m + k2y_m + k2z_m).to(device)\n\n    u_hat = torch.fft.fftn(u_phys, dim=[1, 2, 3])\n\n    pde_residual = None\n\n    if problem == 'SH3D':\n        epsilon_sh = epsilon # pde_params.get('epsilon_sh')\n        if epsilon_sh is None: raise ValueError(\"Parameter 'epsilon_sh' not provided for SH3D.\")\n        k4_m = k2_m**2\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n        rhs_sh3d = -(u_phys**3) - (1 - epsilon_sh) * u_phys - biharm_u - 2 * lap_u\n        pde_residual = du_dt - rhs_sh3d\n\n    elif problem == 'AC3D':\n        Cahn_ac = epsilon # pde_params.get('Cahn_ac')\n        if Cahn_ac is None: raise ValueError(\"Parameter 'Cahn_ac' not provided for AC3D.\")\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        f_prime_u = u_phys**3 - u_phys\n        rhs_ac3d = Cahn_ac * lap_u - f_prime_u\n        pde_residual = du_dt - rhs_ac3d\n\n    elif problem == 'CH3D':\n        Cahn_ch = epsilon #  pde_params.get('Cahn_ch')\n        if Cahn_ch is None: raise ValueError(\"Parameter 'Cahn_ch' not provided for CH3D.\")\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        #mu_terms = (u_phys**3 - 3 * u_phys) - Cahn_ch * lap_u\n        mu_terms = (u_phys ** 3 -  u_phys) - Cahn_ch * lap_u\n        mu_terms_hat = torch.fft.fftn(mu_terms, dim=[1, 2, 3])\n        lap_mu_terms_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * mu_terms_hat\n        lap_mu_terms = torch.fft.ifftn(lap_mu_terms_hat, dim=[1, 2, 3]).real\n        rhs_ch3d = lap_mu_terms\n        pde_residual = du_dt - rhs_ch3d\n\n    elif problem == 'MBE3D':\n        epsilon_mbe = epsilon #  pde_params.get('epsilon_mbe')\n        if epsilon_mbe is None: raise ValueError(\"Parameter 'epsilon_mbe' not provided for MBE3D.\")\n        du_dx_hat = ikx_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dy_hat = iky_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dz_hat = ikz_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dx = torch.fft.ifftn(du_dx_hat, dim=[1, 2, 3]).real\n        du_dy = torch.fft.ifftn(du_dy_hat, dim=[1, 2, 3]).real\n        du_dz = torch.fft.ifftn(du_dz_hat, dim=[1, 2, 3]).real\n        grad_u_sq = du_dx**2 + du_dy**2 + du_dz**2\n        f1 = grad_u_sq * du_dx\n        f2 = grad_u_sq * du_dy\n        f3 = grad_u_sq * du_dz\n        f1_hat = torch.fft.fftn(f1, dim=[1, 2, 3])\n        f2_hat = torch.fft.fftn(f2, dim=[1, 2, 3])\n        f3_hat = torch.fft.fftn(f3, dim=[1, 2, 3])\n        div_term_hat = (ikx_m.unsqueeze(0).unsqueeze(-1) * f1_hat +\n                        iky_m.unsqueeze(0).unsqueeze(-1) * f2_hat +\n                        ikz_m.unsqueeze(0).unsqueeze(-1) * f3_hat)\n        div_term = torch.fft.ifftn(div_term_hat, dim=[1, 2, 3]).real\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        k4_m = k2_m**2\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term\n        pde_residual = du_dt - rhs_mbe3d\n\n    elif problem == 'PFC3D':\n        epsilon_pfc = epsilon # pde_params.get('epsilon_pfc') # Parameter 'r' in PFC, often -(epsilon)\n        if epsilon_pfc is None: raise ValueError(\"Parameter 'epsilon_pfc' not provided for PFC3D.\")\n\n        # Calculate necessary derivatives\n        # -u  (term1_spatial_operator * u)\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n\n        # u   (term2_spatial_operator * u)\n        k4_m = k2_m**2\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n\n        # -u  (term3_spatial_operator * u)\n        k6_m = k2_m**3 # Be careful with sign if k2_m is just kx^2+ky^2+kz^2\n                      # Since k^6 in Fourier space corresponds to (-^2)^3 = -^6 if direct multiplication\n                      # Or (i k)^6 = -k^6.\n                      # The MATLAB denominator (1/dt + (1-eps)k^2 + k^6) implies the k^6 term is positive.\n                      # So in real space, this corresponds to -u (because -(-)^3 u = u is not what we want)\n                      # A positive k^6 in Fourier space means we multiply by k^6, which is (-(laplacian_operator))^3,\n                      # this will become -laplacian_operator^3 which is -.\n                      # The MATLAB form `(pp2+qq2+rr2).^3` is `(k^2)^3 = k^6`.\n                      # So this term becomes `k^6 * u_hat` -> `u` (with a negative sign from implicit to explicit)\n        # Or, if (pp2+qq2+rr2) is k^2, then (pp2+qq2+rr2)^3 is k^6.\n        # The term in the denominator is `+ k^6`, so when moved to RHS it's `-k^6 u_hat`.\n        # `-k^6 u_hat` corresponds to `u` in real space.\n        triharm_u_hat = -k6_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        triharm_u = torch.fft.ifftn(triharm_u_hat, dim=[1, 2, 3]).real\n\n\n        # (u)\n        u_cubed = u_phys**3\n        u_cubed_hat = torch.fft.fftn(u_cubed, dim=[1, 2, 3])\n        lap_u_cubed_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_cubed_hat\n        lap_u_cubed = torch.fft.ifftn(lap_u_cubed_hat, dim=[1, 2, 3]).real\n\n        # PDE: u/t + (1-)u + 2u + u + (u) = 0\n        # RHS = - ( (1-_pfc)u + 2u + u + (u) )\n        # Let's use the parameter `epsilon` from PFC MATLAB as `r` (undercooling param)\n        # A common PFC form is du/dt = nabla^2 * ( (r)u + u^3 - (1+nabla^2)^2 u )\n        # du/dt = nabla^2 * ( ru + u^3 - (1 + 2 nabla^2 + nabla^4)u )\n        # du/dt = r nabla^2 u + nabla^2(u^3) - nabla^2 u - 2 nabla^4 u - nabla^6 u\n        # du/dt = (r-1) nabla^2 u - 2 nabla^4 u - nabla^6 u + nabla^2(u^3)\n        # Here 'r' from literature is often called 'epsilon' in PFC code.\n        # Let's match the form derived from MATLAB:\n        # u/t = -(1-)u - 2u - u - (u)\n        # Residual: du_dt - [-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed]\n\n        term1_spatial = (1 - epsilon_pfc) * lap_u # (1-eps)(-nabla^2 u) -> (eps-1)nabla^2 u\n        term2_spatial = 2 * biharm_u             # 2 nabla^4 u\n        term3_spatial = triharm_u                # nabla^6 u\n        term4_nonlinear = lap_u_cubed            # nabla^2 (u^3)\n\n        # According to the derived form: u/t = -(1-)u - 2u - u - (u)\n        # residual = du_dt - (-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed)\n        rhs_pfc3d = -(1 - epsilon_pfc) * lap_u - 2 * biharm_u - triharm_u - lap_u_cubed\n        pde_residual = du_dt - rhs_pfc3d\n\n    else:\n        raise ValueError(f\"Unknown problem_name: {problem}. PDE residual not defined.\")\n\n    if pde_residual is not None:\n        loss_pde = F.mse_loss(pde_residual, torch.zeros_like(pde_residual))\n    else:\n        loss_pde = torch.zeros(1, device=device, requires_grad=True)\n\n    return loss_pde\n\n\ndef train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,\n                    optimizer, scheduler, normalized, normalizer, device, pde_weight, grid_info, epsilon, problem, pde_loss_scaler=1.0, can_compute_pde = True):\n    train_mse_hybrid_log = []\n    train_l2_hybrid_log = []\n\n    test_mse_hybrid_log = []\n    test_loss_hybrid_log = []\n\n\n    train_data_log = []\n    test_data_log = []\n\n    train_pde_scaled_log = []\n    train_pde_raw_log = []\n\n    test_pde_loss_scaled_log = []\n    test_pde_loss_raw_log = []\n\n\n    if normalized:\n        # a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        # a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n\n        train_mse_hybrid = 0\n        train_l2_hybrid = 0\n\n        train_data = 0.0\n        train_pde_scaled = 0.0\n        train_pde_raw = 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            # print(\"x shape\", x.shape)\n            out = model(x)\n            # print(f\"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}\")\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n\n            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n            loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n            # --- PDE Loss Calculation (on physical scale) ---\n            if can_compute_pde:\n                # loss_pde_raw = calculate_pde_residual_sh3d(pred_phys, grid_info, epsilon, device)\n                #loss_pde_raw = calculate_pde_residual_sh3d(out, grid_info, epsilon, device)\n                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                loss_pde_scaled = loss_pde_raw * pde_loss_scaler  # Apply scaling\n\n            loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled\n            mse_hybrid = (1.0 - pde_weight) * mse_data + pde_weight * loss_pde_scaled\n\n\n            loss_hybrid.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # Hybrid\n            train_mse_hybrid += mse_hybrid.item()\n            train_l2_hybrid += loss_hybrid.item()\n            ##\n            train_data += loss_data.item()\n            train_pde_scaled += loss_pde_scaled.item()\n            train_pde_raw += loss_pde_raw.item()\n\n\n        model.eval()\n        test_data= 0.0 # data\n        test_mse_data = 0.0\n        test_pde_loss_scaled = 0.0\n        test_pde_loss_raw = 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                # test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n                test_mse_data += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n                test_data += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n\n                # PDE Loss\n                if can_compute_pde:\n                    #loss_pde_test_raw = calculate_pde_residual_sh3d(out, grid_info, epsilon, device)\n                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n\n                test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()\n                test_pde_loss_raw += loss_pde_test_raw.item()\n\n            test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled\n            test_mse_hybrid = (1.0 - pde_weight) * test_mse_data + pde_weight * test_pde_loss_scaled\n\n        # Train Hybrid\n        train_mse_hybrid /= len(train_loader)\n        train_l2_hybrid /= (batch_size * len(train_loader))\n\n        # Test Hybrid\n        test_mse_hybrid /= len(test_loader)\n        test_loss_hybrid /= (batch_size * len(test_loader))\n\n        # train data\n        train_data /= (batch_size * len(train_loader))\n        # test data\n        test_data /= (batch_size * len(test_loader))\n        # train pde\n        train_pde_scaled /= (batch_size * len(train_loader))\n        train_pde_raw /= (batch_size * len(train_loader))\n        # test pde\n        test_pde_loss_scaled /= (batch_size * len(test_loader))\n        test_pde_loss_raw /= (batch_size * len(test_loader))\n\n\n\n\n        # train Hybrid\n        train_mse_hybrid_log.append(train_mse_hybrid)\n        train_l2_hybrid_log.append(train_l2_hybrid)\n\n        # Test Hybrid\n        test_mse_hybrid_log.append(test_mse_hybrid)\n        test_loss_hybrid_log.append(test_loss_hybrid)\n\n        # train data\n        train_data_log.append(train_data)\n        # test data\n        test_data_log.append(test_data)\n        # train pde\n        train_pde_scaled_log.append(train_pde_scaled)\n        train_pde_raw_log.append(train_pde_raw)\n        # test pde\n        test_pde_loss_scaled_log.append(test_pde_loss_scaled)\n        test_pde_loss_raw_log.append(test_pde_loss_raw)\n\n        # Update the learning rate based on the test_l2 metric\n        # scheduler.step(test_l2) ##\n\n        t2 = default_timer()\n\n        if ep == 0:\n            # Update header to reflect spectral raw PDE loss\n            print(\"No. Epoch | Time (s)   | Train MSE Hyb  | Train L2 Hyb  | test L2 Hyb | Test L2 data        | test_pde scl.   | test_pde_raw \")\n            print(\"---------------------------------------------------------------------------------------------\")\n        # Update print statement\n        print(f\"{ep:<9}  {t2 - t1:<10.4f}   {train_mse_hybrid:<10.6e}     {train_l2_hybrid:<10.6e} {test_loss_hybrid:<10.6e}  {test_data:<24.6e} {test_pde_loss_scaled:<24.6e} {test_pde_loss_raw:<24.6e} \")\n\n    return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log\n\n\ndef compute_initial_loss_scaler(model, loader, myloss, normalized, normalizer, device, grid_info, epsilon, problem):\n    \"\"\"\n    Computes the scaling factor to balance data and PDE losses.\n    \"\"\"\n    model.eval()\n\n    # Get one batch from the loader\n    x, y = next(iter(loader))\n    x, y = x.to(device), y.to(device)\n\n    with torch.no_grad():\n        out = model(x)\n        if normalized:\n            y_normalizer = normalizer[1].to(device)\n            out = y_normalizer.decode(out)\n            y = y_normalizer.decode(y)\n\n        # Calculate initial data loss\n        initial_loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n        # Calculate initial raw PDE loss\n        initial_loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n\n        # Handle case where PDE loss is zero to avoid division by zero\n        if initial_loss_pde_raw.item() < 1e-12:\n            scaler = 1.0\n            print(\"Warning: Initial PDE loss is near zero. Setting scaler to 1.0.\")\n        else:\n            # The scaler is the ratio of the two losses\n            scaler = initial_loss_data.item() / initial_loss_pde_raw.item()\n            print(f\"Computed initial loss scaler: {scaler:.4f}\")\n            print(f\"  - Initial Data Loss: {initial_loss_data.item():.6f}\")\n            print(f\"  - Initial PDE Loss (raw): {initial_loss_pde_raw.item():.6f}\")\n\n    model.train()  # Set model back to training mode\n    return scaler\n\n\n''''\ndef train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,\n                 optimizer, scheduler, normalized, normalizer, device, pde_weight,\n                 grid_info, epsilon, problem, pde_loss_scaler='auto', can_compute_pde=True):\n    # --- Logging Lists ---\n    train_mse_hybrid_log, train_l2_hybrid_log = [], []\n    test_mse_hybrid_log, test_loss_hybrid_log = [], []\n    train_data_log, test_data_log = [], []\n    train_pde_scaled_log, train_pde_raw_log = [], []\n    test_pde_loss_scaled_log, test_pde_loss_raw_log = [], []\n\n    if normalized:\n        y_normalizer = normalizer[1].to(device)\n    else:\n        y_normalizer = None\n\n    # ====================================================================================\n    # Automatic PDE Loss Scaler Calculation\n    # ====================================================================================\n    if pde_loss_scaler == 'auto' and can_compute_pde and pde_weight > 0:\n        print(\"--- Calibrating PDE loss scaler automatically ---\")\n        model.eval()\n        total_data_loss_for_scaling = 0.0\n        total_pde_loss_for_scaling = 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n                out = model(x)\n\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                # Calculate data loss for this batch\n                data_loss_batch = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n                total_data_loss_for_scaling += data_loss_batch.item()\n\n                # Calculate raw PDE loss for this batch\n                pde_loss_batch_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                total_pde_loss_for_scaling += pde_loss_batch_raw.item()\n\n        # Calculate the average losses\n        avg_data_loss = total_data_loss_for_scaling / len(test_loader)\n        avg_pde_loss = total_pde_loss_for_scaling / len(test_loader)\n\n        # Compute the scaler\n        if avg_pde_loss > 1e-8:  # Avoid division by zero\n            pde_loss_scaler = avg_data_loss / avg_pde_loss\n        else:\n            pde_loss_scaler = 1.0  # Default to 1 if PDE loss is negligible\n\n        print(f\"Initial Avg Data Loss: {avg_data_loss:.6e}\")\n        print(f\"Initial Avg Raw PDE Loss: {avg_pde_loss:.6e}\")\n        print(f\"Calculated pde_loss_scaler: {pde_loss_scaler:.6f}\")\n        print(\"---------------------------------------------\")\n\n    elif not can_compute_pde or pde_weight == 0:\n        pde_loss_scaler = 0.0  # No scaling needed if PDE is not used\n    elif isinstance(pde_loss_scaler, str):  # Handle cases like 'auto' when PDE is off\n        pde_loss_scaler = 1.0\n\n    # --- Main Training Loop ---\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n\n        # Initialize epoch-level accumulators\n        train_mse_hybrid, train_l2_hybrid = 0.0, 0.0\n        train_data, train_pde_scaled, train_pde_raw = 0.0, 0.0, 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            optimizer.zero_grad()\n\n            out = model(x)\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n\n            # --- Loss Calculation ---\n            loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n\n            loss_pde_scaled = torch.tensor(0.0, device=device)\n            loss_pde_raw = torch.tensor(0.0, device=device)\n\n            if can_compute_pde and pde_weight > 0:\n                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                loss_pde_scaled = loss_pde_raw * pde_loss_scaler\n\n            # Combine losses\n            loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled\n            mse_hybrid = (1.0 - pde_weight) * mse_data + pde_weight * loss_pde_scaled\n\n            loss_hybrid.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # --- Accumulate Metrics ---\n            train_mse_hybrid += mse_hybrid.item()\n            train_l2_hybrid += loss_hybrid.item()\n            train_data += loss_data.item()\n            train_pde_scaled += loss_pde_scaled.item()\n            train_pde_raw += loss_pde_raw.item()\n\n        # --- Evaluation ---\n        model.eval()\n        test_data, test_mse_data = 0.0, 0.0\n        test_pde_loss_scaled, test_pde_loss_raw = 0.0, 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                test_data += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n                test_mse_data += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean').item()\n\n                if can_compute_pde and pde_weight > 0:\n                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                    test_pde_loss_raw += loss_pde_test_raw.item()\n                    test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()\n\n        # --- Normalize and Log Metrics ---\n        # Note: We divide by len(loader) because item() gives the mean loss for the batch.\n        # This computes the average of the batch means.\n\n        # Averages for training set\n        train_mse_hybrid /= len(train_loader)\n        train_l2_hybrid /= len(train_loader)\n        train_data /= len(train_loader)\n        train_pde_scaled /= len(train_loader)\n        train_pde_raw /= len(train_loader)\n\n        # Averages for test set\n        test_mse_data /= len(test_loader)\n        test_data /= len(test_loader)\n        test_pde_loss_scaled /= len(test_loader)\n        test_pde_loss_raw /= len(test_loader)\n\n        # Calculate final hybrid test losses from averages\n        test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled\n        test_mse_hybrid = (1.0 - pde_weight) * test_mse_data + pde_weight * test_pde_loss_scaled\n\n        # Append to logs\n        train_mse_hybrid_log.append(train_mse_hybrid)\n        train_l2_hybrid_log.append(train_l2_hybrid)\n        test_mse_hybrid_log.append(test_mse_hybrid)\n        test_loss_hybrid_log.append(test_loss_hybrid)\n        train_data_log.append(train_data)\n        test_data_log.append(test_data)\n        train_pde_scaled_log.append(train_pde_scaled)\n        train_pde_raw_log.append(train_pde_raw)\n        test_pde_loss_scaled_log.append(test_pde_loss_scaled)\n        test_pde_loss_raw_log.append(test_pde_loss_raw)\n\n        t2 = default_timer()\n\n        if ep == 0:\n            print(\"--- Starting Training ---\")\n            print(f\"PDE Loss Scaler is set to: {pde_loss_scaler:.6f}\")\n            print(\n                \"No. Epoch | Time (s)   | Train MSE Hyb  | Train L2 Hyb   | Test L2 Hyb    | Test L2 data   | Test PDE Scl.  | Test PDE Raw\")\n            print(\n                \"-------------------------------------------------------------------------------------------------------------------------\")\n\n        # CORRECTED PRINT STATEMENT:\n        print(\n            f\"{ep:<9} | {t2 - t1:<10.4f} | {train_mse_hybrid:<14.6e} | {train_l2_hybrid:<14.6e} | {test_loss_hybrid:<14.6e} | {test_data:<14.6e} | {test_pde_loss_scaled:<14.6e} | {test_pde_loss_raw:<14.6e}\")\n\n    return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log\n'''
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/training.py b/training.py
++--- a/training.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/training.py	(date 1753623429192)
++@@ -1,8 +1,10 @@
++ import torch
++ import torch.nn.functional as F
++ from timeit import default_timer
+++import numpy as np
++ from tqdm import tqdm
++ 
+++'''
++ def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
++               optimizer, scheduler, normalized, normalizer, device):
++     train_mse_log = []
++@@ -65,7 +67,6 @@
++         # Update the learning rate based on the test_l2 metric
++         #scheduler.step(test_l2) ##
++ 
++-
++         t2 = default_timer()
++         #print(ep, t2 - t1, train_mse, train_l2, test_l2)
++         if ep == 0:  # Print the header row once
++@@ -75,6 +76,347 @@
++ 
++     return model, train_mse_log, train_l2_log, test_l2_log
++ 
+++'''
+++
+++
+++# Make sure SobolevLoss is imported or defined before this function is called
+++# so that isinstance() can work correctly.
+++# from your_utilities import SobolevLoss
+++
+++def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
+++              optimizer, scheduler, normalized, normalizer, device):
+++    # This is a placeholder for the real import.
+++    # In your actual code, you must import SobolevLoss from utilities.py
+++    from utilities import SobolevLoss
+++
+++    train_mse_log = []
+++    train_l2_log = []
+++    test_l2_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++            # --- THIS IS THE FIX ---
+++            # If the loss is SobolevLoss, pass the original multi-dimensional tensors.
+++            # Otherwise, for losses like LpLoss, pass the flattened tensors.
+++            if isinstance(myloss, SobolevLoss):
+++                loss = myloss(out, y)  # Pass the un-flattened tensor
+++            else:
+++                loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))  # The original behavior
+++            # --- END OF FIX ---
+++
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++            train_mse += mse.item()
+++            train_l2 += loss.item()
+++
+++        model.eval()
+++        test_l2 = 0.0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                # --- APPLY THE SAME FIX HERE ---
+++                if isinstance(myloss, SobolevLoss):
+++                    test_l2 += myloss(out, y).item()
+++                else:
+++                    test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()
+++                # --- END OF FIX ---
+++
+++        train_mse /= len(train_loader)
+++        train_l2 /= (batch_size * len(train_loader))
+++        test_l2 /= (batch_size * len(test_loader))
+++
+++        train_mse_log.append(train_mse)
+++        train_l2_log.append(train_l2)
+++        test_l2_log.append(test_l2)
+++
+++        t2 = default_timer()
+++        if ep == 0:
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log
+++''''
+++def train_fno4d(model, myloss, epochs, batch_size, train_loader, test_loader,
+++              optimizer, scheduler, normalized, normalizer, device):
+++    train_mse_log = []
+++    train_l2_log = []
+++    #val_mse_log = []  # New
+++    #val_l2_log = []  # New
+++    test_l2_log = []
+++    test_mse_log = []
+++
+++    # --- Early Stopping Parameters (Optional) ---
+++    #best_val_loss = float('inf')
+++    #patience_counter = 0
+++    #patience_epochs = 5 # 10  # Example: stop if no improvement for 10 epochs
+++    #best_model_state = None
+++    # ---
+++
+++    if normalized:
+++        # a_normalizer = normalizer[0].to(device)
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        # a_normalizer = None
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            #print("x shape", x.shape)
+++            out = model(x)
+++            print(f"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}")
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                #print("out shape1:", out.shape)
+++                y = y_normalizer.decode(y)
+++            print("out shape2 :", out.shape)
+++            print("y shape:", y.shape)
+++
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
+++
+++            loss.backward()
+++            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Adjust max_norm if needed
+++            optimizer.step()
+++            scheduler.step()
+++            train_mse += mse.item()
+++            train_l2 += loss.item()
+++
+++        # Test
+++
+++        model.eval()
+++        test_l2 = 0.0
+++        test_mse = 0.0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                #test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()
+++                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()
+++                test_mse += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++
+++        test_l2 /= (batch_size * len(test_loader))
+++        test_mse /= (batch_size * len(test_loader))
+++
+++        test_l2_log.append(test_l2)
+++        test_mse_log.append(test_mse)
+++        # Update the learning rate based on the test_l2 metric
+++        #scheduler.step(test_l2) ##
+++
+++
+++        t2 = default_timer()
+++        #print(ep, t2 - t1, train_mse, train_l2, test_l2)
+++
+++
+++        if ep == 0:
+++            # Update header to reflect spectral raw PDE loss
+++            print("No. Epoch | Time (s)   | Train MSE     | Test mse     | Train L2      |  Test L2 ")
+++            print("---------------------------------------------------------------------------------------")
+++        # Update print statement
+++        print(f"{ep:<9} | {t2 - t1:<10.4f} | {train_mse:<10.6e} | {test_mse:<10.6e} | {train_l2:<10.6e} | {test_l2:<24.6e} ")
+++
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log, test_mse_log
+++'''
+++
+++
+++def train_fno4d(model, myloss, epochs, batch_size, train_loader, test_loader,
+++                optimizer, scheduler, normalized, normalizer, device):
+++    """Training function for FNO4d model."""
+++    ntrain = len(train_loader) * train_loader.batch_size
+++    ntest = len(test_loader) * test_loader.batch_size
+++
+++    train_mse_log = []
+++    train_l2_log = []
+++    test_l2_log = []
+++    test_mse_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
+++
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++
+++            train_mse += mse.item()
+++            train_l2 += loss.item() / batch_size  # Normalize by batch size
+++
+++        model.eval()
+++        test_l2 = 0
+++        test_mse = 0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                test_mse += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean').item()
+++                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item() / batch_size  # Normalize here too
+++
+++        # Average over number of batches
+++        train_mse /= len(train_loader)
+++        train_l2 /= len(train_loader)
+++        test_mse /= len(test_loader)
+++        test_l2 /= len(test_loader)
+++
+++        train_mse_log.append(train_mse)
+++        train_l2_log.append(train_l2)
+++        test_l2_log.append(test_l2)
+++        test_mse_log.append(test_mse)
+++
+++        t2 = default_timer()
+++
+++        if ep == 0:
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test MSE       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_mse:<13.10f} {test_l2:<13.10f}")
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log
+++
+++
+++
+++import torch
+++import torch.nn.functional as F
+++from timeit import default_timer
+++
+++'''
+++def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
+++              optimizer, scheduler, normalized, normalizer, device):
+++    train_mse_log = []
+++    train_l2_log = []
+++    test_l2_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            # This MSE is kept for logging the data-only error
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++            # --- MINIMAL CHANGE HERE ---
+++            # The loss function now receives the UN-FLATTENED tensors
+++            # so it can compute spatial gradients for the Sobolev loss.
+++            loss = myloss(out, y)
+++
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++            train_mse += mse.item()
+++            train_l2 += loss.item()
+++
+++        model.eval()
+++        test_l2 = 0.0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                # --- MINIMAL CHANGE HERE ---
+++                # Also pass the un-flattened tensors during evaluation.
+++                test_l2 += myloss(out, y).item()
+++
+++        train_mse /= len(train_loader)
+++        train_l2 /= (batch_size * len(train_loader))  # Kept original scaling
+++        test_l2 /= (batch_size * len(test_loader))  # Kept original scaling
+++
+++        train_mse_log.append(train_mse)
+++        train_l2_log.append(train_l2)
+++        test_l2_log.append(test_l2)
+++
+++        t2 = default_timer()
+++        if ep == 0:  # Print the header row once
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log
+++'''
+++
+++
++ def train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,
++                    optimizer, scheduler, normalized, normalizer, device):
++     ntrain = len(train_loader) * train_loader.batch_size
++@@ -164,7 +506,110 @@
++ 
++     return model, train_l2_log, test_l2_log
++ 
+++'''
+++def train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,
+++                   optimizer, scheduler, normalized, normalizer, device):
+++    ntrain = len(train_loader) * train_loader.batch_size
+++    ntest = len(test_loader) * test_loader.batch_size
+++    train_l2_log = []
+++    test_l2_log = []
+++    step = 1
+++
+++    # Normalizer setup is unchanged
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_l2_step = 0
+++        train_l2_full = 0
+++        for xx, yy in train_loader:
+++            loss = 0
+++            xx = xx.to(device)
+++            yy = yy.to(device)
+++            T = yy.shape[-1]
+++
+++            # The auto-regressive loop for one-step-ahead prediction
+++            for t in range(0, T, step):
+++                y = yy[..., t:t + step]
+++                im = model(xx)
+++
+++                # --- MINIMAL CHANGE #1 ---
+++                # Pass the un-flattened tensors (im, y) to myloss.
+++                # Both have shape (batch, s, s, s, 1) here.
+++                loss += myloss(im, y)
+++
+++                if t == 0:
+++                    pred = im
+++                else:
+++                    pred = torch.cat((pred, im), -1)
+++
+++                # Update input for next time step
+++                xx = torch.cat((xx[..., step:], im), dim=-1)
+++
+++            train_l2_step += loss.item()
+++
+++            # --- MINIMAL CHANGE #2 ---
+++            # Also pass the un-flattened full tensors (pred, yy) to myloss.
+++            # Both have shape (batch, s, s, s, T_out) here.
+++            l2_full = myloss(pred, yy)
+++            train_l2_full += l2_full.item()
+++
+++            optimizer.zero_grad()
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++
+++        # Evaluation loop
+++        test_l2_step = 0
+++        test_l2_full = 0
+++        with torch.no_grad():
+++            for xx, yy in test_loader:
+++                loss = 0
+++                xx = xx.to(device)
+++                yy = yy.to(device)
+++                T = yy.shape[-1]  # T is defined inside the loop for safety
+++
+++                for t in range(0, T, step):
+++                    y = yy[..., t:t + step]
+++                    im = model(xx)
+++
+++                    # --- MINIMAL CHANGE #3 ---
+++                    loss += myloss(im, y)
+++
+++                    if t == 0:
+++                        pred = im
+++                    else:
+++                        pred = torch.cat((pred, im), -1)
+++
+++                    xx = torch.cat((xx[..., step:], im), dim=-1)
+++
+++                test_l2_step += loss.item()
+++
+++                # --- MINIMAL CHANGE #4 ---
+++                test_l2_full += myloss(pred, yy).item()
++ 
+++        t2 = default_timer()
+++        # The meaning of these metrics is slightly different now, but the calculation is kept
+++        train_mse = train_l2_step / ntrain / (T / step)
+++        train_l2 = train_l2_full / ntrain
+++        test_l2 = test_l2_full / ntest
+++
+++        # Log the loss values
+++        train_l2_log.append(train_l2_step / ntrain / (T / step))
+++        test_l2_log.append(test_l2_step / ntest / (T / step))
+++
+++        if ep == 0:  # Print the header row once
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
+++
+++    # Returning the logs for the one-step-ahead loss
+++    return model, train_l2_log, test_l2_log
+++'''
++ 
++ ########################
++ ########################
++@@ -227,12 +672,15 @@
++         if Cahn_ac is None: raise ValueError("Parameter 'Cahn_ac' not provided for AC3D.")
++         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
++-        f_prime_u = u_phys**3 - u_phys
++-        rhs_ac3d = Cahn_ac * lap_u - f_prime_u
+++        #f_prime_u = u_phys**3 - u_phys
+++        #rhs_ac3d = Cahn_ac * lap_u - f_prime_u ##
+++        f_prime_u = (1/Cahn_ac) * (u_phys ** 3 - u_phys)
+++        rhs_ac3d = lap_u - f_prime_u  ##
+++
++         pde_residual = du_dt - rhs_ac3d
++ 
++     elif problem == 'CH3D':
++-        Cahn_ch = epsilon #  pde_params.get('Cahn_ch')
+++        Cahn_ch = epsilon**2 #  pde_params.get('Cahn_ch')
++         if Cahn_ch is None: raise ValueError("Parameter 'Cahn_ch' not provided for CH3D.")
++         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
++@@ -269,66 +717,39 @@
++         k4_m = k2_m**2
++         biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real
++-        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term
+++        #rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term
+++        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u + div_term
++         pde_residual = du_dt - rhs_mbe3d
++ 
++     elif problem == 'PFC3D':
++-        epsilon_pfc = epsilon # pde_params.get('epsilon_pfc') # Parameter 'r' in PFC, often -(epsilon)
+++        epsilon_pfc = epsilon
++         if epsilon_pfc is None: raise ValueError("Parameter 'epsilon_pfc' not provided for PFC3D.")
++-
++-        # Calculate necessary derivatives
++-        # -u  (term1_spatial_operator * u)
+++        # Calculate necessary spatial derivatives using Fourier transforms
+++        # u (Laplacian)
++         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
++ 
++-        # u   (term2_spatial_operator * u)
++-        k4_m = k2_m**2
+++        # u (Biharmonic)
+++        k4_m = k2_m ** 2
++         biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real
++ 
++-        # -u  (term3_spatial_operator * u)
++-        k6_m = k2_m**3 # Be careful with sign if k2_m is just kx^2+ky^2+kz^2
++-                      # Since k^6 in Fourier space corresponds to (-^2)^3 = -^6 if direct multiplication
++-                      # Or (i k)^6 = -k^6.
++-                      # The MATLAB denominator (1/dt + (1-eps)k^2 + k^6) implies the k^6 term is positive.
++-                      # So in real space, this corresponds to -u (because -(-)^3 u = u is not what we want)
++-                      # A positive k^6 in Fourier space means we multiply by k^6, which is (-(laplacian_operator))^3,
++-                      # this will become -laplacian_operator^3 which is -.
++-                      # The MATLAB form `(pp2+qq2+rr2).^3` is `(k^2)^3 = k^6`.
++-                      # So this term becomes `k^6 * u_hat` -> `u` (with a negative sign from implicit to explicit)
++-        # Or, if (pp2+qq2+rr2) is k^2, then (pp2+qq2+rr2)^3 is k^6.
++-        # The term in the denominator is `+ k^6`, so when moved to RHS it's `-k^6 u_hat`.
++-        # `-k^6 u_hat` corresponds to `u` in real space.
+++        # u (Triharmonic)
+++        k6_m = k2_m ** 3
+++        # In Fourier space, multiplying by -k^6 corresponds to the  operator
++         triharm_u_hat = -k6_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         triharm_u = torch.fft.ifftn(triharm_u_hat, dim=[1, 2, 3]).real
++ 
++-
++         # (u)
++-        u_cubed = u_phys**3
+++        u_cubed = u_phys ** 3
++         u_cubed_hat = torch.fft.fftn(u_cubed, dim=[1, 2, 3])
++         lap_u_cubed_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_cubed_hat
++         lap_u_cubed = torch.fft.ifftn(lap_u_cubed_hat, dim=[1, 2, 3]).real
++ 
++-        # PDE: u/t + (1-)u + 2u + u + (u) = 0
++-        # RHS = - ( (1-_pfc)u + 2u + u + (u) )
++-        # Let's use the parameter `epsilon` from PFC MATLAB as `r` (undercooling param)
++-        # A common PFC form is du/dt = nabla^2 * ( (r)u + u^3 - (1+nabla^2)^2 u )
++-        # du/dt = nabla^2 * ( ru + u^3 - (1 + 2 nabla^2 + nabla^4)u )
++-        # du/dt = r nabla^2 u + nabla^2(u^3) - nabla^2 u - 2 nabla^4 u - nabla^6 u
++-        # du/dt = (r-1) nabla^2 u - 2 nabla^4 u - nabla^6 u + nabla^2(u^3)
++-        # Here 'r' from literature is often called 'epsilon' in PFC code.
++-        # Let's match the form derived from MATLAB:
++-        # u/t = -(1-)u - 2u - u - (u)
++-        # Residual: du_dt - [-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed]
++-
++-        term1_spatial = (1 - epsilon_pfc) * lap_u # (1-eps)(-nabla^2 u) -> (eps-1)nabla^2 u
++-        term2_spatial = 2 * biharm_u             # 2 nabla^4 u
++-        term3_spatial = triharm_u                # nabla^6 u
++-        term4_nonlinear = lap_u_cubed            # nabla^2 (u^3)
++-
++-        # According to the derived form: u/t = -(1-)u - 2u - u - (u)
++-        # residual = du_dt - (-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed)
++-        rhs_pfc3d = -(1 - epsilon_pfc) * lap_u - 2 * biharm_u - triharm_u - lap_u_cubed
+++        # Construct the Right-Hand Side (RHS) of the PDE to match the MATLAB code
+++        # PDE: u/t = (1-)u + 2u + u + (u)
+++        rhs_pfc3d = (1 - epsilon_pfc) * lap_u + 2 * biharm_u + triharm_u + lap_u_cubed
+++        # The residual is the difference between the time derivative and the RHS
++         pde_residual = du_dt - rhs_pfc3d
++ 
++     else:
++@@ -503,42 +924,117 @@
++     return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log
++ 
++ 
++-def compute_initial_loss_scaler(model, loader, myloss, normalized, normalizer, device, grid_info, epsilon, problem):
++-    """
++-    Computes the scaling factor to balance data and PDE losses.
++-    """
++-    model.eval()
+++'''
+++
+++def train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,
+++                 optimizer, scheduler, normalized, normalizer, device, pde_weight, grid_info, epsilon, problem,
+++                 pde_loss_scaler=1.0, can_compute_pde=True):
+++    train_mse_hybrid_log = []
+++    train_l2_hybrid_log = []
+++    test_loss_hybrid_log = []
+++    train_data_log = []
+++    test_data_log = []
+++    train_pde_scaled_log = []
+++    test_pde_loss_scaled_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++
+++        train_mse_hybrid = 0
+++        train_l2_hybrid = 0
+++        train_data = 0.0
+++        train_pde_scaled = 0.0
+++
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            # --- MINIMAL CHANGE #1 ---
+++            # Pass the UN-FLATTENED tensors to myloss.
+++            loss_data = myloss(out, y)
+++
+++            # Kept for logging purposes
+++            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++            if can_compute_pde and pde_weight > 0:
+++                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
+++                loss_pde_scaled = loss_pde_raw * pde_loss_scaler
+++                loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled
+++            else:
+++                loss_pde_scaled = torch.tensor(0.0)  # For logging
+++                loss_hybrid = loss_data
+++
+++            loss_hybrid.backward()
+++            optimizer.step()
+++            scheduler.step()
+++
+++            train_l2_hybrid += loss_hybrid.item()
+++            train_data += loss_data.item()
+++            train_pde_scaled += loss_pde_scaled.item()
+++
+++        model.eval()
+++        test_data = 0.0
+++        test_pde_loss_scaled = 0.0
++ 
++-    # Get one batch from the loader
++-    x, y = next(iter(loader))
++-    x, y = x.to(device), y.to(device)
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
++ 
++-    with torch.no_grad():
++-        out = model(x)
++-        if normalized:
++-            y_normalizer = normalizer[1].to(device)
++-            out = y_normalizer.decode(out)
++-            y = y_normalizer.decode(y)
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
++ 
++-        # Calculate initial data loss
++-        initial_loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
+++                # --- MINIMAL CHANGE #2 ---
+++                # Pass the UN-FLATTENED tensors here as well.
+++                test_data += myloss(out, y).item()
+++
+++                if can_compute_pde and pde_weight > 0:
+++                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
+++                    test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()
+++
+++        # Normalize losses
+++        train_l2_hybrid /= len(train_loader)
+++        train_data /= len(train_loader)
+++        train_pde_scaled /= len(train_loader)
+++
+++        test_data /= len(test_loader)
+++        test_pde_loss_scaled /= len(test_loader)
++ 
++-        # Calculate initial raw PDE loss
++-        initial_loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
+++        test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled
++ 
++-        # Handle case where PDE loss is zero to avoid division by zero
++-        if initial_loss_pde_raw.item() < 1e-12:
++-            scaler = 1.0
++-            print("Warning: Initial PDE loss is near zero. Setting scaler to 1.0.")
++-        else:
++-            # The scaler is the ratio of the two losses
++-            scaler = initial_loss_data.item() / initial_loss_pde_raw.item()
++-            print(f"Computed initial loss scaler: {scaler:.4f}")
++-            print(f"  - Initial Data Loss: {initial_loss_data.item():.6f}")
++-            print(f"  - Initial PDE Loss (raw): {initial_loss_pde_raw.item():.6f}")
+++        # Append logs
+++        train_l2_hybrid_log.append(train_l2_hybrid)
+++        test_loss_hybrid_log.append(test_loss_hybrid)
+++        train_data_log.append(train_data)
+++        test_data_log.append(test_data)
+++        train_pde_scaled_log.append(train_pde_scaled)
+++        test_pde_loss_scaled_log.append(test_pde_loss_scaled)
++ 
++-    model.train()  # Set model back to training mode
++-    return scaler
+++        t2 = default_timer()
+++
+++        if ep == 0:
+++            print("No. Epoch | Time (s)   | Train L2 Hyb  | Test L2 Hyb   | Test L2 data  | Test PDE Scaled")
+++            print("---------------------------------------------------------------------------------------")
+++
+++        print(
+++            f"{ep:<9} | {t2 - t1:<10.4f} | {train_l2_hybrid:<13.6e} | {test_loss_hybrid:<13.6e} | {test_data:<13.6e} | {test_pde_loss_scaled:<13.6e}")
+++
+++    # Simplified return statement
+++    return model, train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log
+++'''''
+++
++ 
++ 
++ ''''
++Index: main1.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import os\nimport importlib\nimport torch\nimport inspect\nimport numpy as np\nimport matplotlib\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom training import train_fno, train_fno_time, train_hybrid\nfrom torch.utils.data import DataLoader, random_split\nfrom utilities import ImportDataset, count_params, LpLoss, ModelEvaluator\nfrom post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, make_video, save_vtk, plot_xy_plane_subplots\nimport time  # Import the time module at the beginning of the script\nfrom torch_optimizer import Lamb\nimport scipy.io\n\n################################################################\n# Problem Definition\n################################################################\n# problem = 'AC2D'\n#problem = 'AC3D'\n# problem = 'CH2DNL'\n# problem = 'SH2D'\nproblem = 'SH3D'\n# problem = 'PFC2D'\n#problem = 'PFC3D'\n#problem = 'MBE2D'\n#problem = 'MBE3D'\n# problem = 'CH2D'\n#problem = 'CH3D'\n\n#network_name = 'TNO2d'\n# network_name = 'FNO2d'\n#network_name = 'FNO3d'\nnetwork_name = 'TNO3d'\n\nPINN_MODE = False # True # False #\n\nprint(f\"problem = {problem}\")\nprint(f\"network = {network_name}\")\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\") # configuration file\n# above line means: import configs.config_PFC3D_TNO3d as cf\nnetwork = getattr(importlib.import_module('networks'), network_name) # from networks import TNO3d\ntorch.manual_seed(cf.torch_seed)\nnp.random.seed(cf.numpy_seed)\n#device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')\ndevice = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)\n# --- Define Output Directory ---\n\n\nPDE_WEIGHT = cf.pde_weight\nPDE_LOSS_SCALER = cf.pde_loss_scaler\n\nif PINN_MODE:\n    run_descriptor = f\"PINN_w{int(PDE_WEIGHT * 100)}\"\n    output_subdir = f\"plots_Data_Physics_{network_name}\"  # Specific PINN output\nelse:\n    run_descriptor = \"DataDriven\"\n    output_subdir = f\"plots_{network_name}\"  # Original data-driven output\n\n#model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'\nmodel_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}.pt'\nmodel_dir = os.path.join(problem, 'models') # models_smpooth\nmodel_name = f'{model_run_name}'\nmodel_path = os.path.join(model_dir, model_name)\n\nplot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir\nos.makedirs(model_dir, exist_ok=True)\nos.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists\n\nprint(f\"Model Run Name: {model_run_name}\")\nprint(f\"Model Path: {model_path}\")\nprint(f\"Plot Directory: {plot_dir}\")\n\n# width_q = 32\nstart_time = time.time()\n\n################################################################\n# load data and data normalization\n################################################################\n#model_dir = problem + '/models'\n\nprint(f\"model = {model_name}\")\nprint(f\"number of epoch = {cf.epochs}\")\nprint(f\"batch size = {cf.batch_size}\")\nprint(f\"nTrain = {cf.nTrain}\")\nprint(f\"nTest = {cf.nTest}\")\nprint(f\"learning_rate = {cf.learning_rate}\")\nprint(f\"n_layers = {cf.n_layers}\")\nprint(f\"width_q = {cf.width_q}\")\nprint(f\"width_h = {cf.width_h}\")\n\nmodel_path = os.path.join(model_dir, model_name)\nos.makedirs(model_dir, exist_ok=True)\n# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\ntrain_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])\n# to see train_dataset values: print(\"train_dataset subset:\", [train_dataset[i] for i in range(len(train_dataset))])\nnormalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)\n\n################################################################\n# training and evaluation\n################################################################\nsig = inspect.signature(network.__init__)\nrequired_args = [param.name for param in sig.parameters.values()\n                 if param.default == inspect.Parameter.empty and param.name != \"self\"]\nif network_name == 'FNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'FNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelse:\n    raise Exception(\"network_name is not correct\")\n\nprint(count_params(model))      # Print model parameters\ntrain_mse_log, train_l2_log, test_l2_log = [], [], []       # Initialize logs\n\n# Load the entire model and logs\nif os.path.exists(model_path) and cf.load_model:\n    print(f\"Loading pre-trained model from {model_path}\")\n    checkpoint = torch.load(model_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict']) # Use this line if you only save state_dict\n    #model = checkpoint['model'] # Use this line if you save the entire model object\n    train_mse_log = checkpoint.get('train_mse_log', [])\n    train_l2_log = checkpoint.get('train_l2_log', [])\n    test_l2_log = checkpoint.get('test_l2_log', [])\nelse:\n    print(\"No pre-trained model loaded. Initializing a new model.\")\n\n# Define optimizer, scheduler, and loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)\nmyloss = LpLoss(size_average=False)\n\n###\n\n# Train the model\nif cf.training:\n    print(\"\\n--- Starting Training ---\")\n    if PINN_MODE:\n        grid_info = {\n            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,\n            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,\n            'dt_model': cf.dt_model,\n            'T_out': cf.T_out\n        }\n\n        if PDE_WEIGHT == 0.0:\n            print(\"Running PINN training loop with pde_weight=0 (Data-Driven only loss).\")\n        else:\n            print(\n                f\"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {PDE_LOSS_SCALER:.2e}\")\n\n        model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (\n            train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                         optimizer, scheduler, cf.normalized, normalizers, device,\n                         PDE_WEIGHT, grid_info, cf.epsilon, problem,\n                         pde_loss_scaler=PDE_LOSS_SCALER)\n        )\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'train_mse_log': train_mse_hybrid_log,\n            'train_l2_log': train_l2_hybrid_log,\n            'test_l2_log': test_data_log,\n            'test_pde_scaled_log': test_pde_loss_scaled_log,\n            'train_data_log': train_data_log,\n            'train_pde_scaled_log': train_pde_scaled_log,\n            'test_loss_hybrid_log': test_loss_hybrid_log\n        }, model_path)\n\n    else:\n        if network_name in ['FNO2d', 'FNO3d']:\n            model, train_l2_log, test_l2_log = (\n                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                               optimizer, scheduler, cf.normalized, normalizers, device))\n            train_mse_log = []\n        else:\n            model, train_mse_log, train_l2_log, test_l2_log = (\n               train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                           optimizer, scheduler, cf.normalized, normalizers, device))\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'train_mse_log': train_mse_log,\n            'train_l2_log': train_l2_log,\n            'test_l2_log': test_l2_log\n        }, model_path)\n\n\nend_time = time.time()\nFinal_time = round(end_time - start_time, 2)\nprint(f\"Total Execution Time: {Final_time} seconds\")\n\nevaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,\n                           time_history=(network_name in ['FNO2d', 'FNO3d']))\n\nresults = evaluator.evaluate(loss_fn=myloss)\ninp = results['input']\npred = results['prediction']\nexact = results['exact']\ntest_l2_avg = results[\"average\"]\n\nif PINN_MODE:\n    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log]\n    labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\nelse:\n    losses = [train_l2_log, test_l2_log]\n    labels = ['Train L2', 'Test L2']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\n\n\n################################################################\n# post-processing\n################################################################\na_ind = inp[cf.index]\nu_pred = pred[cf.index]\nu_exact = exact[cf.index]\nerror = u_pred - u_exact\n\nplot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]\nprint(f\"Field shape: {u_exact.shape}\")\n\nselected_time_steps = [0, 2, 4, 6, 8, 9]\n\n# Plot exact solution\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=u_exact,\n                      field_name='Exact Solution',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[0],\n                      problem=problem,\n                      network_name=network_name)\n\n# Plot predicted solution\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=u_pred,\n                      field_name='Predicted Solution',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[1],\n                      problem=problem,\n                      network_name=network_name)\n\n# Plot error\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=error,\n                      field_name='Error',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[2],\n                      problem=problem,\n                      network_name=network_name)\n\n\n# ==============================================================================\n# NEW SECTION: PREDICT AND VISUALIZE A SINGLE TRAJECTORY EVOLUTION\n# ==============================================================================\nprint(\"\\n--- Generating Visualization for a Single Predicted Trajectory ---\")\n\n# Ensure dt_simulation is defined in the config file.\nif not hasattr(cf, 'dt_simulation'):\n    raise AttributeError(\"Configuration file is missing 'dt_simulation'. Please add it (e.g., dt_simulation = 0.00002).\")\n\npredicted_trajectory = u_pred # Shape: (s, s, s, T_out)\n\n# 1. Choose 4 suitable time frames for visualization from the predicted steps.\nnum_time_frames_to_plot = 4\ntotal_predicted_steps = predicted_trajectory.shape[-1]  # This is T_out\n\nif total_predicted_steps < 1:\n    print(\"No time steps to plot in the predicted trajectory.\")\nelse:\n    # Select 4 evenly spaced indices from the available time steps.\n    time_indices_to_plot = np.linspace(0, total_predicted_steps - 1, num_time_frames_to_plot, dtype=int).tolist()\n\n    print(f\"Selected time indices for plotting: {time_indices_to_plot}\")\n\n    # 2. Create the subplot (1 row, 4 columns) and save it.\n    fig, axes = plt.subplots(1, num_time_frames_to_plot, figsize=(5 * num_time_frames_to_plot, 5), squeeze=False)\n    axes = axes.flatten()\n\n    vmin = predicted_trajectory.cpu().numpy().min()\n    vmax = predicted_trajectory.cpu().numpy().max()\n    s = cf.s\n    slice_index = s // 2  # Middle slice in the Z-direction\n\n    for i, t_idx in enumerate(time_indices_to_plot):\n        # 3. Calculate the correct physical time for the label.\n        # The prediction starts after T_in steps.\n        physical_time = (cf.T_in + t_idx) * cf.dt_simulation\n\n        slice_2d = predicted_trajectory[:, :, slice_index, t_idx].cpu().numpy()\n\n        ax = axes[i]\n        im = ax.imshow(slice_2d, cmap='viridis', vmin=vmin, vmax=vmax,\n                       extent=[0, cf.Lx, 0, cf.Ly], origin='lower', interpolation='bicubic')\n        ax.set_title(f'Predicted t={physical_time:.2e}') # Use scientific notation for time\n        ax.set_xlabel('x')\n        if i == 0:\n            ax.set_ylabel('y')\n\n    fig.colorbar(im, ax=axes.tolist(), orientation='vertical', pad=0.02)\n    z_coord = cf.Lx / s * (slice_index - s / 2)\n    fig.suptitle(f'Predicted Evolution (Z-slice at z={z_coord:.2f})', fontsize=16)\n    fig.tight_layout(rect=[0, 0, 1, 0.95])\n\n    subplot_filename = os.path.join(plot_dir, f'{model_run_name}_single_trajectory_subplot.png')\n    plt.savefig(subplot_filename, dpi=300, bbox_inches='tight')\n    print(f\"Trajectory subplot saved to {subplot_filename}\")\n    plt.close(fig)\n\n# END OF NEW SECTION\n# ==============================================================================\n\n# The p=2 explicitly specifies the L2 norm.\nl2_norm_error = torch.norm(u_pred - u_exact, p=2)\n\n# Calculate the L2 norm of the exact solution\nl2_norm_exact = torch.norm(u_exact, p=2)\n\n# Calculate the relative L2 norm error\nepsilon = 1e-8\nif l2_norm_exact.item() > epsilon:\n    relative_l2_error = l2_norm_error / l2_norm_exact\nelse:\n    if l2_norm_error.item() < epsilon:\n        relative_l2_error = torch.tensor(0.0, device=u_pred.device, dtype=u_pred.dtype)\n    else:\n        print(f\"Warning: L2 norm of exact solution is {l2_norm_exact.item()}, which is close to zero. L2 norm of error is {l2_norm_error.item()}.\")\n        relative_l2_error = torch.tensor(float('inf'), device=u_pred.device, dtype=u_pred.dtype)\n\nprint(f\"L2 norm of error: {l2_norm_error.item()}\")\nprint(f\"L2 norm of exact solution: {l2_norm_exact.item()}\")\nprint(f\"Relative L2 norm error: {relative_l2_error.item()}\")\nrelative_l2_error_percentage = (relative_l2_error * 100)\nprint(f\"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%\")\n\n###\nplot_combined_results(\n    domain=cf.domain,\n    u_exact=u_exact,\n    u_pred=u_pred,\n    error=error,\n    plot_ranges=[\n        [-1.2, 1.2],\n        [-1.2, 1.2],\n        [-1.2, 1.2]\n    ],\n    problem=problem,\n    network_name=network_name,\n    plot_dir = plot_dir,\n    pde_weight = PDE_WEIGHT\n)\n\nplot_combined_results_3d(\n    domain=cf.domain,\n    u_exact=u_exact,\n    u_pred=u_pred,\n    error=error,\n    plot_ranges=[\n        [-1.2, 1.2],\n        [-1.2, 1.2],\n        [-1.2, 1.2]\n    ],\n    problem=problem,\n    network_name=network_name,\n    plot_dir = plot_dir,\n    pde_weight = PDE_WEIGHT\n)\n\n################################################################\n# Save Results to MATLAB .mat file\n################################################################\nprint(\"\\n--- Saving Results to .mat File ---\")\n\nmat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')\n\nif PINN_MODE:\n    try:\n        results_dict = {\n            'train_mse_log': train_mse_hybrid_log,\n            'train_hybrid_loss': np.array(train_l2_hybrid_log),\n            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),\n            'train_data_log': np.array(train_data_log),\n            'test_data_log': np.array(test_data_log),\n            'train_pde_scaled_log': np.array(train_pde_scaled_log),\n            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,\n            'config_pde_loss_scaler': PDE_LOSS_SCALER if PINN_MODE else 0.0,\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\nelse:\n    try:\n        results_dict = {\n            'train_mse_log': np.array(train_mse_log),\n            'train_l2_log': np.array(train_l2_log),\n            'test_l2_log': np.array(test_l2_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\n\nprint(\"\\n--- Script Finished ---\")
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/main1.py b/main1.py
++--- a/main1.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/main1.py	(date 1753977480583)
++@@ -1,111 +1,128 @@
+++
++ import os
++ import importlib
++ import torch
++ import inspect
++ import numpy as np
++ import matplotlib
+++import h5py  # MODIFIED: Added h5py import
+++import scipy.io
+++
++ matplotlib.use('TkAgg')
++ import matplotlib.pyplot as plt
++ import torch.nn.functional as F
++-from training import train_fno, train_fno_time, train_hybrid
+++from training import train_fno, train_fno_time, train_hybrid, train_fno4d
++ from torch.utils.data import DataLoader, random_split
++-from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator
++-from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, make_video, save_vtk, plot_xy_plane_subplots
++-import time  # Import the time module at the beginning of the script
+++from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator, SobolevLoss
+++from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \
+++    make_video, save_vtk, plot_xy_plane_subplots
+++import time
++ from torch_optimizer import Lamb
++-import scipy.io
+++
+++################################################################
+++# Problem Definition
+++################################################################
++ 
++ ################################################################
++ # Problem Definition
++ ################################################################
++ # problem = 'AC2D'
++-#problem = 'AC3D'
+++problem = 'AC3D'
++ # problem = 'CH2DNL'
++ # problem = 'SH2D'
++-problem = 'SH3D'
+++#problem = 'SH3D'
++ # problem = 'PFC2D'
++ #problem = 'PFC3D'
++-#problem = 'MBE2D'
+++# problem = 'MBE2D'
++ #problem = 'MBE3D'
++ # problem = 'CH2D'
++ #problem = 'CH3D'
++ 
++-#network_name = 'TNO2d'
+++# network_name = 'TNO2d'
++ # network_name = 'FNO2d'
++ #network_name = 'FNO3d'
+++#network_name = 'FNO4d'
++ network_name = 'TNO3d'
++ 
++-PINN_MODE = False # True # False #
+++PINN_MODE =  False # True #  True #  False #  True #   True #    True #
+++#  False #    True # False #  False  # False #
++ 
++ print(f"problem = {problem}")
++ print(f"network = {network_name}")
++ os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
++-cf = importlib.import_module(f"configs.config_{problem}_{network_name}") # configuration file
++-# above line means: import configs.config_PFC3D_TNO3d as cf
++-network = getattr(importlib.import_module('networks'), network_name) # from networks import TNO3d
+++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+++network = getattr(importlib.import_module('networks'), network_name)
++ torch.manual_seed(cf.torch_seed)
++ np.random.seed(cf.numpy_seed)
++-#device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')
++-device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")
+++device = torch.device("cuda:2" if torch.cuda.is_available() else "cpu")
++ print("Device: ", device)
++-# --- Define Output Directory ---
++-
++ 
++ PDE_WEIGHT = cf.pde_weight
++-PDE_LOSS_SCALER = cf.pde_loss_scaler
+++pde_loss_scaler = cf.pde_loss_scaler
++ 
++ if PINN_MODE:
++     run_descriptor = f"PINN_w{int(PDE_WEIGHT * 100)}"
++-    output_subdir = f"plots_Data_Physics_{network_name}"  # Specific PINN output
+++    output_subdir = f"plots_Data_Physics_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_Hybrid_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
++ else:
++     run_descriptor = "DataDriven"
++-    output_subdir = f"plots_{network_name}"  # Original data-driven output
+++    output_subdir = f"plots_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
++ 
++-#model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'
++-model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}.pt'
++-model_dir = os.path.join(problem, 'models') # models_smpooth
+++model_dir = os.path.join(problem, 'models')
++ model_name = f'{model_run_name}'
++ model_path = os.path.join(model_dir, model_name)
++-
++-plot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir
+++plot_dir = os.path.join(problem, output_subdir)
++ os.makedirs(model_dir, exist_ok=True)
++-os.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists
+++os.makedirs(plot_dir, exist_ok=True)
++ 
++ print(f"Model Run Name: {model_run_name}")
++ print(f"Model Path: {model_path}")
++ print(f"Plot Directory: {plot_dir}")
++ 
++-# width_q = 32
++ start_time = time.time()
++ 
++ ################################################################
++ # load data and data normalization
++ ################################################################
++-#model_dir = problem + '/models'
++-
++-print(f"model = {model_name}")
++-print(f"number of epoch = {cf.epochs}")
++-print(f"batch size = {cf.batch_size}")
++-print(f"nTrain = {cf.nTrain}")
++-print(f"nTest = {cf.nTest}")
++-print(f"learning_rate = {cf.learning_rate}")
++-print(f"n_layers = {cf.n_layers}")
++-print(f"width_q = {cf.width_q}")
++-print(f"width_h = {cf.width_h}")
++-
++-model_path = os.path.join(model_dir, model_name)
++-os.makedirs(model_dir, exist_ok=True)
++-# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf
++-dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++# MODIFIED: Added special handling for SH3D dataset loading
+++try:
+++    dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++    if problem == 'SH3D':
+++        print("SH3D dataset detected - applying special handling")
+++        # Verify dataset sizes
+++        sample = dataset[0][0]  # Get first sample
+++        print(f"SH3D sample shape: {sample.shape}, dtype: {sample.dtype}")
+++        print(f"SH3D stats - mean: {sample.mean():.4f}, std: {sample.std():.4f}")
+++except Exception as e:
+++    print(f"Error loading dataset: {e}")
+++    raise
++ 
++ train_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])
++-# to see train_dataset values: print("train_dataset subset:", [train_dataset[i] for i in range(len(train_dataset))])
++ normalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None
++ 
++-train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
++-test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++train_loader = DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
+++test_loader = DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++
++ 
++-################################################################
+++# ==================== CODE TO INSPECT BATCH SHAPE ====================
+++print("\n" + "="*50)
+++print("Inspecting DataLoader Batch Shapes")
+++print("="*50)
+++# Get one batch of data from the train_loader
+++try:
+++    x_batch, y_batch = next(iter(train_loader))
+++    # Print the shape of the batch
+++    # This will be (batch_size, S, S, S, T_in) for input
+++    # and (batch_size, S, S, S, T_out) for target
+++    print(f"Shape of an input batch from DataLoader: {x_batch.shape}")
+++    print(f"Shape of a target batch from DataLoader: {y_batch.shape}")
+++except StopIteration:
+++    print("Train loader is empty. Cannot retrieve a batch.")
+++print("="*50 + "\n")
+++# =======================================================================
+++
+++############AA####################################################
++ # training and evaluation
++ ################################################################
++ sig = inspect.signature(network.__init__)
++@@ -118,19 +135,32 @@
++ elif network_name == 'FNO3d':
++     model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)
++ elif network_name == 'TNO3d':
++-    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)
+++    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(
+++        device)
+++elif network_name == 'FNO4d':
+++    model = network(
+++        modes1=cf.modes,
+++        modes2=cf.modes,
+++        modes3=cf.modes,
+++        modes4_internal =1, # cf.modes_t, # MUST BE 1
+++        width=cf.width,
+++        width_q=cf.width_q,
+++        T_in_channels=cf.T_in,
+++        n_layers=cf.n_layers
+++    ).to(device)
+++
+++
++ else:
++     raise Exception("network_name is not correct")
++ 
++-print(count_params(model))      # Print model parameters
++-train_mse_log, train_l2_log, test_l2_log = [], [], []       # Initialize logs
+++print(count_params(model))  # Print model parameters
+++train_mse_log, train_l2_log, test_l2_log = [], [], []  # Initialize logs
++ 
++ # Load the entire model and logs
++ if os.path.exists(model_path) and cf.load_model:
++     print(f"Loading pre-trained model from {model_path}")
++     checkpoint = torch.load(model_path, map_location=device)
++-    model.load_state_dict(checkpoint['model_state_dict']) # Use this line if you only save state_dict
++-    #model = checkpoint['model'] # Use this line if you save the entire model object
+++    model = checkpoint['model']
++     train_mse_log = checkpoint.get('train_mse_log', [])
++     train_l2_log = checkpoint.get('train_l2_log', [])
++     test_l2_log = checkpoint.get('test_l2_log', [])
++@@ -140,14 +170,19 @@
++ # Define optimizer, scheduler, and loss function
++ optimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)
++ scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)
++-myloss = LpLoss(size_average=False)
+++myloss = LpLoss(p=2, l1_weight=0.1, size_average=False) # size_average=True # False
+++# NEW: Instantiate SobolevLoss instead of LpLoss
+++# You can tune grad_weight. A good starting point is 0.1 or 1.0.
+++#myloss = SobolevLoss(d=3, p=2, grad_weight=0.1)
++ 
++-###
+++# COMPUTE THE DYNAMIC SCALER
+++# Use the train_loader to get a representative batch
+++
++ 
++ # Train the model
++ if cf.training:
++     print("\n--- Starting Training ---")
++-    if PINN_MODE:
+++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
++         grid_info = {
++             'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
++             'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
++@@ -159,18 +194,18 @@
++             print("Running PINN training loop with pde_weight=0 (Data-Driven only loss).")
++         else:
++             print(
++-                f"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {PDE_LOSS_SCALER:.2e}")
+++                f"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {pde_loss_scaler:.2e}")
++ 
++         model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (
++             train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                          optimizer, scheduler, cf.normalized, normalizers, device,
++                          PDE_WEIGHT, grid_info, cf.epsilon, problem,
++-                         pde_loss_scaler=PDE_LOSS_SCALER)
+++                         pde_loss_scaler=pde_loss_scaler)
++         )
++ 
++         print(f"Saving model and logs to {model_path}")
++         torch.save({
++-            'model_state_dict': model.state_dict(),
+++            'model': model,
++             'train_mse_log': train_mse_hybrid_log,
++             'train_l2_log': train_l2_hybrid_log,
++             'test_l2_log': test_data_log,
++@@ -180,32 +215,134 @@
++             'test_loss_hybrid_log': test_loss_hybrid_log
++         }, model_path)
++ 
++-    else:
++-        if network_name in ['FNO2d', 'FNO3d']:
+++    else:  # Original Data-Driven Mode
+++        if network_name == 'FNO2d' or network_name == 'FNO3d':
+++            model, train_l2_log, test_l2_log = (
+++                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                               optimizer, scheduler, cf.normalized, normalizers, device))
+++            train_mse_log = []
+++        elif network_name == 'FNO4d':
+++
+++            model, train_mse_log, train_l2_log, test_l2_log = (  # Add val logs
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++            # train_fno4d = train_fno
+++        else:
+++            model, train_mse_log, train_l2_log, test_l2_log = (
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++    print(f"Saving model and logs to {model_path}")
+++    torch.save({
+++        'model': model,
+++        'train_mse_log': train_mse_log,
+++        'train_l2_log': train_l2_log,
+++        'test_l2_log': test_l2_log
+++    }, model_path)
+++
+++
+++'''
+++# Train the model
+++if cf.training:
+++    print("\n--- Starting Training ---")
+++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
+++        grid_info = {
+++            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
+++            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
+++            'dt_model': cf.dt_model,
+++            'T_out': cf.T_out
+++        }
+++
+++        # --- NEW: Define the two stages for the training curriculum ---
+++        epochs_stage1 = 10
+++        scaler_stage1 = 1e-4
+++
+++        # Calculate remaining epochs for stage 2
+++        epochs_stage2 = cf.epochs - epochs_stage1
+++        scaler_stage2 = 1e-6
+++
+++        # --- Stage 1 Training ---
+++        print("\n--- Starting Training Stage 1 ---")
+++        print(f"Epochs: {epochs_stage1}, PDE Scaler: {scaler_stage1:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++        # Note: The 'model' object is updated in-place by the function call
+++        model, train_mse_s1, train_l2_s1, test_data_s1, test_pde_s1, train_data_s1, train_pde_scl_s1, test_loss_s1 = (
+++            train_hybrid(model, myloss, epochs_stage1, cf.batch_size, train_loader, test_loader,
+++                         optimizer, scheduler, cf.normalized, normalizers, device,
+++                         PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                         pde_loss_scaler=scaler_stage1)
+++        )
+++
+++        # --- Stage 2 Training (if there are remaining epochs) ---
+++        if epochs_stage2 > 0:
+++            print("\n--- Starting Training Stage 2 ---")
+++            print(f"Epochs: {epochs_stage2}, PDE Scaler: {scaler_stage2:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++            model, train_mse_s2, train_l2_s2, test_data_s2, test_pde_s2, train_data_s2, train_pde_scl_s2, test_loss_s2 = (
+++                train_hybrid(model, myloss, epochs_stage2, cf.batch_size, train_loader, test_loader,
+++                             optimizer, scheduler, cf.normalized, normalizers, device,
+++                             PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                             pde_loss_scaler=scaler_stage2)
+++            )
+++
+++            # Combine the logs from both stages for plotting and saving
+++            train_mse_hybrid_log = train_mse_s1 + train_mse_s2
+++            train_l2_hybrid_log = train_l2_s1 + train_l2_s2
+++            test_data_log = test_data_s1 + test_data_s2
+++            test_pde_loss_scaled_log = test_pde_s1 + test_pde_s2
+++            train_data_log = train_data_s1 + train_data_s2
+++            train_pde_scaled_log = train_pde_scl_s1 + train_pde_scl_s2
+++            test_loss_hybrid_log = test_loss_s1 + test_loss_s2
+++        else:
+++            # If only stage 1 was run, the final logs are just the stage 1 logs
+++            train_mse_hybrid_log = train_mse_s1
+++            train_l2_hybrid_log = train_l2_s1
+++            test_data_log = test_data_s1
+++            test_pde_loss_scaled_log = test_pde_s1
+++            train_data_log = train_data_s1
+++            train_pde_scaled_log = train_pde_scl_s1
+++            test_loss_hybrid_log = test_loss_s1
+++
+++        print(f"\n--- Training Finished. Saving model and logs to {model_path} ---")
+++        # The torch.save call remains the same, as the log variables have been correctly prepared
+++        torch.save({
+++            'model': model,
+++            'train_mse_log': train_mse_hybrid_log,
+++            'train_l2_log': train_l2_hybrid_log,
+++            'test_l2_log': test_data_log, # 'test_l2_log' is used by evaluator, it should contain data loss
+++            'test_pde_scaled_log': test_pde_loss_scaled_log,
+++            'train_data_log': train_data_log,
+++            'train_pde_scaled_log': train_pde_scaled_log,
+++            'test_loss_hybrid_log': test_loss_hybrid_log
+++        }, model_path)
+++
+++    else:  # Original Data-Driven Mode (This part remains unchanged)
+++        if network_name == 'FNO2d' or network_name == 'FNO3d':
++             model, train_l2_log, test_l2_log = (
++                 train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                                optimizer, scheduler, cf.normalized, normalizers, device))
++             train_mse_log = []
++         else:
++             model, train_mse_log, train_l2_log, test_l2_log = (
++-               train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++-                           optimizer, scheduler, cf.normalized, normalizers, device))
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
++ 
++         print(f"Saving model and logs to {model_path}")
++         torch.save({
++-            'model_state_dict': model.state_dict(),
+++            'model': model,
++             'train_mse_log': train_mse_log,
++             'train_l2_log': train_l2_log,
++             'test_l2_log': test_l2_log
++         }, model_path)
++-
+++'''
++ 
++ end_time = time.time()
++ Final_time = round(end_time - start_time, 2)
++ print(f"Total Execution Time: {Final_time} seconds")
++ 
++ evaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,
++-                           time_history=(network_name in ['FNO2d', 'FNO3d']))
+++                           time_history=(network_name == 'FNO2d'))
++ 
++ results = evaluator.evaluate(loss_fn=myloss)
++ inp = results['input']
++@@ -214,7 +351,8 @@
++ test_l2_avg = results["average"]
++ 
++ if PINN_MODE:
++-    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log]
+++    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log,
+++              train_pde_scaled_log]
++     labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']
++     plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)
++ else:
++@@ -222,7 +360,6 @@
++     labels = ['Train L2', 'Test L2']
++     plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)
++ 
++-
++ ################################################################
++ # post-processing
++ ################################################################
++@@ -231,115 +368,202 @@
++ u_exact = exact[cf.index]
++ error = u_pred - u_exact
++ 
+++print(f"DEBUG: Shape of u_exact passed to plotting function: {u_exact.shape}")
+++print(f"DEBUG: Shape of u_pred passed to plotting function: {u_pred.shape}")
+++
++ plot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]
++-print(f"Field shape: {u_exact.shape}")
+++
+++# =========================================================================================
+++# ===                START OF MODIFIED PLOTTING PREPARATION BLOCK                      ===
+++# =========================================================================================
+++
+++# 1. Get the initial condition (t=0) data for the chosen sample index
+++a_ind = inp[cf.index]
+++print(f"Shape of initial condition (t=0) data 'a_ind': {a_ind.shape}")
+++
+++# 2. Separate desired times into t=0 vs. future predictions
+++desired_times = cf.time_steps
+++future_times_to_plot = []
+++has_initial_condition = (0 in desired_times)
+++for t in desired_times:
+++    if t > 0:
+++        future_times_to_plot.append(t)
+++
+++# 3. Translate the FUTURE times to array indices
+++indices_to_plot = []
+++valid_future_times = []
+++for t in future_times_to_plot:
+++    if t <= cf.T_out:
+++        indices_to_plot.append(t - 1)
+++        valid_future_times.append(t)
+++    else:
+++        print(f"Warning: Time t={t} is out of valid prediction range. Skipping.")
+++print(f"Plotting for future times: {valid_future_times} --> which correspond to array indices: {indices_to_plot}")
+++
+++# 4. MOVE ALL DATA TO THE TARGET DEVICE BEFORE OPERATIONS
+++t0_data_cpu = a_ind
+++u_exact_cpu = u_exact
+++u_pred_cpu = u_pred
+++error_cpu = error
+++
+++t0_data_gpu = t0_data_cpu.to(device)
+++u_exact_gpu = u_exact_cpu.to(device)
+++u_pred_gpu = u_pred_cpu.to(device)
+++error_gpu = error_cpu.to(device)
+++indices_tensor_gpu = torch.tensor(indices_to_plot, device=device)
+++
+++# 5. PREPARE COMBINED TENSORS FOR PLOTTING on the GPU
+++if has_initial_condition:
+++    # --- ### FIXED DIMENSION HANDLING ### ---
+++    # `a_ind` has shape (sx, sy, sz, 1) where the last dim is a channel.
+++    # `u_exact_gpu` has shape (sx, sy, sz, T) where the last dim is time.
+++    # They are both 4D, so we can concatenate them directly if the last dimension is treated as the time dimension.
+++    # We don't need to do any reshaping. `t0_data_gpu` is already correct.
+++    t0_for_concat = t0_data_gpu
+++
+++    # Select the future time slices from the GPU tensors
+++    u_exact_selected = u_exact_gpu.index_select(-1, indices_tensor_gpu)
+++    u_pred_selected = u_pred_gpu.index_select(-1, indices_tensor_gpu)
+++    error_selected = error_gpu.index_select(-1, indices_tensor_gpu)
+++
+++    # Combine t=0 data with the selected future steps
+++    u_exact_for_plot = torch.cat((t0_for_concat, u_exact_selected), dim=-1)
+++    u_pred_for_plot = torch.cat((t0_for_concat, u_pred_selected), dim=-1)
+++
+++    # The error for t=0 is zero by definition
+++    error_t0 = torch.zeros_like(t0_for_concat)
+++    error_for_plot = torch.cat((error_t0, error_selected), dim=-1)
++ 
++-selected_time_steps = [0, 2, 4, 6, 8, 9]
+++    final_indices = list(range(len(desired_times)))
+++    final_labels = desired_times
+++else:
+++    u_exact_for_plot = u_exact_gpu
+++    u_pred_for_plot = u_pred_gpu
+++    error_for_plot = error_gpu
+++    final_indices = indices_to_plot
+++    final_labels = valid_future_times
++ 
++-# Plot exact solution
+++print(f"Final data prepared for plotting with shape: {u_exact_for_plot.shape}")
+++print(f"Final indices for plotting: {final_indices}")
+++print(f"Final labels for plotting: {final_labels}")
+++
+++
+++# =========================================================================================
+++# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===
+++# =========================================================================================
+++
+++################################################################
+++# Save Results to MATLAB .mat file
+++################################################################
+++print("\n--- Saving Results to .mat File ---")
+++mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
+++
+++# MODIFIED: Enhanced saving logic with fallbacks
+++def save_results(mat_filename, results_dict):
+++    try:
+++        # First try standard save
+++        scipy.io.savemat(mat_filename, results_dict)
+++        print(f"Saved with standard format to {mat_filename}")
+++    except ValueError as e:
+++        if "Format should be '4' or '5'" in str(e):
+++            print("Large data detected, trying v7.3 format...")
+++            try:
+++                scipy.io.savemat(mat_filename, results_dict, format='v7.3')
+++                print(f"Saved with v7.3 format to {mat_filename}")
+++            except Exception as e:
+++                print(f"v7.3 failed: {e}")
+++                # Fallback to HDF5
+++                h5_filename = mat_filename.replace('.mat', '.h5')
+++                with h5py.File(h5_filename, 'w') as f:
+++                    for k, v in results_dict.items():
+++                        f.create_dataset(k, data=v, compression='gzip')
+++                print(f"Saved as HDF5 to {h5_filename}")
+++        else:
+++            raise
+++
+++if PINN_MODE:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_hybrid_log, dtype=np.float32),  # MODIFIED: Added dtype
+++        'train_hybrid_loss': np.array(train_l2_hybrid_log, dtype=np.float32),
+++        'test_loss_hybrid_log': np.array(test_loss_hybrid_log, dtype=np.float32),
+++        'train_data_log': np.array(train_data_log, dtype=np.float32),
+++        'test_data_log': np.array(test_data_log, dtype=np.float32),
+++        'train_pde_scaled_log': np.array(train_pde_scaled_log, dtype=np.float32),
+++        'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),  # MODIFIED: Added astype
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_pde_weight': np.float32(PDE_WEIGHT),
+++        'config_pde_loss_scaler': np.float32(pde_loss_scaler),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++    }
+++else:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_log, dtype=np.float32),
+++        'train_l2_log': np.array(train_l2_log, dtype=np.float32),
+++        'test_l2_log': np.array(test_l2_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++    }
+++
+++# MODIFIED: Use the new save function
+++save_results(mat_filename, results_dict)
+++
+++# Plot XY-plane for the "Exact" solution trajectory (includes t=0)
+++
+++'''
++ plot_xy_plane_subplots(domain=cf.domain,
++-                      field=u_exact,
++-                      field_name='Exact Solution',
++-                      time_steps=selected_time_steps,
++-                      plot_range=plot_range[0],
++-                      problem=problem,
++-                      network_name=network_name)
+++                       field=u_exact_for_plot,
+++                       field_name='Exact Solution',
+++                       time_steps=final_indices,
+++                       desired_times=final_labels,
+++                       plot_range=plot_range[0],
+++                       problem=problem,
+++                       network_name=network_name)
++ 
++-# Plot predicted solution
+++# Plot XY-plane for the "Predicted" solution trajectory (includes t=0 from input)
++ plot_xy_plane_subplots(domain=cf.domain,
++-                      field=u_pred,
++-                      field_name='Predicted Solution',
++-                      time_steps=selected_time_steps,
++-                      plot_range=plot_range[1],
++-                      problem=problem,
++-                      network_name=network_name)
+++                       field=u_pred_for_plot,
+++                       field_name='Predicted Solution',
+++                       time_steps=final_indices,
+++                       desired_times=final_labels,
+++                       plot_range=plot_range[1],
+++                       problem=problem,
+++                       network_name=network_name)
++ 
++-# Plot error
+++# Plot XY-plane for the "Error" (error is 0 at t=0)
++ plot_xy_plane_subplots(domain=cf.domain,
++-                      field=error,
++-                      field_name='Error',
++-                      time_steps=selected_time_steps,
++-                      plot_range=plot_range[2],
++-                      problem=problem,
++-                      network_name=network_name)
++-
++-
++-# ==============================================================================
++-# NEW SECTION: PREDICT AND VISUALIZE A SINGLE TRAJECTORY EVOLUTION
++-# ==============================================================================
++-print("\n--- Generating Visualization for a Single Predicted Trajectory ---")
++-
++-# Ensure dt_simulation is defined in the config file.
++-if not hasattr(cf, 'dt_simulation'):
++-    raise AttributeError("Configuration file is missing 'dt_simulation'. Please add it (e.g., dt_simulation = 0.00002).")
++-
++-predicted_trajectory = u_pred # Shape: (s, s, s, T_out)
++-
++-# 1. Choose 4 suitable time frames for visualization from the predicted steps.
++-num_time_frames_to_plot = 4
++-total_predicted_steps = predicted_trajectory.shape[-1]  # This is T_out
++-
++-if total_predicted_steps < 1:
++-    print("No time steps to plot in the predicted trajectory.")
++-else:
++-    # Select 4 evenly spaced indices from the available time steps.
++-    time_indices_to_plot = np.linspace(0, total_predicted_steps - 1, num_time_frames_to_plot, dtype=int).tolist()
++-
++-    print(f"Selected time indices for plotting: {time_indices_to_plot}")
+++                       field=error_for_plot,
+++                       field_name='Error',
+++                       time_steps=final_indices,
+++                       desired_times=final_labels,
+++                       plot_range=plot_range[2],
+++                       problem=problem,
+++                       network_name=network_name)
+++'''
++ 
++-    # 2. Create the subplot (1 row, 4 columns) and save it.
++-    fig, axes = plt.subplots(1, num_time_frames_to_plot, figsize=(5 * num_time_frames_to_plot, 5), squeeze=False)
++-    axes = axes.flatten()
++-
++-    vmin = predicted_trajectory.cpu().numpy().min()
++-    vmax = predicted_trajectory.cpu().numpy().max()
++-    s = cf.s
++-    slice_index = s // 2  # Middle slice in the Z-direction
++-
++-    for i, t_idx in enumerate(time_indices_to_plot):
++-        # 3. Calculate the correct physical time for the label.
++-        # The prediction starts after T_in steps.
++-        physical_time = (cf.T_in + t_idx) * cf.dt_simulation
++-
++-        slice_2d = predicted_trajectory[:, :, slice_index, t_idx].cpu().numpy()
++-
++-        ax = axes[i]
++-        im = ax.imshow(slice_2d, cmap='viridis', vmin=vmin, vmax=vmax,
++-                       extent=[0, cf.Lx, 0, cf.Ly], origin='lower', interpolation='bicubic')
++-        ax.set_title(f'Predicted t={physical_time:.2e}') # Use scientific notation for time
++-        ax.set_xlabel('x')
++-        if i == 0:
++-            ax.set_ylabel('y')
++-
++-    fig.colorbar(im, ax=axes.tolist(), orientation='vertical', pad=0.02)
++-    z_coord = cf.Lx / s * (slice_index - s / 2)
++-    fig.suptitle(f'Predicted Evolution (Z-slice at z={z_coord:.2f})', fontsize=16)
++-    fig.tight_layout(rect=[0, 0, 1, 0.95])
++-
++-    subplot_filename = os.path.join(plot_dir, f'{model_run_name}_single_trajectory_subplot.png')
++-    plt.savefig(subplot_filename, dpi=300, bbox_inches='tight')
++-    print(f"Trajectory subplot saved to {subplot_filename}")
++-    plt.close(fig)
++-
++-# END OF NEW SECTION
++-# ==============================================================================
++-
++-# The p=2 explicitly specifies the L2 norm.
+++# Calculate L2 norm on original full prediction
++ l2_norm_error = torch.norm(u_pred - u_exact, p=2)
++-
++-# Calculate the L2 norm of the exact solution
++ l2_norm_exact = torch.norm(u_exact, p=2)
++-
++-# Calculate the relative L2 norm error
++ epsilon = 1e-8
++ if l2_norm_exact.item() > epsilon:
++     relative_l2_error = l2_norm_error / l2_norm_exact
++ else:
++-    if l2_norm_error.item() < epsilon:
++-        relative_l2_error = torch.tensor(0.0, device=u_pred.device, dtype=u_pred.dtype)
++-    else:
++-        print(f"Warning: L2 norm of exact solution is {l2_norm_exact.item()}, which is close to zero. L2 norm of error is {l2_norm_error.item()}.")
++-        relative_l2_error = torch.tensor(float('inf'), device=u_pred.device, dtype=u_pred.dtype)
+++    relative_l2_error = torch.tensor(0.0) if l2_norm_error.item() < epsilon else torch.tensor(float('inf'))
++ 
++ print(f"L2 norm of error: {l2_norm_error.item()}")
++ print(f"L2 norm of exact solution: {l2_norm_exact.item()}")
++@@ -347,93 +571,33 @@
++ relative_l2_error_percentage = (relative_l2_error * 100)
++ print(f"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%")
++ 
++-###
+++# Call the combined results plots with the prepared data
++ plot_combined_results(
++     domain=cf.domain,
++-    u_exact=u_exact,
++-    u_pred=u_pred,
++-    error=error,
++-    plot_ranges=[
++-        [-1.2, 1.2],
++-        [-1.2, 1.2],
++-        [-1.2, 1.2]
++-    ],
+++    u_exact=u_exact_for_plot,
+++    u_pred=u_pred_for_plot,
+++    error=error_for_plot,
+++    plot_ranges=plot_range,
++     problem=problem,
++     network_name=network_name,
++-    plot_dir = plot_dir,
++-    pde_weight = PDE_WEIGHT
+++    plot_dir=plot_dir,
+++    pde_weight=PDE_WEIGHT,
+++    time_steps_indices=final_indices,
+++    desired_times=final_labels
++ )
++ 
++ plot_combined_results_3d(
++     domain=cf.domain,
++-    u_exact=u_exact,
++-    u_pred=u_pred,
++-    error=error,
++-    plot_ranges=[
++-        [-1.2, 1.2],
++-        [-1.2, 1.2],
++-        [-1.2, 1.2]
++-    ],
+++    u_exact=u_exact_for_plot,
+++    u_pred=u_pred_for_plot,
+++    error=error_for_plot,
+++    plot_ranges=plot_range,
++     problem=problem,
++     network_name=network_name,
++-    plot_dir = plot_dir,
++-    pde_weight = PDE_WEIGHT
+++    plot_dir=plot_dir,
+++    pde_weight=PDE_WEIGHT,
+++    time_steps_indices=final_indices,
+++    desired_times=final_labels
++ )
++ 
++-################################################################
++-# Save Results to MATLAB .mat file
++-################################################################
++-print("\n--- Saving Results to .mat File ---")
++-
++-mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
++-
++-if PINN_MODE:
++-    try:
++-        results_dict = {
++-            'train_mse_log': train_mse_hybrid_log,
++-            'train_hybrid_loss': np.array(train_l2_hybrid_log),
++-            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),
++-            'train_data_log': np.array(train_data_log),
++-            'test_data_log': np.array(test_data_log),
++-            'train_pde_scaled_log': np.array(train_pde_scaled_log),
++-            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,
++-            'config_pde_loss_scaler': PDE_LOSS_SCALER if PINN_MODE else 0.0,
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-else:
++-    try:
++-        results_dict = {
++-            'train_mse_log': np.array(train_mse_log),
++-            'train_l2_log': np.array(train_l2_log),
++-            'test_l2_log': np.array(test_l2_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-
++ print("\n--- Script Finished ---")
++\ No newline at end of file
++Index: networks.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef get_grid_2d(shape, device):\n    batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n    gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n    gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n    return torch.cat((gridx, gridy), dim=-1).to(device)\n\n\ndef get_grid_3d(shape, device):\n    batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n    gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n    gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n    gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n    return torch.cat((gridx, gridy, gridz), dim=-1).to(device)\n\n\n# Complex multiplication\ndef compl_mul2d(inp, weights):\n    # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n    return torch.einsum(\"bixy,ioxy->boxy\", inp, weights)\n\n\ndef compl_mul3d(inp, weights):\n    # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n    return torch.einsum(\"bixyz,ioxyz->boxyz\", inp, weights)\n\n\nclass SpectralConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, modes1, modes2):\n        super(SpectralConv2d, self).__init__()\n\n        \"\"\"\n        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n        \"\"\"\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n        self.modes2 = modes2\n\n        self.scale = (1 / (in_channels * out_channels))\n        self.weights1 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n        self.weights2 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n\n    def forward(self, x):\n        batchsize = x.shape[0]\n        # Compute Fourier coefficients --  1. Compute Fourier Transform\n        # Now, instead of working with raw pixel/grid values, we work with frequency components\\\n        # Suppose the input x has shape (batch, in_channels, H, W)\n        # x_ft has shape: batchin_channelsH(W/2+1)\n        x_ft = torch.fft.rfft2(x) # 2D Fast Fourier Transform (FFT) --> v0 = F(v0)\n\n        # Multiply relevant Fourier modes -- 2. Apply Spectral Convolution\n        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat,\n                             device=x.device)\n        # v1(k1,k2)= W(k1,k2).v0(k1,k2) --> W(k1,k2) are learnable parameters that control how much each frequency mode contributes\n        out_ft[:, :, :self.modes1, :self.modes2] = \\\n            compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n            compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n\n        # Return to physical space\n        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1))) # Apply Inverse Fourier Transform (iFFT) --> v1(x,y) = F^(-1)[v1(k1,k2)]\n        return x\n\n\nclass SpectralConv3d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n        super(SpectralConv3d, self).__init__()\n\n        \"\"\"\n        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n        \"\"\"\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n        self.modes2 = modes2\n        self.modes3 = modes3\n\n        self.scale = (1 / (in_channels * out_channels))\n        self.weights1 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights2 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights3 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights4 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n\n    def forward(self, x):\n        batchsize = x.shape[0]\n        # Compute Fourier coefficients up to factor of e^(- something constant)\n        x_ft = torch.fft.rfftn(x, dim=[-3, -2, -1])\n\n        # Multiply relevant Fourier modes\n        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1) // 2 + 1,\n                             dtype=torch.cfloat, device=x.device)\n        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n\n        # Return to physical space\n        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n        return x\n\n\nclass MLP2d(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels, T=1, num_layers=2):\n        \"\"\"\n        Initialize the MLP2d class.\n        Parameters:\n        - in_channels: Number of input channels.\n        - out_channels: Number of output channels.\n        - mid_channels: Number of intermediate channels.\n        - T: Number of blocks (default=1).\n        - num_layers: Number of layers in each block (default=2).\n        \"\"\"\n        super(MLP2d, self).__init__()\n\n        self.num_layers = num_layers\n        self.layers = nn.ModuleList()\n\n        for _ in range(T):\n            self.layers.append(nn.Conv2d(in_channels, mid_channels, 1))\n            for _ in range(self.num_layers - 2):\n                self.layers.append(nn.Conv2d(mid_channels, mid_channels, 1))\n            self.layers.append(nn.Conv2d(mid_channels, out_channels, 1))\n\n    def forward(self, x, t=0):\n        start = t * self.num_layers\n        end = start + self.num_layers\n        for i in range(start, end - 1):\n            x = F.gelu(self.layers[i](x))\n        x = self.layers[end - 1](x)\n        return x\n\n\nclass MLP3d(MLP2d):\n    def __init__(self, in_channels, out_channels, mid_channels, T=1, num_layers=2):\n        super(MLP3d, self).__init__(in_channels, out_channels, mid_channels, T, num_layers)\n\n        self.layers = nn.ModuleList()\n        for _ in range(T):\n            self.layers.append(nn.Conv3d(in_channels, mid_channels, 1))\n            # After (3x3x3 kernel)\n            #self.layers.append(nn.Conv3d(in_channels, mid_channels, 3, padding=1))  ## Changed from 1*1*1 to 3*3*3\n            for _ in range(self.num_layers - 2):\n                self.layers.append(nn.Conv3d(mid_channels, mid_channels, 1))\n                #self.layers.append(nn.Conv3d(mid_channels, mid_channels, 3, padding=1))  ## Changed from 1 to 3\n            self.layers.append(nn.Conv3d(mid_channels, out_channels, 1))\n            #self.layers.append(nn.Conv3d(mid_channels, out_channels, 3, padding=1))  ## Changed from 1 to 3\n\n\nclass FNO2d(nn.Module):\n    def __init__(self, modes1, modes2, width, width_q, T_in, T_out, n_layers):\n        super(FNO2d, self).__init__()\n\n        \"\"\"\n        The overall network. It contains 4 layers of the Fourier layer.\n        1. Lift the input to the desire channel dimension by self.fc0 .\n        2. 4 layers of the integral operators u' = (W + K)(u).\n            W defined by self.w; K defined by self.conv .\n        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n\n        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n        input shape: (batchsize, x=64, y=64, c=12)\n        output: the solution of the next timestep\n        output shape: (batchsize, x=64, y=64, c=1)\n        \"\"\"\n\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.width = width\n        self.width_q = width_q\n        self.T_in = T_in\n        self.T_out = T_out\n        self.padding = 8  # pad the domain if input is non-periodic\n        self.n_layers = n_layers\n\n        self.p = nn.Linear(T_in + 2, self.width)  # We start with an input x == u(x,y) of shape (batch,x,y,c), We lift it to a higher-dimensional space using a linear layer\n        # v0(x,y) = p(x=u)\n        self.convs = nn.ModuleList(\n            [SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(n_layers)]) # 2D Fast Fourier Transform (FFT) --> v0 = F(v0)\n        self.mlps = nn.ModuleList([MLP2d(self.width, self.width, self.width) for _ in range(n_layers)])\n        self.ws = nn.ModuleList([nn.Conv2d(self.width, self.width, 1) for _ in range(n_layers)]) # Pointwise convolution layers\n        self.norm = nn.InstanceNorm2d(self.width)\n        self.q = MLP2d(self.width, 1, self.width_q)  # output channel is 1: u(x, y)\n\n    def forward(self, x):\n        grid = get_grid_2d(x.shape, x.device)\n        x = torch.cat((x, grid), dim=-1)\n        x = self.p(x)\n        x = x.permute(0, 3, 1, 2)\n        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            '''\n            x1 = self.mlps[i](x1): Local Mixing Using MLP: Since the Fourier convolution captures global dependencies,\n             we still need local interactions --> v_i+1 = sigma(W.vi  +  b), \n             which W and b are learnable parameters, and  is the activation function.\n            '''\n            x2 = self.ws[i](x)\n            '''\n             x2 = self.ws[i](x): applies a pointwise convolution (11 convolution) to the input tensor x.\n                self.ws is a list (nn.ModuleList) of 11 convolutional layers.\n                Each self.ws[i] is a 2D convolution layer (nn.Conv2d) with a kernel size of 1x1.\n                The purpose of these layers is to perform a linear transformation of the feature maps \n                without mixing spatial locations.\n\n            '''\n            x = x1 + x2 #  Merge Global and Local Representations\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n        x = self.q(x)\n        '''\n         Output Projection back to the desired shape using another MLP\n        v_out = Q.v_final(x,y)\n        Q is a learnable projection.\n\n        '''\n        x = x.permute(0, 2, 3, 1)\n        #The final shape of x is (batch,x,y,1), which represents the predicted function value at each spatial location.\n        return x\n\n\nclass TNO2d(FNO2d):\n    def __init__(self, modes1, modes2, width, width_q, width_h, T_in, T_out, n_layers, n_layers_q=2, n_layers_h=4):\n        super(TNO2d, self).__init__(modes1, modes2, width, width_q, T_in, T_out, n_layers)\n        '''\n         TNO2d extends FNO2d. It introduces temporal modeling by adding two MLP layers:\n        self.q  projects the Fourier features to output over time.\n        self.h  handles temporal dependencies between consecutive time steps.\n        New parameters added:\n        width_h  controls temporal memory features.\n        n_layers_q  depth of self.q (output MLP).\n        n_layers_h  depth of self.h (temporal evolution MLP).\n        '''\n        self.width_h = width_h\n        #self.q = MLP2d(self.width, 1, self.width, T_out) # for AC\n        #self.q2 = MLP2d(1, 1, self.width // 4, T_out - 1)\n        #self.q = MLP2d(self.width, 1, 2 * self.width, T_out)  # for CH\n        #self.q2 = MLP2d(1, 1, self.width, T_out - 1)\n        self.q = MLP2d(self.width, 1, self.width_q, T_out, n_layers_q)  # for CHNL\n        self.h = MLP2d(1, 1, self.width_h, T_out - 1, n_layers_h)\n\n    def forward(self, x):\n        grid = get_grid_2d(x.shape, x.device)\n        x = torch.cat((x, grid), dim=-1) # a(x) or= x : Input function (e.g., initial condition for a PDE)\n        x = self.p(x) # \tLifts input to a high-dimensional space\n        x = x.permute(0, 3, 1, 2)\n        # x = F.pad(x, [0, self.padding, 0, self.padding])\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x # x=GELU(FourierConv(x)+MLP(x)+PointwiseConv(x)\n\n        # x = x[..., :-self.padding, :-self.padding]\n        '''\n         Temporal Evolution Loop\n        Initial time step prediction:\n        Uses self.q(x) to generate the first time step.\n        Stores result in X[..., 0]\n        '''\n        X = torch.zeros(*grid.shape[:-1], self.T_out, device=x.device)\n        xt = self.q(x)\n        X[..., 0] = xt.permute(0, 2, 3, 1).squeeze(-1)\n\n        for t in range(1, self.T_out):\n            x1 = self.q(x, t) # Predicts the next step using Fourier features.  # Q_n(W_L+ K_L )...P(a(x)), Projects final Fourier features to outpu\n            x2 = self.h(xt, t - 1) # Uses previous output (xt) to refine the next state. # H_nG_ (x,t_(n-1) )(a(x)), Models dependency on past states\n            xt = x1 + x2 #  Solution at time t_n : x_t = G_ (x,t_n )(a(x))\n            X[..., t] = xt.permute(0, 2, 3, 1).squeeze(-1)\n            '''\n             Uses previous output (xt) to refine the next state.\n            Combines both predictions --> x_t=MLP_q(x)+MLP_h[(x t1)]\n            Stores result in X[..., t]\n            '''\n        return X\n\n\nclass FNO3d(nn.Module):\n    def __init__(self, modes1, modes2, modes3, width, width_q, T_in, T_out, n_layers, n_layers_q=2, n_layers_h=2):\n        super(FNO3d, self).__init__()\n\n        \"\"\"\n        The FNO3d class is a deep learning model designed for solving spatiotemporal problems. \n        The overall network. It contains 4 layers of the Fourier layer.\n        1. Lift the input to the desire channel dimension by self.fc0 .\n        2. 4 layers of the integral operators u' = (W + K)(u).\n            W defined by self.w; K defined by self.conv .\n        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n\n        input: the solution of the first 10 time_steps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n        input shape: (batchsize, x=64, y=64, t=40, c=13)\n        output: the solution of the next 40 time_steps\n        output shape: (batchsize, x=64, y=64, t=40, c=1)\n        \"\"\"\n\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.modes3 = modes3\n        self.width = width\n        self.width_q = width_q\n        self.T_in = T_in\n        self.T_out = T_out\n        self.padding = 6  # pad the domain if input is non-periodic\n        self.n_layers = n_layers\n\n        self.p = nn.Linear(self.T_in + 3, self.width)  # Lifting Layer: input channel is 12: the solution of the first 10 time_steps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n\n        self.convs = nn.ModuleList(\n            [SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3) for _ in range(n_layers)])\n        self.mlps = nn.ModuleList([MLP3d(self.width, self.width, self.width) for _ in range(n_layers)])\n        self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 1) for _ in range(n_layers)])\n        #self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 3, padding=1) for _ in range(n_layers)])  ## kernel changed\n        #self.q = MLP3d(self.width, 1, self.width)  # output channel is 1: u(x, y)\n        self.q = MLP3d(self.width, 1, self.width_q)  # output channel is 1: u(x, y)\n\n    def forward(self, x):\n        #x = x.unsqueeze(3).repeat([1, 1, 1, self.T_out, 1])\n        grid = get_grid_3d(x.shape, x.device)\n        #print(' x shape:', x.shape)\n        x = torch.cat((x, grid), dim=-1)\n        #print(' x shape after cat:', x.shape)\n        x = self.p(x)\n        x = x.permute(0, 4, 1, 2, 3)\n        #x = F.pad(x, [0, self.padding])  # pad the domain if input is non-periodic\n        #print(' x shape after permute:', x.shape)\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        #x = x[..., :-self.padding]\n        x = self.q(x)\n        #x = x.permute(0, 2, 3, 4, 1)[..., 0]  # pad the domain if input is non-periodic\n        x = x.permute(0, 2, 3, 4, 1)\n        #print('FNO3d return x shape:', x.shape)\n        return x\n\n\nclass TNO3d(FNO3d):\n    def __init__(self, modes1, modes2, modes3, width, width_q, width_h, T_in, T_out, n_layers):\n        super(TNO3d, self).__init__(modes1, modes2, modes3, width, width_q, T_in, T_out, n_layers)\n        \"\"\"\n        The super() function calls the parent class (FNO3d) constructor to initialize \n        the parameters that are inherited from the parent class.\n        input: the initial condition and locations (a(x, y, z), x, y, z)\n        input shape: (batchsize, x=s, y=s, z=s, c=4)\n        output: the solution \n        output shape: (batchsize, x=s, y=s, z=s, t=T)\n        \"\"\"\n        self.width_h = width_h\n\n        #self.q = MLP3d(self.width, 1, self.width, T_out)\n        #self.q2 = MLP3d(1, 1, self.width // 4, T_out - 1)\n        self.q = MLP3d(self.width, 1, self.width_q, T_out)\n        self.h = MLP3d(1, 1, self.width_h, T_out - 1)\n\n    def forward(self, x):\n        grid = get_grid_3d(x.shape, x.device)\n        #print('x shape: ',x.shape)\n        #print('grid shape: ', grid.shape)\n        x = torch.cat((x, grid), dim=-1)\n        x = self.p(x)\n        x = x.permute(0, 4, 1, 2, 3)\n        # x = F.pad(x, [0, self.padding, 0, self.padding])\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        # x = x[..., :-self.padding, :-self.padding]\n        X = torch.zeros(*grid.shape[:-1], self.T_out, device=x.device)\n        xt = self.q(x)\n        X[..., 0] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)\n        for t in range(1, self.T_out):\n            x1 = self.q(x, t)\n            x2 = self.h(xt, t - 1)\n            xt = x1 + x2\n            X[..., t] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)\n\n        #print('shape X for model TNO: ', X.shape)\n        return X\n\n\ndef compute_spatial_derivatives(field, coordinates):\n    \"\"\"\n    Computes first and second spatial derivatives of a field with respect to coordinates\n\n    Args:\n        field: Tensor of shape [batch, x, y, z]\n        coordinates: Tensor of shape [batch, x, y, z, 3] (must require grad)\n\n    Returns:\n        laplacian: Tensor of shape [batch, x, y, z] containing \n    \"\"\"\n    # Ensure we can compute gradients\n    field = field.clone().requires_grad_(True)\n    coordinates = coordinates.clone().requires_grad_(True)\n\n    # Compute first derivatives\n    grad_outputs = torch.ones_like(field)\n    grad_x, grad_y, grad_z = torch.autograd.grad(\n        outputs=field,\n        inputs=coordinates,\n        grad_outputs=grad_outputs,\n        create_graph=True,\n        retain_graph=True,\n        allow_unused=False\n    )[0].unbind(dim=-1)\n\n    # Compute second derivatives\n    laplacian = 0.0\n    for grad in [grad_x, grad_y, grad_z]:\n        grad_outputs = torch.ones_like(grad)\n        d2phi = torch.autograd.grad(\n            outputs=grad,\n            inputs=coordinates,\n            grad_outputs=grad_outputs,\n            create_graph=True,\n            retain_graph=True,\n            allow_unused=False\n        )[0].unbind(dim=-1)[0]  # Take derivative along same axis\n        laplacian += d2phi\n\n    return laplacian\ndef compute_allen_cahn_loss(predictions, coordinates, epsilon=0.05, delta_t=0.01):\n    \"\"\"\n    Robust physics loss calculation for Allen-Cahn equation\n\n    Args:\n        predictions: Model outputs [batch, x, y, z, time]\n        coordinates: Spatial coordinates [batch, x, y, z, 3]\n        epsilon: Interface width parameter\n        delta_t: Time step size\n\n    Returns:\n        pde_loss: PDE residual loss\n        bc_loss: Boundary condition loss\n    \"\"\"\n    batch_size = predictions.shape[0]\n    pde_loss = 0.0\n    bc_loss = 0.0\n\n    # Compute for each time step\n    for t in range(predictions.shape[-1]):\n        phi_t = predictions[..., t]\n\n        # Compute Laplacian\n        laplacian = compute_spatial_derivatives(phi_t, coordinates)\n\n        # Compute time derivative (finite difference)\n        if t == 0:\n            dt = (predictions[..., t + 1] - predictions[..., t]) / delta_t\n        elif t == predictions.shape[-1] - 1:\n            dt = (predictions[..., t] - predictions[..., t - 1]) / delta_t\n        else:\n            dt = (predictions[..., t + 1] - predictions[..., t - 1]) / (2 * delta_t)\n\n        # Allen-Cahn residual\n        residual = dt - (laplacian - (1 / epsilon ** 2) * (phi_t ** 3 - phi_t))\n        pde_loss += torch.mean(residual ** 2)\n\n        # Periodic boundary conditions\n        bc_loss += torch.mean((phi_t[..., 0, :, :] - phi_t[..., -1, :, :]) ** 2)\n        bc_loss += torch.mean((phi_t[..., :, 0, :] - phi_t[..., :, -1, :]) ** 2)\n        bc_loss += torch.mean((phi_t[..., :, :, 0] - phi_t[..., :, :, -1]) ** 2)\n\n    return pde_loss / predictions.shape[-1], bc_loss / (3 * predictions.shape[-1])
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/networks.py b/networks.py
++--- a/networks.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/networks.py	(date 1753733660666)
++@@ -410,8 +410,9 @@
++         xt = self.q(x)
++         X[..., 0] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)
++         for t in range(1, self.T_out):
++-            x1 = self.q(x, t)
++-            x2 = self.h(xt, t - 1)
+++            #  two special MLPs (self.q and self.h) to generate the forecast step-by-step.
+++            x1 = self.q(x, t) # A new prediction based on the original initial state.
+++            x2 = self.h(xt, t - 1) #  A "correction" or "update" based on the prediction from the previous step (Time=1).
++             xt = x1 + x2
++             X[..., t] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)
++ 
++@@ -419,87 +420,150 @@
++         return X
++ 
++ 
++-def compute_spatial_derivatives(field, coordinates):
++-    """
++-    Computes first and second spatial derivatives of a field with respect to coordinates
+++###############
+++###############
+++
+++
+++# Add to networks.py
+++''''
+++def get_grid_4d(shape, device):
+++    batchsize, size_x, size_y, size_z, size_t = shape[0], shape[1], shape[2], shape[3], shape[4]
+++    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
+++    gridx = gridx.reshape(1, size_x, 1, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, size_t, 1])
+++    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
+++    gridy = gridy.reshape(1, 1, size_y, 1, 1, 1).repeat([batchsize, size_x, 1, size_z, size_t, 1])
+++    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
+++    gridz = gridz.reshape(1, 1, 1, size_z, 1, 1).repeat([batchsize, size_x, size_y, 1, size_t, 1])
+++    gridt = torch.tensor(np.linspace(0, 1, size_t), dtype=torch.float)
+++    gridt = gridt.reshape(1, 1, 1, 1, size_t, 1).repeat([batchsize, size_x, size_y, size_z, 1, 1])
+++    return torch.cat((gridx, gridy, gridz, gridt), dim=-1).to(device)
+++'''
+++
+++def get_grid_4d(shape, device):
+++    batchsize, size_x, size_y, size_z, _ = shape  # Note: last dim is channels, not time
+++    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
+++    gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])
+++    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
+++    gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])
+++    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
+++    gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])
+++    return torch.cat((gridx, gridy, gridz), dim=-1).to(device)  # Returns (batch, x, y, z, 3)
+++
+++
+++def compl_mul4d(inp, weights):
+++    # (batch, in_channel, x,y,z,t), (in_channel, out_channel, x,y,z,t) -> (batch, out_channel, x,y,z,t)
+++    return torch.einsum("bixyzt,ioxyzt->boxyzt", inp, weights)
+++
+++
+++class SpectralConv4d(nn.Module):
+++    def __init__(self, in_channels, out_channels, modes1, modes2, modes3, modes4):
+++        super(SpectralConv4d, self).__init__()
++ 
++-    Args:
++-        field: Tensor of shape [batch, x, y, z]
++-        coordinates: Tensor of shape [batch, x, y, z, 3] (must require grad)
+++        self.in_channels = in_channels
+++        self.out_channels = out_channels
+++        self.modes1 = modes1  # Number of Fourier modes to multiply
+++        self.modes2 = modes2
+++        self.modes3 = modes3
+++        self.modes4 = modes4
++ 
++-    Returns:
++-        laplacian: Tensor of shape [batch, x, y, z] containing 
++-    """
++-    # Ensure we can compute gradients
++-    field = field.clone().requires_grad_(True)
++-    coordinates = coordinates.clone().requires_grad_(True)
+++        self.scale = (1 / (in_channels * out_channels))
+++        # We'll use 8 weights for 4D (similar to how 3D uses 4 weights)
+++        self.weights1 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights2 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights3 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights4 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights5 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights6 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights7 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights8 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
++ 
++-    # Compute first derivatives
++-    grad_outputs = torch.ones_like(field)
++-    grad_x, grad_y, grad_z = torch.autograd.grad(
++-        outputs=field,
++-        inputs=coordinates,
++-        grad_outputs=grad_outputs,
++-        create_graph=True,
++-        retain_graph=True,
++-        allow_unused=False
++-    )[0].unbind(dim=-1)
+++    def forward(self, x):
+++        batchsize = x.shape[0]
+++        # Compute Fourier coefficients
+++        x_ft = torch.fft.rfftn(x, dim=[-4, -3, -2, -1])  # FFT over spatial and time dimensions
++ 
++-    # Compute second derivatives
++-    laplacian = 0.0
++-    for grad in [grad_x, grad_y, grad_z]:
++-        grad_outputs = torch.ones_like(grad)
++-        d2phi = torch.autograd.grad(
++-            outputs=grad,
++-            inputs=coordinates,
++-            grad_outputs=grad_outputs,
++-            create_graph=True,
++-            retain_graph=True,
++-            allow_unused=False
++-        )[0].unbind(dim=-1)[0]  # Take derivative along same axis
++-        laplacian += d2phi
+++        # Multiply relevant Fourier modes
+++        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-4), x.size(-3), x.size(-2), x.size(-1) // 2 + 1,
+++                             dtype=torch.cfloat, device=x.device)
++ 
++-    return laplacian
++-def compute_allen_cahn_loss(predictions, coordinates, epsilon=0.05, delta_t=0.01):
++-    """
++-    Robust physics loss calculation for Allen-Cahn equation
+++        # Handle all combinations of modes
+++        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3, :self.modes4], self.weights1)
+++        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3, :self.modes4], self.weights2)
+++        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3, :self.modes4], self.weights3)
+++        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3, :self.modes4], self.weights4)
+++        out_ft[:, :, :self.modes1, :self.modes2, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, :self.modes2, -self.modes3:, :self.modes4], self.weights5)
+++        out_ft[:, :, -self.modes1:, :self.modes2, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, :self.modes2, -self.modes3:, :self.modes4], self.weights6)
+++        out_ft[:, :, :self.modes1, -self.modes2:, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, -self.modes2:, -self.modes3:, :self.modes4], self.weights7)
+++        out_ft[:, :, -self.modes1:, -self.modes2:, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, -self.modes2:, -self.modes3:, :self.modes4], self.weights8)
++ 
++-    Args:
++-        predictions: Model outputs [batch, x, y, z, time]
++-        coordinates: Spatial coordinates [batch, x, y, z, 3]
++-        epsilon: Interface width parameter
++-        delta_t: Time step size
+++        # Return to physical space
+++        x = torch.fft.irfftn(out_ft, s=(x.size(-4), x.size(-3), x.size(-2), x.size(-1)))
+++        return x
++ 
++-    Returns:
++-        pde_loss: PDE residual loss
++-        bc_loss: Boundary condition loss
++-    """
++-    batch_size = predictions.shape[0]
++-    pde_loss = 0.0
++-    bc_loss = 0.0
++ 
++-    # Compute for each time step
++-    for t in range(predictions.shape[-1]):
++-        phi_t = predictions[..., t]
+++class FNO4d(nn.Module):
+++    def __init__(self, modes1, modes2, modes3, modes4_internal, width, width_q, T_in_channels, n_layers):
+++        super(FNO4d, self).__init__()
++ 
++-        # Compute Laplacian
++-        laplacian = compute_spatial_derivatives(phi_t, coordinates)
+++        self.modes1 = modes1
+++        self.modes2 = modes2
+++        self.modes3 = modes3
+++        self.modes4 = modes4_internal
+++        self.width = width
+++        self.width_q = width_q
+++        self.T_in = T_in_channels
+++        self.n_layers = n_layers
+++        self.padding = 6
++ 
++-        # Compute time derivative (finite difference)
++-        if t == 0:
++-            dt = (predictions[..., t + 1] - predictions[..., t]) / delta_t
++-        elif t == predictions.shape[-1] - 1:
++-            dt = (predictions[..., t] - predictions[..., t - 1]) / delta_t
++-        else:
++-            dt = (predictions[..., t + 1] - predictions[..., t - 1]) / (2 * delta_t)
+++        # Input is (x,y,z) + time channels (t_in_channels) + 3 spatial coordinates
+++        self.p = nn.Linear(self.T_in + 3, self.width)  # +3 for (x,y,z) coordinates
++ 
++-        # Allen-Cahn residual
++-        residual = dt - (laplacian - (1 / epsilon ** 2) * (phi_t ** 3 - phi_t))
++-        pde_loss += torch.mean(residual ** 2)
+++        self.convs = nn.ModuleList([
+++            SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)
+++            for _ in range(n_layers)
+++        ])
+++        self.mlps = nn.ModuleList([MLP3d(self.width, self.width, self.width) for _ in range(n_layers)])
+++        self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 1) for _ in range(n_layers)])
+++        self.q = MLP3d(self.width, 1, self.width_q)  # Output channel is 1
++ 
++-        # Periodic boundary conditions
++-        bc_loss += torch.mean((phi_t[..., 0, :, :] - phi_t[..., -1, :, :]) ** 2)
++-        bc_loss += torch.mean((phi_t[..., :, 0, :] - phi_t[..., :, -1, :]) ** 2)
++-        bc_loss += torch.mean((phi_t[..., :, :, 0] - phi_t[..., :, :, -1]) ** 2)
+++    def forward(self, x):
+++        # Input shape: (batch, x, y, z, t_in_channels)
+++        grid = get_grid_4d(x.shape, x.device)
+++        x = torch.cat((x, grid), dim=-1)  # This is the key step where "time" is handled.  Now both are 5D: (batch, x, y, z, t_in_channels + 3)
+++        x = self.p(x)  # Lift to higher dimension
+++        x = x.permute(0, 4, 1, 2, 3)  # (batch, channels, x, y, z)
++ 
++-    return pde_loss / predictions.shape[-1], bc_loss / (3 * predictions.shape[-1])
++\ No newline at end of file
+++        for i in range(self.n_layers):
+++            x1 = self.convs[i](x)
+++            x1 = self.mlps[i](x1)
+++            x2 = self.ws[i](x)
+++            x = x1 + x2
+++            x = F.gelu(x) if i < self.n_layers - 1 else x
+++
+++        x = self.q(x)
+++        x = x.permute(0, 2, 3, 4, 1)  # (batch, x, y, z, 1)
+++        return x
++\ No newline at end of file
++Index: configs/config_CH3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_CH3D_FNO4d.py b/configs/config_CH3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1753632225910)
+++++ b/configs/config_CH3D_FNO4d.py	(date 1753632225910)
++@@ -0,0 +1,77 @@
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda:3'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1300 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+++nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
+++batch_size = 20 # 10 # 20 # 20 # 50 # 3 # 20 # 50 # 5 # 50
+++learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
+++weight_decay = 1e-4 # 1e-3 # 1e-4
+++epochs = 50 # 100 # 500 # 1000 # 25 # 100 # 1000
+++iterations = epochs * (nTrain // batch_size)
+++modes = 14 # 10 #12 # 14 # 16 # 10 # 16
+++width = 12 # 8 #12 #14 # 12 # 16 # 32
+++width_q = width # 2 * width #
+++width_h = width//2 # width//4 # width #
+++n_layers = 3 # 2 # 4 # 5 # 5 # 8
+++
+++# Discretization
+++
+++s = 32 # 64 # 32 # 64 #32 # 64
+++T_in = 1
+++T_out = 91 # 20 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True # False # True # False  # True
+++load_model = False # True # False # False #True
+++
+++# Database
+++parent_dir = './data/'
+++
+++#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
+++# Plotting
+++index = 62  # 24 # 62
+++#domain = [-np.pi, np.pi]
+++Lx = 2 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.05  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: .idea/workspace.xml
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"TNO3d vs FNO3d\">\n      <change afterPath=\"$PROJECT_DIR$/run_inference.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/vcs.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/vcs.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/main.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/main.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/networks.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/networks.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/post_processing.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/post_processing.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/training.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/training.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/utilities.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/utilities.py\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <excluded-from-favorite>\n      <branch-storage>\n        <map>\n          <entry type=\"LOCAL\">\n            <value>\n              <list>\n                <branch-info repo=\"$PROJECT_DIR$\" source=\"master\" />\n              </list>\n            </value>\n          </entry>\n        </map>\n      </branch-storage>\n    </excluded-from-favorite>\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\n      <map>\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\n      </map>\n    </option>\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n    <option name=\"ROOT_SYNC\" value=\"DONT_SYNC\" />\n  </component>\n  <component name=\"GitHubPullRequestSearchHistory\">{\n  &quot;lastFilter&quot;: {\n    &quot;state&quot;: &quot;OPEN&quot;,\n    &quot;assignee&quot;: &quot;MBamdad&quot;\n  }\n}</component>\n  <component name=\"GithubPullRequestsUISettings\">{\n  &quot;selectedUrlAndAccountId&quot;: {\n    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,\n    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;\n  }\n}</component>\n  <component name=\"ProjectColorInfo\">{\n  &quot;associatedIndex&quot;: 1\n}</component>\n  <component name=\"ProjectId\" id=\"2p11NySvsgjZ8eu9d53SI84567l\" />\n  <component name=\"ProjectReloadState\">\n    <option name=\"STATE\" value=\"1\" />\n  </component>\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">{\n  &quot;keyToString&quot;: {\n    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.main.executor&quot;: &quot;Run&quot;,\n    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.networks.executor&quot;: &quot;Run&quot;,\n    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,\n    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,\n    &quot;Python.test1.executor&quot;: &quot;Run&quot;,\n    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,\n    &quot;git-widget-placeholder&quot;: &quot;main&quot;,\n    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,\n    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,\n    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,\n    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,\n    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,\n    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,\n    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,\n    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;\n  },\n  &quot;keyToStringList&quot;: {\n    &quot;ChangesTree.GroupingKeys&quot;: [\n      &quot;directory&quot;\n    ]\n  }\n}</component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$/configs\" />\n      <recent name=\"$PROJECT_DIR$/AC2Dtest/models\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code/AC2D\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code\" />\n    </key>\n    <key name=\"MoveFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.AC3D_TNO3d\">\n    <configuration name=\"AC3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_TNO3d_hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"MBE3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d_Hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <list>\n      <item itemvalue=\"Python.AC3D_TNO3d\" />\n      <item itemvalue=\"Python.AC3d_FNO3d\" />\n      <item itemvalue=\"Python.AC3d_TNO3d_hybrid\" />\n      <item itemvalue=\"Python.CH3D_TNO3d\" />\n      <item itemvalue=\"Python.MBE3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_FNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d_Hybrid\" />\n    </list>\n  </component>\n  <component name=\"SharedIndexes\">\n    <attachedChunks>\n      <set>\n        <option value=\"bundled-js-predefined-1d06a55b98c1-0b3e54e931b4-JavaScript-PY-241.18034.82\" />\n        <option value=\"bundled-python-sdk-975db3bf15a3-2767605e8bc2-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-241.18034.82\" />\n      </set>\n    </attachedChunks>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"\" />\n      <created>1731918731711</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1731918731711</updated>\n      <workItem from=\"1731918732726\" duration=\"17070000\" />\n      <workItem from=\"1732010735784\" duration=\"777000\" />\n      <workItem from=\"1732011520582\" duration=\"8000\" />\n      <workItem from=\"1732011538945\" duration=\"13153000\" />\n      <workItem from=\"1732106481018\" duration=\"3721000\" />\n      <workItem from=\"1732480846034\" duration=\"2889000\" />\n      <workItem from=\"1732483872465\" duration=\"14926000\" />\n      <workItem from=\"1732567216112\" duration=\"964000\" />\n      <workItem from=\"1732765090621\" duration=\"5000\" />\n      <workItem from=\"1732765102609\" duration=\"12000\" />\n      <workItem from=\"1732765345288\" duration=\"10000\" />\n      <workItem from=\"1732903897716\" duration=\"3074000\" />\n      <workItem from=\"1732911303920\" duration=\"27201000\" />\n      <workItem from=\"1732999179592\" duration=\"8241000\" />\n      <workItem from=\"1733039613684\" duration=\"6792000\" />\n      <workItem from=\"1733095843263\" duration=\"10000\" />\n      <workItem from=\"1733140600841\" duration=\"6993000\" />\n      <workItem from=\"1733150993229\" duration=\"184000\" />\n      <workItem from=\"1733151279786\" duration=\"6000\" />\n      <workItem from=\"1733151296310\" duration=\"16875000\" />\n      <workItem from=\"1733233230739\" duration=\"5172000\" />\n      <workItem from=\"1733246997923\" duration=\"15986000\" />\n      <workItem from=\"1733349590652\" duration=\"1949000\" />\n      <workItem from=\"1733352121741\" duration=\"6332000\" />\n      <workItem from=\"1733405466233\" duration=\"12731000\" />\n      <workItem from=\"1733557048829\" duration=\"5541000\" />\n      <workItem from=\"1733583489891\" duration=\"16419000\" />\n      <workItem from=\"1733859258781\" duration=\"7356000\" />\n      <workItem from=\"1733995059967\" duration=\"7899000\" />\n      <workItem from=\"1734011167665\" duration=\"991000\" />\n      <workItem from=\"1734029966470\" duration=\"25769000\" />\n      <workItem from=\"1734205412700\" duration=\"7689000\" />\n      <workItem from=\"1734644992163\" duration=\"5017000\" />\n      <workItem from=\"1734788130789\" duration=\"2312000\" />\n      <workItem from=\"1734863751114\" duration=\"9000\" />\n      <workItem from=\"1734863775073\" duration=\"9221000\" />\n      <workItem from=\"1734880034791\" duration=\"57000\" />\n      <workItem from=\"1734880213539\" duration=\"15000\" />\n      <workItem from=\"1734880329890\" duration=\"30000\" />\n      <workItem from=\"1734880369064\" duration=\"31312000\" />\n      <workItem from=\"1734983129135\" duration=\"55000\" />\n      <workItem from=\"1735034212628\" duration=\"2274000\" />\n      <workItem from=\"1735049036048\" duration=\"5309000\" />\n      <workItem from=\"1735126261413\" duration=\"75000\" />\n      <workItem from=\"1735356723104\" duration=\"1208000\" />\n      <workItem from=\"1735422837186\" duration=\"1387000\" />\n      <workItem from=\"1735719009558\" duration=\"561000\" />\n      <workItem from=\"1736101930735\" duration=\"570000\" />\n      <workItem from=\"1736102511675\" duration=\"4000\" />\n      <workItem from=\"1736161159525\" duration=\"7670000\" />\n      <workItem from=\"1736237907904\" duration=\"111000\" />\n      <workItem from=\"1736519480236\" duration=\"1867000\" />\n      <workItem from=\"1737577034938\" duration=\"3945000\" />\n      <workItem from=\"1737590448155\" duration=\"6145000\" />\n      <workItem from=\"1738310597042\" duration=\"2502000\" />\n      <workItem from=\"1738316162773\" duration=\"726000\" />\n      <workItem from=\"1738326887364\" duration=\"4500000\" />\n      <workItem from=\"1738586797583\" duration=\"600000\" />\n      <workItem from=\"1738663690532\" duration=\"4505000\" />\n      <workItem from=\"1738668267214\" duration=\"5368000\" />\n      <workItem from=\"1738685509837\" duration=\"74000\" />\n      <workItem from=\"1738703726377\" duration=\"1677000\" />\n      <workItem from=\"1738774383038\" duration=\"2249000\" />\n      <workItem from=\"1738787637783\" duration=\"7013000\" />\n      <workItem from=\"1738962434877\" duration=\"1153000\" />\n      <workItem from=\"1738967049524\" duration=\"782000\" />\n      <workItem from=\"1739275350614\" duration=\"312000\" />\n      <workItem from=\"1739464522072\" duration=\"12498000\" />\n      <workItem from=\"1739572784568\" duration=\"1228000\" />\n      <workItem from=\"1739626528163\" duration=\"5778000\" />\n      <workItem from=\"1739689815626\" duration=\"10399000\" />\n      <workItem from=\"1739812786805\" duration=\"48519000\" />\n      <workItem from=\"1740212626723\" duration=\"1263000\" />\n      <workItem from=\"1740213932190\" duration=\"644000\" />\n      <workItem from=\"1741475492994\" duration=\"40894000\" />\n      <workItem from=\"1741690305204\" duration=\"339000\" />\n      <workItem from=\"1741705983516\" duration=\"604000\" />\n      <workItem from=\"1741713165753\" duration=\"1198000\" />\n      <workItem from=\"1741861318912\" duration=\"2286000\" />\n      <workItem from=\"1742201562752\" duration=\"618000\" />\n      <workItem from=\"1742209067924\" duration=\"383000\" />\n      <workItem from=\"1742226300133\" duration=\"2432000\" />\n      <workItem from=\"1743071528350\" duration=\"9513000\" />\n      <workItem from=\"1743490058046\" duration=\"9000\" />\n      <workItem from=\"1743587112942\" duration=\"1188000\" />\n      <workItem from=\"1748900986740\" duration=\"1771000\" />\n      <workItem from=\"1748931928220\" duration=\"446000\" />\n      <workItem from=\"1748932436127\" duration=\"20890000\" />\n      <workItem from=\"1748970706276\" duration=\"3719000\" />\n      <workItem from=\"1748988822181\" duration=\"59000\" />\n      <workItem from=\"1749200290051\" duration=\"680000\" />\n      <workItem from=\"1749203502833\" duration=\"1349000\" />\n      <workItem from=\"1749213099437\" duration=\"3082000\" />\n      <workItem from=\"1750057109660\" duration=\"10453000\" />\n      <workItem from=\"1750070416210\" duration=\"46415000\" />\n    </task>\n    <task id=\"LOCAL-00001\" summary=\"Initial Commit\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732484343908</created>\n      <option name=\"number\" value=\"00001\" />\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732484343908</updated>\n    </task>\n    <task id=\"LOCAL-00002\" summary=\"added TransformerFNO\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732497990642</created>\n      <option name=\"number\" value=\"00002\" />\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732497990642</updated>\n    </task>\n    <task id=\"LOCAL-00003\" summary=\"added the connection between time steps - the model development is finished\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732910153380</created>\n      <option name=\"number\" value=\"00003\" />\n      <option name=\"presentableId\" value=\"LOCAL-00003\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732910153380</updated>\n    </task>\n    <task id=\"LOCAL-00004\" summary=\"Finished Allen-Cahn Problem\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733176021525</created>\n      <option name=\"number\" value=\"00004\" />\n      <option name=\"presentableId\" value=\"LOCAL-00004\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733176021525</updated>\n    </task>\n    <task id=\"LOCAL-00005\" summary=\"Added Allen-Cahn 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733583274023</created>\n      <option name=\"number\" value=\"00005\" />\n      <option name=\"presentableId\" value=\"LOCAL-00005\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733583274023</updated>\n    </task>\n    <task id=\"LOCAL-00006\" summary=\"added save_vtk\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733995237535</created>\n      <option name=\"number\" value=\"00006\" />\n      <option name=\"presentableId\" value=\"LOCAL-00006\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733995237535</updated>\n    </task>\n    <task id=\"LOCAL-00007\" summary=\"added MATLAB codes for creating database\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1734788540933</created>\n      <option name=\"number\" value=\"00007\" />\n      <option name=\"presentableId\" value=\"LOCAL-00007\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1734788540933</updated>\n    </task>\n    <task id=\"LOCAL-00008\" summary=\"added CH2DNL\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735126332032</created>\n      <option name=\"number\" value=\"00008\" />\n      <option name=\"presentableId\" value=\"LOCAL-00008\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735126332032</updated>\n    </task>\n    <task id=\"LOCAL-00009\" summary=\"added SH2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735719422931</created>\n      <option name=\"number\" value=\"00009\" />\n      <option name=\"presentableId\" value=\"LOCAL-00009\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735719422931</updated>\n    </task>\n    <task id=\"LOCAL-00010\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1736237977029</created>\n      <option name=\"number\" value=\"00010\" />\n      <option name=\"presentableId\" value=\"LOCAL-00010\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1736237977029</updated>\n    </task>\n    <task id=\"LOCAL-00011\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738788849261</created>\n      <option name=\"number\" value=\"00011\" />\n      <option name=\"presentableId\" value=\"LOCAL-00011\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738788849261</updated>\n    </task>\n    <task id=\"LOCAL-00012\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738789326593</created>\n      <option name=\"number\" value=\"00012\" />\n      <option name=\"presentableId\" value=\"LOCAL-00012\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738789326593</updated>\n    </task>\n    <task id=\"LOCAL-00013\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738796104012</created>\n      <option name=\"number\" value=\"00013\" />\n      <option name=\"presentableId\" value=\"LOCAL-00013\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738796104012</updated>\n    </task>\n    <task id=\"LOCAL-00014\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962464719</created>\n      <option name=\"number\" value=\"00014\" />\n      <option name=\"presentableId\" value=\"LOCAL-00014\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962464719</updated>\n    </task>\n    <task id=\"LOCAL-00015\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962748829</created>\n      <option name=\"number\" value=\"00015\" />\n      <option name=\"presentableId\" value=\"LOCAL-00015\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962748829</updated>\n    </task>\n    <task id=\"LOCAL-00016\" summary=\"Turn Nx to 64\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738967163754</created>\n      <option name=\"number\" value=\"00016\" />\n      <option name=\"presentableId\" value=\"LOCAL-00016\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738967163754</updated>\n    </task>\n    <task id=\"LOCAL-00017\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275401458</created>\n      <option name=\"number\" value=\"00017\" />\n      <option name=\"presentableId\" value=\"LOCAL-00017\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275401458</updated>\n    </task>\n    <task id=\"LOCAL-00018\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275433418</created>\n      <option name=\"number\" value=\"00018\" />\n      <option name=\"presentableId\" value=\"LOCAL-00018\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275433418</updated>\n    </task>\n    <task id=\"LOCAL-00019\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690373369</created>\n      <option name=\"number\" value=\"00019\" />\n      <option name=\"presentableId\" value=\"LOCAL-00019\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690373369</updated>\n    </task>\n    <task id=\"LOCAL-00020\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690420059</created>\n      <option name=\"number\" value=\"00020\" />\n      <option name=\"presentableId\" value=\"LOCAL-00020\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690420059</updated>\n    </task>\n    <task id=\"LOCAL-00021\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1743587271259</created>\n      <option name=\"number\" value=\"00021\" />\n      <option name=\"presentableId\" value=\"LOCAL-00021\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1743587271259</updated>\n    </task>\n    <option name=\"localTasksCounter\" value=\"22\" />\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"Vcs.Log.Tabs.Properties\">\n    <option name=\"RECENT_FILTERS\">\n      <map>\n        <entry key=\"Branch\">\n          <value>\n            <list>\n              <RecentGroup>\n                <option name=\"FILTER_VALUES\">\n                  <option value=\"main\" />\n                </option>\n              </RecentGroup>\n            </list>\n          </value>\n        </entry>\n      </map>\n    </option>\n    <option name=\"TAB_STATES\">\n      <map>\n        <entry key=\"MAIN\">\n          <value>\n            <State>\n              <option name=\"FILTERS\">\n                <map>\n                  <entry key=\"branch\">\n                    <value>\n                      <list>\n                        <option value=\"main\" />\n                      </list>\n                    </value>\n                  </entry>\n                </map>\n              </option>\n            </State>\n          </value>\n        </entry>\n      </map>\n    </option>\n  </component>\n  <component name=\"VcsManagerConfiguration\">\n    <MESSAGE value=\"Initial Commit\" />\n    <MESSAGE value=\"added TransformerFNO\" />\n    <MESSAGE value=\"added the connection between time steps - the model development is finished\" />\n    <MESSAGE value=\"refactored\" />\n    <MESSAGE value=\"Finished Allen-Cahn Problem\" />\n    <MESSAGE value=\"Added Allen-Cahn 3D\" />\n    <MESSAGE value=\"added save_vtk\" />\n    <MESSAGE value=\"added MATLAB codes for creating database\" />\n    <MESSAGE value=\"seperated the number of layers in fourier part and convolutional part\" />\n    <MESSAGE value=\"added CH2DNL\" />\n    <MESSAGE value=\"added SH2D\" />\n    <MESSAGE value=\"added PFC2D\" />\n    <MESSAGE value=\"Turn Nx to 64\" />\n    <MESSAGE value=\"update to 3D\" />\n    <MESSAGE value=\"TNO3d vs FNO3d\" />\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"TNO3d vs FNO3d\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>142</line>\n          <option name=\"timeStamp\" value=\"17\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>163</line>\n          <option name=\"timeStamp\" value=\"18\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>134</line>\n          <option name=\"timeStamp\" value=\"19\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>327</line>\n          <option name=\"timeStamp\" value=\"20\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>243</line>\n          <option name=\"timeStamp\" value=\"21\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_2.py</url>\n          <line>333</line>\n          <option name=\"timeStamp\" value=\"27\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>\n          <line>371</line>\n          <option name=\"timeStamp\" value=\"44\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>\n          <line>338</line>\n          <option name=\"timeStamp\" value=\"54\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>53</line>\n          <option name=\"timeStamp\" value=\"128\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>30</line>\n          <option name=\"timeStamp\" value=\"129\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>25</line>\n          <option name=\"timeStamp\" value=\"133\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>18</line>\n          <option name=\"timeStamp\" value=\"135\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>\n          <line>44</line>\n          <option name=\"timeStamp\" value=\"138\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test2.py</url>\n          <line>16</line>\n          <option name=\"timeStamp\" value=\"144\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/utilities.py</url>\n          <line>98</line>\n          <option name=\"timeStamp\" value=\"170\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/main.py</url>\n          <line>157</line>\n          <option name=\"timeStamp\" value=\"177\" />\n        </line-breakpoint>\n      </breakpoints>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n  </component>\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test3.coverage\" NAME=\"Test3 Coverage Results\" MODIFIED=\"1739273938386\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage\" NAME=\"config_AC2D_FNO3d Coverage Results\" MODIFIED=\"1733233385695\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1743065376798\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_2.coverage\" NAME=\"AC2D_Net2D_2 Coverage Results\" MODIFIED=\"1732904114403\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$test2.coverage\" NAME=\"test2 Coverage Results\" MODIFIED=\"1742889074336\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1741561715014\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage\" NAME=\"config_SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254757455\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$backend_interagg.coverage\" NAME=\"backend_interagg Coverage Results\" MODIFIED=\"1737630366471\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript3.coverage\" NAME=\"RunScript3 Coverage Results\" MODIFIED=\"1736368081257\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_2.coverage\" NAME=\"AC2D_2 Coverage Results\" MODIFIED=\"1732483323689\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1733086051390\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main_TF.coverage\" NAME=\"main_TF Coverage Results\" MODIFIED=\"1738704014479\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1741538869064\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$THFNO.coverage\" NAME=\"THFNO Coverage Results\" MODIFIED=\"1732911474644\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/networks\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1740088478224\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$PFC3D.coverage\" NAME=\"PFC3D Coverage Results\" MODIFIED=\"1740083613128\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1741603428589\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$run_inference.coverage\" NAME=\"run_inference Coverage Results\" MODIFIED=\"1750323709039\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1738663765959\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$post_processing.coverage\" NAME=\"post_processing Coverage Results\" MODIFIED=\"1733557098801\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage\" NAME=\"config_CH2D_TNO2d Coverage Results\" MODIFIED=\"1734086207850\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1748933697533\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1750255151255\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript2.coverage\" NAME=\"RunScript2 Coverage Results\" MODIFIED=\"1736369209710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1742215946758\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_3.coverage\" NAME=\"AC2D_Net2D_3 Coverage Results\" MODIFIED=\"1732974697103\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_FNO3d.coverage\" NAME=\"AC3d_FNO3d Coverage Results\" MODIFIED=\"1749017845623\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D.coverage\" NAME=\"AC2D Coverage Results\" MODIFIED=\"1733088640665\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/Archive_Code\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D.coverage\" NAME=\"AC2D_Net2D Coverage Results\" MODIFIED=\"1732567473230\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1740054182408\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage\" NAME=\"MBE3D_TNO3d Coverage Results\" MODIFIED=\"1741562061391\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_AC3D_TNO3d.coverage\" NAME=\"config_AC3D_TNO3d Coverage Results\" MODIFIED=\"1737644605063\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D.coverage\" NAME=\"MBE3D Coverage Results\" MODIFIED=\"1739283566145\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1741605347375\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1743071672425\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1736268192289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage\" NAME=\"PFC3D_TNO3d Coverage Results\" MODIFIED=\"1741564210973\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage\" NAME=\"config_CH2DNL_TNO2d Coverage Results\" MODIFIED=\"1735052490996\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$MBE2D.coverage\" NAME=\"MBE2D Coverage Results\" MODIFIED=\"1732278526731\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1739914172084\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test_Run.coverage\" NAME=\"Test_Run Coverage Results\" MODIFIED=\"1738945320139\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1741561294310\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741861381348\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1743081225414\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage\" NAME=\"PFV3D_FNO3d Coverage Results\" MODIFIED=\"1741564487710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript1.coverage\" NAME=\"RunScript1 Coverage Results\" MODIFIED=\"1736368790622\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$SH2D.coverage\" NAME=\"SH2D Coverage Results\" MODIFIED=\"1732347080402\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$PFC2D.coverage\" NAME=\"PFC2D Coverage Results\" MODIFIED=\"1732278679485\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$CH2D.coverage\" NAME=\"CH2D Coverage Results\" MODIFIED=\"1732347055915\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_FNO3d.coverage\" NAME=\"AC3D_FNO3d Coverage Results\" MODIFIED=\"1741561435127\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D.coverage\" NAME=\"SH3D Coverage Results\" MODIFIED=\"1739044808411\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test.coverage\" NAME=\"Test Coverage Results\" MODIFIED=\"1739459206236\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741547133078\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage\" NAME=\"config_AC2D_FNO2d Coverage Results\" MODIFIED=\"1733393903488\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$AC3D.coverage\" NAME=\"AC3D Coverage Results\" MODIFIED=\"1740041515520\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_CH3D_TNO3d.coverage\" NAME=\"config_CH3D_TNO3d Coverage Results\" MODIFIED=\"1738089807566\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test2.coverage\" NAME=\"Test2 Coverage Results\" MODIFIED=\"1739283715182\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_FNO3d.coverage\" NAME=\"CH3D_FNO3d Coverage Results\" MODIFIED=\"1741628529142\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage\" NAME=\"AC3d_TNO3d_hybrid Coverage Results\" MODIFIED=\"1748989478372\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1737899062785\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D.coverage\" NAME=\"config_AC2D Coverage Results\" MODIFIED=\"1733087276180\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_1.coverage\" NAME=\"AC2D_Net2D_1 Coverage Results\" MODIFIED=\"1732535211383\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1736520700819\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$fourier_3d.coverage\" NAME=\"fourier_3d Coverage Results\" MODIFIED=\"1732221600628\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1750254767095\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage\" NAME=\"SH3D_TNO3d_Hybrid Coverage Results\" MODIFIED=\"1749216389646\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1748990262244\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$test1.coverage\" NAME=\"test1 Coverage Results\" MODIFIED=\"1733413325318\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_2.coverage\" NAME=\"CH3D_2 Coverage Results\" MODIFIED=\"1739918355289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254975290\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage\" NAME=\"config_MBE2D_TNO2d Coverage Results\" MODIFIED=\"1736261397712\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n  </component>\n</project>
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/.idea/workspace.xml b/.idea/workspace.xml
++--- a/.idea/workspace.xml	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/.idea/workspace.xml	(date 1754055246952)
++@@ -4,29 +4,51 @@
++     <option name="autoReloadType" value="SELECTIVE" />
++   </component>
++   <component name="ChangeListManager">
++-    <list default="true" id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="TNO3d vs FNO3d">
++-      <change afterPath="$PROJECT_DIR$/run_inference.py" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/.idea/vcs.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />
+++    <list default="true" id="4e84c369-97f3-4301-a9fc-5fc5327e1a8a" name="Changes" comment="3d_phase_evolution">
+++      <change afterPath="$PROJECT_DIR$/MBE3D/plots_Data_Physics_TNO3d/MBE3D_Hybrid.jpg" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/PFC3D.iml" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_CH3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_MBE3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_PFC3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO4d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_FNO3d/combined_results.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_loss_curve_mixed.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison_FINAL.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_loss_curve.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/combined_results.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison_mixed.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_loss_curve_mixed.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/combined_results.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" beforeDir="false" afterPath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" beforeDir="false" afterPath="$PROJECT_DIR$/SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/CH3D_Comparison_star_SANO.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_SANO_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_CH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_CH3D_FNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_CH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_CH3D_TNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_MBE3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_MBE3D_FNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_MBE3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_MBE3D_TNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_PFC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_PFC3D_FNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/main.py" beforeDir="false" afterPath="$PROJECT_DIR$/main.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/main1.py" beforeDir="false" afterPath="$PROJECT_DIR$/main1.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/networks.py" beforeDir="false" afterPath="$PROJECT_DIR$/networks.py" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/post_processing.py" beforeDir="false" afterPath="$PROJECT_DIR$/post_processing.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/run_interface3.py" beforeDir="false" afterPath="$PROJECT_DIR$/run_interface3.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/training.py" beforeDir="false" afterPath="$PROJECT_DIR$/training.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/utilities.py" beforeDir="false" afterPath="$PROJECT_DIR$/utilities.py" afterDir="false" />
++     </list>
++@@ -43,163 +65,49 @@
++     </option>
++   </component>
++   <component name="Git.Settings">
++-    <excluded-from-favorite>
++-      <branch-storage>
++-        <map>
++-          <entry type="LOCAL">
++-            <value>
++-              <list>
++-                <branch-info repo="$PROJECT_DIR$" source="master" />
++-              </list>
++-            </value>
++-          </entry>
++-        </map>
++-      </branch-storage>
++-    </excluded-from-favorite>
++-    <option name="RECENT_BRANCH_BY_REPOSITORY">
++-      <map>
++-        <entry key="$PROJECT_DIR$" value="main" />
++-      </map>
++-    </option>
++     <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
++-    <option name="ROOT_SYNC" value="DONT_SYNC" />
++   </component>
++-  <component name="GitHubPullRequestSearchHistory">{
++-  &quot;lastFilter&quot;: {
++-    &quot;state&quot;: &quot;OPEN&quot;,
++-    &quot;assignee&quot;: &quot;MBamdad&quot;
++-  }
++-}</component>
++-  <component name="GithubPullRequestsUISettings">{
++-  &quot;selectedUrlAndAccountId&quot;: {
++-    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,
++-    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;
++-  }
++-}</component>
++   <component name="ProjectColorInfo">{
+++  &quot;customColor&quot;: &quot;&quot;,
++   &quot;associatedIndex&quot;: 1
++ }</component>
++-  <component name="ProjectId" id="2p11NySvsgjZ8eu9d53SI84567l" />
++-  <component name="ProjectReloadState">
++-    <option name="STATE" value="1" />
++-  </component>
+++  <component name="ProjectId" id="30Ji1A2o7U8uDkwC8cwxQfRFc4k" />
++   <component name="ProjectViewState">
++     <option name="hideEmptyMiddlePackages" value="true" />
++     <option name="showLibraryContents" value="true" />
++   </component>
++   <component name="PropertiesComponent">{
++   &quot;keyToString&quot;: {
++-    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.Test.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.CH3D_FNO4d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.PFC3D_FNO4d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.SH3D_FNO4d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.SH3D_Hybrid.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.SH3D_TNO3D.executor&quot;: &quot;Run&quot;,
++     &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,
++     &quot;Python.main.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.networks.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.test1.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.main1.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.run_interface3.executor&quot;: &quot;Run&quot;,
++     &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
++     &quot;git-widget-placeholder&quot;: &quot;main&quot;,
++-    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,
+++    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_TNO3d&quot;,
++     &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
++-    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,
++     &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
++     &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,
++     &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,
++-    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,
++     &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;
++-  },
++-  &quot;keyToStringList&quot;: {
++-    &quot;ChangesTree.GroupingKeys&quot;: [
++-      &quot;directory&quot;
++-    ]
++   }
++ }</component>
++   <component name="RecentsManager">
++     <key name="CopyFile.RECENT_KEYS">
++-      <recent name="$PROJECT_DIR$/data" />
++-      <recent name="$PROJECT_DIR$/configs" />
++-      <recent name="$PROJECT_DIR$/AC2Dtest/models" />
++-      <recent name="$PROJECT_DIR$/Archive_Code/AC2D" />
++-      <recent name="$PROJECT_DIR$/Archive_Code" />
++-    </key>
++-    <key name="MoveFile.RECENT_KEYS">
++-      <recent name="$PROJECT_DIR$/data" />
++-      <recent name="$PROJECT_DIR$" />
+++      <recent name="$PROJECT_DIR$/SH3D/plots_TNO3d" />
+++      <recent name="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d" />
+++      <recent name="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d" />
+++      <recent name="$PROJECT_DIR$/PFC3D/plots_TNO3d" />
+++      <recent name="$PROJECT_DIR$/AC3D/plots_Data_Physics_TNO3d" />
++     </key>
++   </component>
++-  <component name="RunManager" selected="Python.AC3D_TNO3d">
++-    <configuration name="AC3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="AC3d_FNO3d" type="PythonConfigurationType" factoryName="Python">
+++  <component name="RunManager" selected="Python.CH3D_FNO4d">
+++    <configuration name="CH3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
++       <module name="PhaseFieldNet" />
++       <option name="ENV_FILES" value="" />
++       <option name="INTERPRETER_OPTIONS" value="" />
++@@ -223,7 +131,7 @@
++       <option name="INPUT_FILE" value="" />
++       <method v="2" />
++     </configuration>
++-    <configuration name="AC3d_TNO3d_hybrid" type="PythonConfigurationType" factoryName="Python">
+++    <configuration name="PFC3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
++       <module name="PhaseFieldNet" />
++       <option name="ENV_FILES" value="" />
++       <option name="INTERPRETER_OPTIONS" value="" />
++@@ -247,7 +155,7 @@
++       <option name="INPUT_FILE" value="" />
++       <method v="2" />
++     </configuration>
++-    <configuration name="CH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
+++    <configuration name="SH3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
++       <module name="PhaseFieldNet" />
++       <option name="ENV_FILES" value="" />
++       <option name="INTERPRETER_OPTIONS" value="" />
++@@ -256,127 +164,7 @@
++         <env name="PYTHONUNBUFFERED" value="1" />
++       </envs>
++       <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="CH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="MBE3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="SH3D_FNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="SH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="SH3D_TNO3d_Hybrid" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
+++      <option name="SDK_NAME" value="torch_env" />
++       <option name="WORKING_DIRECTORY" value="" />
++       <option name="IS_MODULE_SDK" value="false" />
++       <option name="ADD_CONTENT_ROOTS" value="true" />
++@@ -392,14 +180,9 @@
++       <method v="2" />
++     </configuration>
++     <list>
++-      <item itemvalue="Python.AC3D_TNO3d" />
++-      <item itemvalue="Python.AC3d_FNO3d" />
++-      <item itemvalue="Python.AC3d_TNO3d_hybrid" />
++-      <item itemvalue="Python.CH3D_TNO3d" />
++-      <item itemvalue="Python.MBE3D_TNO3d" />
++-      <item itemvalue="Python.SH3D_FNO3d" />
++-      <item itemvalue="Python.SH3D_TNO3d" />
++-      <item itemvalue="Python.SH3D_TNO3d_Hybrid" />
+++      <item itemvalue="Python.CH3D_FNO4d" />
+++      <item itemvalue="Python.PFC3D_FNO4d" />
+++      <item itemvalue="Python.SH3D_FNO4d" />
++     </list>
++   </component>
++   <component name="SharedIndexes">
++@@ -413,501 +196,275 @@
++   <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
++   <component name="TaskManager">
++     <task active="true" id="Default" summary="Default task">
++-      <changelist id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="" />
++-      <created>1731918731711</created>
+++      <changelist id="4e84c369-97f3-4301-a9fc-5fc5327e1a8a" name="Changes" comment="3d_phase_evolution" />
+++      <created>1753351859462</created>
++       <option name="number" value="Default" />
++       <option name="presentableId" value="Default" />
++-      <updated>1731918731711</updated>
++-      <workItem from="1731918732726" duration="17070000" />
++-      <workItem from="1732010735784" duration="777000" />
++-      <workItem from="1732011520582" duration="8000" />
++-      <workItem from="1732011538945" duration="13153000" />
++-      <workItem from="1732106481018" duration="3721000" />
++-      <workItem from="1732480846034" duration="2889000" />
++-      <workItem from="1732483872465" duration="14926000" />
++-      <workItem from="1732567216112" duration="964000" />
++-      <workItem from="1732765090621" duration="5000" />
++-      <workItem from="1732765102609" duration="12000" />
++-      <workItem from="1732765345288" duration="10000" />
++-      <workItem from="1732903897716" duration="3074000" />
++-      <workItem from="1732911303920" duration="27201000" />
++-      <workItem from="1732999179592" duration="8241000" />
++-      <workItem from="1733039613684" duration="6792000" />
++-      <workItem from="1733095843263" duration="10000" />
++-      <workItem from="1733140600841" duration="6993000" />
++-      <workItem from="1733150993229" duration="184000" />
++-      <workItem from="1733151279786" duration="6000" />
++-      <workItem from="1733151296310" duration="16875000" />
++-      <workItem from="1733233230739" duration="5172000" />
++-      <workItem from="1733246997923" duration="15986000" />
++-      <workItem from="1733349590652" duration="1949000" />
++-      <workItem from="1733352121741" duration="6332000" />
++-      <workItem from="1733405466233" duration="12731000" />
++-      <workItem from="1733557048829" duration="5541000" />
++-      <workItem from="1733583489891" duration="16419000" />
++-      <workItem from="1733859258781" duration="7356000" />
++-      <workItem from="1733995059967" duration="7899000" />
++-      <workItem from="1734011167665" duration="991000" />
++-      <workItem from="1734029966470" duration="25769000" />
++-      <workItem from="1734205412700" duration="7689000" />
++-      <workItem from="1734644992163" duration="5017000" />
++-      <workItem from="1734788130789" duration="2312000" />
++-      <workItem from="1734863751114" duration="9000" />
++-      <workItem from="1734863775073" duration="9221000" />
++-      <workItem from="1734880034791" duration="57000" />
++-      <workItem from="1734880213539" duration="15000" />
++-      <workItem from="1734880329890" duration="30000" />
++-      <workItem from="1734880369064" duration="31312000" />
++-      <workItem from="1734983129135" duration="55000" />
++-      <workItem from="1735034212628" duration="2274000" />
++-      <workItem from="1735049036048" duration="5309000" />
++-      <workItem from="1735126261413" duration="75000" />
++-      <workItem from="1735356723104" duration="1208000" />
++-      <workItem from="1735422837186" duration="1387000" />
++-      <workItem from="1735719009558" duration="561000" />
++-      <workItem from="1736101930735" duration="570000" />
++-      <workItem from="1736102511675" duration="4000" />
++-      <workItem from="1736161159525" duration="7670000" />
++-      <workItem from="1736237907904" duration="111000" />
++-      <workItem from="1736519480236" duration="1867000" />
++-      <workItem from="1737577034938" duration="3945000" />
++-      <workItem from="1737590448155" duration="6145000" />
++-      <workItem from="1738310597042" duration="2502000" />
++-      <workItem from="1738316162773" duration="726000" />
++-      <workItem from="1738326887364" duration="4500000" />
++-      <workItem from="1738586797583" duration="600000" />
++-      <workItem from="1738663690532" duration="4505000" />
++-      <workItem from="1738668267214" duration="5368000" />
++-      <workItem from="1738685509837" duration="74000" />
++-      <workItem from="1738703726377" duration="1677000" />
++-      <workItem from="1738774383038" duration="2249000" />
++-      <workItem from="1738787637783" duration="7013000" />
++-      <workItem from="1738962434877" duration="1153000" />
++-      <workItem from="1738967049524" duration="782000" />
++-      <workItem from="1739275350614" duration="312000" />
++-      <workItem from="1739464522072" duration="12498000" />
++-      <workItem from="1739572784568" duration="1228000" />
++-      <workItem from="1739626528163" duration="5778000" />
++-      <workItem from="1739689815626" duration="10399000" />
++-      <workItem from="1739812786805" duration="48519000" />
++-      <workItem from="1740212626723" duration="1263000" />
++-      <workItem from="1740213932190" duration="644000" />
++-      <workItem from="1741475492994" duration="40894000" />
++-      <workItem from="1741690305204" duration="339000" />
++-      <workItem from="1741705983516" duration="604000" />
++-      <workItem from="1741713165753" duration="1198000" />
++-      <workItem from="1741861318912" duration="2286000" />
++-      <workItem from="1742201562752" duration="618000" />
++-      <workItem from="1742209067924" duration="383000" />
++-      <workItem from="1742226300133" duration="2432000" />
++-      <workItem from="1743071528350" duration="9513000" />
++-      <workItem from="1743490058046" duration="9000" />
++-      <workItem from="1743587112942" duration="1188000" />
++-      <workItem from="1748900986740" duration="1771000" />
++-      <workItem from="1748931928220" duration="446000" />
++-      <workItem from="1748932436127" duration="20890000" />
++-      <workItem from="1748970706276" duration="3719000" />
++-      <workItem from="1748988822181" duration="59000" />
++-      <workItem from="1749200290051" duration="680000" />
++-      <workItem from="1749203502833" duration="1349000" />
++-      <workItem from="1749213099437" duration="3082000" />
++-      <workItem from="1750057109660" duration="10453000" />
++-      <workItem from="1750070416210" duration="46415000" />
+++      <updated>1753351859462</updated>
+++      <workItem from="1753351861131" duration="6344000" />
+++      <workItem from="1753438320712" duration="13353000" />
+++      <workItem from="1753603965993" duration="23907000" />
+++      <workItem from="1753709105378" duration="8957000" />
+++      <workItem from="1753783502864" duration="521000" />
+++      <workItem from="1753784038079" duration="2184000" />
+++      <workItem from="1753792651870" duration="5722000" />
+++      <workItem from="1753867421329" duration="923000" />
+++      <workItem from="1753871809956" duration="11925000" />
+++      <workItem from="1754025478167" duration="1649000" />
+++      <workItem from="1754054724448" duration="509000" />
++     </task>
++-    <task id="LOCAL-00001" summary="Initial Commit">
+++    <task id="LOCAL-00001" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1732484343908</created>
+++      <created>1753438388631</created>
++       <option name="number" value="00001" />
++       <option name="presentableId" value="LOCAL-00001" />
++       <option name="project" value="LOCAL" />
++-      <updated>1732484343908</updated>
+++      <updated>1753438388631</updated>
++     </task>
++-    <task id="LOCAL-00002" summary="added TransformerFNO">
+++    <task id="LOCAL-00002" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1732497990642</created>
+++      <created>1753444583988</created>
++       <option name="number" value="00002" />
++       <option name="presentableId" value="LOCAL-00002" />
++       <option name="project" value="LOCAL" />
++-      <updated>1732497990642</updated>
+++      <updated>1753444583988</updated>
++     </task>
++-    <task id="LOCAL-00003" summary="added the connection between time steps - the model development is finished">
+++    <task id="LOCAL-00003" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1732910153380</created>
+++      <created>1753529013551</created>
++       <option name="number" value="00003" />
++       <option name="presentableId" value="LOCAL-00003" />
++       <option name="project" value="LOCAL" />
++-      <updated>1732910153380</updated>
+++      <updated>1753529013551</updated>
++     </task>
++-    <task id="LOCAL-00004" summary="Finished Allen-Cahn Problem">
+++    <task id="LOCAL-00004" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1733176021525</created>
+++      <created>1753539586020</created>
++       <option name="number" value="00004" />
++       <option name="presentableId" value="LOCAL-00004" />
++       <option name="project" value="LOCAL" />
++-      <updated>1733176021525</updated>
+++      <updated>1753539586020</updated>
++     </task>
++-    <task id="LOCAL-00005" summary="Added Allen-Cahn 3D">
+++    <task id="LOCAL-00005" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1733583274023</created>
+++      <created>1753640098974</created>
++       <option name="number" value="00005" />
++       <option name="presentableId" value="LOCAL-00005" />
++       <option name="project" value="LOCAL" />
++-      <updated>1733583274023</updated>
+++      <updated>1753640098974</updated>
++     </task>
++-    <task id="LOCAL-00006" summary="added save_vtk">
+++    <task id="LOCAL-00006" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1733995237535</created>
+++      <created>1753713910794</created>
++       <option name="number" value="00006" />
++       <option name="presentableId" value="LOCAL-00006" />
++       <option name="project" value="LOCAL" />
++-      <updated>1733995237535</updated>
+++      <updated>1753713910794</updated>
++     </task>
++-    <task id="LOCAL-00007" summary="added MATLAB codes for creating database">
+++    <task id="LOCAL-00007" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1734788540933</created>
+++      <created>1753722333819</created>
++       <option name="number" value="00007" />
++       <option name="presentableId" value="LOCAL-00007" />
++       <option name="project" value="LOCAL" />
++-      <updated>1734788540933</updated>
+++      <updated>1753722333819</updated>
++     </task>
++-    <task id="LOCAL-00008" summary="added CH2DNL">
+++    <task id="LOCAL-00008" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1735126332032</created>
+++      <created>1753789147535</created>
++       <option name="number" value="00008" />
++       <option name="presentableId" value="LOCAL-00008" />
++       <option name="project" value="LOCAL" />
++-      <updated>1735126332032</updated>
+++      <updated>1753789147535</updated>
++     </task>
++-    <task id="LOCAL-00009" summary="added SH2D">
+++    <task id="LOCAL-00009" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1735719422931</created>
+++      <created>1753867478797</created>
++       <option name="number" value="00009" />
++       <option name="presentableId" value="LOCAL-00009" />
++       <option name="project" value="LOCAL" />
++-      <updated>1735719422931</updated>
+++      <updated>1753867478797</updated>
++     </task>
++-    <task id="LOCAL-00010" summary="added PFC2D">
+++    <task id="LOCAL-00010" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1736237977029</created>
+++      <created>1753872227989</created>
++       <option name="number" value="00010" />
++       <option name="presentableId" value="LOCAL-00010" />
++       <option name="project" value="LOCAL" />
++-      <updated>1736237977029</updated>
+++      <updated>1753872227989</updated>
++     </task>
++-    <task id="LOCAL-00011" summary="added PFC2D">
+++    <task id="LOCAL-00011" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738788849261</created>
+++      <created>1753974441825</created>
++       <option name="number" value="00011" />
++       <option name="presentableId" value="LOCAL-00011" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738788849261</updated>
+++      <updated>1753974441825</updated>
++     </task>
++-    <task id="LOCAL-00012" summary="added PFC2D">
+++    <task id="LOCAL-00012" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738789326593</created>
+++      <created>1753976447489</created>
++       <option name="number" value="00012" />
++       <option name="presentableId" value="LOCAL-00012" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738789326593</updated>
+++      <updated>1753976447489</updated>
++     </task>
++-    <task id="LOCAL-00013" summary="added PFC2D">
+++    <task id="LOCAL-00013" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738796104012</created>
+++      <created>1753976663822</created>
++       <option name="number" value="00013" />
++       <option name="presentableId" value="LOCAL-00013" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738796104012</updated>
+++      <updated>1753976663822</updated>
++     </task>
++-    <task id="LOCAL-00014" summary="added PFC2D">
+++    <task id="LOCAL-00014" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738962464719</created>
+++      <created>1753984140485</created>
++       <option name="number" value="00014" />
++       <option name="presentableId" value="LOCAL-00014" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738962464719</updated>
+++      <updated>1753984140485</updated>
++     </task>
++-    <task id="LOCAL-00015" summary="added PFC2D">
+++    <task id="LOCAL-00015" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738962748829</created>
+++      <created>1754027236458</created>
++       <option name="number" value="00015" />
++       <option name="presentableId" value="LOCAL-00015" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738962748829</updated>
++-    </task>
++-    <task id="LOCAL-00016" summary="Turn Nx to 64">
++-      <option name="closed" value="true" />
++-      <created>1738967163754</created>
++-      <option name="number" value="00016" />
++-      <option name="presentableId" value="LOCAL-00016" />
++-      <option name="project" value="LOCAL" />
++-      <updated>1738967163754</updated>
++-    </task>
++-    <task id="LOCAL-00017" summary="update to 3D">
++-      <option name="closed" value="true" />
++-      <created>1739275401458</created>
++-      <option name="number" value="00017" />
++-      <option name="presentableId" value="LOCAL-00017" />
++-      <option name="project" value="LOCAL" />
++-      <updated>1739275401458</updated>
++-    </task>
++-    <task id="LOCAL-00018" summary="update to 3D">
++-      <option name="closed" value="true" />
++-      <created>1739275433418</created>
++-      <option name="number" value="00018" />
++-      <option name="presentableId" value="LOCAL-00018" />
++-      <option name="project" value="LOCAL" />
++-      <updated>1739275433418</updated>
++-    </task>
++-    <task id="LOCAL-00019" summary="TNO3d vs FNO3d">
++-      <option name="closed" value="true" />
++-      <created>1741690373369</created>
++-      <option name="number" value="00019" />
++-      <option name="presentableId" value="LOCAL-00019" />
++-      <option name="project" value="LOCAL" />
++-      <updated>1741690373369</updated>
++-    </task>
++-    <task id="LOCAL-00020" summary="TNO3d vs FNO3d">
++-      <option name="closed" value="true" />
++-      <created>1741690420059</created>
++-      <option name="number" value="00020" />
++-      <option name="presentableId" value="LOCAL-00020" />
++-      <option name="project" value="LOCAL" />
++-      <updated>1741690420059</updated>
++-    </task>
++-    <task id="LOCAL-00021" summary="TNO3d vs FNO3d">
++-      <option name="closed" value="true" />
++-      <created>1743587271259</created>
++-      <option name="number" value="00021" />
++-      <option name="presentableId" value="LOCAL-00021" />
++-      <option name="project" value="LOCAL" />
++-      <updated>1743587271259</updated>
+++      <updated>1754027236458</updated>
++     </task>
++-    <option name="localTasksCounter" value="22" />
+++    <option name="localTasksCounter" value="16" />
++     <servers />
++   </component>
++   <component name="TypeScriptGeneratedFilesManager">
++     <option name="version" value="3" />
++-  </component>
++-  <component name="Vcs.Log.Tabs.Properties">
++-    <option name="RECENT_FILTERS">
++-      <map>
++-        <entry key="Branch">
++-          <value>
++-            <list>
++-              <RecentGroup>
++-                <option name="FILTER_VALUES">
++-                  <option value="main" />
++-                </option>
++-              </RecentGroup>
++-            </list>
++-          </value>
++-        </entry>
++-      </map>
++-    </option>
++-    <option name="TAB_STATES">
++-      <map>
++-        <entry key="MAIN">
++-          <value>
++-            <State>
++-              <option name="FILTERS">
++-                <map>
++-                  <entry key="branch">
++-                    <value>
++-                      <list>
++-                        <option value="main" />
++-                      </list>
++-                    </value>
++-                  </entry>
++-                </map>
++-              </option>
++-            </State>
++-          </value>
++-        </entry>
++-      </map>
++-    </option>
++   </component>
++   <component name="VcsManagerConfiguration">
++-    <MESSAGE value="Initial Commit" />
++-    <MESSAGE value="added TransformerFNO" />
++-    <MESSAGE value="added the connection between time steps - the model development is finished" />
++-    <MESSAGE value="refactored" />
++-    <MESSAGE value="Finished Allen-Cahn Problem" />
++-    <MESSAGE value="Added Allen-Cahn 3D" />
++-    <MESSAGE value="added save_vtk" />
++-    <MESSAGE value="added MATLAB codes for creating database" />
++-    <MESSAGE value="seperated the number of layers in fourier part and convolutional part" />
++-    <MESSAGE value="added CH2DNL" />
++-    <MESSAGE value="added SH2D" />
++-    <MESSAGE value="added PFC2D" />
++-    <MESSAGE value="Turn Nx to 64" />
++-    <MESSAGE value="update to 3D" />
++-    <MESSAGE value="TNO3d vs FNO3d" />
++-    <option name="LAST_COMMIT_MESSAGE" value="TNO3d vs FNO3d" />
+++    <MESSAGE value="3d_phase_evolution" />
+++    <option name="LAST_COMMIT_MESSAGE" value="3d_phase_evolution" />
++   </component>
++   <component name="XDebuggerManager">
++     <breakpoint-manager>
++       <breakpoints>
++         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>142</line>
++-          <option name="timeStamp" value="17" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>163</line>
++-          <option name="timeStamp" value="18" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>134</line>
++-          <option name="timeStamp" value="19" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>327</line>
++-          <option name="timeStamp" value="20" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>243</line>
++-          <option name="timeStamp" value="21" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/AC2D_2.py</url>
++-          <line>333</line>
++-          <option name="timeStamp" value="27" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>
++-          <line>371</line>
++-          <option name="timeStamp" value="44" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>
++-          <line>338</line>
++-          <option name="timeStamp" value="54" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>53</line>
++-          <option name="timeStamp" value="128" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>30</line>
++-          <option name="timeStamp" value="129" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>25</line>
++-          <option name="timeStamp" value="133" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>18</line>
++-          <option name="timeStamp" value="135" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>
++-          <line>44</line>
++-          <option name="timeStamp" value="138" />
+++          <url>file://$PROJECT_DIR$/training.py</url>
+++          <line>208</line>
+++          <option name="timeStamp" value="1" />
++         </line-breakpoint>
++         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test2.py</url>
++-          <line>16</line>
++-          <option name="timeStamp" value="144" />
+++          <url>file://$PROJECT_DIR$/training.py</url>
+++          <line>209</line>
+++          <option name="timeStamp" value="3" />
++         </line-breakpoint>
++         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/utilities.py</url>
++-          <line>98</line>
++-          <option name="timeStamp" value="170" />
+++          <url>file://$PROJECT_DIR$/networks.py</url>
+++          <line>373</line>
+++          <option name="timeStamp" value="5" />
++         </line-breakpoint>
++         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/main.py</url>
++-          <line>157</line>
++-          <option name="timeStamp" value="177" />
+++          <url>file://$PROJECT_DIR$/networks.py</url>
+++          <line>252</line>
+++          <option name="timeStamp" value="6" />
++         </line-breakpoint>
++       </breakpoints>
++-      <default-breakpoints>
++-        <breakpoint type="python-exception">
++-          <properties notifyOnTerminate="true" exception="BaseException">
++-            <option name="notifyOnTerminate" value="true" />
++-          </properties>
++-        </breakpoint>
++-      </default-breakpoints>
++     </breakpoint-manager>
++   </component>
++   <component name="com.intellij.coverage.CoverageDataManagerImpl">
++-    <SUITE FILE_PATH="coverage/PhaseField1$Test3.coverage" NAME="Test3 Coverage Results" MODIFIED="1739273938386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO4d.coverage" NAME="SH3D_FNO4d Coverage Results" MODIFIED="1753633990803" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage" NAME="config_AC2D_FNO3d Coverage Results" MODIFIED="1733233385695" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$main.coverage" NAME="main Coverage Results" MODIFIED="1743065376798" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_2.coverage" NAME="AC2D_Net2D_2 Coverage Results" MODIFIED="1732904114403" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_PFC3D_TNO3d.coverage" NAME="config_PFC3D_TNO3d Coverage Results" MODIFIED="1752681001873" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$test2.coverage" NAME="test2 Coverage Results" MODIFIED="1742889074336" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1741561715014" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage" NAME="config_SH3D_TNO3d Coverage Results" MODIFIED="1750254757455" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$backend_interagg.coverage" NAME="backend_interagg Coverage Results" MODIFIED="1737630366471" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript3.coverage" NAME="RunScript3 Coverage Results" MODIFIED="1736368081257" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_2.coverage" NAME="AC2D_2 Coverage Results" MODIFIED="1732483323689" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3D.coverage" NAME="SH3D_TNO3D Coverage Results" MODIFIED="1753359664305" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$networks.coverage" NAME="networks Coverage Results" MODIFIED="1733086051390" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$main_TF.coverage" NAME="main_TF Coverage Results" MODIFIED="1738704014479" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1741538869064" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$THFNO.coverage" NAME="THFNO Coverage Results" MODIFIED="1732911474644" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/networks" />
++     <SUITE FILE_PATH="coverage/PhaseField1$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1740088478224" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$PFC3D.coverage" NAME="PFC3D Coverage Results" MODIFIED="1740083613128" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1741603428589" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_inference.coverage" NAME="run_inference Coverage Results" MODIFIED="1750323709039" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3d_TNO3d_hybrid.coverage" NAME="PFC3d_TNO3d_hybrid Coverage Results" MODIFIED="1753174544263" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$main.coverage" NAME="main Coverage Results" MODIFIED="1738663765959" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$post_processing.coverage" NAME="post_processing Coverage Results" MODIFIED="1733557098801" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage" NAME="config_CH2D_TNO2d Coverage Results" MODIFIED="1734086207850" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$networks.coverage" NAME="networks Coverage Results" MODIFIED="1748933697533" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1750255151255" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript2.coverage" NAME="RunScript2 Coverage Results" MODIFIED="1736369209710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1742215946758" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_3.coverage" NAME="AC2D_Net2D_3 Coverage Results" MODIFIED="1732974697103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_FNO3d.coverage" NAME="AC3d_FNO3d Coverage Results" MODIFIED="1749017845623" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1751364899601" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_Hybrid.coverage" NAME="SH3D_Hybrid Coverage Results" MODIFIED="1753435630879" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D.coverage" NAME="AC2D Coverage Results" MODIFIED="1733088640665" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Archive_Code" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D.coverage" NAME="AC2D_Net2D Coverage Results" MODIFIED="1732567473230" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField1$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1740054182408" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1741562061391" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1753174449133" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1737644605063" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$MBE3D.coverage" NAME="MBE3D Coverage Results" MODIFIED="1739283566145" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1741605347375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1743071672425" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$main.coverage" NAME="main Coverage Results" MODIFIED="1736268192289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1741564210973" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage" NAME="config_CH2DNL_TNO2d Coverage Results" MODIFIED="1735052490996" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$MBE2D.coverage" NAME="MBE2D Coverage Results" MODIFIED="1732278526731" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1739914172084" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$Test_Run.coverage" NAME="Test_Run Coverage Results" MODIFIED="1738945320139" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1741561294310" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741861381348" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_Hybrid.coverage" NAME="PFC3D_Hybrid Coverage Results" MODIFIED="1752753153734" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1743081225414" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage" NAME="PFV3D_FNO3d Coverage Results" MODIFIED="1741564487710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript1.coverage" NAME="RunScript1 Coverage Results" MODIFIED="1736368790622" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$SH2D.coverage" NAME="SH2D Coverage Results" MODIFIED="1732347080402" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1752763076697" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$PFC2D.coverage" NAME="PFC2D Coverage Results" MODIFIED="1732278679485" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$CH2D.coverage" NAME="CH2D Coverage Results" MODIFIED="1732347055915" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_FNO3d.coverage" NAME="AC3D_FNO3d Coverage Results" MODIFIED="1741561435127" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$SH3D.coverage" NAME="SH3D Coverage Results" MODIFIED="1739044808411" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$Test.coverage" NAME="Test Coverage Results" MODIFIED="1739459206236" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_hybrid.coverage" NAME="MBE3D_hybrid Coverage Results" MODIFIED="1753449172728" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741547133078" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage" NAME="config_AC2D_FNO2d Coverage Results" MODIFIED="1733393903488" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_FNO4d.coverage" NAME="PFC3D_FNO4d Coverage Results" MODIFIED="1753634100431" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$AC3D.coverage" NAME="AC3D Coverage Results" MODIFIED="1740041515520" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$config_CH3D_TNO3d.coverage" NAME="config_CH3D_TNO3d Coverage Results" MODIFIED="1738089807566" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseField1$Test2.coverage" NAME="Test2 Coverage Results" MODIFIED="1739283715182" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_FNO3d.coverage" NAME="CH3D_FNO3d Coverage Results" MODIFIED="1741628529142" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage" NAME="AC3d_TNO3d_hybrid Coverage Results" MODIFIED="1748989478372" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1737899062785" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1751535690856" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D.coverage" NAME="config_AC2D Coverage Results" MODIFIED="1733087276180" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_1.coverage" NAME="AC2D_Net2D_1 Coverage Results" MODIFIED="1732535211383" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1736520700819" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$fourier_3d.coverage" NAME="fourier_3d Coverage Results" MODIFIED="1732221600628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1750254767095" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1749216389646" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1748990262244" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_interface3.coverage" NAME="run_interface3 Coverage Results" MODIFIED="1754035179654" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1751390276789" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1753270153654" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1753435969375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$test1.coverage" NAME="test1 Coverage Results" MODIFIED="1733413325318" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_TNO3d_Hybrid.coverage" NAME="PFC3D_TNO3d_Hybrid Coverage Results" MODIFIED="1752850166757" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$Test3.coverage" NAME="Test3 Coverage Results" MODIFIED="1739273938386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_2.coverage" NAME="AC2D_Net2D_2 Coverage Results" MODIFIED="1732904114403" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_MBE3D_TNO3d.coverage" NAME="config_MBE3D_TNO3d Coverage Results" MODIFIED="1753524263103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage" NAME="config_SH3D_TNO3d Coverage Results" MODIFIED="1753348599806" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$backend_interagg.coverage" NAME="backend_interagg Coverage Results" MODIFIED="1737630366471" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript3.coverage" NAME="RunScript3 Coverage Results" MODIFIED="1736368081257" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_2.coverage" NAME="AC2D_2 Coverage Results" MODIFIED="1732483323689" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$main_TF.coverage" NAME="main_TF Coverage Results" MODIFIED="1738704014479" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1741538869064" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$THFNO.coverage" NAME="THFNO Coverage Results" MODIFIED="1732911474644" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/networks" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$PFC3D.coverage" NAME="PFC3D Coverage Results" MODIFIED="1740083613128" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$CH3D_FNO4d.coverage" NAME="CH3D_FNO4d Coverage Results" MODIFIED="1753634021694" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_AC3D_FNO3d.coverage" NAME="config_AC3D_FNO3d Coverage Results" MODIFIED="1751958646687" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_inference.coverage" NAME="run_inference Coverage Results" MODIFIED="1751264322005" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage" NAME="config_CH2D_TNO2d Coverage Results" MODIFIED="1734086207850" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$networks.coverage" NAME="networks Coverage Results" MODIFIED="1748933697533" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript2.coverage" NAME="RunScript2 Coverage Results" MODIFIED="1736369209710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1742215946758" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_3.coverage" NAME="AC2D_Net2D_3 Coverage Results" MODIFIED="1732974697103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$utilities.coverage" NAME="utilities Coverage Results" MODIFIED="1752595653294" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_FNO3d.coverage" NAME="AC3d_FNO3d Coverage Results" MODIFIED="1751961986602" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1741562061391" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_TNO.coverage" NAME="MBE3D_TNO Coverage Results" MODIFIED="1753438703018" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$MBE3D.coverage" NAME="MBE3D Coverage Results" MODIFIED="1739283566145" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1743071672425" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FO.coverage" NAME="SH3D_FO Coverage Results" MODIFIED="1753438614882" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$MBE2D.coverage" NAME="MBE2D Coverage Results" MODIFIED="1732278526731" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1739914172084" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3d_hybrid.coverage" NAME="MBE3d_hybrid Coverage Results" MODIFIED="1753458461671" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741861381348" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage" NAME="PFV3D_FNO3d Coverage Results" MODIFIED="1741564487710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$training.coverage" NAME="training Coverage Results" MODIFIED="1751968651692" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_Hybrid.coverage" NAME="MBE3D_Hybrid Coverage Results" MODIFIED="1753516430619" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript1.coverage" NAME="RunScript1 Coverage Results" MODIFIED="1736368790622" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$SH2D.coverage" NAME="SH2D Coverage Results" MODIFIED="1732347080402" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_FNO3d.coverage" NAME="PFC3D_FNO3d Coverage Results" MODIFIED="1753174772461" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$SH3D.coverage" NAME="SH3D Coverage Results" MODIFIED="1739044808411" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$Test.coverage" NAME="Test Coverage Results" MODIFIED="1739459206236" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$CH3D_TNO3d_Hybrid.coverage" NAME="CH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1752411744994" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage" NAME="config_AC2D_FNO2d Coverage Results" MODIFIED="1733393903488" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$config_CH3D_TNO3d.coverage" NAME="config_CH3D_TNO3d Coverage Results" MODIFIED="1738089807566" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_FNO3d.coverage" NAME="CH3D_FNO3d Coverage Results" MODIFIED="1741628529142" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage" NAME="AC3d_TNO3d_hybrid Coverage Results" MODIFIED="1751963486807" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1737899062785" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1753977480601" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main1.coverage" NAME="main1 Coverage Results" MODIFIED="1753709191839" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField1$CH3D_2.coverage" NAME="CH3D_2 Coverage Results" MODIFIED="1739918355289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1750254975290" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage" NAME="config_MBE2D_TNO2d Coverage Results" MODIFIED="1736261397712" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++   </component>
++ </project>
++\ No newline at end of file
++Index: configs/config_SH3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_SH3D_FNO4d.py b/configs/config_SH3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1753632627957)
+++++ b/configs/config_SH3D_FNO4d.py	(date 1753632627957)
++@@ -0,0 +1,80 @@
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda:2'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1200 # 5250 # 7500
+++nTest = 300 # 2250 #500
+++batch_size = 20 # 10 # 50 # 50
+++learning_rate = 0.001 # 0.005 # 0.001
+++weight_decay = 1e-4 # 1e-4
+++epochs = 30 # 1000
+++iterations = epochs * (nTrain // batch_size)
+++modes =  14 # 16
+++width =  12 #32
+++width_q =   width # width # 2 * width #
+++width_h = width//2  # width//4 # width #
+++n_layers = 2 # 8
+++
+++# Discretization
+++s = 32 # 32 # 64
+++T_in = 1
+++T_out = 91 # 100 # 100
+++
+++# Training Setting
+++normalized = True # False #True
+++training = True # False  # True
+++load_model = False # False #True
+++
+++# Database
+++parent_dir = './data/'
+++#matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
+++# Plotting
+++
+++# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
+++Lx = 15 # 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++Ly =Lx
+++Lz= Lx
+++
+++index = 62  # 24 # 62
+++#domain = [-np.pi, np.pi]  ######
+++domain = [-Lx/2, Lx/2]
+++
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++### Hybrid method
+++
+++# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
+++#Lx = np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++# domain = [-Lx/2, Lx/2] # Assuming centered domain
+++
+++# Time Discretization (from MATLAB)
+++dt_sim = 0.0002 # Simulation time step
+++Nt = 100 # Total simulation steps
+++num_saved_steps = 101 # Number of saved steps (includes t=0)
+++ns = Nt / (num_saved_steps - 1) # Interval between saved steps
+++dt_model = ns * dt_sim # Effective time step between model outputs
+++
+++# PDE Parameters
+++epsilon = 0.15
+++#pde_weight = 0.3 # Example: 30% physics loss
+++pde_weight = 0.0 # Example: 70% physics loss
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++pde_loss_scaler = 1e-0
+++###########################
+++# ... rest of config ...
++\ No newline at end of file
++Index: configs/config_SH3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:2'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 # 5250 # 7500\nnTest = 300 # 2250 #500\nbatch_size = 20 # 50\nlearning_rate = 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-4\nepochs = 30 # 50 # 50 # 50 # 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 16 # 16\nwidth =  12 # 12 #32\nwidth_q =   width # width # 2 * width #\nwidth_h = width//2  # width//4 # width #\nn_layers = 2 # 8\n\n# Discretization\n#s = 32 # 32 # 64\n#T_in = 1\n#T_out = 20 # 100\n# Discretization\ns = 32 # 80         # CRITICAL: Must match Nx, Ny, Nz from MATLAB (which is 80)\nT_in = 1       # CRITICAL: Use the first time step (t=0) as input\nT_out = 100 # 91 # 100 # 20     # CRITICAL: Predict the next 10 time steps. Total steps used = 1+10=11, which matches the data.\n\n# Training Setting\nnormalized = True # False\ntraining = True # False  #   True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_3232.mat' # correct\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results\n# Plotting\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\nLx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\nLy =Lx\nLz= Lx\n\n\nindex = 62  # 24 # 62\n#domain = [-np.pi, np.pi] ######\ndomain = [-Lx/2, Lx/2]\n\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\n#time_steps = [0, 9, 19]\ntime_steps = [0, 50, 90]\n####\n### Hybrid method\n\n\n#domain = [-Lx/2, Lx/2] # Assuming centered domain\n\n# Time Discretization (from MATLAB)\ndt_sim = 0.05 # Simulation time step\ndt_simulation = 0.05\nNt = 100 # Total simulation steps\nnum_saved_steps = 101 # Number of saved steps (includes t=0)\nns = Nt / (num_saved_steps - 1) # Interval between saved steps\ndt_model = ns * dt_sim # Effective time step between model outputs\n\n# PDE Parameters\nepsilon = 0.15\n#pde_weight = 0.3 # Example: 30% physics loss\npde_weight = 0.4 # Example: 70% physics loss\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\npde_loss_scaler = 1e1\n###########################\n# ... rest of config ...
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_SH3D_TNO3d.py b/configs/config_SH3D_TNO3d.py
++--- a/configs/config_SH3D_TNO3d.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/configs/config_SH3D_TNO3d.py	(date 1753601090740)
++@@ -6,18 +6,18 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 1200 # 5250 # 7500
++-nTest = 300 # 2250 #500
+++nTrain = 1200 # 1600 # 5250 # 7500
+++nTest = 300 # 400 # 2250 #500
++ batch_size = 20 # 50
++ learning_rate = 0.001 # 0.005 # 0.001
++ weight_decay = 1e-4 # 1e-4
++-epochs = 30 # 50 # 50 # 50 # 50 # 1000
+++epochs = 30 # 50 # 50 # 50 # 50 # 50 # 1000
++ iterations = epochs * (nTrain // batch_size)
++ modes =  14 # 16 # 16
++ width =  12 # 12 #32
++-width_q =   width # width # 2 * width #
+++width_q = width # width # 2 * width #
++ width_h = width//2  # width//4 # width #
++-n_layers = 2 # 8
+++n_layers = 2 # 4 # 8
++ 
++ # Discretization
++ #s = 32 # 32 # 64
++@@ -38,11 +38,13 @@
++ 
++ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_3232.mat' # correct
++ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++
+++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
++ # Plotting
++ 
++ # In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
++-Lx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++Lx = 15 # 10 # 15 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
++ Ly =Lx
++ Lz= Lx
++ 
++@@ -76,11 +78,11 @@
++ # PDE Parameters
++ epsilon = 0.15
++ #pde_weight = 0.3 # Example: 30% physics loss
++-pde_weight = 0.4 # Example: 70% physics loss
+++pde_weight = 0.5 # 0.2 # Example: 70% physics loss
++ 
++ # Learning Rate Scheduler Parameters (for StepLR)
++ scheduler_step = 20  # Decay learning rate every 20 epochs
++ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++-pde_loss_scaler = 1e1
+++pde_loss_scaler = 1e0
++ ###########################
++ # ... rest of config ...
++\ No newline at end of file
++Index: configs/config_MBE3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\nimport numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 #1600 # 4000\nnTest = 300  # 400\nbatch_size = 50# 25 #100\nlearning_rate = 0.005\nweight_decay = 1e-4\nepochs = 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 12\nwidth = 12 #32\nwidth_q = width #32\nwidth_h = width // 2 # width # 32\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # True  # True\nload_model = False #True  # False  # False\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'\nmatlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 9  # 72\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_MBE3D_FNO3d.py b/configs/config_MBE3D_FNO3d.py
++--- a/configs/config_MBE3D_FNO3d.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/configs/config_MBE3D_FNO3d.py	(date 1753601090805)
++@@ -9,21 +9,21 @@
++ # Network Parameters
++ nTrain = 1200 #1600 # 4000
++ nTest = 300  # 400
++-batch_size = 50# 25 #100
++-learning_rate = 0.005
+++batch_size = 10 # 20 # 50# 25 #100
+++learning_rate = 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 1000
+++epochs = 50 # 50 # 1000
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 # 12
++ width = 12 #32
++ width_q = width #32
++ width_h = width // 2 # width # 32
++-n_layers = 4
+++n_layers = 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -32,14 +32,44 @@
++ 
++ # Database
++ parent_dir = './data/'
++-#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'
++-matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat'
+++
+++# Plotting
++ # Plotting
++-index = 9  # 72
++-domain = [-np.pi, np.pi]
+++index = 62  # 72
+++#domain = [-np.pi, np.pi]
+++Lx = 10 # np.pi            # Domain size from MATLAB
+++domain = [-Lx/2, Lx/2]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_AC3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_AC3D_FNO4d.py b/configs/config_AC3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1753632094128)
+++++ b/configs/config_AC3D_FNO4d.py	(date 1753632094128)
++@@ -0,0 +1,76 @@
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1000 # 900 # 1000
+++nTest = 300 # 100 # 100
+++batch_size = 20 # 10 # 50 # 20 #5 # 25
+++learning_rate = 0.001
+++weight_decay = 1e-4
+++epochs = 20 # 50 # 100 # 900  # 100
+++iterations = epochs * (nTrain // batch_size)
+++modes =  14 # 8 # last time modes =  8
+++width =  12 # 32 # last time width =  32
+++width_q = width
+++width_h = width // 2 # width // 4 # last time
+++n_layers = 2 # 4
+++
+++# Discretization
+++s = 32
+++T_in = 1
+++T_out = 91 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True # False  # False
+++load_model = False # True  # True
+++
+++# Database
+++parent_dir = './data/'
+++# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'AC3D_32_1000.mat'
+++#matlab_dataset = 'AC3D_32_1300.mat'
+++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
+++# Plotting
+++index = 9 # 12
+++#domain = [-np.pi, np.pi]
+++Lx = 5 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
+++
+++# time_steps = [29, 69]
+++#time_steps = [39, 49, 59, 69, 79, 89, 99]
+++# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++#############
+++#Lx = np.pi            # Domain size from MATLAB
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0001     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-5
++\ No newline at end of file
++Index: configs/config_AC3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1000 # 900 # 1000\nnTest = 300 # 100 # 100\nbatch_size = 50 # 20 #5 # 25\nlearning_rate = 0.001\nweight_decay = 1e-4\nepochs = 50 # 100 # 900  # 100\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 8 # last time modes =  8\nwidth =  12 # 32 # last time width =  32\nwidth_q = width\nwidth_h = width // 2 # width // 4 # last time\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # False\nload_model = False # True  # True\n\n# Database\nparent_dir = './data/'\n# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'\n#matlab_dataset = 'AC3D_32_1000.mat'\nmatlab_dataset = 'AC3D_32_1300.mat'\n# Plotting\nindex = 9 # 12\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 69]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]\n\n#############\nLx = np.pi            # Domain size from MATLAB\n# Time Discretization Parameters (from AC3D MATLAB)\ndt_sim = 0.0001     # Time step in the MATLAB simulation\nNt_sim = 50        # Total number of simulation steps in MATLAB\nnum_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)\n# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps\n# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output\n# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.\ndt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in\n# PDE Parameters for Allen-Cahn (AC3D)\n# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.\n# The PDE implemented in calculate_pde_residual was:\n# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)\nepsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter\n# PINN Specific Settings (if PINN_MODE is True in main.py)\npde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.\n# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\n\npde_loss_scaler = 1e-5
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_AC3D_FNO3d.py b/configs/config_AC3D_FNO3d.py
++--- a/configs/config_AC3D_FNO3d.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/configs/config_AC3D_FNO3d.py	(date 1753601090825)
++@@ -8,21 +8,21 @@
++ # Network Parameters
++ nTrain = 1000 # 900 # 1000
++ nTest = 300 # 100 # 100
++-batch_size = 50 # 20 #5 # 25
+++batch_size = 10 # 50 # 20 #5 # 25
++ learning_rate = 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 100 # 900  # 100
+++epochs = 20 # 50 # 100 # 900  # 100
++ iterations = epochs * (nTrain // batch_size)
++ modes =  14 # 8 # last time modes =  8
++ width =  12 # 32 # last time width =  32
++ width_q = width
++ width_h = width // 2 # width // 4 # last time
++-n_layers = 4
+++n_layers = 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -33,19 +33,25 @@
++ parent_dir = './data/'
++ # matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
++ #matlab_dataset = 'AC3D_32_1000.mat'
++-matlab_dataset = 'AC3D_32_1300.mat'
+++#matlab_dataset = 'AC3D_32_1300.mat'
+++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
++ # Plotting
++ index = 9 # 12
++-domain = [-np.pi, np.pi]
+++#domain = [-np.pi, np.pi]
+++Lx = 5 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
+++
++ # time_steps = [29, 69]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ # time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
+++time_steps = [0, 50, 90]
++ 
++ #############
++-Lx = np.pi            # Domain size from MATLAB
+++#Lx = np.pi            # Domain size from MATLAB
++ # Time Discretization Parameters (from AC3D MATLAB)
++ dt_sim = 0.0001     # Time step in the MATLAB simulation
++ Nt_sim = 50        # Total number of simulation steps in MATLAB
++Index: configs/config_PFC3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\"\"\"\nDevice:  cuda:0\nmodel = TNO2d_PFC2D_S64_T1to100_width32_modes12_q32_h16.pt\nnumber of epoch = 1000\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n2539703\n\nThe average testing error is 0.027059923857450485\nStd. deviation of testing error is 0.01980009116232395\n----------------------------------------------\nmodel = TNO2d_PFC2D_S64_T1to50_width16_modes12_q32_h16.pt\nnumber of epoch = 200\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n651059\n\nThe average testing error is 0.005057875066995621\nStd. deviation of testing error is 0.0021678071934729815\n----------------------------------------------\n\n\n\"\"\"\n\nimport numpy as np\n\n# General SettingnTrain = 1200 # 5250 # 7500\n\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200\nnTest = 300\nbatch_size = 50 # 100\nlearning_rate = 0.005\nweight_decay = 1e-4 # 1e-4\nepochs = 50\niterations = epochs * (nTrain // batch_size)\nmodes = 14 #12\nwidth = 12 # 16 # 32\nwidth_q = width # 32\nwidth_h = width//2 # 16\nn_layers = 4\n\n'''\ntau = 315;\nalpha = 115; \n'''\n\n# Discretization\ns = 32 # 64 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # True\nload_model = False # True # False # True  # False\n\n# Database\nparent_dir = './data/'\nmatlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 200  # 110  # 200\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n# time_steps = [0, 2, 4, 6, 8, 9]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_PFC3D_FNO3d.py b/configs/config_PFC3D_FNO3d.py
++--- a/configs/config_PFC3D_FNO3d.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/configs/config_PFC3D_FNO3d.py	(date 1753601090864)
++@@ -43,16 +43,16 @@
++ # Network Parameters
++ nTrain = 1200
++ nTest = 300
++-batch_size = 50 # 100
++-learning_rate = 0.005
+++batch_size = 15 # 100
+++learning_rate = 0.001
++ weight_decay = 1e-4 # 1e-4
++-epochs = 50
+++epochs = 30 # 50
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 #12
++ width = 12 # 16 # 32
++ width_q = width # 32
++ width_h = width//2 # 16
++-n_layers = 4
+++n_layers = 2 # 4
++ 
++ '''
++ tau = 315;
++@@ -62,7 +62,7 @@
++ # Discretization
++ s = 32 # 64 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -71,14 +71,45 @@
++ 
++ # Database
++ parent_dir = './data/'
++-matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
++ # Plotting
++-index = 200  # 110  # 200
++-domain = [-np.pi, np.pi]
+++
+++# Plotting
+++index = 69  # 110  # 200
+++Lx = 10*np.pi
+++domain = [-5*np.pi, 5*np.pi]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ # time_steps = [0, 2, 4, 6, 8, 9]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.05 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_PFC3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_PFC3D_FNO4d.py b/configs/config_PFC3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1753632355834)
+++++ b/configs/config_PFC3D_FNO4d.py	(date 1753632355834)
++@@ -0,0 +1,81 @@
+++import numpy as np
+++
+++# General SettingnTrain = 1200 # 5250 # 7500
+++
+++gpu_number = 'cuda:1'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1200
+++nTest = 300
+++batch_size = 20 # 15 # 100
+++learning_rate = 0.001
+++weight_decay = 1e-4 # 1e-4
+++epochs = 30 # 50
+++iterations = epochs * (nTrain // batch_size)
+++modes = 14 #12
+++width = 12 # 16 # 32
+++width_q = width # 32
+++width_h = width//2 # 16
+++n_layers = 2 # 4
+++
+++'''
+++tau = 315;
+++alpha = 115; 
+++'''
+++
+++# Discretization
+++s = 32 # 64 # 64
+++T_in = 1
+++T_out = 91 # 20 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True # False  # True
+++load_model = False # True # False # True  # False
+++
+++# Database
+++parent_dir = './data/'
+++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
+++# Plotting
+++
+++# Plotting
+++index = 69  # 110  # 200
+++Lx = 10*np.pi
+++domain = [-5*np.pi, 5*np.pi]
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++# time_steps = [0, 2, 4, 6, 8, 9]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.05 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_AC3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1000 # 900 # 1000\nnTest = 300 # 100 # 100\nbatch_size = 10 # 50 # 20 #5 # 25\nlearning_rate = 0.001\nweight_decay = 1e-4\nepochs = 50 # 100 # 900  # 100\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 8 # last time modes =  8\nwidth =  12 # 32 # last time width =  32\nwidth_q = width\nwidth_h = width // 2 # width // 4 # last time\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # False #  False\nload_model = False # True  #  True  # True\n\n# Database\nparent_dir = './data/'\n# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'\n#matlab_dataset = 'AC3D_32_1000.mat'\nmatlab_dataset = 'AC3D_32_1300.mat'\n# Plotting\nindex = 9 # 12\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 69]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]\n\n\n#############\nLx = np.pi            # Domain size from MATLAB\n# Time Discretization Parameters (from AC3D MATLAB)\ndt_sim = 0.0001     # Time step in the MATLAB simulation\nNt_sim = 50        # Total number of simulation steps in MATLAB\nnum_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)\n# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps\n# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output\n# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.\ndt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in\n# PDE Parameters for Allen-Cahn (AC3D)\n# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.\n# The PDE implemented in calculate_pde_residual was:\n# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)\nepsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter\n# PINN Specific Settings (if PINN_MODE is True in main.py)\npde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.\n# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\n\npde_loss_scaler = 1e-3
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_AC3D_TNO3d.py b/configs/config_AC3D_TNO3d.py
++--- a/configs/config_AC3D_TNO3d.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/configs/config_AC3D_TNO3d.py	(date 1753792952341)
++@@ -6,23 +6,23 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 1000 # 900 # 1000
+++nTrain = 1200 # 900 # 1000
++ nTest = 300 # 100 # 100
++-batch_size = 10 # 50 # 20 #5 # 25
++-learning_rate = 0.001
+++batch_size = 20 # 20 # 50 # 20 #5 # 25
+++learning_rate = 0.001 # 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 100 # 900  # 100
+++epochs = 20 # 50 #  # 100 # 900  # 100
++ iterations = epochs * (nTrain // batch_size)
++ modes =  14 # 8 # last time modes =  8
++-width =  12 # 32 # last time width =  32
+++width =  12 # 12 # 32 # last time width =  32
++ width_q = width
++ width_h = width // 2 # width // 4 # last time
++-n_layers = 4
+++n_layers = 2 # 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -31,24 +31,26 @@
++ 
++ # Database
++ parent_dir = './data/'
++-# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
++-#matlab_dataset = 'AC3D_32_1000.mat'
++-matlab_dataset = 'AC3D_32_1300.mat'
+++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
+++#matlab_dataset ='AC3D_32_1500_Augmented.mat' # mixed --> 75% GRF and 25% sphere...
++ # Plotting
++ index = 9 # 12
++-domain = [-np.pi, np.pi]
+++Lx = 5 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
++ # time_steps = [29, 69]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ # time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
+++time_steps = [1, 50, 90]
++ 
++ 
++ #############
++-Lx = np.pi            # Domain size from MATLAB
+++
++ # Time Discretization Parameters (from AC3D MATLAB)
++-dt_sim = 0.0001     # Time step in the MATLAB simulation
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
++ Nt_sim = 50        # Total number of simulation steps in MATLAB
++ num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++ # ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++@@ -61,11 +63,11 @@
++ # du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++ epsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++ # PINN Specific Settings (if PINN_MODE is True in main.py)
++-pde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++ # PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++ 
++ # Learning Rate Scheduler Parameters (for StepLR)
++ scheduler_step = 20  # Decay learning rate every 20 epochs
++ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++ 
++-pde_loss_scaler = 1e-3
++\ No newline at end of file
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: configs/config_CH3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:3'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500\nnTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500\nbatch_size = 2 # 20 # 50 # 3 # 20 # 50 # 5 # 50\nlearning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-3 # 1e-4\nepochs = 100 # 500 # 1000 # 25 # 100 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 10 #12 # 14 # 16 # 10 # 16\nwidth = 12 # 8 #12 #14 # 12 # 16 # 32\nwidth_q = width # 2 * width #\nwidth_h = width//2 # width//4 # width #\nn_layers = 4 # 4 # 5 # 5 # 8\n\n# Discretization\n\ns = 64 # 32 # 64 #32 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False # True # False  # True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n\n#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'\n\n# Plotting\nindex = 62  # 24 # 62\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_CH3D_FNO3d.py b/configs/config_CH3D_FNO3d.py
++--- a/configs/config_CH3D_FNO3d.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/configs/config_CH3D_FNO3d.py	(date 1753601090894)
++@@ -6,24 +6,24 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+++nTrain = 1300 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
++ nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
++-batch_size = 2 # 20 # 50 # 3 # 20 # 50 # 5 # 50
+++batch_size = 10 # 20 # 20 # 50 # 3 # 20 # 50 # 5 # 50
++ learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
++ weight_decay = 1e-4 # 1e-3 # 1e-4
++-epochs = 100 # 500 # 1000 # 25 # 100 # 1000
+++epochs = 50 # 100 # 500 # 1000 # 25 # 100 # 1000
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 # 10 #12 # 14 # 16 # 10 # 16
++ width = 12 # 8 #12 #14 # 12 # 16 # 32
++ width_q = width # 2 * width #
++ width_h = width//2 # width//4 # width #
++-n_layers = 4 # 4 # 5 # 5 # 8
+++n_layers = 3 # 2 # 4 # 5 # 5 # 8
++ 
++ # Discretization
++ 
++-s = 64 # 32 # 64 #32 # 64
+++s = 32 # 64 # 32 # 64 #32 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -34,15 +34,44 @@
++ parent_dir = './data/'
++ 
++ #matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
++-
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++ # Plotting
++ index = 62  # 24 # 62
++-domain = [-np.pi, np.pi]
+++#domain = [-np.pi, np.pi]
+++Lx = 2 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.05  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: configs/config_SH3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:2'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 # 5250 # 7500\nnTest = 300 # 2250 #500\nbatch_size = 10 # 50 # 50\nlearning_rate = 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-4\nepochs = 30 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 16\nwidth =  12 #32\nwidth_q =   width # width # 2 * width #\nwidth_h = width//2  # width//4 # width #\nn_layers = 2 # 8\n\n# Discretization\ns = 32 # 32 # 64\nT_in = 1\nT_out = 91 # 100 # 100\n\n# Training Setting\nnormalized = True # False #True\ntraining = True # False  # True\nload_model = False # False #True\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results\n\n# Plotting\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\nLx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\nLy =Lx\nLz= Lx\n\nindex = 62  # 24 # 62\n#domain = [-np.pi, np.pi]  ######\ndomain = [-Lx/2, Lx/2]\n\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 50, 90]\n\n\n### Hybrid method\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\n#Lx = np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\n# domain = [-Lx/2, Lx/2] # Assuming centered domain\n\n# Time Discretization (from MATLAB)\ndt_sim = 0.0000002 # Simulation time step\nNt = 100 # Total simulation steps\nnum_saved_steps = 101 # Number of saved steps (includes t=0)\nns = Nt / (num_saved_steps - 1) # Interval between saved steps\ndt_model = ns * dt_sim # Effective time step between model outputs\n\n# PDE Parameters\nepsilon = 0.15\n#pde_weight = 0.3 # Example: 30% physics loss\npde_weight = 0.0 # Example: 70% physics loss\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\npde_loss_scaler = 1e-11\n###########################\n# ... rest of config ...
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_SH3D_FNO3d.py b/configs/config_SH3D_FNO3d.py
++--- a/configs/config_SH3D_FNO3d.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/configs/config_SH3D_FNO3d.py	(date 1753601090905)
++@@ -33,12 +33,12 @@
++ parent_dir = './data/'
++ #matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'
++ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
++-
+++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
++ # Plotting
++ 
++ # In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
++-Lx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++Lx = 15 # 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
++ Ly =Lx
++ Lz= Lx
++ 
++@@ -62,7 +62,7 @@
++ # domain = [-Lx/2, Lx/2] # Assuming centered domain
++ 
++ # Time Discretization (from MATLAB)
++-dt_sim = 0.0000002 # Simulation time step
+++dt_sim = 0.0002 # Simulation time step
++ Nt = 100 # Total simulation steps
++ num_saved_steps = 101 # Number of saved steps (includes t=0)
++ ns = Nt / (num_saved_steps - 1) # Interval between saved steps
++@@ -75,6 +75,6 @@
++ # Learning Rate Scheduler Parameters (for StepLR)
++ scheduler_step = 20  # Decay learning rate every 20 epochs
++ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++-pde_loss_scaler = 1e-11
+++pde_loss_scaler = 1e-0
++ ###########################
++ # ... rest of config ...
++\ No newline at end of file
++Index: configs/config_CH3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500\nnTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500\nbatch_size = 20 # 50 # 3 # 20 # 50 # 5 # 50\nlearning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-3 # 1e-4\nepochs = 100 # 500 # 1000 # 25 # 100 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 10 #12 # 14 # 16 # 10 # 16\nwidth = 12 # 8 #12 #14 # 12 # 16 # 32\nwidth_q = width # 2 * width #\nwidth_h = width//2 # width//4 # width #\nn_layers = 4 # 4 # 5 # 5 # 8\n\n# Discretization\n\ns = 64 # 64 #32 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False # True # False  # True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'\n\n\n# Plotting\nindex = 62  # 24 # 62\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_CH3D_TNO3d.py b/configs/config_CH3D_TNO3d.py
++--- a/configs/config_CH3D_TNO3d.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/configs/config_CH3D_TNO3d.py	(date 1753601090927)
++@@ -6,24 +6,24 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
++-nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
++-batch_size = 20 # 50 # 3 # 20 # 50 # 5 # 50
+++nTrain = 1200 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+++nTest =  300 # 300 # 100 # 2000 # 4000 #300 # 300 #500
+++batch_size = 20 # 15 # 50 # 3 # 20 # 50 # 5 # 50
++ learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
++ weight_decay = 1e-4 # 1e-3 # 1e-4
++-epochs = 100 # 500 # 1000 # 25 # 100 # 1000
+++epochs = 50 # 50 # 50 # 100 # 500 # 1000 # 25 # 100 # 1000
++ iterations = epochs * (nTrain // batch_size)
++-modes = 14 # 10 #12 # 14 # 16 # 10 # 16
++-width = 12 # 8 #12 #14 # 12 # 16 # 32
+++modes = 14 # 14 # 12 # 14 # 10 #12 # 14 # 16 # 10 # 16
+++width = 12 # 12 # 8 #12 #14 # 12 # 16 # 32
++ width_q = width # 2 * width #
++ width_h = width//2 # width//4 # width #
++-n_layers = 4 # 4 # 5 # 5 # 8
+++n_layers = 3 # 4 # 5 # 5 # 8
++ 
++ # Discretization
++ 
++-s = 64 # 64 #32 # 64
+++s = 32 # 64 # 64 #32 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -33,16 +33,46 @@
++ # Database
++ parent_dir = './data/'
++ #matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
++-
++-
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_32.mat'
+++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++ # Plotting
++ index = 62  # 24 # 62
++-domain = [-np.pi, np.pi]
+++Lx = 2 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
+++#domain = [-np.pi, np.pi]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.05 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: PFC3D/.idea/PFC3D.iml
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/PFC3D/.idea/PFC3D.iml b/PFC3D/.idea/PFC3D.iml
++new file mode 100644
++--- /dev/null	(date 1753601090873)
+++++ b/PFC3D/.idea/PFC3D.iml	(date 1753601090873)
++@@ -0,0 +1,8 @@
+++<?xml version="1.0" encoding="UTF-8"?>
+++<module type="PYTHON_MODULE" version="4">
+++  <component name="NewModuleRootManager">
+++    <content url="file://$MODULE_DIR$" />
+++    <orderEntry type="inheritedJdk" />
+++    <orderEntry type="sourceFolder" forTests="false" />
+++  </component>
+++</module>
++\ No newline at end of file
++Index: utilities.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport numpy as np\nimport scipy.io\nimport h5py\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport os\n\nimport operator\nfrom functools import reduce\nfrom functools import partial\n\n#################################################\n#\n# Utilities\n#\n#################################################\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# reading data\nclass MatReader(object):\n    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n        super(MatReader, self).__init__()\n\n        self.to_torch = to_torch\n        self.to_cuda = to_cuda\n        self.to_float = to_float\n\n        self.file_path = file_path\n\n        self.data = None\n        self.old_mat = None\n        self._load_file()\n\n    def _load_file(self):\n        try:\n            self.data = scipy.io.loadmat(self.file_path)\n            self.old_mat = True\n        except:\n            self.data = h5py.File(self.file_path)\n            self.old_mat = False\n\n    def load_file(self, file_path):\n        self.file_path = file_path\n        self._load_file()\n\n    def read_field(self, field):\n        print(f\"Available keys in self.data: {list(self.data.keys())}\")\n        x = self.data[field]\n\n        if not self.old_mat:\n            x = x[()]\n            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n\n        if self.to_float:\n            x = x.astype(np.float32)\n\n        if self.to_torch:\n            x = torch.from_numpy(x)\n\n            if self.to_cuda:\n                x = x.cuda()\n\n        return x\n\n    def set_cuda(self, to_cuda):\n        self.to_cuda = to_cuda\n\n    def set_torch(self, to_torch):\n        self.to_torch = to_torch\n\n    def set_float(self, to_float):\n        self.to_float = to_float\n\n\n# normalization, pointwise gaussian\nclass UnitGaussianNormalizer(object):\n    def __init__(self, x, eps=0.00001, time_last=True):\n        super(UnitGaussianNormalizer, self).__init__()\n\n        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T in 1D\n        # x could be in shape of ntrain*w*l or ntrain*T*w*l or ntrain*w*l*T in 2D\n        self.mean = torch.mean(x, 0)\n        self.std = torch.std(x, 0)\n        self.eps = eps\n        self.time_last = time_last  # if the time dimension is the last dim\n\n    def encode(self, x):\n        x = (x - self.mean) / (self.std + self.eps)\n        return x\n\n    def decode(self, x, sample_idx=None):\n        # sample_idx is the spatial sampling mask\n        #print('x shape in decode: ', x.shape)\n        global std, mean\n        if sample_idx is None:\n            std = self.std + self.eps  # n\n            mean = self.mean\n            #print(\"x shape:\", x.shape)\n            #print(\"std shape:\", std.shape)\n            #print(\"mean shape:\", mean.shape)\n        else:\n            if self.mean.ndim == sample_idx.ndim or self.time_last:\n                std = self.std[sample_idx] + self.eps  # batch*n\n                mean = self.mean[sample_idx]\n            if self.mean.ndim > sample_idx.ndim and not self.time_last:\n                std = self.std[..., sample_idx] + self.eps  # T*batch*n\n                mean = self.mean[..., sample_idx]\n        # x is in shape of batch*(spatial discretization size) or T*batch*(spatial discretization size)\n\n        x = (x * std) + mean\n        return x\n\n    def to(self, device):\n        if torch.is_tensor(self.mean):\n            self.mean = self.mean.to(device)\n            self.std = self.std.to(device)\n        else:\n            self.mean = torch.from_numpy(self.mean).to(device)\n            self.std = torch.from_numpy(self.std).to(device)\n        return self\n\n    def cuda(self):\n        self.mean = self.mean.cuda()\n        self.std = self.std.cuda()\n\n    def cpu(self):\n        self.mean = self.mean.cpu()\n        self.std = self.std.cpu()\n\n\n# normalization, Gaussian\nclass GaussianNormalizer(object):\n    def __init__(self, x, eps=0.00001):\n        super(GaussianNormalizer, self).__init__()\n\n        self.mean = torch.mean(x)\n        self.std = torch.std(x)\n        self.eps = eps\n\n    def encode(self, x):\n        x = (x - self.mean) / (self.std + self.eps)\n        return x\n\n    def decode(self, x, sample_idx=None):\n        x = (x * (self.std + self.eps)) + self.mean\n        return x\n\n    def cuda(self):\n        self.mean = self.mean.cuda()\n        self.std = self.std.cuda()\n\n    def cpu(self):\n        self.mean = self.mean.cpu()\n        self.std = self.std.cpu()\n\n\n# normalization, scaling by range\nclass RangeNormalizer(object):\n    def __init__(self, x, low=0.0, high=1.0):\n        super(RangeNormalizer, self).__init__()\n        mymin = torch.min(x, 0)[0].view(-1)\n        mymax = torch.max(x, 0)[0].view(-1)\n\n        self.a = (high - low) / (mymax - mymin)\n        self.b = -self.a * mymax + high\n\n    def encode(self, x):\n        s = x.size()\n        x = x.view(s[0], -1)\n        x = self.a * x + self.b\n        x = x.view(s)\n        return x\n\n    def decode(self, x):\n        s = x.size()\n        x = x.view(s[0], -1)\n        x = (x - self.b) / self.a\n        x = x.view(s)\n        return x\n\n\n# loss function with rel/abs Lp loss\nclass LpLoss(object):\n    #def __init__(self, d=2, p=2, size_average=True, reduction=True):\n    #    super(LpLoss, self).__init__()\n    def __init__(self, d=2, p=2, l1_weight=0.0, size_average=True, reduction=True):\n        super(LpLoss, self).__init__()\n        assert d > 0 and p > 0\n\n\n        # Dimension and Lp-norm type are postive\n        assert d > 0 and p > 0\n\n        self.d = d\n        self.p = p\n        self.l1_weight = l1_weight  # Weight for the L1 compon\n        self.reduction = reduction\n        self.size_average = size_average\n\n    def abs(self, x, y):\n        num_examples = x.size()[0] # number of rows\n\n        # Assume uniform mesh\n        h = 1.0 / (x.size()[1] - 1.0)\n\n        all_norms = (h ** (self.d / self.p)) * torch.norm(x.view(num_examples, -1) - y.view(num_examples, -1), self.p,\n                                                          1)\n\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(all_norms)\n            else:\n                return torch.sum(all_norms)\n\n        return all_norms\n\n    def rel(self, x, y):\n        num_examples = x.size()[0]\n\n        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(diff_norms / y_norms)\n            else:\n                return torch.sum(diff_norms / y_norms)\n\n        return diff_norms / y_norms\n\n    #def __call__(self, x, y):\n    #    return self.rel(x, y)\n    # --- UPDATE THE __call__ METHOD ---\n    def __call__(self, x, y):\n        # Calculate the primary loss (e.g., L2)\n        primary_loss = self.rel(x, y)\n\n        # If an L1 weight is specified, calculate and add the L1 loss\n        if self.l1_weight > 0:\n            # Temporarily set p=1 to calculate L1 loss\n            original_p = self.p\n            self.p = 1\n            l1_loss = self.rel(x, y)\n            self.p = original_p  # Restore original p\n\n            # Return the weighted combination\n            return (1.0 - self.l1_weight) * primary_loss + self.l1_weight * l1_loss\n        else:\n            # If no L1 weight, return the primary loss as before\n            return primary_loss\n\n\n# Sobolev norm (HS norm)\n# where we also compare the numerical derivatives between the output and target\nclass HsLoss(object):\n    def __init__(self, d=2, p=2, k=1, a=None, group=False, size_average=True, reduction=True):\n        super(HsLoss, self).__init__()\n\n        # Dimension and Lp-norm type are postive\n        assert d > 0 and p > 0\n\n        self.d = d\n        self.p = p\n        self.k = k\n        self.balanced = group\n        self.reduction = reduction\n        self.size_average = size_average\n\n        if a == None:\n            a = [1, ] * k\n        self.a = a\n\n    def rel(self, x, y):\n        num_examples = x.size()[0]\n        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(diff_norms / y_norms)\n            else:\n                return torch.sum(diff_norms / y_norms)\n        return diff_norms / y_norms\n\n    def __call__(self, x, y, a=None):\n        nx = x.size()[1]\n        ny = x.size()[2]\n        k = self.k\n        balanced = self.balanced\n        a = self.a\n        x = x.view(x.shape[0], nx, ny, -1)\n        y = y.view(y.shape[0], nx, ny, -1)\n\n        k_x = torch.cat((torch.arange(start=0, end=nx // 2, step=1), torch.arange(start=-nx // 2, end=0, step=1)),\n                        0).reshape(nx, 1).repeat(1, ny)\n        k_y = torch.cat((torch.arange(start=0, end=ny // 2, step=1), torch.arange(start=-ny // 2, end=0, step=1)),\n                        0).reshape(1, ny).repeat(nx, 1)\n        k_x = torch.abs(k_x).reshape(1, nx, ny, 1).to(x.device)\n        k_y = torch.abs(k_y).reshape(1, nx, ny, 1).to(x.device)\n\n        x = torch.fft.fftn(x, dim=[1, 2])\n        y = torch.fft.fftn(y, dim=[1, 2])\n\n        if balanced == False:\n            weight = 1\n            if k >= 1:\n                weight += a[0] ** 2 * (k_x ** 2 + k_y ** 2)\n            if k >= 2:\n                weight += a[1] ** 2 * (k_x ** 4 + 2 * k_x ** 2 * k_y ** 2 + k_y ** 4)\n            weight = torch.sqrt(weight)\n            loss = self.rel(x * weight, y * weight)\n        else:\n            loss = self.rel(x, y)\n            if k >= 1:\n                weight = a[0] * torch.sqrt(k_x ** 2 + k_y ** 2)\n                loss += self.rel(x * weight, y * weight)\n            if k >= 2:\n                weight = a[1] * torch.sqrt(k_x ** 4 + 2 * k_x ** 2 * k_y ** 2 + k_y ** 4)\n                loss += self.rel(x * weight, y * weight)\n            loss = loss / (k + 1)\n\n        return loss\n\n\n# A simple feedforward neural network\nclass DenseNet(torch.nn.Module):\n    def __init__(self, layers, nonlinearity, out_nonlinearity=None, normalize=False):\n        super(DenseNet, self).__init__()\n\n        self.n_layers = len(layers) - 1\n\n        assert self.n_layers >= 1\n\n        self.layers = nn.ModuleList()\n\n        for j in range(self.n_layers):\n            self.layers.append(nn.Linear(layers[j], layers[j + 1]))\n\n            if j != self.n_layers - 1:\n                if normalize:\n                    self.layers.append(nn.BatchNorm1d(layers[j + 1]))\n\n                self.layers.append(nonlinearity())\n\n        if out_nonlinearity is not None:\n            self.layers.append(out_nonlinearity())\n\n    def forward(self, x):\n        for _, l in enumerate(self.layers):\n            x = l(x)\n\n        return x\n\n\n# print the number of parameters\ndef count_params(model):\n    c = 0\n    for p in list(model.parameters()):\n        c += reduce(operator.mul, list(p.size() + (2,) if p.is_complex() else p.size()))\n    return c\n\n\nclass ImportDataset(Dataset):\n    def __init__(self, parent_dir, matlab_dataset, normalized, T_in, T_out):\n        self.y = None # Stores target\n        self.x = None # Stores input\n        '''\n        The values for x and y are not yet available but will be assigned later (inside the set_data() method).\n        '''\n        self.T_in = T_in\n        self.T_out = T_out\n        self.normalized = normalized\n        self.normalizer_x = None\n        self.normalizer_y = None\n\n        matlab_dataset = parent_dir + matlab_dataset\n        python_dataset = matlab_dataset.replace('.mat', '.pt')\n        #python_dataset = matlab_dataset.replace('.npz', '.pt')\n        os.makedirs(parent_dir, exist_ok=True)\n\n        if os.path.exists(python_dataset):\n            print(\"Found saved dataset at\", python_dataset)\n            self.data = torch.load(python_dataset)['data']\n        else:\n            reader = MatReader(matlab_dataset)\n            self.data = reader.read_field('phi')\n            torch.save({'data': self.data}, python_dataset)\n        self.set_data()\n\n    def set_data(self):\n        permute_order = list(range(self.data.ndim))\n        permute_order.append(permute_order.pop(1))  # Move the second dimension to the end\n        self.x = self.data[:, 0:self.T_in, *[slice(None)] * (self.data.ndim - 3)].permute(*permute_order)\n        self.y = self.data[:, self.T_in:self.T_in + self.T_out, *[slice(None)] * (\n                self.data.ndim - 3)].permute(*permute_order)\n       # print(self.x.shape)\n       # print(self.y.shape)\n        if self.normalized:\n            self.make_normal()\n\n    def make_normal(self):\n        self.normalizer_x = UnitGaussianNormalizer(self.x)\n        self.normalizer_y = UnitGaussianNormalizer(self.y)\n        self.x = self.normalizer_x.encode(self.x)\n        self.y = self.normalizer_y.encode(self.y)\n\n    def __len__(self):\n        return self.x.shape[0]\n\n    def __getitem__(self, idx):\n        return self.x[idx], self.y[idx]\n\n\nclass ModelEvaluator:\n    def __init__(self, model, test_dataset, s, T_in, T_out, device, normalized=False, normalizers=None,\n                 time_history=False):\n        self.model = model\n        self.test_dataset = test_dataset\n        self.s = s\n        self.T_in = T_in\n        self.T_out = T_out\n        self.device = device\n        self.normalized = normalized\n        self.time_history = time_history\n        self.normalizer_x = normalizers[0].to(self.device)\n        self.normalizer_y = normalizers[1].to(self.device)\n        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n        spatial_dims = [s] * (len(test_dataset[0][0].shape) - 1)\n        self.inp = torch.zeros((len(test_dataset), *spatial_dims, T_in))\n        self.exact = torch.zeros((len(test_dataset), *spatial_dims, T_out))\n        self.pred = torch.zeros((len(test_dataset), *spatial_dims, T_out))\n        self.test_l2_set = []\n\n    def evaluate(self, loss_fn):\n        if self.time_history:\n            index = 0\n            step = 1\n            with torch.no_grad():\n                for xx, yy in self.test_loader:\n                    self.inp[index] = xx.squeeze(0)\n                    xx, yy = xx.to(self.device), yy.to(self.device)\n\n                    for t in range(0, self.T_out, step):\n                        y = yy[..., t:t + step]\n                        im = self.model(xx)\n                        # loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n                        if t == 0:\n                            pred = im\n                        else:\n                            pred = torch.cat((pred, im), -1)\n                        xx = torch.cat((xx[..., step:], im), dim=-1)\n\n                    self.exact[index] = yy.squeeze(0)\n                    self.pred[index] = pred.squeeze(0)\n                    test_l2 = loss_fn(pred.view(1, -1), yy.view(1, -1)).item()\n                    self.test_l2_set.append(test_l2)\n                    #print(index, test_l2)\n                    index += 1\n\n        else:\n            index = 0\n            with torch.no_grad():\n                for x, y in self.test_loader:\n                    x, y = x.to(self.device), y.to(self.device)\n                    out = self.model(x)\n                    if self.normalized:\n                        out = self.normalizer_y.decode(out)\n                        y = self.normalizer_y.decode(y)\n                        x = self.normalizer_x.decode(x)\n                    self.inp[index] = x.squeeze(0)\n                    self.exact[index] = y.squeeze(0)\n                    self.pred[index] = out.squeeze(0)\n                    test_l2 = loss_fn(out.view(1, -1), y.view(1, -1)).item()\n                    self.test_l2_set.append(test_l2)\n                    #print(index, test_l2)\n                    index += 1\n\n        return self._compute_statistics()\n\n    def _compute_statistics(self):\n        self.test_l2_set = torch.tensor(self.test_l2_set)\n        test_l2_avg = torch.mean(self.test_l2_set)\n        test_l2_std = torch.std(self.test_l2_set)\n        test_l2_min, min_idx = torch.min(self.test_l2_set), torch.argmin(self.test_l2_set)\n        test_l2_max, max_idx = torch.max(self.test_l2_set), torch.argmax(self.test_l2_set)\n        test_l2_mode, mode_count = torch.mode(self.test_l2_set)\n        mode_indices = torch.nonzero(self.test_l2_set == test_l2_mode).squeeze().tolist()\n\n        print(\"The average testing error is\", test_l2_avg.item())\n        print(\"Std. deviation of testing error is\", test_l2_std.item())\n        print(\"Min testing error is\", test_l2_min.item(), \"at index\", min_idx.item())\n        print(\"Max testing error is\", test_l2_max.item(), \"at index\", max_idx.item())\n        print(\"Mode of testing errors is\", test_l2_mode.item(), \"appearing\", mode_count.item(), \"times at indices\",\n              mode_indices)\n\n        return {\n            \"input\": self.inp,\n            \"exact\": self.exact,\n            \"prediction\": self.pred,\n            \"average\": test_l2_avg.item(),\n            \"std_dev\": test_l2_std.item(),\n            \"min\": {\"value\": test_l2_min.item(), \"index\": min_idx.item()},\n            \"max\": {\"value\": test_l2_max.item(), \"index\": max_idx.item()},\n            \"mode\": {\"value\": test_l2_mode.item(), \"count\": mode_count.item(), \"indices\": mode_indices}\n        }\n
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/utilities.py b/utilities.py
++--- a/utilities.py	(revision 92c48669419385e3d8d01a9ffd15fdb820bb1d1c)
+++++ b/utilities.py	(date 1753613859008)
++@@ -252,6 +252,81 @@
++             return primary_loss
++ 
++ 
+++# Add this code to your utilities.py file
+++
+++import torch
+++import torch.nn.functional as F
+++
+++
+++# --- NEW SOBOLEV LOSS CLASS ---
+++class SobolevLoss(object):
+++    def __init__(self, d=3, p=2, grad_weight=0.1, size_average=False, reduction=True):
+++        super(SobolevLoss, self).__init__()
+++        # Ensure dimension and p-norm are valid
+++        assert d > 0 and p > 0
+++
+++        self.d = d
+++        self.p = p
+++        self.reduction = reduction
+++        self.size_average = size_average
+++        self.grad_weight = grad_weight  # Weight for the gradient loss component
+++
+++    def _compute_gradients(self, x):
+++        """
+++        Computes spatial gradients using a 3D Sobel filter.
+++        Assumes input x has shape (batch, sx, sy, sz, t)
+++        """
+++        # We need to operate on each time step independently
+++        # and on data with shape (B, C, D, H, W) for conv3d
+++
+++        # Permute to (batch, t, sx, sy, sz)
+++        x_permuted = x.permute(0, 4, 1, 2, 3)
+++        batch_size, T, sx, sy, sz = x_permuted.shape
+++
+++        # Reshape to treat time steps as part of the batch for convolution
+++        x_reshaped = x_permuted.reshape(batch_size * T, 1, sx, sy, sz)
+++
+++        # 3D Sobel filters
+++        sobel_x = torch.tensor([[[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]],
+++                                 [[-2, 0, 2], [-4, 0, 4], [-2, 0, 2]],
+++                                 [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]]],
+++                               dtype=torch.float32, device=x.device).unsqueeze(0)
+++        sobel_y = sobel_x.permute(0, 1, 3, 2, 4)
+++        sobel_z = sobel_x.permute(0, 1, 4, 3, 2)
+++
+++        grad_x = F.conv3d(x_reshaped, sobel_x, padding='same')
+++        grad_y = F.conv3d(x_reshaped, sobel_y, padding='same')
+++        grad_z = F.conv3d(x_reshaped, sobel_z, padding='same')
+++
+++        # Reshape back to (batch, t, sx, sy, sz, 3_grads)
+++        grads = torch.stack([grad_x, grad_y, grad_z], dim=-1)
+++        return grads.reshape(batch_size, T, sx, sy, sz, 3)
+++
+++    def __call__(self, x, y):
+++        """
+++        x: prediction, y: ground truth
+++        Assumes x and y have shape (batch, sx, sy, sz, T)
+++        """
+++        num_examples = x.size(0)
+++
+++        # 1. Standard L2 Data Loss (relative)
+++        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)
+++        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)
+++        data_loss = torch.mean(diff_norms / y_norms)
+++
+++        # 2. Gradient Loss
+++        if self.grad_weight > 0:
+++            pred_grads = self._compute_gradients(x)
+++            true_grads = self._compute_gradients(y)
+++            grad_loss = F.mse_loss(pred_grads, true_grads)
+++
+++            # Combine losses
+++            total_loss = data_loss + self.grad_weight * grad_loss
+++        else:
+++            total_loss = data_loss
+++
+++        return total_loss
+++
++ # Sobolev norm (HS norm)
++ # where we also compare the numerical derivatives between the output and target
++ class HsLoss(object):
++@@ -371,7 +446,7 @@
++         self.T_in = T_in
++         self.T_out = T_out
++         self.normalized = normalized
++-        self.normalizer_x = None
+++        self.normalizer_x =  None
++         self.normalizer_y = None
++ 
++         matlab_dataset = parent_dir + matlab_dataset
++@@ -432,6 +507,7 @@
++         self.pred = torch.zeros((len(test_dataset), *spatial_dims, T_out))
++         self.test_l2_set = []
++ 
+++    '''''
++     def evaluate(self, loss_fn):
++         if self.time_history:
++             index = 0
++@@ -477,7 +553,58 @@
++                     index += 1
++ 
++         return self._compute_statistics()
++-
+++    '''
+++
+++    # Replace the evaluate method in your ModelEvaluator class with this one.
+++
+++    def evaluate(self, loss_fn):
+++        if self.time_history:
+++            index = 0
+++            step = 1
+++            with torch.no_grad():
+++                for xx, yy in self.test_loader:
+++                    self.inp[index] = xx.squeeze(0)
+++                    xx, yy = xx.to(self.device), yy.to(self.device)
+++
+++                    for t in range(0, self.T_out, step):
+++                        y = yy[..., t:t + step]
+++                        im = self.model(xx)
+++                        if t == 0:
+++                            pred = im
+++                        else:
+++                            pred = torch.cat((pred, im), -1)
+++                        xx = torch.cat((xx[..., step:], im), dim=-1)
+++
+++                    self.exact[index] = yy.squeeze(0)
+++                    self.pred[index] = pred.squeeze(0)
+++
+++                    # --- CORRECTED LINE ---
+++                    # Pass the un-flattened tensors directly to the loss function
+++                    test_l2 = loss_fn(pred, yy).item()
+++                    self.test_l2_set.append(test_l2)
+++                    index += 1
+++
+++        else:
+++            index = 0
+++            with torch.no_grad():
+++                for x, y in self.test_loader:
+++                    x, y = x.to(self.device), y.to(self.device)
+++                    out = self.model(x)
+++                    if self.normalized:
+++                        out = self.normalizer_y.decode(out)
+++                        y = self.normalizer_y.decode(y)
+++                        x = self.normalizer_x.decode(x)
+++                    self.inp[index] = x.squeeze(0)
+++                    self.exact[index] = y.squeeze(0)
+++                    self.pred[index] = out.squeeze(0)
+++
+++                    # --- CORRECTED LINE ---
+++                    # Pass the un-flattened tensors directly to the loss function
+++                    test_l2 = loss_fn(out, y).item()
+++                    self.test_l2_set.append(test_l2)
+++                    index += 1
+++
+++        return self._compute_statistics()
++     def _compute_statistics(self):
++         self.test_l2_set = torch.tensor(self.test_l2_set)
++         test_l2_avg = torch.mean(self.test_l2_set)
++Index: configs/config_MBE3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_MBE3D_FNO4d.py b/configs/config_MBE3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1753616777030)
+++++ b/configs/config_MBE3D_FNO4d.py	(date 1753616777030)
++@@ -0,0 +1,75 @@
+++
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda:1'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1200 #1600 # 4000
+++nTest = 300  # 400
+++batch_size = 50 # 10 # 20 # 50# 25 #100
+++learning_rate = 0.001
+++weight_decay = 1e-4
+++epochs = 30 # 50 # 1000
+++iterations = epochs * (nTrain // batch_size)
+++modes = 14 # 12
+++width = 12 #32
+++width_q = width #32
+++width_h = width // 2 # width # 32
+++n_layers = 2 # 4
+++
+++# Discretization
+++s = 32
+++T_in = 1
+++T_out = 91 #20 #91 # 20 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True  # True  # True
+++load_model = False #True  # False  # False
+++
+++# Database
+++parent_dir = './data/'
+++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat'
+++
+++# Plotting
+++# Plotting
+++index = 62  # 72
+++#domain = [-np.pi, np.pi]
+++Lx = 10 # np.pi            # Domain size from MATLAB
+++domain = [-Lx/2, Lx/2]
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 59, 79]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
+Index: PFC3D/.idea/.gitignore
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/PFC3D/.idea/.gitignore b/PFC3D/.idea/.gitignore
+new file mode 100644
+--- /dev/null	(date 1752127417633)
++++ b/PFC3D/.idea/.gitignore	(date 1752127417633)
+@@ -0,0 +1,8 @@
++# Default ignored files
++/shelf/
++/workspace.xml
++# Editor-based HTTP Client requests
++/httpRequests/
++# Datasource local storage ignored files
++/dataSources/
++/dataSources.local.xml
+Index: PFC3D/.idea/vcs.xml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/PFC3D/.idea/vcs.xml b/PFC3D/.idea/vcs.xml
+new file mode 100644
+--- /dev/null	(date 1752127452608)
++++ b/PFC3D/.idea/vcs.xml	(date 1752127452608)
+@@ -0,0 +1,6 @@
++<?xml version="1.0" encoding="UTF-8"?>
++<project version="4">
++  <component name="VcsDirectoryMappings">
++    <mapping directory="$PROJECT_DIR$/.." vcs="Git" />
++  </component>
++</project>
+\ No newline at end of file
+Index: configs/config_MBE3D_FNO3d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>\nimport numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 #1600 # 4000\nnTest = 300  # 400\nbatch_size = 50# 25 #100\nlearning_rate = 0.005\nweight_decay = 1e-4\nepochs = 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 12\nwidth = 12 #32\nwidth_q = width #32\nwidth_h = width // 2 # width # 32\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # True  # True\nload_model = False #True  # False  # False\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'\nmatlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 9  # 72\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_MBE3D_FNO3d.py b/configs/config_MBE3D_FNO3d.py
+--- a/configs/config_MBE3D_FNO3d.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/configs/config_MBE3D_FNO3d.py	(date 1754547784024)
+@@ -9,21 +9,21 @@
+ # Network Parameters
+ nTrain = 1200 #1600 # 4000
+ nTest = 300  # 400
+-batch_size = 50# 25 #100
+-learning_rate = 0.005
++batch_size = 10 # 20 # 50# 25 #100
++learning_rate = 0.001
+ weight_decay = 1e-4
+-epochs = 50 # 1000
++epochs = 50 # 50 # 1000
+ iterations = epochs * (nTrain // batch_size)
+ modes = 14 # 12
+ width = 12 #32
+ width_q = width #32
+ width_h = width // 2 # width # 32
+-n_layers = 4
++n_layers = 2 # 4
+ 
+ # Discretization
+ s = 32
+ T_in = 1
+-T_out = 20 # 100
++T_out = 91 # 20 # 100
+ 
+ # Training Setting
+ normalized = True
+@@ -32,14 +32,44 @@
+ 
+ # Database
+ parent_dir = './data/'
+-#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'
+-matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'
++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat'
++
++# Plotting
+ # Plotting
+-index = 9  # 72
+-domain = [-np.pi, np.pi]
++index = 62  # 72
++#domain = [-np.pi, np.pi]
++Lx = 10 # np.pi            # Domain size from MATLAB
++domain = [-Lx/2, Lx/2]
+ # time_steps = [29, 35, 39, 45, 49]
+ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+ #time_steps = [39, 59, 79]
+-time_steps = [0, 9, 19]
+\ No newline at end of file
++#time_steps = [39, 59, 79]
++time_steps = [0, 50, 90]
++
++
++#############
++
++# Time Discretization Parameters (from AC3D MATLAB)
++dt_sim = 0.1     # Time step in the MATLAB simulation
++Nt_sim = 50        # Total number of simulation steps in MATLAB
++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
++# PDE Parameters for Allen-Cahn (AC3D)
++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
++# The PDE implemented in calculate_pde_residual was:
++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++epsilon = 0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++# PINN Specific Settings (if PINN_MODE is True in main.py)
++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++
++pde_loss_scaler = 1e-6
+\ No newline at end of file
+Index: configs/config_AC3D_FNO3d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1000 # 900 # 1000\nnTest = 300 # 100 # 100\nbatch_size = 50 # 20 #5 # 25\nlearning_rate = 0.001\nweight_decay = 1e-4\nepochs = 50 # 100 # 900  # 100\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 8 # last time modes =  8\nwidth =  12 # 32 # last time width =  32\nwidth_q = width\nwidth_h = width // 2 # width // 4 # last time\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # False\nload_model = False # True  # True\n\n# Database\nparent_dir = './data/'\n# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'\n#matlab_dataset = 'AC3D_32_1000.mat'\nmatlab_dataset = 'AC3D_32_1300.mat'\n# Plotting\nindex = 9 # 12\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 69]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]\n\n#############\nLx = np.pi            # Domain size from MATLAB\n# Time Discretization Parameters (from AC3D MATLAB)\ndt_sim = 0.0001     # Time step in the MATLAB simulation\nNt_sim = 50        # Total number of simulation steps in MATLAB\nnum_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)\n# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps\n# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output\n# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.\ndt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in\n# PDE Parameters for Allen-Cahn (AC3D)\n# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.\n# The PDE implemented in calculate_pde_residual was:\n# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)\nepsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter\n# PINN Specific Settings (if PINN_MODE is True in main.py)\npde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.\n# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\n\npde_loss_scaler = 1e-5
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_AC3D_FNO3d.py b/configs/config_AC3D_FNO3d.py
+--- a/configs/config_AC3D_FNO3d.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/configs/config_AC3D_FNO3d.py	(date 1754547784048)
+@@ -8,21 +8,21 @@
+ # Network Parameters
+ nTrain = 1000 # 900 # 1000
+ nTest = 300 # 100 # 100
+-batch_size = 50 # 20 #5 # 25
++batch_size = 10 # 50 # 20 #5 # 25
+ learning_rate = 0.001
+ weight_decay = 1e-4
+-epochs = 50 # 100 # 900  # 100
++epochs = 20 # 50 # 100 # 900  # 100
+ iterations = epochs * (nTrain // batch_size)
+ modes =  14 # 8 # last time modes =  8
+ width =  12 # 32 # last time width =  32
+ width_q = width
+ width_h = width // 2 # width // 4 # last time
+-n_layers = 4
++n_layers = 2 # 4
+ 
+ # Discretization
+ s = 32
+ T_in = 1
+-T_out = 20 # 100
++T_out = 91 # 100
+ 
+ # Training Setting
+ normalized = True
+@@ -33,19 +33,25 @@
+ parent_dir = './data/'
+ # matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
+ #matlab_dataset = 'AC3D_32_1000.mat'
+-matlab_dataset = 'AC3D_32_1300.mat'
++#matlab_dataset = 'AC3D_32_1300.mat'
++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
+ # Plotting
+ index = 9 # 12
+-domain = [-np.pi, np.pi]
++#domain = [-np.pi, np.pi]
++Lx = 5 # np.pi            # Domain size from MATLAB
++#domain = [-np.pi, np.pi]
++domain = [-Lx/2, Lx/2]
++
++
+ # time_steps = [29, 69]
+ #time_steps = [39, 49, 59, 69, 79, 89, 99]
+ # time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+ #               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+ #time_steps = [39, 59, 79]
+-time_steps = [0, 9, 19]
++time_steps = [0, 50, 90]
+ 
+ #############
+-Lx = np.pi            # Domain size from MATLAB
++#Lx = np.pi            # Domain size from MATLAB
+ # Time Discretization Parameters (from AC3D MATLAB)
+ dt_sim = 0.0001     # Time step in the MATLAB simulation
+ Nt_sim = 50        # Total number of simulation steps in MATLAB
+Index: configs/config_PFC3D_FNO4d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_PFC3D_FNO4d.py b/configs/config_PFC3D_FNO4d.py
+new file mode 100644
+--- /dev/null	(date 1754547784229)
++++ b/configs/config_PFC3D_FNO4d.py	(date 1754547784229)
+@@ -0,0 +1,81 @@
++import numpy as np
++
++# General SettingnTrain = 1200 # 5250 # 7500
++
++gpu_number = 'cuda:1'  # 'cuda:1'
++torch_seed = 0
++numpy_seed = 0
++
++# Network Parameters
++nTrain = 1200
++nTest = 300
++batch_size = 20 # 15 # 100
++learning_rate = 0.001
++weight_decay = 1e-4 # 1e-4
++epochs = 30 # 50
++iterations = epochs * (nTrain // batch_size)
++modes = 14 #12
++width = 12 # 16 # 32
++width_q = width # 32
++width_h = width//2 # 16
++n_layers = 2 # 4
++
++'''
++tau = 315;
++alpha = 115; 
++'''
++
++# Discretization
++s = 32 # 64 # 64
++T_in = 1
++T_out = 91 # 20 # 100
++
++# Training Setting
++normalized = True
++training = True # False  # True
++load_model = False # True # False # True  # False
++
++# Database
++parent_dir = './data/'
++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
++# Plotting
++
++# Plotting
++index = 69  # 110  # 200
++Lx = 10*np.pi
++domain = [-5*np.pi, 5*np.pi]
++# time_steps = [29, 35, 39, 45, 49]
++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++# time_steps = [0, 2, 4, 6, 8, 9]
++#time_steps = [39, 59, 79]
++time_steps = [0, 50, 90]
++
++
++
++#############
++
++# Time Discretization Parameters (from AC3D MATLAB)
++dt_sim = 0.05 # 0.1     # Time step in the MATLAB simulation
++Nt_sim = 50        # Total number of simulation steps in MATLAB
++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
++# PDE Parameters for Allen-Cahn (AC3D)
++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
++# The PDE implemented in calculate_pde_residual was:
++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++# PINN Specific Settings (if PINN_MODE is True in main.py)
++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++
++pde_loss_scaler = 1e-6
+\ No newline at end of file
+Index: configs/config_SH3D_FNO4d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_SH3D_FNO4d.py b/configs/config_SH3D_FNO4d.py
+new file mode 100644
+--- /dev/null	(date 1754558969371)
++++ b/configs/config_SH3D_FNO4d.py	(date 1754558969371)
+@@ -0,0 +1,80 @@
++import numpy as np
++
++# General Setting
++gpu_number = 'cuda:2'  # 'cuda:1'
++torch_seed = 0
++numpy_seed = 0
++
++# Network Parameters
++nTrain = 1200 # 5250 # 7500
++nTest = 300 # 2250 #500
++batch_size = 20 # 10 # 50 # 50
++learning_rate = 0.001 # 0.005 # 0.001
++weight_decay = 1e-4 # 1e-4
++epochs = 30 # 1000
++iterations = epochs * (nTrain // batch_size)
++modes =  14 # 16
++width =  12 #32
++width_q =   width # width # 2 * width #
++width_h = width//2  # width//4 # width #
++n_layers = 2 # 8
++
++# Discretization
++s = 32 # 32 # 64
++T_in = 1
++T_out = 100 # 91 # 100 # 100
++
++# Training Setting
++normalized = True # False #True
++training = True # False  # True
++load_model = False # False #True
++
++# Database
++parent_dir = './data/'
++#matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'
++#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
++# Plotting
++
++# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
++Lx = 15 # 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
++Ly =Lx
++Lz= Lx
++
++index = 62  # 24 # 62
++#domain = [-np.pi, np.pi]  ######
++domain = [-Lx/2, Lx/2]
++
++# time_steps = [29, 35, 39, 45, 49]
++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++#time_steps = [39, 49, 59, 69, 79, 89, 99]
++#time_steps = [39, 59, 79]
++time_steps = [0, 50, 90]
++
++
++### Hybrid method
++
++# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
++#Lx = np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
++# domain = [-Lx/2, Lx/2] # Assuming centered domain
++
++# Time Discretization (from MATLAB)
++dt_sim = 0.0002 # Simulation time step
++Nt = 100 # Total simulation steps
++num_saved_steps = 101 # Number of saved steps (includes t=0)
++ns = Nt / (num_saved_steps - 1) # Interval between saved steps
++dt_model = ns * dt_sim # Effective time step between model outputs
++
++# PDE Parameters
++epsilon = 0.15
++#pde_weight = 0.3 # Example: 30% physics loss
++pde_weight = 0.0 # Example: 70% physics loss
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++pde_loss_scaler = 1e-0
++###########################
++# ... rest of config ...
+\ No newline at end of file
+Index: configs/config_MBE3D_TNO3d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>\nimport numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 #1600 # 4000\nnTest = 300  # 400\nbatch_size = 50# 25 #100\nlearning_rate = 0.005\nweight_decay = 1e-4\nepochs = 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 12\nwidth = 12 #32\nwidth_q = width #32\nwidth_h = width // 2 # width # 32\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # True  # True\nload_model = False #True  # False  # False\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'\nmatlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 9  # 72\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_MBE3D_TNO3d.py b/configs/config_MBE3D_TNO3d.py
+--- a/configs/config_MBE3D_TNO3d.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/configs/config_MBE3D_TNO3d.py	(date 1754547784060)
+@@ -7,23 +7,23 @@
+ numpy_seed = 0
+ 
+ # Network Parameters
+-nTrain = 1200 #1600 # 4000
++nTrain = 1300 #1600 # 4000
+ nTest = 300  # 400
+-batch_size = 50# 25 #100
+-learning_rate = 0.005
++batch_size = 20 # 50# 25 #100
++learning_rate = 0.001
+ weight_decay = 1e-4
+-epochs = 50 # 1000
++epochs =  50 # 25# 50 # 20 # 50 # 1000
+ iterations = epochs * (nTrain // batch_size)
+-modes = 14 # 12
+-width = 12 #32
++modes = 14 # 14 # 12
++width = 12 # 12 #32
+ width_q = width #32
+ width_h = width // 2 # width # 32
+-n_layers = 4
++n_layers = 2 # 4 # 3 # 2 # 4
+ 
+ # Discretization
+ s = 32
+ T_in = 1
+-T_out = 20 # 100
++T_out = 100 # 20 # 100
+ 
+ # Training Setting
+ normalized = True
+@@ -32,14 +32,45 @@
+ 
+ # Database
+ parent_dir = './data/'
+-#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'
+-matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'
++
++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat' # I got the result based on this Dataset!! epochs = 50 !! n_layers = 2 pde_loss_scaler = 1e-4 # 1e-3
++#matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat' # not valid
++
+ # Plotting
+-index = 9  # 72
+-domain = [-np.pi, np.pi]
++index = 62  # 72
++#domain = [-np.pi, np.pi]
++Lx = 2* np.pi  # 6 # 2* np.pi            # Domain size from MATLAB
++domain = [-Lx/2, Lx/2]
+ # time_steps = [29, 35, 39, 45, 49]
+ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+ #time_steps = [39, 59, 79]
+-time_steps = [0, 9, 19]
+\ No newline at end of file
++time_steps = [0, 50, 90]
++
++
++
++#############
++
++# Time Discretization Parameters (from AC3D MATLAB)
++dt_sim = 0.001 # 0.1     # Time step in the MATLAB simulation
++Nt_sim = 50        # Total number of simulation steps in MATLAB
++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
++# PDE Parameters for Allen-Cahn (AC3D)
++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
++# The PDE implemented in calculate_pde_residual was:
++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++epsilon =  0.1 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++# PINN Specific Settings (if PINN_MODE is True in main.py)
++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++
++pde_loss_scaler = 1e-4 # 1e-3
+\ No newline at end of file
+Index: configs/config_AC3D_FNO4d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_AC3D_FNO4d.py b/configs/config_AC3D_FNO4d.py
+new file mode 100644
+--- /dev/null	(date 1754547784250)
++++ b/configs/config_AC3D_FNO4d.py	(date 1754547784250)
+@@ -0,0 +1,76 @@
++import numpy as np
++
++# General Setting
++gpu_number = 'cuda'
++torch_seed = 0
++numpy_seed = 0
++
++# Network Parameters
++nTrain = 1000 # 900 # 1000
++nTest = 300 # 100 # 100
++batch_size = 20 # 10 # 50 # 20 #5 # 25
++learning_rate = 0.001
++weight_decay = 1e-4
++epochs = 20 # 50 # 100 # 900  # 100
++iterations = epochs * (nTrain // batch_size)
++modes =  14 # 8 # last time modes =  8
++width =  12 # 32 # last time width =  32
++width_q = width
++width_h = width // 2 # width // 4 # last time
++n_layers = 2 # 4
++
++# Discretization
++s = 32
++T_in = 1
++T_out = 91 # 100
++
++# Training Setting
++normalized = True
++training = True # False  # False
++load_model = False # True  # True
++
++# Database
++parent_dir = './data/'
++# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
++#matlab_dataset = 'AC3D_32_1000.mat'
++#matlab_dataset = 'AC3D_32_1300.mat'
++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
++# Plotting
++index = 9 # 12
++#domain = [-np.pi, np.pi]
++Lx = 5 # np.pi            # Domain size from MATLAB
++#domain = [-np.pi, np.pi]
++domain = [-Lx/2, Lx/2]
++
++
++# time_steps = [29, 69]
++#time_steps = [39, 49, 59, 69, 79, 89, 99]
++# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++#time_steps = [39, 59, 79]
++time_steps = [0, 50, 90]
++
++#############
++#Lx = np.pi            # Domain size from MATLAB
++# Time Discretization Parameters (from AC3D MATLAB)
++dt_sim = 0.0001     # Time step in the MATLAB simulation
++Nt_sim = 50        # Total number of simulation steps in MATLAB
++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
++# PDE Parameters for Allen-Cahn (AC3D)
++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
++# The PDE implemented in calculate_pde_residual was:
++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++epsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++# PINN Specific Settings (if PINN_MODE is True in main.py)
++pde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.
++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++
++pde_loss_scaler = 1e-5
+\ No newline at end of file
+Index: .idea/shelf/Uncommitted_changes_before_Update_at_8_1_25__3_40_PM__Changes_.xml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25__3_40_PM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25__3_40_PM__Changes_.xml
+new file mode 100644
+--- /dev/null	(date 1754578056875)
++++ b/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25__3_40_PM__Changes_.xml	(date 1754578056875)
+@@ -0,0 +1,119 @@
++<changelist name="Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]" date="1754055607637" recycled="true" deleted="true">
++  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/shelved.patch" />
++  <option name="DESCRIPTION" value="Uncommitted changes before Update at 8/1/25, 3:40 PM [Changes]" />
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_loss_curve_mixed.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" />
++    <option name="AFTER_PATH" value="SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" />
++    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/SH3D_Hybrid_field_comparison.png" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/CH3D_Comparison_star_SANO.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/combined_results.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_loss_curve_mixed.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" />
++    <option name="AFTER_PATH" value="MBE3D/plots_Data_Physics_TNO3d/MBE3D_Hybrid.jpg" />
++    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/MBE3D_Hybrid.jpg" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MBE3D/plots_FNO3d/3d_phase_evolution.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MBE3D/plots_TNO3d/3d_phase_evolution.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_loss_curve.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/SH3D_SANO_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison_FINAL.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/combined_results.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MBE3D/plots_FNO3d/combined_results.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison_mixed.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" />
++    <option name="AFTER_PATH" value="SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" />
++    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/SH3D_FNO_field_comparison.png" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/3d_phase_evolution.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++</changelist>
+\ No newline at end of file
+Index: .idea/shelf/Uncommitted_changes_before_Update_at_8_6_25__12_21_PM__Changes_.xml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25__12_21_PM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25__12_21_PM__Changes_.xml
+new file mode 100644
+--- /dev/null	(date 1754578056897)
++++ b/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25__12_21_PM__Changes_.xml	(date 1754578056897)
+@@ -0,0 +1,264 @@
++<changelist name="Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]" date="1754475721651" recycled="true" deleted="true">
++  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/shelved.patch" />
++  <option name="DESCRIPTION" value="Uncommitted changes before Update at 8/6/25, 12:21 PM [Changes]" />
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/AC3D_rand_new.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/MBE2D.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/SH3D_Comparison_Plot_Modified.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/AC3D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/AC2D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/AC3D_rand_new.asv" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/combined_results.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/AC2D_4circle.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/SH2D.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" />
++    <option name="AFTER_PATH" value="MBE3D/plots_Data_Physics_TNO3d/MBE3D_Hybrid.jpg" />
++    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/MBE3D_Hybrid.jpg" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/MBE3D_rand.asv" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_loss_curve.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison_FINAL.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/combined_results.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison_mixed.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" />
++    <option name="AFTER_PATH" value="SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" />
++    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/SH3D_FNO_field_comparison.png" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH3D_random_new.asv" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/middle.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/PFC3D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/GRF.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/3d_phase_evolution.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/MBE3D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/PFC2D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH2DNL_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_loss_curve_mixed.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" />
++    <option name="AFTER_PATH" value="SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" />
++    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/SH3D_Hybrid_field_comparison.png" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/PFC2D.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/SH3D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/SH2D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH3D_test.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/CH3D_Comparison_star_SANO.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/MBE2D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_loss_curve_mixed.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH3D_random_new.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MBE3D/plots_FNO3d/3d_phase_evolution.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MBE3D/plots_TNO3d/3d_phase_evolution.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/GRF3D.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/SH3D_SANO_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MBE3D/plots_FNO3d/combined_results.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH3D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH2DNL.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/GRFtest.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH2D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH2D.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/AC2D.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++</changelist>
+\ No newline at end of file
+Index: .idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/shelved.patch
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/shelved.patch
+new file mode 100644
+--- /dev/null	(date 1754547781901)
++++ b/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/shelved.patch	(date 1754547781901)
+@@ -0,0 +1,8074 @@
++Index: run_interface3.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport numpy as np\nimport importlib\nfrom utilities import ImportDataset\nimport matplotlib\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom skimage import measure\nfrom matplotlib.colors import LightSource\n\n# Load model\ndevice = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n\n#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6.pt'\n\nmodel_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'\n\n# Option 1 (Recommended secure approach)\ntry:\n    from networks import TNO3d  # Import your custom network class\n    torch.serialization.add_safe_globals([TNO3d])\n    checkpoint = torch.load(model_path, map_location=device, weights_only=True)\nexcept Exception as e:\n    print(f\"Secure loading failed: {e}\\nFalling back to weights_only=False\")\n    # Option 2 (Less secure fallback)\n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n\nmodel = checkpoint['model']\nmodel.eval()\n\n# Load dataset for normalization\nproblem = 'SH3D'\nnetwork_name = 'TNO3d'\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\")\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\n# Move normalizer parameters to device\ndataset.normalizer_x.mean = dataset.normalizer_x.mean.to(device)\ndataset.normalizer_x.std = dataset.normalizer_x.std.to(device)\ndataset.normalizer_y.mean = dataset.normalizer_y.mean.to(device)\ndataset.normalizer_y.std = dataset.normalizer_y.std.to(device)\n\n\n# Create spherical initial condition\ndef create_sharp_sphere_initial_condition(N=32, radius=2, L=10):\n    x = np.linspace(-L / 2, L / 2, N)\n    y = np.linspace(-L / 2, L / 2, N)\n    z = np.linspace(-L / 2, L / 2, N)\n    xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')\n\n    r = np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)\n    sphere = np.ones((N, N, N), dtype=np.float32)  # Use float32 for consistency\n\n    # Perfectly sharp transition (no smoothing)\n    outer_mask = r > radius\n    sphere[outer_mask] = -1.0\n\n    # Force exact values (no floating point artifacts)\n    sphere = np.where(r <= radius, 1.0, -1.0)\n\n    return sphere\n# Create initial condition with perfect sharp interface\nsphere_ic = create_sharp_sphere_initial_condition()\n\ninput_tensor = torch.from_numpy(sphere_ic).float().unsqueeze(0).unsqueeze(-1).to(device)\ninput_tensor = dataset.normalizer_x.encode(input_tensor)\n\n# Run prediction\nwith torch.no_grad():\n    prediction = model(input_tensor)  # Shape [1, 32, 32, 32, 10]\n    prediction = dataset.normalizer_y.decode(prediction)\n\n# Define your custom frames to display\nselected_frames = [0, 50, 90]  # Adjusted for T_out=10\nnum_frames = len(selected_frames)\n\n# Create figure with two subplots: 3D views and 1D profile\nfig = plt.figure(figsize=(20, 10))\ngrid = plt.GridSpec(2, num_frames, hspace=0.3, wspace=0.2)\n\n# 1. Plot 3D isosurfaces for selected frames\nfor i, t in enumerate(selected_frames):\n    ax = fig.add_subplot(grid[0, i], projection='3d')\n    frame_data = prediction[0, ..., t].cpu().numpy()\n\n    # Print data range for debugging\n    print(f\"Frame {t}: min={np.min(frame_data):.3f}, max={np.max(frame_data):.3f}\")\n\n    # Determine appropriate level\n    data_min, data_max = np.min(frame_data), np.max(frame_data)\n    if data_min > 0 or data_max < 0:\n        level = (data_max + data_min) / 2  # Midpoint if zero is outside range\n    else:\n        level = 0.0  # Default level\n\n    try:\n        # Extract smooth isosurface with adjusted level\n        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level)\n\n        # Apply lighting and coloring\n        ls = LightSource(azdeg=135, altdeg=45)\n        rgb = ls.shade_normals(verts[faces], fraction=0.8)\n\n        mesh = Poly3DCollection(verts[faces],\n                                facecolors=rgb,\n                                edgecolor='none',\n                                alpha=0.9)\n\n        ax.add_collection3d(mesh)\n        plot_success = True\n    except ValueError as e:\n        print(f\"Could not generate isosurface for frame {t}: {e}\")\n        plot_success = False\n        # Display empty plot with error message\n        ax.text(0.5, 0.5, 0.5, f\"No isosurface\\nat level={level:.2f}\",\n                ha='center', va='center', fontsize=10)\n\n    # Set viewing parameters\n    ax.set_xlim(0, frame_data.shape[0])\n    ax.set_ylim(0, frame_data.shape[1])\n    ax.set_zlim(0, frame_data.shape[2])\n    ax.set_title(f'Time = {t}\\nLevel = {level:.2f}', pad=10)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_zticks([])\n    if plot_success:\n        ax.view_init(elev=30, azim=45)\n\n# 2. Plot 1D profile through center for all time steps\nax_profile = fig.add_subplot(grid[1, :])\nL = 10  # Domain size\nx = np.linspace(-L / 2, L / 2, prediction.shape[1])\ncenter_idx = prediction.shape[1] // 2  # Middle of the domain\n\n# Plot profiles for the same custom frames in the profile plot\nfor t in selected_frames:\n    profile = prediction[0, :, center_idx, center_idx, t].cpu().numpy()\n    ax_profile.plot(x, profile, label=f't={t}', alpha=0.8, linewidth=1.5)\n\n# Format profile plot\nax_profile.set_xlabel('Position along x-axis', fontsize=12)\nax_profile.set_ylabel('Field value', fontsize=12)\nax_profile.set_title('1D Profile Evolution Through Domain Center', pad=15)\nax_profile.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nax_profile.grid(True, alpha=0.3)\nax_profile.set_ylim([-1.2, 1.5])  # Match MATLAB y-limits\n\nplt.tight_layout()\nplt.show()\n\n# After getting predictions in Python\nprediction_np = prediction.cpu().numpy()  # Convert to numpy array\n\n# Save to .mat file\nfrom scipy.io import savemat\nsavemat('SH3D_python_predictions.mat', {\n    'python_pred': prediction_np,\n    'selected_frames': np.array(selected_frames),\n    'x': x  # Spatial coordinates\n})
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/run_interface3.py b/run_interface3.py
++--- a/run_interface3.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/run_interface3.py	(date 1754546519894)
++@@ -3,125 +3,375 @@
++ import importlib
++ from utilities import ImportDataset
++ import matplotlib
+++
++ matplotlib.use('TkAgg')
++ import matplotlib.pyplot as plt
++ from mpl_toolkits.mplot3d import Axes3D
++ from mpl_toolkits.mplot3d.art3d import Poly3DCollection
++ from skimage import measure
++ from matplotlib.colors import LightSource
+++from scipy.io import savemat
++ 
+++# ============================================================================
+++# 1. CHOOSE INITIAL CONDITION
+++# ============================================================================
+++# Options: 'sphere', 'dumbbell', 'star', separation, torus, 'heart'
+++initial_condition_type = 'torus'  # <-- CHANGE THIS VALUE TO RUN A DIFFERENT SIMULATION
+++print(f"Running simulation for Initial Condition: {initial_condition_type.upper()}")
+++
+++# ============================================================================
+++# 2. MODEL AND DATASET LOADING
+++# ============================================================================
++ # Load model
++ device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")
++ 
++-#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6.pt'
+++# SH3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++#model_path = '/SH3D/models/TNO3d_SH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d_valid_old.pt'
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++
+++# AC3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/AC3D/models/TNO3d_AC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt' # AC3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/AC3D/models/TNO3d_AC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt' # AC3D
+++
+++# CH3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/CH3D/models/TNO3d_CH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/CH3D/models/TNO3d_CH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++
++ 
++-model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++# mixed MBE3d#
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++model_path = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
++ 
++-# Option 1 (Recommended secure approach)
+++# No Mixed
+++# model_path ='/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_S32_T1to100_width12_modes14_q12_h6_grf3d_NoMixed.pt'
+++# model_path ='/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d_NoMixed.pt'
+++
+++# PFC (we plotted this)
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/models/TNO3d_PFC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/models/TNO3d_PFC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++
+++
+++
++ try:
++-    from networks import TNO3d  # Import your custom network class
++-    torch.serialization.add_safe_globals([TNO3d])
+++    from networks import TNO3d  # Assuming networks.py and TNO3d are available
+++
+++    # Add builtins.set to safe globals for robust loading
+++    torch.serialization.add_safe_globals([set])
+++    torch.serialization.add_safe_globals([TNO3d])  # Add TNO3d if it's part of the global scope during saving
+++
++     checkpoint = torch.load(model_path, map_location=device, weights_only=True)
++ except Exception as e:
++     print(f"Secure loading failed: {e}\nFalling back to weights_only=False")
++-    # Option 2 (Less secure fallback)
+++    # It's good practice to ensure the safe globals are added even for fallback
+++    torch.serialization.add_safe_globals([set])
+++    torch.serialization.add_safe_globals([TNO3d])
++     checkpoint = torch.load(model_path, map_location=device, weights_only=False)
++ 
++ model = checkpoint['model']
++ model.eval()
++ 
++-# Load dataset for normalization
++-problem = 'SH3D'
+++# Load dataset for normalization AND EXTRACT PROBLEM NAME
+++key_directory = 'phase_field_equations_4d'
+++problem = ''
+++try:
+++    parts = model_path.split('/')
+++    index = parts.index(key_directory)
+++    problem = parts[index + 1]  # This gets the directory name (e.g., 'AC3D')
+++except (ValueError, IndexError):
+++    print(f"Could not automatically determine problem name. Set manually if needed.")
+++
+++print(f"Problem Name Determined: {problem}")
++ network_name = 'TNO3d'
++-cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")  # Assuming configs module is available
++ dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
++ 
++-# Move normalizer parameters to device
++ dataset.normalizer_x.mean = dataset.normalizer_x.mean.to(device)
++ dataset.normalizer_x.std = dataset.normalizer_x.std.to(device)
++ dataset.normalizer_y.mean = dataset.normalizer_y.mean.to(device)
++ dataset.normalizer_y.std = dataset.normalizer_y.std.to(device)
++ 
++ 
++-# Create spherical initial condition
++-def create_sharp_sphere_initial_condition(N=32, radius=2, L=10):
++-    x = np.linspace(-L / 2, L / 2, N)
++-    y = np.linspace(-L / 2, L / 2, N)
++-    z = np.linspace(-L / 2, L / 2, N)
++-    xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')
+++# ============================================================================
+++# 3. CREATE INITIAL CONDITION
+++# ============================================================================
+++def create_initial_condition(ic_type='sphere'):
+++    Nx, Ny, Nz = 0, 0, 0
+++    Lx, Ly, Lz = 0, 0, 0
+++    epsilon = 0
+++    Nt = 0
+++    selected_frames = []
+++    u = None
+++    dt = 0
+++
+++    if ic_type == 'sphere':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        # Lx = 10*np.pi; # PFC3D
+++        Lx = 5 # AC3D
+++        #Lx = 15  # SH3D
+++        Ly = Lx;
+++        Lz = Lx
+++        # epsilon = 0.5 # PFC3D
+++        #epsilon = 0.15 # SH3d
+++        epsilon = 0.1 # AC3d
+++        # dt = 0.0005
+++        dt = 0.05  # SH3D
+++        Nt = 100
+++        selected_frames = [0, 70, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        # radius = 6 # PFC3D
+++        radius = 0.5 # AC3D
+++        #radius = 2.0  # SH3D
+++        interface_width = np.sqrt(2) * epsilon
+++        u = np.tanh((radius - np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)) / interface_width)
+++
+++    elif ic_type == 'dumbbell':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        Lx = 40;
+++        Ly = 20;
+++        Lz = 20
+++        epsilon = 0.005
+++        dt = 0.01
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(0, Lx, Nx)
+++        y_grid = np.linspace(0, Ly, Ny)
+++        z_grid = np.linspace(0, Lz, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        R0 = 0.25
+++        interface_width = np.sqrt(2) * epsilon
+++
+++        r1 = np.sqrt((xx - (0.3 * Lx)) ** 2 + (yy - (0.5 * Ly)) ** 2 + (zz - (0.5 * Lz)) ** 2)
+++        r2 = np.sqrt((xx - (1.7 * Lx)) ** 2 + (yy - (0.5 * Ly)) ** 2 + (zz - (0.5 * Lz)) ** 2)
+++        u_spheres = np.tanh((R0 - r1) / interface_width) + np.tanh((R0 - r2) / interface_width) + 1
+++
+++        bar_mask = (xx > (0.4 * Lx)) & (xx < (1.6 * Lx)) & \
+++                   (yy > (0.4 * Ly)) & (yy < (0.6 * Ly)) & \
+++                   (zz > (0.4 * Lz)) & (zz < (0.6 * Lz))
+++        u = u_spheres
+++        u[bar_mask] = 1.0
+++        u = np.clip(u, -1.0, 1.0)
+++
+++    elif ic_type == 'star':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        #Lx = 5 # AC3D,
+++        Lx = 10 * np.pi  # --> PFC3D
+++        #Lx = 2  # CH3D
+++        Ly = Lx;
+++        Lz = Lx
+++        epsilon = 0.5  # PFC3D
+++        #epsilon = 0.05 # CH3d
+++        dt = 0.005
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++ 
++-    r = np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)
++-    sphere = np.ones((N, N, N), dtype=np.float32)  # Use float32 for consistency
+++        interface_width = np.sqrt(2.0) * epsilon
+++        theta = np.arctan2(zz, xx)
+++        R_theta = 5.0 + 1.0 * np.cos(6 * theta)  # PFC3D
+++        # R_theta = 0.7 + 0.2 * np.cos(6 * theta)  # AC3D
+++        #R_theta = 0.7 + 0.2 * np.cos(6 * theta)  # CH3D
+++        dist = np.sqrt(xx ** 2 + 2 * yy ** 2 + zz ** 2)
+++        u = np.tanh((R_theta - dist) / interface_width)
++ 
++-    # Perfectly sharp transition (no smoothing)
++-    outer_mask = r > radius
++-    sphere[outer_mask] = -1.0
+++    elif ic_type == 'torus':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        # Lx = 10*np.pi;
+++        Lx = 2 * np.pi  # MBE3D
+++        Ly = Lx;
+++        Lz = Lx
+++        # epsilon = 0.5
+++        epsilon = 0.1  # MBE3D
+++        # dt = 0.005
+++        dt = 0.001  # MBE3D
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
++ 
++-    # Force exact values (no floating point artifacts)
++-    sphere = np.where(r <= radius, 1.0, -1.0)
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++ 
++-    return sphere
++-# Create initial condition with perfect sharp interface
++-sphere_ic = create_sharp_sphere_initial_condition()
+++        # R_major = 5.5
+++        # r_minor = 3.5
+++        R_major = 2.1  # MBE3D
+++        r_minor = 0.7  # MBE3D
++ 
++-input_tensor = torch.from_numpy(sphere_ic).float().unsqueeze(0).unsqueeze(-1).to(device)
+++        interface_width = np.sqrt(2) * epsilon
+++        torus_dist = np.sqrt((np.sqrt(xx ** 2 + yy ** 2) - R_major) ** 2 + zz ** 2)
+++        u = np.tanh((r_minor - torus_dist) / interface_width)
+++        # u = np.clip(u, -1.0, 1.0)
+++
+++    elif ic_type == 'separation':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        Lx = 2 * np.pi;
+++        Ly = 2 * np.pi;
+++        Lz = 2 * np.pi
+++        epsilon = 0.5
+++        dt = 0.0005
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        interface_width = np.sqrt(2) * epsilon
+++
+++        r1_dist = np.sqrt((xx + 1) ** 2 + yy ** 2 + zz ** 2)
+++        r2_dist = np.sqrt((xx - 1) ** 2 + yy ** 2 + zz ** 2)
+++
+++        u = np.tanh((1 - r1_dist) / interface_width) + np.tanh((1 - r2_dist) / interface_width)
+++        # u = np.clip(u, -1.0, 1.0)
+++
+++    elif ic_type == 'heart':
+++        Nx = 32
+++        Ny = 32
+++        Nz = 32
+++        Lx = 5.0
+++        Ly = Lx
+++        Lz = Lx
+++        epsilon = 0.15
+++        dt = 0.005  # Assuming a dt similar to other conditions
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        # Equation from image: phi(x,y,z,0) = tanh( ( (x^2 + 9/4*y^2 + z^2 - 1)^3 - x^2*z^3 - 9/80*y^2*z^3 ) / sqrt(2*epsilon) )
+++        denominator = np.sqrt(2 * epsilon)
+++        numerator = (xx ** 2 + (9 / 4) * yy ** 2 + zz ** 2 - 1) ** 3 - xx ** 2 * zz ** 3 - (9 / 80) * yy ** 2 * zz ** 3
+++        u = np.tanh(numerator / denominator)
+++
+++    else:
+++        raise ValueError(f"Unknown initial condition type: {ic_type}")
+++
+++    return u, (Lx, Ly, Lz), (Nx, Ny, Nz), Nt, dt, selected_frames
+++
+++
+++# Create the selected initial condition
+++initial_condition_field, domain_lengths, grid_sizes, Nt, dt, selected_frames = create_initial_condition(
+++    ic_type=initial_condition_type)
+++Lx, Ly, Lz = domain_lengths
+++Nx, Ny, Nz = grid_sizes
+++
+++# ============================================================================
+++# 4. PREDICTION AND VISUALIZATION
+++# ============================================================================
+++# Prepare tensor for the model
+++input_tensor = torch.from_numpy(initial_condition_field).float().unsqueeze(0).unsqueeze(-1).to(device)
++ input_tensor = dataset.normalizer_x.encode(input_tensor)
++ 
++ # Run prediction
++ with torch.no_grad():
++-    prediction = model(input_tensor)  # Shape [1, 32, 32, 32, 10]
+++    # Start timer
+++    start_time = torch.cuda.Event(enable_timing=True)
+++    end_time = torch.cuda.Event(enable_timing=True)
+++
+++    torch.cuda.synchronize()  # Wait for all operations to complete
+++    start_time.record()  # Start recording
+++
+++    prediction = model(input_tensor)
+++
+++    end_time.record()  # Stop recording
+++    torch.cuda.synchronize()  # Wait for all operations to complete
+++
+++    # ==================== MODIFICATION START ====================
+++    # Calculate elapsed time in milliseconds
+++    inference_time_ms = start_time.elapsed_time(end_time)
+++    # Convert milliseconds to seconds for saving
+++    inference_time = inference_time_ms / 1000.0
+++    # ===================== MODIFICATION END =====================
+++
++     prediction = dataset.normalizer_y.decode(prediction)
+++    # Clip the prediction to be within the physical bounds [-1, 1].
+++    #prediction = torch.clamp(prediction, min=-1.0, max=1.0) # SH3d
++ 
++-# Define your custom frames to display
++-selected_frames = [0, 50, 90]  # Adjusted for T_out=10
++-num_frames = len(selected_frames)
+++# ==================== MODIFICATION START ====================
+++# Updated print statement to show both units
+++print(f"Inference time: {inference_time_ms:.3f} milliseconds ({inference_time:.6f} seconds)")
+++# ===================== MODIFICATION END =====================
++ 
++-# Create figure with two subplots: 3D views and 1D profile
+++
+++# Create figure
++ fig = plt.figure(figsize=(20, 10))
++-grid = plt.GridSpec(2, num_frames, hspace=0.3, wspace=0.2)
+++grid = plt.GridSpec(2, len(selected_frames), hspace=0.3, wspace=0.2)
+++fig.suptitle(f"TNO Prediction for {initial_condition_type.upper()} Initial Condition ({problem})", fontsize=16)
++ 
++-# 1. Plot 3D isosurfaces for selected frames
+++# Define mesh coordinates for plotting
+++if initial_condition_type in ['sphere', 'star', 'torus', 'separation', 'heart']:
+++    x_coords = np.linspace(-Lx / 2, Lx / 2, Nx)
+++    x_lim_low, x_lim_high = -Lx / 2, Lx / 2
+++    y_lim_low, y_lim_high = -Ly / 2, Ly / 2
+++    z_lim_low, z_lim_high = -Lz / 2, Lz / 2
+++elif initial_condition_type == 'dumbbell':
+++    x_coords = np.linspace(0, Lx, Nx)
+++    x_lim_low, x_lim_high = 0, Lx
+++    y_lim_low, y_lim_high = 0, Ly
+++    z_lim_low, z_lim_high = 0, Lz
+++
+++# 1. Plot 3D isosurfaces
++ for i, t in enumerate(selected_frames):
++     ax = fig.add_subplot(grid[0, i], projection='3d')
+++
+++    # if t == 0:
+++    #    frame_data = initial_condition_field
+++    #    title_text = f'Initial Condition\nTime = {t}'
+++    # else:
+++    #    frame_data = prediction[0, ..., t].cpu().numpy()
+++    #    title_text = f'Prediction\nTime = {t}'
+++
++     frame_data = prediction[0, ..., t].cpu().numpy()
++-
++-    # Print data range for debugging
++-    print(f"Frame {t}: min={np.min(frame_data):.3f}, max={np.max(frame_data):.3f}")
+++    title_text = f'Prediction\nTime = {t}'
++ 
++-    # Determine appropriate level
++-    data_min, data_max = np.min(frame_data), np.max(frame_data)
++-    if data_min > 0 or data_max < 0:
++-        level = (data_max + data_min) / 2  # Midpoint if zero is outside range
++-    else:
++-        level = 0.0  # Default level
++-
+++    level = 0.0
++     try:
++-        # Extract smooth isosurface with adjusted level
++-        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level)
+++        dx, dy, dz = Lx / (Nx - 1), Ly / (Ny - 1), Lz / (Nz - 1)
+++        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level, spacing=(dx, dy, dz))
++ 
++-        # Apply lighting and coloring
+++        if initial_condition_type in ['sphere', 'star', 'torus', 'separation', 'heart']:
+++            verts[:, 0] -= Lx / 2
+++            verts[:, 1] -= Ly / 2
+++            verts[:, 2] -= Lz / 2
+++
++         ls = LightSource(azdeg=135, altdeg=45)
++-        rgb = ls.shade_normals(verts[faces], fraction=0.8)
++-
++-        mesh = Poly3DCollection(verts[faces],
++-                                facecolors=rgb,
++-                                edgecolor='none',
++-                                alpha=0.9)
++-
+++        mesh = Poly3DCollection(verts[faces], facecolors='gray', edgecolor='none', alpha=0.9)
++         ax.add_collection3d(mesh)
++         plot_success = True
++     except ValueError as e:
++         print(f"Could not generate isosurface for frame {t}: {e}")
+++        ax.text(0.5, 0.5, 0.5, f"No isosurface\nat level={level:.2f}", ha='center', va='center', transform=ax.transAxes)
++         plot_success = False
++-        # Display empty plot with error message
++-        ax.text(0.5, 0.5, 0.5, f"No isosurface\nat level={level:.2f}",
++-                ha='center', va='center', fontsize=10)
++ 
++-    # Set viewing parameters
++-    ax.set_xlim(0, frame_data.shape[0])
++-    ax.set_ylim(0, frame_data.shape[1])
++-    ax.set_zlim(0, frame_data.shape[2])
++-    ax.set_title(f'Time = {t}\nLevel = {level:.2f}', pad=10)
+++    ax.set_xlim(x_lim_low, x_lim_high)
+++    ax.set_ylim(y_lim_low, y_lim_high)
+++    ax.set_zlim(z_lim_low, z_lim_high)
+++    ax.set_title(f'{title_text}\nLevel = {level:.2f}', pad=10)
++     ax.grid(False)
++     ax.set_xticks([])
++     ax.set_yticks([])
++@@ -129,35 +379,76 @@
++     if plot_success:
++         ax.view_init(elev=30, azim=45)
++ 
++-# 2. Plot 1D profile through center for all time steps
+++# 2. Plot 1D profile
++ ax_profile = fig.add_subplot(grid[1, :])
++-L = 10  # Domain size
++-x = np.linspace(-L / 2, L / 2, prediction.shape[1])
++-center_idx = prediction.shape[1] // 2  # Middle of the domain
+++center_y_idx = Ny // 2
+++center_z_idx = Nz // 2
++ 
++-# Plot profiles for the same custom frames in the profile plot
++ for t in selected_frames:
++-    profile = prediction[0, :, center_idx, center_idx, t].cpu().numpy()
++-    ax_profile.plot(x, profile, label=f't={t}', alpha=0.8, linewidth=1.5)
+++    if t == 0:
+++        profile = initial_condition_field[:, center_y_idx, center_z_idx]
+++        label_text = f't={t} (IC)'
+++    else:
+++        profile = prediction[0, :, center_y_idx, center_z_idx, t].cpu().numpy()
+++        label_text = f't={t}'
+++    # profile = prediction[0, :, center_y_idx, center_z_idx, t].cpu().numpy()
+++    # label_text = f't={t}'
++ 
++-# Format profile plot
+++    ax_profile.plot(x_coords, profile, label=label_text, alpha=0.8, linewidth=1.5)
+++
++ ax_profile.set_xlabel('Position along x-axis', fontsize=12)
++ ax_profile.set_ylabel('Field value', fontsize=12)
++ ax_profile.set_title('1D Profile Evolution Through Domain Center', pad=15)
++ ax_profile.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
++ ax_profile.grid(True, alpha=0.3)
++-ax_profile.set_ylim([-1.2, 1.5])  # Match MATLAB y-limits
+++ax_profile.set_ylim([-1.5, 1.5])
++ 
++-plt.tight_layout()
+++plt.tight_layout(rect=[0, 0, 1, 0.96])
++ plt.show()
++ 
++-# After getting predictions in Python
++-prediction_np = prediction.cpu().numpy()  # Convert to numpy array
++ 
++-# Save to .mat file
++-from scipy.io import savemat
++-savemat('SH3D_python_predictions.mat', {
++-    'python_pred': prediction_np,
+++## This is saved the data of initial condition itself
+++# ============================================================================
+++# 5. SAVE RESULTS TO .MAT FILE
+++# ============================================================================
+++# Get the raw prediction tensor from the model as a NumPy array
+++prediction_np = prediction.cpu().numpy()
+++# Create a "hybrid" tensor for saving, ensuring the t=0 slice is the true IC
+++final_prediction_to_save = np.copy(prediction_np)
+++final_prediction_to_save[0, :, :, :, 0] = initial_condition_field
+++# Define the output filename using the 'problem' variable extracted earlier
+++# from the model_path. This makes the filename dynamic.
+++output_filename = f'{problem}_python_predictions_{initial_condition_type}_PIMHNO.mat'
+++
+++# ==================== MODIFICATION START ====================
+++# Save the corrected data and the inference time to the .mat file
+++savemat(output_filename, {
+++    'python_pred': final_prediction_to_save,
++     'selected_frames': np.array(selected_frames),
++-    'x': x  # Spatial coordinates
++-})
++\ No newline at end of file
+++    'x': x_coords,
+++    'inference_time': inference_time  # Add the inference time (in seconds)
+++})
+++print(f"Corrected prediction (with true IC at t=0) and inference time saved to {output_filename}")
+++
+++# ===================== MODIFICATION END =====================
+++
+++'''
+++# ============================================================================
+++# 5. SAVE RESULTS TO .MAT FILE
+++# ============================================================================
+++# Get the raw prediction tensor from the model as a NumPy array
+++prediction_np = prediction.cpu().numpy()
+++# The array to save is now just the raw prediction
+++final_prediction_to_save = prediction_np
+++# The line that overwrites t=0 has been removed.
+++output_filename = f'{problem}_python_predictions_{initial_condition_type}.mat'
+++# Save the raw prediction data to the .mat file
+++savemat(output_filename, {
+++    'python_pred': final_prediction_to_save,
+++    'selected_frames': np.array(selected_frames),
+++    'x': x_coords,
+++    'inference_time': inference_time  # Add the inference time (in seconds)
+++})
+++print(f"Raw model prediction saved to {output_filename}")
+++
+++'''
++Index: configs/config_SH3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:2'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 # 5250 # 7500\nnTest = 300 # 2250 #500\nbatch_size = 20 # 50\nlearning_rate = 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-4\nepochs = 30 # 50 # 50 # 50 # 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 16 # 16\nwidth =  12 # 12 #32\nwidth_q =   width # width # 2 * width #\nwidth_h = width//2  # width//4 # width #\nn_layers = 2 # 8\n\n# Discretization\n#s = 32 # 32 # 64\n#T_in = 1\n#T_out = 20 # 100\n# Discretization\ns = 32 # 80         # CRITICAL: Must match Nx, Ny, Nz from MATLAB (which is 80)\nT_in = 1       # CRITICAL: Use the first time step (t=0) as input\nT_out = 100 # 91 # 100 # 20     # CRITICAL: Predict the next 10 time steps. Total steps used = 1+10=11, which matches the data.\n\n# Training Setting\nnormalized = True # False\ntraining = True # False  #   True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_3232.mat' # correct\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results\n# Plotting\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\nLx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\nLy =Lx\nLz= Lx\n\n\nindex = 62  # 24 # 62\n#domain = [-np.pi, np.pi] ######\ndomain = [-Lx/2, Lx/2]\n\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\n#time_steps = [0, 9, 19]\ntime_steps = [0, 50, 90]\n####\n### Hybrid method\n\n\n#domain = [-Lx/2, Lx/2] # Assuming centered domain\n\n# Time Discretization (from MATLAB)\ndt_sim = 0.05 # Simulation time step\ndt_simulation = 0.05\nNt = 100 # Total simulation steps\nnum_saved_steps = 101 # Number of saved steps (includes t=0)\nns = Nt / (num_saved_steps - 1) # Interval between saved steps\ndt_model = ns * dt_sim # Effective time step between model outputs\n\n# PDE Parameters\nepsilon = 0.15\n#pde_weight = 0.3 # Example: 30% physics loss\npde_weight = 0.4 # Example: 70% physics loss\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\npde_loss_scaler = 1e1\n###########################\n# ... rest of config ...
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_SH3D_TNO3d.py b/configs/config_SH3D_TNO3d.py
++--- a/configs/config_SH3D_TNO3d.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/configs/config_SH3D_TNO3d.py	(date 1754503716802)
++@@ -6,18 +6,18 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 1200 # 5250 # 7500
++-nTest = 300 # 2250 #500
+++nTrain = 1200 # 1600 # 5250 # 7500
+++nTest = 300 # 400 # 2250 #500
++ batch_size = 20 # 50
++ learning_rate = 0.001 # 0.005 # 0.001
++ weight_decay = 1e-4 # 1e-4
++-epochs = 30 # 50 # 50 # 50 # 50 # 1000
+++epochs = 30 # 50 # 50 # 50 # 50 # 50 # 1000
++ iterations = epochs * (nTrain // batch_size)
++ modes =  14 # 16 # 16
++ width =  12 # 12 #32
++-width_q =   width # width # 2 * width #
+++width_q = width # width # 2 * width #
++ width_h = width//2  # width//4 # width #
++-n_layers = 2 # 8
+++n_layers = 2 # 4 # 8
++ 
++ # Discretization
++ #s = 32 # 32 # 64
++@@ -38,11 +38,13 @@
++ 
++ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_3232.mat' # correct
++ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++
+++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
++ # Plotting
++ 
++ # In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
++-Lx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++Lx = 15 # 10 # 15 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
++ Ly =Lx
++ Lz= Lx
++ 
++@@ -76,11 +78,11 @@
++ # PDE Parameters
++ epsilon = 0.15
++ #pde_weight = 0.3 # Example: 30% physics loss
++-pde_weight = 0.4 # Example: 70% physics loss
+++pde_weight = 0.5 # 0.2 # Example: 70% physics loss
++ 
++ # Learning Rate Scheduler Parameters (for StepLR)
++ scheduler_step = 20  # Decay learning rate every 20 epochs
++ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++-pde_loss_scaler = 1e1
+++pde_loss_scaler = 1.5e0
++ ###########################
++ # ... rest of config ...
++\ No newline at end of file
++Index: main.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import os\nimport importlib\nimport torch\nimport inspect\nimport numpy as np\nimport matplotlib\n\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom training import train_fno, train_fno_time, train_hybrid, compute_initial_loss_scaler\nfrom torch.utils.data import DataLoader, random_split\nfrom utilities import ImportDataset, count_params, LpLoss, ModelEvaluator\nfrom post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \\\n    make_video, save_vtk, plot_xy_plane_subplots\nimport time  # Import the time module at the beginning of the script\nfrom torch_optimizer import Lamb\n\n################################################################\n# Problem Definition\n################################################################\n# problem = 'AC2D'\n# problem = 'AC3D'\n# problem = 'CH2DNL'\n# problem = 'SH2D'\nproblem = 'SH3D'\n# problem = 'PFC2D'\n# problem = 'PFC3D'\n# problem = 'MBE2D'\n# problem = 'MBE3D'\n# problem = 'CH2D'\n# problem = 'CH3D'\n\n# network_name = 'TNO2d'\n# network_name = 'FNO2d'\n#network_name = 'FNO3d'\nnetwork_name = 'TNO3d'\n\nPINN_MODE =  True #False #  False #  False  # False #\n\nprint(f\"problem = {problem}\")\nprint(f\"network = {network_name}\")\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\")  # configuration file\n# above line means: import configs.config_PFC3D_TNO3d as cf\nnetwork = getattr(importlib.import_module('networks'), network_name)  # from networks import TNO3d\ntorch.manual_seed(cf.torch_seed)\nnp.random.seed(cf.numpy_seed)\n# device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')\ndevice = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)\n# --- Define Output Directory ---\n\n\nPDE_WEIGHT = cf.pde_weight\n#PDE_LOSS_SCALER = cf.pde_loss_scaler\n\nif PINN_MODE:\n    run_descriptor = f\"PINN_w{int(PDE_WEIGHT * 100)}\"\n    output_subdir = f\"plots_Data_Physics_{network_name}\"  # Specific PINN output\nelse:\n    run_descriptor = \"DataDriven\"\n    output_subdir = f\"plots_{network_name}\"  # Original data-driven output\n\n# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'\n# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_SH3D_random_sphere_finial.pt'\nmodel_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d.pt'\nmodel_dir = os.path.join(problem, 'models')  # models_smpooth\nmodel_name = f'{model_run_name}'\nmodel_path = os.path.join(model_dir, model_name)\n\nplot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir\nos.makedirs(model_dir, exist_ok=True)\nos.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists\n\nprint(f\"Model Run Name: {model_run_name}\")\nprint(f\"Model Path: {model_path}\")\nprint(f\"Plot Directory: {plot_dir}\")\n\n# width_q = 32\nstart_time = time.time()\n\n################################################################\n# load data and data normalization\n################################################################\n# model_dir = problem + '/models'\n\nprint(f\"model = {model_name}\")\nprint(f\"number of epoch = {cf.epochs}\")\nprint(f\"batch size = {cf.batch_size}\")\nprint(f\"nTrain = {cf.nTrain}\")\nprint(f\"nTest = {cf.nTest}\")\nprint(f\"learning_rate = {cf.learning_rate}\")\nprint(f\"n_layers = {cf.n_layers}\")\nprint(f\"width_q = {cf.width_q}\")\nprint(f\"width_h = {cf.width_h}\")\n\nmodel_path = os.path.join(model_dir, model_name)\nos.makedirs(model_dir, exist_ok=True)\n# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\ntrain_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])\n# to see train_dataset values: print(\"train_dataset subset:\", [train_dataset[i] for i in range(len(train_dataset))])\nnormalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)\n\n############AA####################################################\n# training and evaluation\n################################################################\nsig = inspect.signature(network.__init__)\nrequired_args = [param.name for param in sig.parameters.values()\n                 if param.default == inspect.Parameter.empty and param.name != \"self\"]\nif network_name == 'FNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'FNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(\n        device)\nelse:\n    raise Exception(\"network_name is not correct\")\n\nprint(count_params(model))  # Print model parameters\ntrain_mse_log, train_l2_log, test_l2_log = [], [], []  # Initialize logs\n\n# Load the entire model and logs\nif os.path.exists(model_path) and cf.load_model:\n    print(f\"Loading pre-trained model from {model_path}\")\n    checkpoint = torch.load(model_path, map_location=device)\n    model = checkpoint['model']\n    train_mse_log = checkpoint.get('train_mse_log', [])\n    train_l2_log = checkpoint.get('train_l2_log', [])\n    test_l2_log = checkpoint.get('test_l2_log', [])\nelse:\n    print(\"No pre-trained model loaded. Initializing a new model.\")\n\n# Define optimizer, scheduler, and loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)\nmyloss = LpLoss(p=2, l1_weight=0.0, size_average=False)\n\n# COMPUTE THE DYNAMIC SCALER\n# Use the train_loader to get a representative batch\n\n\n# Train the model\nif cf.training:\n    print(\"\\n--- Starting Training ---\")\n    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)\n        grid_info = {\n            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,\n            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,\n            'dt_model': cf.dt_model,\n            'T_out': cf.T_out\n        }\n\n        pde_loss_scaler = compute_initial_loss_scaler(\n            model,\n            train_loader,\n            myloss,\n            cf.normalized,\n            normalizers,\n            device,\n            grid_info,\n            cf.epsilon,\n            problem\n        )\n\n\n        if PDE_WEIGHT == 0.0:\n            print(\"Running PINN training loop with pde_weight=0 (Data-Driven only loss).\")\n        else:\n            print(\n                f\"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {pde_loss_scaler:.2e}\")\n\n        model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (\n            train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                         optimizer, scheduler, cf.normalized, normalizers, device,\n                         PDE_WEIGHT, grid_info, cf.epsilon, problem,\n                         pde_loss_scaler=pde_loss_scaler)\n        )\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model': model,\n            'train_mse_log': train_mse_hybrid_log,\n            'train_l2_log': train_l2_hybrid_log,\n            'test_l2_log': test_data_log,\n            'test_pde_scaled_log': test_pde_loss_scaled_log,\n            'train_data_log': train_data_log,\n            'train_pde_scaled_log': train_pde_scaled_log,\n            'test_loss_hybrid_log': test_loss_hybrid_log\n        }, model_path)\n\n    else:  # Original Data-Driven Mode\n        if network_name == 'FNO2d' or network_name == 'FNO3d':\n            model, train_l2_log, test_l2_log = (\n                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                               optimizer, scheduler, cf.normalized, normalizers, device))\n            train_mse_log = []\n        else:\n            model, train_mse_log, train_l2_log, test_l2_log = (\n                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                          optimizer, scheduler, cf.normalized, normalizers, device))\n\n    print(f\"Saving model and logs to {model_path}\")\n    torch.save({\n        'model': model,\n        'train_mse_log': train_mse_log,\n        'train_l2_log': train_l2_log,\n        'test_l2_log': test_l2_log\n    }, model_path)\n\nend_time = time.time()\nFinal_time = round(end_time - start_time, 2)\nprint(f\"Total Execution Time: {Final_time} seconds\")\n\nevaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,\n                           time_history=(network_name == 'FNO2d'))\n\nresults = evaluator.evaluate(loss_fn=myloss)\ninp = results['input']\npred = results['prediction']\nexact = results['exact']\ntest_l2_avg = results[\"average\"]\n\nif PINN_MODE:\n    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log,\n              train_pde_scaled_log]\n    labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\nelse:\n    losses = [train_l2_log, test_l2_log]\n    labels = ['Train L2', 'Test L2']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\n\n################################################################\n# post-processing\n################################################################\na_ind = inp[cf.index]\nu_pred = pred[cf.index]\nu_exact = exact[cf.index]\nerror = u_pred - u_exact\n\nprint(f\"DEBUG: Shape of u_exact passed to plotting function: {u_exact.shape}\")\nprint(f\"DEBUG: Shape of u_pred passed to plotting function: {u_pred.shape}\")\n\nplot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]\n\n# =========================================================================================\n# ===                START OF MODIFIED PLOTTING PREPARATION BLOCK                      ===\n# =========================================================================================\n\n# 1. Get the initial condition (t=0) data for the chosen sample index\na_ind = inp[cf.index]\nprint(f\"Shape of initial condition (t=0) data 'a_ind': {a_ind.shape}\")\n\n# 2. Separate desired times into t=0 vs. future predictions\ndesired_times = cf.time_steps\nfuture_times_to_plot = []\nhas_initial_condition = (0 in desired_times)\nfor t in desired_times:\n    if t > 0:\n        future_times_to_plot.append(t)\n\n# 3. Translate the FUTURE times to array indices\nindices_to_plot = []\nvalid_future_times = []\nfor t in future_times_to_plot:\n    if t <= cf.T_out:\n        indices_to_plot.append(t - 1)\n        valid_future_times.append(t)\n    else:\n        print(f\"Warning: Time t={t} is out of valid prediction range. Skipping.\")\nprint(f\"Plotting for future times: {valid_future_times} --> which correspond to array indices: {indices_to_plot}\")\n\n# 4. MOVE ALL DATA TO THE TARGET DEVICE BEFORE OPERATIONS\nt0_data_cpu = a_ind\nu_exact_cpu = u_exact\nu_pred_cpu = u_pred\nerror_cpu = error\n\nt0_data_gpu = t0_data_cpu.to(device)\nu_exact_gpu = u_exact_cpu.to(device)\nu_pred_gpu = u_pred_cpu.to(device)\nerror_gpu = error_cpu.to(device)\nindices_tensor_gpu = torch.tensor(indices_to_plot, device=device)\n\n# 5. PREPARE COMBINED TENSORS FOR PLOTTING on the GPU\nif has_initial_condition:\n    # --- ### FIXED DIMENSION HANDLING ### ---\n    # `a_ind` has shape (sx, sy, sz, 1) where the last dim is a channel.\n    # `u_exact_gpu` has shape (sx, sy, sz, T) where the last dim is time.\n    # They are both 4D, so we can concatenate them directly if the last dimension is treated as the time dimension.\n    # We don't need to do any reshaping. `t0_data_gpu` is already correct.\n    t0_for_concat = t0_data_gpu\n\n    # Select the future time slices from the GPU tensors\n    u_exact_selected = u_exact_gpu.index_select(-1, indices_tensor_gpu)\n    u_pred_selected = u_pred_gpu.index_select(-1, indices_tensor_gpu)\n    error_selected = error_gpu.index_select(-1, indices_tensor_gpu)\n\n    # Combine t=0 data with the selected future steps\n    u_exact_for_plot = torch.cat((t0_for_concat, u_exact_selected), dim=-1)\n    u_pred_for_plot = torch.cat((t0_for_concat, u_pred_selected), dim=-1)\n\n    # The error for t=0 is zero by definition\n    error_t0 = torch.zeros_like(t0_for_concat)\n    error_for_plot = torch.cat((error_t0, error_selected), dim=-1)\n\n    final_indices = list(range(len(desired_times)))\n    final_labels = desired_times\nelse:\n    u_exact_for_plot = u_exact_gpu\n    u_pred_for_plot = u_pred_gpu\n    error_for_plot = error_gpu\n    final_indices = indices_to_plot\n    final_labels = valid_future_times\n\nprint(f\"Final data prepared for plotting with shape: {u_exact_for_plot.shape}\")\nprint(f\"Final indices for plotting: {final_indices}\")\nprint(f\"Final labels for plotting: {final_labels}\")\n\n# Plot XY-plane for the \"Exact\" solution trajectory (includes t=0)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=u_exact_for_plot,\n                       field_name='Exact Solution',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[0],\n                       problem=problem,\n                       network_name=network_name)\n\n# Plot XY-plane for the \"Predicted\" solution trajectory (includes t=0 from input)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=u_pred_for_plot,\n                       field_name='Predicted Solution',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[1],\n                       problem=problem,\n                       network_name=network_name)\n\n# Plot XY-plane for the \"Error\" (error is 0 at t=0)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=error_for_plot,\n                       field_name='Error',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[2],\n                       problem=problem,\n                       network_name=network_name)\n\n# Calculate L2 norm on original full prediction\nl2_norm_error = torch.norm(u_pred - u_exact, p=2)\nl2_norm_exact = torch.norm(u_exact, p=2)\nepsilon = 1e-8\nif l2_norm_exact.item() > epsilon:\n    relative_l2_error = l2_norm_error / l2_norm_exact\nelse:\n    relative_l2_error = torch.tensor(0.0) if l2_norm_error.item() < epsilon else torch.tensor(float('inf'))\n\nprint(f\"L2 norm of error: {l2_norm_error.item()}\")\nprint(f\"L2 norm of exact solution: {l2_norm_exact.item()}\")\nprint(f\"Relative L2 norm error: {relative_l2_error.item()}\")\nrelative_l2_error_percentage = (relative_l2_error * 100)\nprint(f\"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%\")\n\n# Call the combined results plots with the prepared data\nplot_combined_results(\n    domain=cf.domain,\n    u_exact=u_exact_for_plot,\n    u_pred=u_pred_for_plot,\n    error=error_for_plot,\n    plot_ranges=plot_range,\n    problem=problem,\n    network_name=network_name,\n    plot_dir=plot_dir,\n    pde_weight=PDE_WEIGHT,\n    time_steps_indices=final_indices,\n    desired_times=final_labels\n)\n\nplot_combined_results_3d(\n    domain=cf.domain,\n    u_exact=u_exact_for_plot,\n    u_pred=u_pred_for_plot,\n    error=error_for_plot,\n    plot_ranges=plot_range,\n    problem=problem,\n    network_name=network_name,\n    plot_dir=plot_dir,\n    pde_weight=PDE_WEIGHT,\n    time_steps_indices=final_indices,\n    desired_times=final_labels\n)\n\n# =========================================================================================\n# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===\n# =========================================================================================\n\n################################################################\n# Save Results to MATLAB .mat file\n################################################################\nprint(\"\\n--- Saving Results to .mat File ---\")\nimport scipy.io\n\nmat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')\n\nif PINN_MODE:\n    try:\n        results_dict = {\n            'train_mse_log': train_mse_hybrid_log,\n            'train_hybrid_loss': np.array(train_l2_hybrid_log),\n            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),\n            'train_data_log': np.array(train_data_log),\n            'test_data_log': np.array(test_data_log),\n            'train_pde_scaled_log': np.array(train_pde_scaled_log),\n            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,\n            'config_pde_loss_scaler': pde_loss_scaler if PINN_MODE else 0.0,\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\nelse:\n    try:\n        results_dict = {\n            'train_mse_log': np.array(train_mse_log),\n            'train_l2_log': np.array(train_l2_log),\n            'test_l2_log': np.array(test_l2_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\n\nprint(\"\\n--- Script Finished ---\")
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/main.py b/main.py
++--- a/main.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/main.py	(date 1754497331681)
++@@ -4,108 +4,122 @@
++ import inspect
++ import numpy as np
++ import matplotlib
+++import h5py  # MODIFIED: Added h5py import
+++import scipy.io
++ 
++ matplotlib.use('TkAgg')
++ import matplotlib.pyplot as plt
++ import torch.nn.functional as F
++-from training import train_fno, train_fno_time, train_hybrid, compute_initial_loss_scaler
+++from training import train_fno, train_fno_time, train_hybrid, train_fno4d
++ from torch.utils.data import DataLoader, random_split
++-from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator
+++from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator, SobolevLoss
++ from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \
++     make_video, save_vtk, plot_xy_plane_subplots
++-import time  # Import the time module at the beginning of the script
+++import time
++ from torch_optimizer import Lamb
++ 
+++################################################################
+++# Problem Definition
+++################################################################
+++
++ ################################################################
++ # Problem Definition
++ ################################################################
++ # problem = 'AC2D'
++-# problem = 'AC3D'
+++#problem = 'AC3D'
++ # problem = 'CH2DNL'
++ # problem = 'SH2D'
++ problem = 'SH3D'
++ # problem = 'PFC2D'
++-# problem = 'PFC3D'
+++#problem = 'PFC3D'
++ # problem = 'MBE2D'
++-# problem = 'MBE3D'
+++#problem = 'MBE3D'
++ # problem = 'CH2D'
++-# problem = 'CH3D'
+++#problem = 'CH3D'
++ 
++ # network_name = 'TNO2d'
++ # network_name = 'FNO2d'
++ #network_name = 'FNO3d'
+++#network_name = 'FNO4d'
++ network_name = 'TNO3d'
++ 
++-PINN_MODE =  True #False #  False #  False  # False #
+++PINN_MODE =  True #False #   True #  False #  True #   True #    True #
+++#  False #    True # False #  False  # False #
++ 
++ print(f"problem = {problem}")
++ print(f"network = {network_name}")
++ os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
++-cf = importlib.import_module(f"configs.config_{problem}_{network_name}")  # configuration file
++-# above line means: import configs.config_PFC3D_TNO3d as cf
++-network = getattr(importlib.import_module('networks'), network_name)  # from networks import TNO3d
+++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+++network = getattr(importlib.import_module('networks'), network_name)
++ torch.manual_seed(cf.torch_seed)
++ np.random.seed(cf.numpy_seed)
++-# device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')
++-device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
+++device = torch.device("cuda:2" if torch.cuda.is_available() else "cpu")
++ print("Device: ", device)
++-# --- Define Output Directory ---
++-
++ 
++ PDE_WEIGHT = cf.pde_weight
++-#PDE_LOSS_SCALER = cf.pde_loss_scaler
+++pde_loss_scaler = cf.pde_loss_scaler
++ 
++ if PINN_MODE:
++     run_descriptor = f"PINN_w{int(PDE_WEIGHT * 100)}"
++-    output_subdir = f"plots_Data_Physics_{network_name}"  # Specific PINN output
+++    output_subdir = f"plots_Data_Physics_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_Hybrid_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d.pt'
++ else:
++     run_descriptor = "DataDriven"
++-    output_subdir = f"plots_{network_name}"  # Original data-driven output
++-
++-# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'
++-# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_SH3D_random_sphere_finial.pt'
++-model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d.pt'
++-model_dir = os.path.join(problem, 'models')  # models_smpooth
+++    output_subdir = f"plots_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d.pt'
+++
+++model_dir = os.path.join(problem, 'models')
++ model_name = f'{model_run_name}'
++ model_path = os.path.join(model_dir, model_name)
++-
++-plot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir
+++plot_dir = os.path.join(problem, output_subdir)
++ os.makedirs(model_dir, exist_ok=True)
++-os.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists
+++os.makedirs(plot_dir, exist_ok=True)
++ 
++ print(f"Model Run Name: {model_run_name}")
++ print(f"Model Path: {model_path}")
++ print(f"Plot Directory: {plot_dir}")
++ 
++-# width_q = 32
++ start_time = time.time()
++ 
++ ################################################################
++ # load data and data normalization
++ ################################################################
++-# model_dir = problem + '/models'
++-
++-print(f"model = {model_name}")
++-print(f"number of epoch = {cf.epochs}")
++-print(f"batch size = {cf.batch_size}")
++-print(f"nTrain = {cf.nTrain}")
++-print(f"nTest = {cf.nTest}")
++-print(f"learning_rate = {cf.learning_rate}")
++-print(f"n_layers = {cf.n_layers}")
++-print(f"width_q = {cf.width_q}")
++-print(f"width_h = {cf.width_h}")
++-
++-model_path = os.path.join(model_dir, model_name)
++-os.makedirs(model_dir, exist_ok=True)
++-# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf
++-dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++# MODIFIED: Added special handling for SH3D dataset loading
+++try:
+++    dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++    if problem == 'SH3D':
+++        print("SH3D dataset detected - applying special handling")
+++        # Verify dataset sizes
+++        sample = dataset[0][0]  # Get first sample
+++        print(f"SH3D sample shape: {sample.shape}, dtype: {sample.dtype}")
+++        print(f"SH3D stats - mean: {sample.mean():.4f}, std: {sample.std():.4f}")
+++except Exception as e:
+++    print(f"Error loading dataset: {e}")
+++    raise
++ 
++ train_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])
++-# to see train_dataset values: print("train_dataset subset:", [train_dataset[i] for i in range(len(train_dataset))])
++ normalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None
++ 
++-train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
++-test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++train_loader = DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
+++test_loader = DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++
+++
+++# ==================== CODE TO INSPECT BATCH SHAPE ====================
+++print("\n" + "="*50)
+++print("Inspecting DataLoader Batch Shapes")
+++print("="*50)
+++# Get one batch of data from the train_loader
+++try:
+++    x_batch, y_batch = next(iter(train_loader))
+++    # Print the shape of the batch
+++    # This will be (batch_size, S, S, S, T_in) for input
+++    # and (batch_size, S, S, S, T_out) for target
+++    print(f"Shape of an input batch from DataLoader: {x_batch.shape}")
+++    print(f"Shape of a target batch from DataLoader: {y_batch.shape}")
+++except StopIteration:
+++    print("Train loader is empty. Cannot retrieve a batch.")
+++print("="*50 + "\n")
+++# =======================================================================
++ 
++ ############AA####################################################
++ # training and evaluation
++@@ -122,6 +136,19 @@
++ elif network_name == 'TNO3d':
++     model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(
++         device)
+++elif network_name == 'FNO4d':
+++    model = network(
+++        modes1=cf.modes,
+++        modes2=cf.modes,
+++        modes3=cf.modes,
+++        modes4_internal =1, # cf.modes_t, # MUST BE 1
+++        width=cf.width,
+++        width_q=cf.width_q,
+++        T_in_channels=cf.T_in,
+++        n_layers=cf.n_layers
+++    ).to(device)
+++
+++
++ else:
++     raise Exception("network_name is not correct")
++ 
++@@ -142,7 +169,10 @@
++ # Define optimizer, scheduler, and loss function
++ optimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)
++ scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)
++-myloss = LpLoss(p=2, l1_weight=0.0, size_average=False)
+++myloss = LpLoss(p=2, l1_weight=0.1, size_average=False) # size_average=True # False
+++# NEW: Instantiate SobolevLoss instead of LpLoss
+++# You can tune grad_weight. A good starting point is 0.1 or 1.0.
+++#myloss = SobolevLoss(d=3, p=2, grad_weight=0.1)
++ 
++ # COMPUTE THE DYNAMIC SCALER
++ # Use the train_loader to get a representative batch
++@@ -159,19 +189,6 @@
++             'T_out': cf.T_out
++         }
++ 
++-        pde_loss_scaler = compute_initial_loss_scaler(
++-            model,
++-            train_loader,
++-            myloss,
++-            cf.normalized,
++-            normalizers,
++-            device,
++-            grid_info,
++-            cf.epsilon,
++-            problem
++-        )
++-
++-
++         if PDE_WEIGHT == 0.0:
++             print("Running PINN training loop with pde_weight=0 (Data-Driven only loss).")
++         else:
++@@ -203,6 +220,13 @@
++                 train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                                optimizer, scheduler, cf.normalized, normalizers, device))
++             train_mse_log = []
+++        elif network_name == 'FNO4d':
+++
+++            model, train_mse_log, train_l2_log, test_l2_log = (  # Add val logs
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++            # train_fno4d = train_fno
++         else:
++             model, train_mse_log, train_l2_log, test_l2_log = (
++                 train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++@@ -216,14 +240,129 @@
++         'test_l2_log': test_l2_log
++     }, model_path)
++ 
+++
+++'''
+++# Train the model
+++if cf.training:
+++    print("\n--- Starting Training ---")
+++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
+++        grid_info = {
+++            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
+++            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
+++            'dt_model': cf.dt_model,
+++            'T_out': cf.T_out
+++        }
+++
+++        # --- NEW: Define the two stages for the training curriculum ---
+++        epochs_stage1 = 10
+++        scaler_stage1 = 1e-4
+++
+++        # Calculate remaining epochs for stage 2
+++        epochs_stage2 = cf.epochs - epochs_stage1
+++        scaler_stage2 = 1e-6
+++
+++        # --- Stage 1 Training ---
+++        print("\n--- Starting Training Stage 1 ---")
+++        print(f"Epochs: {epochs_stage1}, PDE Scaler: {scaler_stage1:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++        # Note: The 'model' object is updated in-place by the function call
+++        model, train_mse_s1, train_l2_s1, test_data_s1, test_pde_s1, train_data_s1, train_pde_scl_s1, test_loss_s1 = (
+++            train_hybrid(model, myloss, epochs_stage1, cf.batch_size, train_loader, test_loader,
+++                         optimizer, scheduler, cf.normalized, normalizers, device,
+++                         PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                         pde_loss_scaler=scaler_stage1)
+++        )
+++
+++        # --- Stage 2 Training (if there are remaining epochs) ---
+++        if epochs_stage2 > 0:
+++            print("\n--- Starting Training Stage 2 ---")
+++            print(f"Epochs: {epochs_stage2}, PDE Scaler: {scaler_stage2:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++            model, train_mse_s2, train_l2_s2, test_data_s2, test_pde_s2, train_data_s2, train_pde_scl_s2, test_loss_s2 = (
+++                train_hybrid(model, myloss, epochs_stage2, cf.batch_size, train_loader, test_loader,
+++                             optimizer, scheduler, cf.normalized, normalizers, device,
+++                             PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                             pde_loss_scaler=scaler_stage2)
+++            )
+++
+++            # Combine the logs from both stages for plotting and saving
+++            train_mse_hybrid_log = train_mse_s1 + train_mse_s2
+++            train_l2_hybrid_log = train_l2_s1 + train_l2_s2
+++            test_data_log = test_data_s1 + test_data_s2
+++            test_pde_loss_scaled_log = test_pde_s1 + test_pde_s2
+++            train_data_log = train_data_s1 + train_data_s2
+++            train_pde_scaled_log = train_pde_scl_s1 + train_pde_scl_s2
+++            test_loss_hybrid_log = test_loss_s1 + test_loss_s2
+++        else:
+++            # If only stage 1 was run, the final logs are just the stage 1 logs
+++            train_mse_hybrid_log = train_mse_s1
+++            train_l2_hybrid_log = train_l2_s1
+++            test_data_log = test_data_s1
+++            test_pde_loss_scaled_log = test_pde_s1
+++            train_data_log = train_data_s1
+++            train_pde_scaled_log = train_pde_scl_s1
+++            test_loss_hybrid_log = test_loss_s1
+++
+++        print(f"\n--- Training Finished. Saving model and logs to {model_path} ---")
+++        # The torch.save call remains the same, as the log variables have been correctly prepared
+++        torch.save({
+++            'model': model,
+++            'train_mse_log': train_mse_hybrid_log,
+++            'train_l2_log': train_l2_hybrid_log,
+++            'test_l2_log': test_data_log, # 'test_l2_log' is used by evaluator, it should contain data loss
+++            'test_pde_scaled_log': test_pde_loss_scaled_log,
+++            'train_data_log': train_data_log,
+++            'train_pde_scaled_log': train_pde_scaled_log,
+++            'test_loss_hybrid_log': test_loss_hybrid_log
+++        }, model_path)
+++
+++    else:  # Original Data-Driven Mode (This part remains unchanged)
+++        if network_name == 'FNO2d' or network_name == 'FNO3d':
+++            model, train_l2_log, test_l2_log = (
+++                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                               optimizer, scheduler, cf.normalized, normalizers, device))
+++            train_mse_log = []
+++        else:
+++            model, train_mse_log, train_l2_log, test_l2_log = (
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++        print(f"Saving model and logs to {model_path}")
+++        torch.save({
+++            'model': model,
+++            'train_mse_log': train_mse_log,
+++            'train_l2_log': train_l2_log,
+++            'test_l2_log': test_l2_log
+++        }, model_path)
+++'''
+++
++ end_time = time.time()
++ Final_time = round(end_time - start_time, 2)
++ print(f"Total Execution Time: {Final_time} seconds")
++ 
+++# ==================== START: CAPTURE PREDICTION AND EXACT SOLUTION TIMES ====================
+++print("\n--- Evaluating Model and Measuring Prediction Time ---")
++ evaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,
++                            time_history=(network_name == 'FNO2d'))
++ 
+++# Measure the time it takes to get predictions for the entire test set
+++prediction_start_time = time.time()
++ results = evaluator.evaluate(loss_fn=myloss)
+++prediction_end_time = time.time()
+++
+++# Calculate the model's prediction time
+++model_prediction_time = prediction_end_time - prediction_start_time
+++print(f"Model prediction time for the test set: {model_prediction_time:.4f} seconds")
+++
+++# IMPORTANT: Placeholder for the exact solution time.
+++# This value MUST be updated manually with the time it took the numerical
+++# solver to generate the ground truth data for the test set.
+++# The value here is just an example.
+++exact_solution_time = 3600.0  # Placeholder in seconds (e.g., 1 hour)
+++print(f"Using placeholder for exact solution time: {exact_solution_time:.2f} seconds. PLEASE UPDATE THIS VALUE.")
+++# ===================== END: CAPTURE PREDICTION AND EXACT SOLUTION TIMES =====================
+++
+++
++ inp = results['input']
++ pred = results['prediction']
++ exact = results['exact']
++@@ -326,7 +465,89 @@
++ print(f"Final indices for plotting: {final_indices}")
++ print(f"Final labels for plotting: {final_labels}")
++ 
+++
+++# =========================================================================================
+++# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===
+++# =========================================================================================
+++
+++################################################################
+++# Save Results to MATLAB .mat file
+++################################################################
+++print("\n--- Saving Results to .mat File ---")
+++mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
+++
+++# MODIFIED: Enhanced saving logic with fallbacks
+++def save_results(mat_filename, results_dict):
+++    try:
+++        # First try standard save
+++        scipy.io.savemat(mat_filename, results_dict)
+++        print(f"Saved with standard format to {mat_filename}")
+++    except ValueError as e:
+++        if "Format should be '4' or '5'" in str(e):
+++            print("Large data detected, trying v7.3 format...")
+++            try:
+++                scipy.io.savemat(mat_filename, results_dict, format='v7.3')
+++                print(f"Saved with v7.3 format to {mat_filename}")
+++            except Exception as e:
+++                print(f"v7.3 failed: {e}")
+++                # Fallback to HDF5
+++                h5_filename = mat_filename.replace('.mat', '.h5')
+++                with h5py.File(h5_filename, 'w') as f:
+++                    for k, v in results_dict.items():
+++                        f.create_dataset(k, data=v, compression='gzip')
+++                print(f"Saved as HDF5 to {h5_filename}")
+++        else:
+++            raise
+++
+++if PINN_MODE:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_hybrid_log, dtype=np.float32),  # MODIFIED: Added dtype
+++        'train_hybrid_loss': np.array(train_l2_hybrid_log, dtype=np.float32),
+++        'test_loss_hybrid_log': np.array(test_loss_hybrid_log, dtype=np.float32),
+++        'train_data_log': np.array(train_data_log, dtype=np.float32),
+++        'test_data_log': np.array(test_data_log, dtype=np.float32),
+++        'train_pde_scaled_log': np.array(train_pde_scaled_log, dtype=np.float32),
+++        'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),  # MODIFIED: Added astype
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_pde_weight': np.float32(PDE_WEIGHT),
+++        'config_pde_loss_scaler': np.float32(pde_loss_scaler),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++        'model_prediction_time': np.float32(model_prediction_time),  # ADDED
+++        'exact_solution_time': np.float32(exact_solution_time),      # ADDED
+++    }
+++else:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_log, dtype=np.float32),
+++        'train_l2_log': np.array(train_l2_log, dtype=np.float32),
+++        'test_l2_log': np.array(test_l2_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++        'model_prediction_time': np.float32(model_prediction_time),  # ADDED
+++        'exact_solution_time': np.float32(exact_solution_time),      # ADDED
+++    }
+++
+++# MODIFIED: Use the new save function
+++save_results(mat_filename, results_dict)
+++
++ # Plot XY-plane for the "Exact" solution trajectory (includes t=0)
+++
+++'''
++ plot_xy_plane_subplots(domain=cf.domain,
++                        field=u_exact_for_plot,
++                        field_name='Exact Solution',
++@@ -355,6 +576,7 @@
++                        plot_range=plot_range[2],
++                        problem=problem,
++                        network_name=network_name)
+++'''
++ 
++ # Calculate L2 norm on original full prediction
++ l2_norm_error = torch.norm(u_pred - u_exact, p=2)
++@@ -400,65 +622,4 @@
++     desired_times=final_labels
++ )
++ 
++-# =========================================================================================
++-# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===
++-# =========================================================================================
++-
++-################################################################
++-# Save Results to MATLAB .mat file
++-################################################################
++-print("\n--- Saving Results to .mat File ---")
++-import scipy.io
++-
++-mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
++-
++-if PINN_MODE:
++-    try:
++-        results_dict = {
++-            'train_mse_log': train_mse_hybrid_log,
++-            'train_hybrid_loss': np.array(train_l2_hybrid_log),
++-            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),
++-            'train_data_log': np.array(train_data_log),
++-            'test_data_log': np.array(test_data_log),
++-            'train_pde_scaled_log': np.array(train_pde_scaled_log),
++-            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,
++-            'config_pde_loss_scaler': pde_loss_scaler if PINN_MODE else 0.0,
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-else:
++-    try:
++-        results_dict = {
++-            'train_mse_log': np.array(train_mse_log),
++-            'train_l2_log': np.array(train_l2_log),
++-            'test_l2_log': np.array(test_l2_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-
++ print("\n--- Script Finished ---")
++\ No newline at end of file
++Index: training.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport torch.nn.functional as F\nfrom timeit import default_timer\nfrom tqdm import tqdm\n\ndef train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,\n              optimizer, scheduler, normalized, normalizer, device):\n    train_mse_log = []\n    train_l2_log = []\n    test_l2_log = []\n\n    if normalized:\n        # a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        # a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n        train_mse = 0\n        train_l2 = 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            #print(\"x shape\", x.shape)\n            out = model(x)\n            #print(f\"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}\")\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            train_mse += mse.item()\n            train_l2 += loss.item()\n\n        model.eval()\n        test_l2 = 0.0\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                #test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n\n        train_mse /= len(train_loader)\n        train_l2 /= (batch_size * len(train_loader))\n        test_l2 /= (batch_size * len(test_loader))\n\n        train_mse_log.append(train_mse)\n        train_l2_log.append(train_l2)\n        test_l2_log.append(test_l2)\n\n        # Update the learning rate based on the test_l2 metric\n        #scheduler.step(test_l2) ##\n\n\n        t2 = default_timer()\n        #print(ep, t2 - t1, train_mse, train_l2, test_l2)\n        if ep == 0:  # Print the header row once\n            print(\"No. Epoch   Time (s)       Train MSE      Train L2       Test L2\")\n\n        print(f\"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}\")\n\n    return model, train_mse_log, train_l2_log, test_l2_log\n\ndef train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,\n                   optimizer, scheduler, normalized, normalizer, device):\n    ntrain = len(train_loader) * train_loader.batch_size\n    ntest = len(test_loader) * test_loader.batch_size\n    train_mse_log = []\n    train_l2_log = []\n    test_l2_log = []\n    step = 1\n    if normalized:\n        a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n        train_l2_step = 0\n        train_l2_full = 0\n        for xx, yy in train_loader:\n            loss = 0\n            xx = xx.to(device)\n            yy = yy.to(device)\n            T = yy.shape[-1]\n            #print(f\" T : {T}\")\n            #print(f\"target shape: {yy.shape}\")\n            #print(f\"Input shape: {xx.shape}, y (target): {yy.shape}\")\n            for t in range(0, T, step):\n                y = yy[..., t:t + step]\n                im = model(xx)\n                #print(f\"Input shape: {xx.shape}, y (target): {y.shape}, prediction (model output): {im.shape}\")\n                #print(f\"target shape 2: {yy.shape}\")\n                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n\n                if t == 0:\n                    pred = im\n                else:\n                    pred = torch.cat((pred, im), -1)\n                xx = torch.cat((xx[..., step:], im), dim=-1)\n\n            train_l2_step += loss.item()\n            l2_full = myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1))\n            train_l2_full += l2_full.item()\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n        test_l2_step = 0\n        test_l2_full = 0\n        with torch.no_grad():\n            for xx, yy in test_loader:\n                loss = 0\n                xx = xx.to(device)\n                yy = yy.to(device)\n\n                for t in range(0, T, step):\n                    y = yy[..., t:t + step]\n                    im = model(xx)\n                    loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n\n                    if t == 0:\n                        pred = im\n                    else:\n                        pred = torch.cat((pred, im), -1)\n\n                    xx = torch.cat((xx[..., step:], im), dim=-1)\n\n                test_l2_step += loss.item()\n                test_l2_full += myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1)).item()\n\n        t2 = default_timer()\n        train_mse = train_l2_step / ntrain / (T / step)\n        train_l2 = train_l2_full / ntrain\n        test_l2 = test_l2_full / ntest\n\n        # Log the loss values\n        train_l2_log.append(train_l2_step / ntrain / (T / step))\n        test_l2_log.append(test_l2_step / ntest / (T / step))\n\n        if ep == 0:  # Print the header row once\n            print(\"No. Epoch   Time (s)       Train MSE      Train L2       Test L2\")\n\n        print(f\"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}\")\n\n    return model, train_l2_log, test_l2_log\n\n\n\n########################\n########################\n\ndef calculate_pde_residual(u_phys, grid_info, epsilon, problem, device):\n    \"\"\"\n    Calculates the residual for a specified 3D PDE on PHYSICAL data.\n    u_phys shape: (batch, Nx, Ny, Nz, T_out) - Denormalized data\n    grid_info: Dictionary containing Nx, Ny, Nz, Lx, Ly, Lz, dt_model, T_out\n    pde_params: Dictionary containing PDE-specific parameters\n    problem_name: String identifier for the PDE (e.g., 'SH3D', 'AC3D', 'CH3D', 'MBE3D', 'PFC3D')\n    device: PyTorch device\n    \"\"\"\n    batch_size, Nx, Ny, Nz, T_out = u_phys.shape\n    Lx, Ly, Lz = grid_info['Lx'], grid_info['Ly'], grid_info['Lz']\n    dt_model = grid_info['dt_model']\n\n    if T_out <= 1:\n        print(f\"Warning: T_out ({T_out}) <= 1 for problem {problem}. PDE loss requires T_out > 1. Returning zero loss.\")\n        return torch.zeros(1, device=device, requires_grad=True)\n\n    # --- Calculate Time Derivative (u/t) ---\n    du_dt = torch.zeros_like(u_phys)\n    du_dt[..., 0] = (u_phys[..., 1] - u_phys[..., 0]) / dt_model\n    du_dt[..., -1] = (u_phys[..., -1] - u_phys[..., -2]) / dt_model\n    if T_out > 2:\n       du_dt[..., 1:-1] = (u_phys[..., 2:] - u_phys[..., :-2]) / (2 * dt_model)\n\n    # --- Common Spectral Derivative Setup ---\n    _kx = torch.fft.fftfreq(Nx, d=Lx/Nx) * 2 * torch.pi\n    _ky = torch.fft.fftfreq(Ny, d=Ly/Ny) * 2 * torch.pi\n    _kz = torch.fft.fftfreq(Nz, d=Lz/Nz) * 2 * torch.pi\n\n    ikx_m, iky_m, ikz_m = torch.meshgrid(1j * _kx, 1j * _ky, 1j * _kz, indexing='ij')\n    ikx_m = ikx_m.to(device)\n    iky_m = iky_m.to(device)\n    ikz_m = ikz_m.to(device)\n\n    k2x_m, k2y_m, k2z_m = torch.meshgrid(_kx**2, _ky**2, _kz**2, indexing='ij')\n    # k2_m is kx^2 + ky^2 + kz^2. In Fourier space, laplacian is -k2_m\n    k2_m = (k2x_m + k2y_m + k2z_m).to(device)\n\n    u_hat = torch.fft.fftn(u_phys, dim=[1, 2, 3])\n\n    pde_residual = None\n\n    if problem == 'SH3D':\n        epsilon_sh = epsilon # pde_params.get('epsilon_sh')\n        if epsilon_sh is None: raise ValueError(\"Parameter 'epsilon_sh' not provided for SH3D.\")\n        k4_m = k2_m**2\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n        rhs_sh3d = -(u_phys**3) - (1 - epsilon_sh) * u_phys - biharm_u - 2 * lap_u\n        pde_residual = du_dt - rhs_sh3d\n\n    elif problem == 'AC3D':\n        Cahn_ac = epsilon # pde_params.get('Cahn_ac')\n        if Cahn_ac is None: raise ValueError(\"Parameter 'Cahn_ac' not provided for AC3D.\")\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        f_prime_u = u_phys**3 - u_phys\n        rhs_ac3d = Cahn_ac * lap_u - f_prime_u\n        pde_residual = du_dt - rhs_ac3d\n\n    elif problem == 'CH3D':\n        Cahn_ch = epsilon #  pde_params.get('Cahn_ch')\n        if Cahn_ch is None: raise ValueError(\"Parameter 'Cahn_ch' not provided for CH3D.\")\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        #mu_terms = (u_phys**3 - 3 * u_phys) - Cahn_ch * lap_u\n        mu_terms = (u_phys ** 3 -  u_phys) - Cahn_ch * lap_u\n        mu_terms_hat = torch.fft.fftn(mu_terms, dim=[1, 2, 3])\n        lap_mu_terms_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * mu_terms_hat\n        lap_mu_terms = torch.fft.ifftn(lap_mu_terms_hat, dim=[1, 2, 3]).real\n        rhs_ch3d = lap_mu_terms\n        pde_residual = du_dt - rhs_ch3d\n\n    elif problem == 'MBE3D':\n        epsilon_mbe = epsilon #  pde_params.get('epsilon_mbe')\n        if epsilon_mbe is None: raise ValueError(\"Parameter 'epsilon_mbe' not provided for MBE3D.\")\n        du_dx_hat = ikx_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dy_hat = iky_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dz_hat = ikz_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dx = torch.fft.ifftn(du_dx_hat, dim=[1, 2, 3]).real\n        du_dy = torch.fft.ifftn(du_dy_hat, dim=[1, 2, 3]).real\n        du_dz = torch.fft.ifftn(du_dz_hat, dim=[1, 2, 3]).real\n        grad_u_sq = du_dx**2 + du_dy**2 + du_dz**2\n        f1 = grad_u_sq * du_dx\n        f2 = grad_u_sq * du_dy\n        f3 = grad_u_sq * du_dz\n        f1_hat = torch.fft.fftn(f1, dim=[1, 2, 3])\n        f2_hat = torch.fft.fftn(f2, dim=[1, 2, 3])\n        f3_hat = torch.fft.fftn(f3, dim=[1, 2, 3])\n        div_term_hat = (ikx_m.unsqueeze(0).unsqueeze(-1) * f1_hat +\n                        iky_m.unsqueeze(0).unsqueeze(-1) * f2_hat +\n                        ikz_m.unsqueeze(0).unsqueeze(-1) * f3_hat)\n        div_term = torch.fft.ifftn(div_term_hat, dim=[1, 2, 3]).real\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        k4_m = k2_m**2\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term\n        pde_residual = du_dt - rhs_mbe3d\n\n    elif problem == 'PFC3D':\n        epsilon_pfc = epsilon # pde_params.get('epsilon_pfc') # Parameter 'r' in PFC, often -(epsilon)\n        if epsilon_pfc is None: raise ValueError(\"Parameter 'epsilon_pfc' not provided for PFC3D.\")\n\n        # Calculate necessary derivatives\n        # -u  (term1_spatial_operator * u)\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n\n        # u   (term2_spatial_operator * u)\n        k4_m = k2_m**2\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n\n        # -u  (term3_spatial_operator * u)\n        k6_m = k2_m**3 # Be careful with sign if k2_m is just kx^2+ky^2+kz^2\n                      # Since k^6 in Fourier space corresponds to (-^2)^3 = -^6 if direct multiplication\n                      # Or (i k)^6 = -k^6.\n                      # The MATLAB denominator (1/dt + (1-eps)k^2 + k^6) implies the k^6 term is positive.\n                      # So in real space, this corresponds to -u (because -(-)^3 u = u is not what we want)\n                      # A positive k^6 in Fourier space means we multiply by k^6, which is (-(laplacian_operator))^3,\n                      # this will become -laplacian_operator^3 which is -.\n                      # The MATLAB form `(pp2+qq2+rr2).^3` is `(k^2)^3 = k^6`.\n                      # So this term becomes `k^6 * u_hat` -> `u` (with a negative sign from implicit to explicit)\n        # Or, if (pp2+qq2+rr2) is k^2, then (pp2+qq2+rr2)^3 is k^6.\n        # The term in the denominator is `+ k^6`, so when moved to RHS it's `-k^6 u_hat`.\n        # `-k^6 u_hat` corresponds to `u` in real space.\n        triharm_u_hat = -k6_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        triharm_u = torch.fft.ifftn(triharm_u_hat, dim=[1, 2, 3]).real\n\n\n        # (u)\n        u_cubed = u_phys**3\n        u_cubed_hat = torch.fft.fftn(u_cubed, dim=[1, 2, 3])\n        lap_u_cubed_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_cubed_hat\n        lap_u_cubed = torch.fft.ifftn(lap_u_cubed_hat, dim=[1, 2, 3]).real\n\n        # PDE: u/t + (1-)u + 2u + u + (u) = 0\n        # RHS = - ( (1-_pfc)u + 2u + u + (u) )\n        # Let's use the parameter `epsilon` from PFC MATLAB as `r` (undercooling param)\n        # A common PFC form is du/dt = nabla^2 * ( (r)u + u^3 - (1+nabla^2)^2 u )\n        # du/dt = nabla^2 * ( ru + u^3 - (1 + 2 nabla^2 + nabla^4)u )\n        # du/dt = r nabla^2 u + nabla^2(u^3) - nabla^2 u - 2 nabla^4 u - nabla^6 u\n        # du/dt = (r-1) nabla^2 u - 2 nabla^4 u - nabla^6 u + nabla^2(u^3)\n        # Here 'r' from literature is often called 'epsilon' in PFC code.\n        # Let's match the form derived from MATLAB:\n        # u/t = -(1-)u - 2u - u - (u)\n        # Residual: du_dt - [-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed]\n\n        term1_spatial = (1 - epsilon_pfc) * lap_u # (1-eps)(-nabla^2 u) -> (eps-1)nabla^2 u\n        term2_spatial = 2 * biharm_u             # 2 nabla^4 u\n        term3_spatial = triharm_u                # nabla^6 u\n        term4_nonlinear = lap_u_cubed            # nabla^2 (u^3)\n\n        # According to the derived form: u/t = -(1-)u - 2u - u - (u)\n        # residual = du_dt - (-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed)\n        rhs_pfc3d = -(1 - epsilon_pfc) * lap_u - 2 * biharm_u - triharm_u - lap_u_cubed\n        pde_residual = du_dt - rhs_pfc3d\n\n    else:\n        raise ValueError(f\"Unknown problem_name: {problem}. PDE residual not defined.\")\n\n    if pde_residual is not None:\n        loss_pde = F.mse_loss(pde_residual, torch.zeros_like(pde_residual))\n    else:\n        loss_pde = torch.zeros(1, device=device, requires_grad=True)\n\n    return loss_pde\n\n\ndef train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,\n                    optimizer, scheduler, normalized, normalizer, device, pde_weight, grid_info, epsilon, problem, pde_loss_scaler=1.0, can_compute_pde = True):\n    train_mse_hybrid_log = []\n    train_l2_hybrid_log = []\n\n    test_mse_hybrid_log = []\n    test_loss_hybrid_log = []\n\n\n    train_data_log = []\n    test_data_log = []\n\n    train_pde_scaled_log = []\n    train_pde_raw_log = []\n\n    test_pde_loss_scaled_log = []\n    test_pde_loss_raw_log = []\n\n\n    if normalized:\n        # a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        # a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n\n        train_mse_hybrid = 0\n        train_l2_hybrid = 0\n\n        train_data = 0.0\n        train_pde_scaled = 0.0\n        train_pde_raw = 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            # print(\"x shape\", x.shape)\n            out = model(x)\n            # print(f\"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}\")\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n\n            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n            loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n            # --- PDE Loss Calculation (on physical scale) ---\n            if can_compute_pde:\n                # loss_pde_raw = calculate_pde_residual_sh3d(pred_phys, grid_info, epsilon, device)\n                #loss_pde_raw = calculate_pde_residual_sh3d(out, grid_info, epsilon, device)\n                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                loss_pde_scaled = loss_pde_raw * pde_loss_scaler  # Apply scaling\n\n            loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled\n            mse_hybrid = (1.0 - pde_weight) * mse_data + pde_weight * loss_pde_scaled\n\n\n            loss_hybrid.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # Hybrid\n            train_mse_hybrid += mse_hybrid.item()\n            train_l2_hybrid += loss_hybrid.item()\n            ##\n            train_data += loss_data.item()\n            train_pde_scaled += loss_pde_scaled.item()\n            train_pde_raw += loss_pde_raw.item()\n\n\n        model.eval()\n        test_data= 0.0 # data\n        test_mse_data = 0.0\n        test_pde_loss_scaled = 0.0\n        test_pde_loss_raw = 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                # test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n                test_mse_data += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n                test_data += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n\n                # PDE Loss\n                if can_compute_pde:\n                    #loss_pde_test_raw = calculate_pde_residual_sh3d(out, grid_info, epsilon, device)\n                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n\n                test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()\n                test_pde_loss_raw += loss_pde_test_raw.item()\n\n            test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled\n            test_mse_hybrid = (1.0 - pde_weight) * test_mse_data + pde_weight * test_pde_loss_scaled\n\n        # Train Hybrid\n        train_mse_hybrid /= len(train_loader)\n        train_l2_hybrid /= (batch_size * len(train_loader))\n\n        # Test Hybrid\n        test_mse_hybrid /= len(test_loader)\n        test_loss_hybrid /= (batch_size * len(test_loader))\n\n        # train data\n        train_data /= (batch_size * len(train_loader))\n        # test data\n        test_data /= (batch_size * len(test_loader))\n        # train pde\n        train_pde_scaled /= (batch_size * len(train_loader))\n        train_pde_raw /= (batch_size * len(train_loader))\n        # test pde\n        test_pde_loss_scaled /= (batch_size * len(test_loader))\n        test_pde_loss_raw /= (batch_size * len(test_loader))\n\n\n\n\n        # train Hybrid\n        train_mse_hybrid_log.append(train_mse_hybrid)\n        train_l2_hybrid_log.append(train_l2_hybrid)\n\n        # Test Hybrid\n        test_mse_hybrid_log.append(test_mse_hybrid)\n        test_loss_hybrid_log.append(test_loss_hybrid)\n\n        # train data\n        train_data_log.append(train_data)\n        # test data\n        test_data_log.append(test_data)\n        # train pde\n        train_pde_scaled_log.append(train_pde_scaled)\n        train_pde_raw_log.append(train_pde_raw)\n        # test pde\n        test_pde_loss_scaled_log.append(test_pde_loss_scaled)\n        test_pde_loss_raw_log.append(test_pde_loss_raw)\n\n        # Update the learning rate based on the test_l2 metric\n        # scheduler.step(test_l2) ##\n\n        t2 = default_timer()\n\n        if ep == 0:\n            # Update header to reflect spectral raw PDE loss\n            print(\"No. Epoch | Time (s)   | Train MSE Hyb  | Train L2 Hyb  | test L2 Hyb | Test L2 data        | test_pde scl.   | test_pde_raw \")\n            print(\"---------------------------------------------------------------------------------------------\")\n        # Update print statement\n        print(f\"{ep:<9}  {t2 - t1:<10.4f}   {train_mse_hybrid:<10.6e}     {train_l2_hybrid:<10.6e} {test_loss_hybrid:<10.6e}  {test_data:<24.6e} {test_pde_loss_scaled:<24.6e} {test_pde_loss_raw:<24.6e} \")\n\n    return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log\n\n\ndef compute_initial_loss_scaler(model, loader, myloss, normalized, normalizer, device, grid_info, epsilon, problem):\n    \"\"\"\n    Computes the scaling factor to balance data and PDE losses.\n    \"\"\"\n    model.eval()\n\n    # Get one batch from the loader\n    x, y = next(iter(loader))\n    x, y = x.to(device), y.to(device)\n\n    with torch.no_grad():\n        out = model(x)\n        if normalized:\n            y_normalizer = normalizer[1].to(device)\n            out = y_normalizer.decode(out)\n            y = y_normalizer.decode(y)\n\n        # Calculate initial data loss\n        initial_loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n        # Calculate initial raw PDE loss\n        initial_loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n\n        # Handle case where PDE loss is zero to avoid division by zero\n        if initial_loss_pde_raw.item() < 1e-12:\n            scaler = 1.0\n            print(\"Warning: Initial PDE loss is near zero. Setting scaler to 1.0.\")\n        else:\n            # The scaler is the ratio of the two losses\n            scaler = initial_loss_data.item() / initial_loss_pde_raw.item()\n            print(f\"Computed initial loss scaler: {scaler:.4f}\")\n            print(f\"  - Initial Data Loss: {initial_loss_data.item():.6f}\")\n            print(f\"  - Initial PDE Loss (raw): {initial_loss_pde_raw.item():.6f}\")\n\n    model.train()  # Set model back to training mode\n    return scaler\n\n\n''''\ndef train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,\n                 optimizer, scheduler, normalized, normalizer, device, pde_weight,\n                 grid_info, epsilon, problem, pde_loss_scaler='auto', can_compute_pde=True):\n    # --- Logging Lists ---\n    train_mse_hybrid_log, train_l2_hybrid_log = [], []\n    test_mse_hybrid_log, test_loss_hybrid_log = [], []\n    train_data_log, test_data_log = [], []\n    train_pde_scaled_log, train_pde_raw_log = [], []\n    test_pde_loss_scaled_log, test_pde_loss_raw_log = [], []\n\n    if normalized:\n        y_normalizer = normalizer[1].to(device)\n    else:\n        y_normalizer = None\n\n    # ====================================================================================\n    # Automatic PDE Loss Scaler Calculation\n    # ====================================================================================\n    if pde_loss_scaler == 'auto' and can_compute_pde and pde_weight > 0:\n        print(\"--- Calibrating PDE loss scaler automatically ---\")\n        model.eval()\n        total_data_loss_for_scaling = 0.0\n        total_pde_loss_for_scaling = 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n                out = model(x)\n\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                # Calculate data loss for this batch\n                data_loss_batch = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n                total_data_loss_for_scaling += data_loss_batch.item()\n\n                # Calculate raw PDE loss for this batch\n                pde_loss_batch_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                total_pde_loss_for_scaling += pde_loss_batch_raw.item()\n\n        # Calculate the average losses\n        avg_data_loss = total_data_loss_for_scaling / len(test_loader)\n        avg_pde_loss = total_pde_loss_for_scaling / len(test_loader)\n\n        # Compute the scaler\n        if avg_pde_loss > 1e-8:  # Avoid division by zero\n            pde_loss_scaler = avg_data_loss / avg_pde_loss\n        else:\n            pde_loss_scaler = 1.0  # Default to 1 if PDE loss is negligible\n\n        print(f\"Initial Avg Data Loss: {avg_data_loss:.6e}\")\n        print(f\"Initial Avg Raw PDE Loss: {avg_pde_loss:.6e}\")\n        print(f\"Calculated pde_loss_scaler: {pde_loss_scaler:.6f}\")\n        print(\"---------------------------------------------\")\n\n    elif not can_compute_pde or pde_weight == 0:\n        pde_loss_scaler = 0.0  # No scaling needed if PDE is not used\n    elif isinstance(pde_loss_scaler, str):  # Handle cases like 'auto' when PDE is off\n        pde_loss_scaler = 1.0\n\n    # --- Main Training Loop ---\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n\n        # Initialize epoch-level accumulators\n        train_mse_hybrid, train_l2_hybrid = 0.0, 0.0\n        train_data, train_pde_scaled, train_pde_raw = 0.0, 0.0, 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            optimizer.zero_grad()\n\n            out = model(x)\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n\n            # --- Loss Calculation ---\n            loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n\n            loss_pde_scaled = torch.tensor(0.0, device=device)\n            loss_pde_raw = torch.tensor(0.0, device=device)\n\n            if can_compute_pde and pde_weight > 0:\n                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                loss_pde_scaled = loss_pde_raw * pde_loss_scaler\n\n            # Combine losses\n            loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled\n            mse_hybrid = (1.0 - pde_weight) * mse_data + pde_weight * loss_pde_scaled\n\n            loss_hybrid.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # --- Accumulate Metrics ---\n            train_mse_hybrid += mse_hybrid.item()\n            train_l2_hybrid += loss_hybrid.item()\n            train_data += loss_data.item()\n            train_pde_scaled += loss_pde_scaled.item()\n            train_pde_raw += loss_pde_raw.item()\n\n        # --- Evaluation ---\n        model.eval()\n        test_data, test_mse_data = 0.0, 0.0\n        test_pde_loss_scaled, test_pde_loss_raw = 0.0, 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                test_data += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n                test_mse_data += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean').item()\n\n                if can_compute_pde and pde_weight > 0:\n                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                    test_pde_loss_raw += loss_pde_test_raw.item()\n                    test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()\n\n        # --- Normalize and Log Metrics ---\n        # Note: We divide by len(loader) because item() gives the mean loss for the batch.\n        # This computes the average of the batch means.\n\n        # Averages for training set\n        train_mse_hybrid /= len(train_loader)\n        train_l2_hybrid /= len(train_loader)\n        train_data /= len(train_loader)\n        train_pde_scaled /= len(train_loader)\n        train_pde_raw /= len(train_loader)\n\n        # Averages for test set\n        test_mse_data /= len(test_loader)\n        test_data /= len(test_loader)\n        test_pde_loss_scaled /= len(test_loader)\n        test_pde_loss_raw /= len(test_loader)\n\n        # Calculate final hybrid test losses from averages\n        test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled\n        test_mse_hybrid = (1.0 - pde_weight) * test_mse_data + pde_weight * test_pde_loss_scaled\n\n        # Append to logs\n        train_mse_hybrid_log.append(train_mse_hybrid)\n        train_l2_hybrid_log.append(train_l2_hybrid)\n        test_mse_hybrid_log.append(test_mse_hybrid)\n        test_loss_hybrid_log.append(test_loss_hybrid)\n        train_data_log.append(train_data)\n        test_data_log.append(test_data)\n        train_pde_scaled_log.append(train_pde_scaled)\n        train_pde_raw_log.append(train_pde_raw)\n        test_pde_loss_scaled_log.append(test_pde_loss_scaled)\n        test_pde_loss_raw_log.append(test_pde_loss_raw)\n\n        t2 = default_timer()\n\n        if ep == 0:\n            print(\"--- Starting Training ---\")\n            print(f\"PDE Loss Scaler is set to: {pde_loss_scaler:.6f}\")\n            print(\n                \"No. Epoch | Time (s)   | Train MSE Hyb  | Train L2 Hyb   | Test L2 Hyb    | Test L2 data   | Test PDE Scl.  | Test PDE Raw\")\n            print(\n                \"-------------------------------------------------------------------------------------------------------------------------\")\n\n        # CORRECTED PRINT STATEMENT:\n        print(\n            f\"{ep:<9} | {t2 - t1:<10.4f} | {train_mse_hybrid:<14.6e} | {train_l2_hybrid:<14.6e} | {test_loss_hybrid:<14.6e} | {test_data:<14.6e} | {test_pde_loss_scaled:<14.6e} | {test_pde_loss_raw:<14.6e}\")\n\n    return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log\n'''
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/training.py b/training.py
++--- a/training.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/training.py	(date 1754475689201)
++@@ -1,8 +1,10 @@
++ import torch
++ import torch.nn.functional as F
++ from timeit import default_timer
+++import numpy as np
++ from tqdm import tqdm
++ 
+++'''
++ def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
++               optimizer, scheduler, normalized, normalizer, device):
++     train_mse_log = []
++@@ -65,7 +67,6 @@
++         # Update the learning rate based on the test_l2 metric
++         #scheduler.step(test_l2) ##
++ 
++-
++         t2 = default_timer()
++         #print(ep, t2 - t1, train_mse, train_l2, test_l2)
++         if ep == 0:  # Print the header row once
++@@ -75,6 +76,347 @@
++ 
++     return model, train_mse_log, train_l2_log, test_l2_log
++ 
+++'''
+++
+++
+++# Make sure SobolevLoss is imported or defined before this function is called
+++# so that isinstance() can work correctly.
+++# from your_utilities import SobolevLoss
+++
+++def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
+++              optimizer, scheduler, normalized, normalizer, device):
+++    # This is a placeholder for the real import.
+++    # In your actual code, you must import SobolevLoss from utilities.py
+++    from utilities import SobolevLoss
+++
+++    train_mse_log = []
+++    train_l2_log = []
+++    test_l2_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++            # --- THIS IS THE FIX ---
+++            # If the loss is SobolevLoss, pass the original multi-dimensional tensors.
+++            # Otherwise, for losses like LpLoss, pass the flattened tensors.
+++            if isinstance(myloss, SobolevLoss):
+++                loss = myloss(out, y)  # Pass the un-flattened tensor
+++            else:
+++                loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))  # The original behavior
+++            # --- END OF FIX ---
+++
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++            train_mse += mse.item()
+++            train_l2 += loss.item()
+++
+++        model.eval()
+++        test_l2 = 0.0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                # --- APPLY THE SAME FIX HERE ---
+++                if isinstance(myloss, SobolevLoss):
+++                    test_l2 += myloss(out, y).item()
+++                else:
+++                    test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()
+++                # --- END OF FIX ---
+++
+++        train_mse /= len(train_loader)
+++        train_l2 /= (batch_size * len(train_loader))
+++        test_l2 /= (batch_size * len(test_loader))
+++
+++        train_mse_log.append(train_mse)
+++        train_l2_log.append(train_l2)
+++        test_l2_log.append(test_l2)
+++
+++        t2 = default_timer()
+++        if ep == 0:
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log
+++''''
+++def train_fno4d(model, myloss, epochs, batch_size, train_loader, test_loader,
+++              optimizer, scheduler, normalized, normalizer, device):
+++    train_mse_log = []
+++    train_l2_log = []
+++    #val_mse_log = []  # New
+++    #val_l2_log = []  # New
+++    test_l2_log = []
+++    test_mse_log = []
+++
+++    # --- Early Stopping Parameters (Optional) ---
+++    #best_val_loss = float('inf')
+++    #patience_counter = 0
+++    #patience_epochs = 5 # 10  # Example: stop if no improvement for 10 epochs
+++    #best_model_state = None
+++    # ---
+++
+++    if normalized:
+++        # a_normalizer = normalizer[0].to(device)
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        # a_normalizer = None
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            #print("x shape", x.shape)
+++            out = model(x)
+++            print(f"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}")
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                #print("out shape1:", out.shape)
+++                y = y_normalizer.decode(y)
+++            print("out shape2 :", out.shape)
+++            print("y shape:", y.shape)
+++
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
+++
+++            loss.backward()
+++            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Adjust max_norm if needed
+++            optimizer.step()
+++            scheduler.step()
+++            train_mse += mse.item()
+++            train_l2 += loss.item()
+++
+++        # Test
+++
+++        model.eval()
+++        test_l2 = 0.0
+++        test_mse = 0.0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                #test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()
+++                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()
+++                test_mse += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++
+++        test_l2 /= (batch_size * len(test_loader))
+++        test_mse /= (batch_size * len(test_loader))
+++
+++        test_l2_log.append(test_l2)
+++        test_mse_log.append(test_mse)
+++        # Update the learning rate based on the test_l2 metric
+++        #scheduler.step(test_l2) ##
+++
+++
+++        t2 = default_timer()
+++        #print(ep, t2 - t1, train_mse, train_l2, test_l2)
+++
+++
+++        if ep == 0:
+++            # Update header to reflect spectral raw PDE loss
+++            print("No. Epoch | Time (s)   | Train MSE     | Test mse     | Train L2      |  Test L2 ")
+++            print("---------------------------------------------------------------------------------------")
+++        # Update print statement
+++        print(f"{ep:<9} | {t2 - t1:<10.4f} | {train_mse:<10.6e} | {test_mse:<10.6e} | {train_l2:<10.6e} | {test_l2:<24.6e} ")
+++
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log, test_mse_log
+++'''
+++
+++
+++def train_fno4d(model, myloss, epochs, batch_size, train_loader, test_loader,
+++                optimizer, scheduler, normalized, normalizer, device):
+++    """Training function for FNO4d model."""
+++    ntrain = len(train_loader) * train_loader.batch_size
+++    ntest = len(test_loader) * test_loader.batch_size
+++
+++    train_mse_log = []
+++    train_l2_log = []
+++    test_l2_log = []
+++    test_mse_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
+++
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++
+++            train_mse += mse.item()
+++            train_l2 += loss.item() / batch_size  # Normalize by batch size
+++
+++        model.eval()
+++        test_l2 = 0
+++        test_mse = 0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                test_mse += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean').item()
+++                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item() / batch_size  # Normalize here too
+++
+++        # Average over number of batches
+++        train_mse /= len(train_loader)
+++        train_l2 /= len(train_loader)
+++        test_mse /= len(test_loader)
+++        test_l2 /= len(test_loader)
+++
+++        train_mse_log.append(train_mse)
+++        train_l2_log.append(train_l2)
+++        test_l2_log.append(test_l2)
+++        test_mse_log.append(test_mse)
+++
+++        t2 = default_timer()
+++
+++        if ep == 0:
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test MSE       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_mse:<13.10f} {test_l2:<13.10f}")
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log
+++
+++
+++
+++import torch
+++import torch.nn.functional as F
+++from timeit import default_timer
+++
+++'''
+++def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
+++              optimizer, scheduler, normalized, normalizer, device):
+++    train_mse_log = []
+++    train_l2_log = []
+++    test_l2_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            # This MSE is kept for logging the data-only error
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++            # --- MINIMAL CHANGE HERE ---
+++            # The loss function now receives the UN-FLATTENED tensors
+++            # so it can compute spatial gradients for the Sobolev loss.
+++            loss = myloss(out, y)
+++
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++            train_mse += mse.item()
+++            train_l2 += loss.item()
+++
+++        model.eval()
+++        test_l2 = 0.0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                # --- MINIMAL CHANGE HERE ---
+++                # Also pass the un-flattened tensors during evaluation.
+++                test_l2 += myloss(out, y).item()
+++
+++        train_mse /= len(train_loader)
+++        train_l2 /= (batch_size * len(train_loader))  # Kept original scaling
+++        test_l2 /= (batch_size * len(test_loader))  # Kept original scaling
+++
+++        train_mse_log.append(train_mse)
+++        train_l2_log.append(train_l2)
+++        test_l2_log.append(test_l2)
+++
+++        t2 = default_timer()
+++        if ep == 0:  # Print the header row once
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log
+++'''
+++
+++
++ def train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,
++                    optimizer, scheduler, normalized, normalizer, device):
++     ntrain = len(train_loader) * train_loader.batch_size
++@@ -164,7 +506,110 @@
++ 
++     return model, train_l2_log, test_l2_log
++ 
+++'''
+++def train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,
+++                   optimizer, scheduler, normalized, normalizer, device):
+++    ntrain = len(train_loader) * train_loader.batch_size
+++    ntest = len(test_loader) * test_loader.batch_size
+++    train_l2_log = []
+++    test_l2_log = []
+++    step = 1
+++
+++    # Normalizer setup is unchanged
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_l2_step = 0
+++        train_l2_full = 0
+++        for xx, yy in train_loader:
+++            loss = 0
+++            xx = xx.to(device)
+++            yy = yy.to(device)
+++            T = yy.shape[-1]
+++
+++            # The auto-regressive loop for one-step-ahead prediction
+++            for t in range(0, T, step):
+++                y = yy[..., t:t + step]
+++                im = model(xx)
+++
+++                # --- MINIMAL CHANGE #1 ---
+++                # Pass the un-flattened tensors (im, y) to myloss.
+++                # Both have shape (batch, s, s, s, 1) here.
+++                loss += myloss(im, y)
+++
+++                if t == 0:
+++                    pred = im
+++                else:
+++                    pred = torch.cat((pred, im), -1)
+++
+++                # Update input for next time step
+++                xx = torch.cat((xx[..., step:], im), dim=-1)
+++
+++            train_l2_step += loss.item()
+++
+++            # --- MINIMAL CHANGE #2 ---
+++            # Also pass the un-flattened full tensors (pred, yy) to myloss.
+++            # Both have shape (batch, s, s, s, T_out) here.
+++            l2_full = myloss(pred, yy)
+++            train_l2_full += l2_full.item()
+++
+++            optimizer.zero_grad()
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++
+++        # Evaluation loop
+++        test_l2_step = 0
+++        test_l2_full = 0
+++        with torch.no_grad():
+++            for xx, yy in test_loader:
+++                loss = 0
+++                xx = xx.to(device)
+++                yy = yy.to(device)
+++                T = yy.shape[-1]  # T is defined inside the loop for safety
+++
+++                for t in range(0, T, step):
+++                    y = yy[..., t:t + step]
+++                    im = model(xx)
+++
+++                    # --- MINIMAL CHANGE #3 ---
+++                    loss += myloss(im, y)
+++
+++                    if t == 0:
+++                        pred = im
+++                    else:
+++                        pred = torch.cat((pred, im), -1)
+++
+++                    xx = torch.cat((xx[..., step:], im), dim=-1)
+++
+++                test_l2_step += loss.item()
+++
+++                # --- MINIMAL CHANGE #4 ---
+++                test_l2_full += myloss(pred, yy).item()
++ 
+++        t2 = default_timer()
+++        # The meaning of these metrics is slightly different now, but the calculation is kept
+++        train_mse = train_l2_step / ntrain / (T / step)
+++        train_l2 = train_l2_full / ntrain
+++        test_l2 = test_l2_full / ntest
+++
+++        # Log the loss values
+++        train_l2_log.append(train_l2_step / ntrain / (T / step))
+++        test_l2_log.append(test_l2_step / ntest / (T / step))
+++
+++        if ep == 0:  # Print the header row once
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
+++
+++    # Returning the logs for the one-step-ahead loss
+++    return model, train_l2_log, test_l2_log
+++'''
++ 
++ ########################
++ ########################
++@@ -227,12 +672,15 @@
++         if Cahn_ac is None: raise ValueError("Parameter 'Cahn_ac' not provided for AC3D.")
++         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
++-        f_prime_u = u_phys**3 - u_phys
++-        rhs_ac3d = Cahn_ac * lap_u - f_prime_u
+++        #f_prime_u = u_phys**3 - u_phys
+++        #rhs_ac3d = Cahn_ac * lap_u - f_prime_u ##
+++        f_prime_u = (1/Cahn_ac) * (u_phys ** 3 - u_phys)
+++        rhs_ac3d = lap_u - f_prime_u  ##
+++
++         pde_residual = du_dt - rhs_ac3d
++ 
++     elif problem == 'CH3D':
++-        Cahn_ch = epsilon #  pde_params.get('Cahn_ch')
+++        Cahn_ch = epsilon**2 #  pde_params.get('Cahn_ch')
++         if Cahn_ch is None: raise ValueError("Parameter 'Cahn_ch' not provided for CH3D.")
++         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
++@@ -269,66 +717,39 @@
++         k4_m = k2_m**2
++         biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real
++-        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term
+++        #rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term
+++        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u + div_term
++         pde_residual = du_dt - rhs_mbe3d
++ 
++     elif problem == 'PFC3D':
++-        epsilon_pfc = epsilon # pde_params.get('epsilon_pfc') # Parameter 'r' in PFC, often -(epsilon)
+++        epsilon_pfc = epsilon
++         if epsilon_pfc is None: raise ValueError("Parameter 'epsilon_pfc' not provided for PFC3D.")
++-
++-        # Calculate necessary derivatives
++-        # -u  (term1_spatial_operator * u)
+++        # Calculate necessary spatial derivatives using Fourier transforms
+++        # u (Laplacian)
++         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
++ 
++-        # u   (term2_spatial_operator * u)
++-        k4_m = k2_m**2
+++        # u (Biharmonic)
+++        k4_m = k2_m ** 2
++         biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real
++ 
++-        # -u  (term3_spatial_operator * u)
++-        k6_m = k2_m**3 # Be careful with sign if k2_m is just kx^2+ky^2+kz^2
++-                      # Since k^6 in Fourier space corresponds to (-^2)^3 = -^6 if direct multiplication
++-                      # Or (i k)^6 = -k^6.
++-                      # The MATLAB denominator (1/dt + (1-eps)k^2 + k^6) implies the k^6 term is positive.
++-                      # So in real space, this corresponds to -u (because -(-)^3 u = u is not what we want)
++-                      # A positive k^6 in Fourier space means we multiply by k^6, which is (-(laplacian_operator))^3,
++-                      # this will become -laplacian_operator^3 which is -.
++-                      # The MATLAB form `(pp2+qq2+rr2).^3` is `(k^2)^3 = k^6`.
++-                      # So this term becomes `k^6 * u_hat` -> `u` (with a negative sign from implicit to explicit)
++-        # Or, if (pp2+qq2+rr2) is k^2, then (pp2+qq2+rr2)^3 is k^6.
++-        # The term in the denominator is `+ k^6`, so when moved to RHS it's `-k^6 u_hat`.
++-        # `-k^6 u_hat` corresponds to `u` in real space.
+++        # u (Triharmonic)
+++        k6_m = k2_m ** 3
+++        # In Fourier space, multiplying by -k^6 corresponds to the  operator
++         triharm_u_hat = -k6_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         triharm_u = torch.fft.ifftn(triharm_u_hat, dim=[1, 2, 3]).real
++ 
++-
++         # (u)
++-        u_cubed = u_phys**3
+++        u_cubed = u_phys ** 3
++         u_cubed_hat = torch.fft.fftn(u_cubed, dim=[1, 2, 3])
++         lap_u_cubed_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_cubed_hat
++         lap_u_cubed = torch.fft.ifftn(lap_u_cubed_hat, dim=[1, 2, 3]).real
++ 
++-        # PDE: u/t + (1-)u + 2u + u + (u) = 0
++-        # RHS = - ( (1-_pfc)u + 2u + u + (u) )
++-        # Let's use the parameter `epsilon` from PFC MATLAB as `r` (undercooling param)
++-        # A common PFC form is du/dt = nabla^2 * ( (r)u + u^3 - (1+nabla^2)^2 u )
++-        # du/dt = nabla^2 * ( ru + u^3 - (1 + 2 nabla^2 + nabla^4)u )
++-        # du/dt = r nabla^2 u + nabla^2(u^3) - nabla^2 u - 2 nabla^4 u - nabla^6 u
++-        # du/dt = (r-1) nabla^2 u - 2 nabla^4 u - nabla^6 u + nabla^2(u^3)
++-        # Here 'r' from literature is often called 'epsilon' in PFC code.
++-        # Let's match the form derived from MATLAB:
++-        # u/t = -(1-)u - 2u - u - (u)
++-        # Residual: du_dt - [-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed]
++-
++-        term1_spatial = (1 - epsilon_pfc) * lap_u # (1-eps)(-nabla^2 u) -> (eps-1)nabla^2 u
++-        term2_spatial = 2 * biharm_u             # 2 nabla^4 u
++-        term3_spatial = triharm_u                # nabla^6 u
++-        term4_nonlinear = lap_u_cubed            # nabla^2 (u^3)
++-
++-        # According to the derived form: u/t = -(1-)u - 2u - u - (u)
++-        # residual = du_dt - (-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed)
++-        rhs_pfc3d = -(1 - epsilon_pfc) * lap_u - 2 * biharm_u - triharm_u - lap_u_cubed
+++        # Construct the Right-Hand Side (RHS) of the PDE to match the MATLAB code
+++        # PDE: u/t = (1-)u + 2u + u + (u)
+++        rhs_pfc3d = (1 - epsilon_pfc) * lap_u + 2 * biharm_u + triharm_u + lap_u_cubed
+++        # The residual is the difference between the time derivative and the RHS
++         pde_residual = du_dt - rhs_pfc3d
++ 
++     else:
++@@ -503,42 +924,117 @@
++     return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log
++ 
++ 
++-def compute_initial_loss_scaler(model, loader, myloss, normalized, normalizer, device, grid_info, epsilon, problem):
++-    """
++-    Computes the scaling factor to balance data and PDE losses.
++-    """
++-    model.eval()
+++'''
+++
+++def train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,
+++                 optimizer, scheduler, normalized, normalizer, device, pde_weight, grid_info, epsilon, problem,
+++                 pde_loss_scaler=1.0, can_compute_pde=True):
+++    train_mse_hybrid_log = []
+++    train_l2_hybrid_log = []
+++    test_loss_hybrid_log = []
+++    train_data_log = []
+++    test_data_log = []
+++    train_pde_scaled_log = []
+++    test_pde_loss_scaled_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++
+++        train_mse_hybrid = 0
+++        train_l2_hybrid = 0
+++        train_data = 0.0
+++        train_pde_scaled = 0.0
+++
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            # --- MINIMAL CHANGE #1 ---
+++            # Pass the UN-FLATTENED tensors to myloss.
+++            loss_data = myloss(out, y)
+++
+++            # Kept for logging purposes
+++            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++            if can_compute_pde and pde_weight > 0:
+++                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
+++                loss_pde_scaled = loss_pde_raw * pde_loss_scaler
+++                loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled
+++            else:
+++                loss_pde_scaled = torch.tensor(0.0)  # For logging
+++                loss_hybrid = loss_data
+++
+++            loss_hybrid.backward()
+++            optimizer.step()
+++            scheduler.step()
+++
+++            train_l2_hybrid += loss_hybrid.item()
+++            train_data += loss_data.item()
+++            train_pde_scaled += loss_pde_scaled.item()
+++
+++        model.eval()
+++        test_data = 0.0
+++        test_pde_loss_scaled = 0.0
++ 
++-    # Get one batch from the loader
++-    x, y = next(iter(loader))
++-    x, y = x.to(device), y.to(device)
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
++ 
++-    with torch.no_grad():
++-        out = model(x)
++-        if normalized:
++-            y_normalizer = normalizer[1].to(device)
++-            out = y_normalizer.decode(out)
++-            y = y_normalizer.decode(y)
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
++ 
++-        # Calculate initial data loss
++-        initial_loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
+++                # --- MINIMAL CHANGE #2 ---
+++                # Pass the UN-FLATTENED tensors here as well.
+++                test_data += myloss(out, y).item()
+++
+++                if can_compute_pde and pde_weight > 0:
+++                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
+++                    test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()
+++
+++        # Normalize losses
+++        train_l2_hybrid /= len(train_loader)
+++        train_data /= len(train_loader)
+++        train_pde_scaled /= len(train_loader)
+++
+++        test_data /= len(test_loader)
+++        test_pde_loss_scaled /= len(test_loader)
++ 
++-        # Calculate initial raw PDE loss
++-        initial_loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
+++        test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled
++ 
++-        # Handle case where PDE loss is zero to avoid division by zero
++-        if initial_loss_pde_raw.item() < 1e-12:
++-            scaler = 1.0
++-            print("Warning: Initial PDE loss is near zero. Setting scaler to 1.0.")
++-        else:
++-            # The scaler is the ratio of the two losses
++-            scaler = initial_loss_data.item() / initial_loss_pde_raw.item()
++-            print(f"Computed initial loss scaler: {scaler:.4f}")
++-            print(f"  - Initial Data Loss: {initial_loss_data.item():.6f}")
++-            print(f"  - Initial PDE Loss (raw): {initial_loss_pde_raw.item():.6f}")
+++        # Append logs
+++        train_l2_hybrid_log.append(train_l2_hybrid)
+++        test_loss_hybrid_log.append(test_loss_hybrid)
+++        train_data_log.append(train_data)
+++        test_data_log.append(test_data)
+++        train_pde_scaled_log.append(train_pde_scaled)
+++        test_pde_loss_scaled_log.append(test_pde_loss_scaled)
++ 
++-    model.train()  # Set model back to training mode
++-    return scaler
+++        t2 = default_timer()
+++
+++        if ep == 0:
+++            print("No. Epoch | Time (s)   | Train L2 Hyb  | Test L2 Hyb   | Test L2 data  | Test PDE Scaled")
+++            print("---------------------------------------------------------------------------------------")
+++
+++        print(
+++            f"{ep:<9} | {t2 - t1:<10.4f} | {train_l2_hybrid:<13.6e} | {test_loss_hybrid:<13.6e} | {test_data:<13.6e} | {test_pde_loss_scaled:<13.6e}")
+++
+++    # Simplified return statement
+++    return model, train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log
+++'''''
+++
++ 
++ 
++ ''''
++Index: main1.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import os\nimport importlib\nimport torch\nimport inspect\nimport numpy as np\nimport matplotlib\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom training import train_fno, train_fno_time, train_hybrid\nfrom torch.utils.data import DataLoader, random_split\nfrom utilities import ImportDataset, count_params, LpLoss, ModelEvaluator\nfrom post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, make_video, save_vtk, plot_xy_plane_subplots\nimport time  # Import the time module at the beginning of the script\nfrom torch_optimizer import Lamb\nimport scipy.io\n\n################################################################\n# Problem Definition\n################################################################\n# problem = 'AC2D'\n#problem = 'AC3D'\n# problem = 'CH2DNL'\n# problem = 'SH2D'\nproblem = 'SH3D'\n# problem = 'PFC2D'\n#problem = 'PFC3D'\n#problem = 'MBE2D'\n#problem = 'MBE3D'\n# problem = 'CH2D'\n#problem = 'CH3D'\n\n#network_name = 'TNO2d'\n# network_name = 'FNO2d'\n#network_name = 'FNO3d'\nnetwork_name = 'TNO3d'\n\nPINN_MODE = False # True # False #\n\nprint(f\"problem = {problem}\")\nprint(f\"network = {network_name}\")\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\") # configuration file\n# above line means: import configs.config_PFC3D_TNO3d as cf\nnetwork = getattr(importlib.import_module('networks'), network_name) # from networks import TNO3d\ntorch.manual_seed(cf.torch_seed)\nnp.random.seed(cf.numpy_seed)\n#device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')\ndevice = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)\n# --- Define Output Directory ---\n\n\nPDE_WEIGHT = cf.pde_weight\nPDE_LOSS_SCALER = cf.pde_loss_scaler\n\nif PINN_MODE:\n    run_descriptor = f\"PINN_w{int(PDE_WEIGHT * 100)}\"\n    output_subdir = f\"plots_Data_Physics_{network_name}\"  # Specific PINN output\nelse:\n    run_descriptor = \"DataDriven\"\n    output_subdir = f\"plots_{network_name}\"  # Original data-driven output\n\n#model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'\nmodel_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}.pt'\nmodel_dir = os.path.join(problem, 'models') # models_smpooth\nmodel_name = f'{model_run_name}'\nmodel_path = os.path.join(model_dir, model_name)\n\nplot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir\nos.makedirs(model_dir, exist_ok=True)\nos.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists\n\nprint(f\"Model Run Name: {model_run_name}\")\nprint(f\"Model Path: {model_path}\")\nprint(f\"Plot Directory: {plot_dir}\")\n\n# width_q = 32\nstart_time = time.time()\n\n################################################################\n# load data and data normalization\n################################################################\n#model_dir = problem + '/models'\n\nprint(f\"model = {model_name}\")\nprint(f\"number of epoch = {cf.epochs}\")\nprint(f\"batch size = {cf.batch_size}\")\nprint(f\"nTrain = {cf.nTrain}\")\nprint(f\"nTest = {cf.nTest}\")\nprint(f\"learning_rate = {cf.learning_rate}\")\nprint(f\"n_layers = {cf.n_layers}\")\nprint(f\"width_q = {cf.width_q}\")\nprint(f\"width_h = {cf.width_h}\")\n\nmodel_path = os.path.join(model_dir, model_name)\nos.makedirs(model_dir, exist_ok=True)\n# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\ntrain_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])\n# to see train_dataset values: print(\"train_dataset subset:\", [train_dataset[i] for i in range(len(train_dataset))])\nnormalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)\n\n################################################################\n# training and evaluation\n################################################################\nsig = inspect.signature(network.__init__)\nrequired_args = [param.name for param in sig.parameters.values()\n                 if param.default == inspect.Parameter.empty and param.name != \"self\"]\nif network_name == 'FNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'FNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelse:\n    raise Exception(\"network_name is not correct\")\n\nprint(count_params(model))      # Print model parameters\ntrain_mse_log, train_l2_log, test_l2_log = [], [], []       # Initialize logs\n\n# Load the entire model and logs\nif os.path.exists(model_path) and cf.load_model:\n    print(f\"Loading pre-trained model from {model_path}\")\n    checkpoint = torch.load(model_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict']) # Use this line if you only save state_dict\n    #model = checkpoint['model'] # Use this line if you save the entire model object\n    train_mse_log = checkpoint.get('train_mse_log', [])\n    train_l2_log = checkpoint.get('train_l2_log', [])\n    test_l2_log = checkpoint.get('test_l2_log', [])\nelse:\n    print(\"No pre-trained model loaded. Initializing a new model.\")\n\n# Define optimizer, scheduler, and loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)\nmyloss = LpLoss(size_average=False)\n\n###\n\n# Train the model\nif cf.training:\n    print(\"\\n--- Starting Training ---\")\n    if PINN_MODE:\n        grid_info = {\n            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,\n            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,\n            'dt_model': cf.dt_model,\n            'T_out': cf.T_out\n        }\n\n        if PDE_WEIGHT == 0.0:\n            print(\"Running PINN training loop with pde_weight=0 (Data-Driven only loss).\")\n        else:\n            print(\n                f\"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {PDE_LOSS_SCALER:.2e}\")\n\n        model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (\n            train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                         optimizer, scheduler, cf.normalized, normalizers, device,\n                         PDE_WEIGHT, grid_info, cf.epsilon, problem,\n                         pde_loss_scaler=PDE_LOSS_SCALER)\n        )\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'train_mse_log': train_mse_hybrid_log,\n            'train_l2_log': train_l2_hybrid_log,\n            'test_l2_log': test_data_log,\n            'test_pde_scaled_log': test_pde_loss_scaled_log,\n            'train_data_log': train_data_log,\n            'train_pde_scaled_log': train_pde_scaled_log,\n            'test_loss_hybrid_log': test_loss_hybrid_log\n        }, model_path)\n\n    else:\n        if network_name in ['FNO2d', 'FNO3d']:\n            model, train_l2_log, test_l2_log = (\n                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                               optimizer, scheduler, cf.normalized, normalizers, device))\n            train_mse_log = []\n        else:\n            model, train_mse_log, train_l2_log, test_l2_log = (\n               train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                           optimizer, scheduler, cf.normalized, normalizers, device))\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'train_mse_log': train_mse_log,\n            'train_l2_log': train_l2_log,\n            'test_l2_log': test_l2_log\n        }, model_path)\n\n\nend_time = time.time()\nFinal_time = round(end_time - start_time, 2)\nprint(f\"Total Execution Time: {Final_time} seconds\")\n\nevaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,\n                           time_history=(network_name in ['FNO2d', 'FNO3d']))\n\nresults = evaluator.evaluate(loss_fn=myloss)\ninp = results['input']\npred = results['prediction']\nexact = results['exact']\ntest_l2_avg = results[\"average\"]\n\nif PINN_MODE:\n    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log]\n    labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\nelse:\n    losses = [train_l2_log, test_l2_log]\n    labels = ['Train L2', 'Test L2']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\n\n\n################################################################\n# post-processing\n################################################################\na_ind = inp[cf.index]\nu_pred = pred[cf.index]\nu_exact = exact[cf.index]\nerror = u_pred - u_exact\n\nplot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]\nprint(f\"Field shape: {u_exact.shape}\")\n\nselected_time_steps = [0, 2, 4, 6, 8, 9]\n\n# Plot exact solution\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=u_exact,\n                      field_name='Exact Solution',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[0],\n                      problem=problem,\n                      network_name=network_name)\n\n# Plot predicted solution\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=u_pred,\n                      field_name='Predicted Solution',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[1],\n                      problem=problem,\n                      network_name=network_name)\n\n# Plot error\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=error,\n                      field_name='Error',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[2],\n                      problem=problem,\n                      network_name=network_name)\n\n\n# ==============================================================================\n# NEW SECTION: PREDICT AND VISUALIZE A SINGLE TRAJECTORY EVOLUTION\n# ==============================================================================\nprint(\"\\n--- Generating Visualization for a Single Predicted Trajectory ---\")\n\n# Ensure dt_simulation is defined in the config file.\nif not hasattr(cf, 'dt_simulation'):\n    raise AttributeError(\"Configuration file is missing 'dt_simulation'. Please add it (e.g., dt_simulation = 0.00002).\")\n\npredicted_trajectory = u_pred # Shape: (s, s, s, T_out)\n\n# 1. Choose 4 suitable time frames for visualization from the predicted steps.\nnum_time_frames_to_plot = 4\ntotal_predicted_steps = predicted_trajectory.shape[-1]  # This is T_out\n\nif total_predicted_steps < 1:\n    print(\"No time steps to plot in the predicted trajectory.\")\nelse:\n    # Select 4 evenly spaced indices from the available time steps.\n    time_indices_to_plot = np.linspace(0, total_predicted_steps - 1, num_time_frames_to_plot, dtype=int).tolist()\n\n    print(f\"Selected time indices for plotting: {time_indices_to_plot}\")\n\n    # 2. Create the subplot (1 row, 4 columns) and save it.\n    fig, axes = plt.subplots(1, num_time_frames_to_plot, figsize=(5 * num_time_frames_to_plot, 5), squeeze=False)\n    axes = axes.flatten()\n\n    vmin = predicted_trajectory.cpu().numpy().min()\n    vmax = predicted_trajectory.cpu().numpy().max()\n    s = cf.s\n    slice_index = s // 2  # Middle slice in the Z-direction\n\n    for i, t_idx in enumerate(time_indices_to_plot):\n        # 3. Calculate the correct physical time for the label.\n        # The prediction starts after T_in steps.\n        physical_time = (cf.T_in + t_idx) * cf.dt_simulation\n\n        slice_2d = predicted_trajectory[:, :, slice_index, t_idx].cpu().numpy()\n\n        ax = axes[i]\n        im = ax.imshow(slice_2d, cmap='viridis', vmin=vmin, vmax=vmax,\n                       extent=[0, cf.Lx, 0, cf.Ly], origin='lower', interpolation='bicubic')\n        ax.set_title(f'Predicted t={physical_time:.2e}') # Use scientific notation for time\n        ax.set_xlabel('x')\n        if i == 0:\n            ax.set_ylabel('y')\n\n    fig.colorbar(im, ax=axes.tolist(), orientation='vertical', pad=0.02)\n    z_coord = cf.Lx / s * (slice_index - s / 2)\n    fig.suptitle(f'Predicted Evolution (Z-slice at z={z_coord:.2f})', fontsize=16)\n    fig.tight_layout(rect=[0, 0, 1, 0.95])\n\n    subplot_filename = os.path.join(plot_dir, f'{model_run_name}_single_trajectory_subplot.png')\n    plt.savefig(subplot_filename, dpi=300, bbox_inches='tight')\n    print(f\"Trajectory subplot saved to {subplot_filename}\")\n    plt.close(fig)\n\n# END OF NEW SECTION\n# ==============================================================================\n\n# The p=2 explicitly specifies the L2 norm.\nl2_norm_error = torch.norm(u_pred - u_exact, p=2)\n\n# Calculate the L2 norm of the exact solution\nl2_norm_exact = torch.norm(u_exact, p=2)\n\n# Calculate the relative L2 norm error\nepsilon = 1e-8\nif l2_norm_exact.item() > epsilon:\n    relative_l2_error = l2_norm_error / l2_norm_exact\nelse:\n    if l2_norm_error.item() < epsilon:\n        relative_l2_error = torch.tensor(0.0, device=u_pred.device, dtype=u_pred.dtype)\n    else:\n        print(f\"Warning: L2 norm of exact solution is {l2_norm_exact.item()}, which is close to zero. L2 norm of error is {l2_norm_error.item()}.\")\n        relative_l2_error = torch.tensor(float('inf'), device=u_pred.device, dtype=u_pred.dtype)\n\nprint(f\"L2 norm of error: {l2_norm_error.item()}\")\nprint(f\"L2 norm of exact solution: {l2_norm_exact.item()}\")\nprint(f\"Relative L2 norm error: {relative_l2_error.item()}\")\nrelative_l2_error_percentage = (relative_l2_error * 100)\nprint(f\"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%\")\n\n###\nplot_combined_results(\n    domain=cf.domain,\n    u_exact=u_exact,\n    u_pred=u_pred,\n    error=error,\n    plot_ranges=[\n        [-1.2, 1.2],\n        [-1.2, 1.2],\n        [-1.2, 1.2]\n    ],\n    problem=problem,\n    network_name=network_name,\n    plot_dir = plot_dir,\n    pde_weight = PDE_WEIGHT\n)\n\nplot_combined_results_3d(\n    domain=cf.domain,\n    u_exact=u_exact,\n    u_pred=u_pred,\n    error=error,\n    plot_ranges=[\n        [-1.2, 1.2],\n        [-1.2, 1.2],\n        [-1.2, 1.2]\n    ],\n    problem=problem,\n    network_name=network_name,\n    plot_dir = plot_dir,\n    pde_weight = PDE_WEIGHT\n)\n\n################################################################\n# Save Results to MATLAB .mat file\n################################################################\nprint(\"\\n--- Saving Results to .mat File ---\")\n\nmat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')\n\nif PINN_MODE:\n    try:\n        results_dict = {\n            'train_mse_log': train_mse_hybrid_log,\n            'train_hybrid_loss': np.array(train_l2_hybrid_log),\n            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),\n            'train_data_log': np.array(train_data_log),\n            'test_data_log': np.array(test_data_log),\n            'train_pde_scaled_log': np.array(train_pde_scaled_log),\n            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,\n            'config_pde_loss_scaler': PDE_LOSS_SCALER if PINN_MODE else 0.0,\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\nelse:\n    try:\n        results_dict = {\n            'train_mse_log': np.array(train_mse_log),\n            'train_l2_log': np.array(train_l2_log),\n            'test_l2_log': np.array(test_l2_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\n\nprint(\"\\n--- Script Finished ---\")
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/main1.py b/main1.py
++--- a/main1.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/main1.py	(date 1754475689222)
++@@ -1,111 +1,128 @@
+++
++ import os
++ import importlib
++ import torch
++ import inspect
++ import numpy as np
++ import matplotlib
+++import h5py  # MODIFIED: Added h5py import
+++import scipy.io
+++
++ matplotlib.use('TkAgg')
++ import matplotlib.pyplot as plt
++ import torch.nn.functional as F
++-from training import train_fno, train_fno_time, train_hybrid
+++from training import train_fno, train_fno_time, train_hybrid, train_fno4d
++ from torch.utils.data import DataLoader, random_split
++-from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator
++-from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, make_video, save_vtk, plot_xy_plane_subplots
++-import time  # Import the time module at the beginning of the script
+++from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator, SobolevLoss
+++from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \
+++    make_video, save_vtk, plot_xy_plane_subplots
+++import time
++ from torch_optimizer import Lamb
++-import scipy.io
+++
+++################################################################
+++# Problem Definition
+++################################################################
++ 
++ ################################################################
++ # Problem Definition
++ ################################################################
++ # problem = 'AC2D'
++-#problem = 'AC3D'
+++problem = 'AC3D'
++ # problem = 'CH2DNL'
++ # problem = 'SH2D'
++-problem = 'SH3D'
+++#problem = 'SH3D'
++ # problem = 'PFC2D'
++ #problem = 'PFC3D'
++-#problem = 'MBE2D'
+++# problem = 'MBE2D'
++ #problem = 'MBE3D'
++ # problem = 'CH2D'
++ #problem = 'CH3D'
++ 
++-#network_name = 'TNO2d'
+++# network_name = 'TNO2d'
++ # network_name = 'FNO2d'
++ #network_name = 'FNO3d'
+++#network_name = 'FNO4d'
++ network_name = 'TNO3d'
++ 
++-PINN_MODE = False # True # False #
+++PINN_MODE =  False # True #  True #  False #  True #   True #    True #
+++#  False #    True # False #  False  # False #
++ 
++ print(f"problem = {problem}")
++ print(f"network = {network_name}")
++ os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
++-cf = importlib.import_module(f"configs.config_{problem}_{network_name}") # configuration file
++-# above line means: import configs.config_PFC3D_TNO3d as cf
++-network = getattr(importlib.import_module('networks'), network_name) # from networks import TNO3d
+++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+++network = getattr(importlib.import_module('networks'), network_name)
++ torch.manual_seed(cf.torch_seed)
++ np.random.seed(cf.numpy_seed)
++-#device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')
++-device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")
+++device = torch.device("cuda:2" if torch.cuda.is_available() else "cpu")
++ print("Device: ", device)
++-# --- Define Output Directory ---
++-
++ 
++ PDE_WEIGHT = cf.pde_weight
++-PDE_LOSS_SCALER = cf.pde_loss_scaler
+++pde_loss_scaler = cf.pde_loss_scaler
++ 
++ if PINN_MODE:
++     run_descriptor = f"PINN_w{int(PDE_WEIGHT * 100)}"
++-    output_subdir = f"plots_Data_Physics_{network_name}"  # Specific PINN output
+++    output_subdir = f"plots_Data_Physics_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_Hybrid_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
++ else:
++     run_descriptor = "DataDriven"
++-    output_subdir = f"plots_{network_name}"  # Original data-driven output
+++    output_subdir = f"plots_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
++ 
++-#model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'
++-model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}.pt'
++-model_dir = os.path.join(problem, 'models') # models_smpooth
+++model_dir = os.path.join(problem, 'models')
++ model_name = f'{model_run_name}'
++ model_path = os.path.join(model_dir, model_name)
++-
++-plot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir
+++plot_dir = os.path.join(problem, output_subdir)
++ os.makedirs(model_dir, exist_ok=True)
++-os.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists
+++os.makedirs(plot_dir, exist_ok=True)
++ 
++ print(f"Model Run Name: {model_run_name}")
++ print(f"Model Path: {model_path}")
++ print(f"Plot Directory: {plot_dir}")
++ 
++-# width_q = 32
++ start_time = time.time()
++ 
++ ################################################################
++ # load data and data normalization
++ ################################################################
++-#model_dir = problem + '/models'
++-
++-print(f"model = {model_name}")
++-print(f"number of epoch = {cf.epochs}")
++-print(f"batch size = {cf.batch_size}")
++-print(f"nTrain = {cf.nTrain}")
++-print(f"nTest = {cf.nTest}")
++-print(f"learning_rate = {cf.learning_rate}")
++-print(f"n_layers = {cf.n_layers}")
++-print(f"width_q = {cf.width_q}")
++-print(f"width_h = {cf.width_h}")
++-
++-model_path = os.path.join(model_dir, model_name)
++-os.makedirs(model_dir, exist_ok=True)
++-# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf
++-dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++# MODIFIED: Added special handling for SH3D dataset loading
+++try:
+++    dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++    if problem == 'SH3D':
+++        print("SH3D dataset detected - applying special handling")
+++        # Verify dataset sizes
+++        sample = dataset[0][0]  # Get first sample
+++        print(f"SH3D sample shape: {sample.shape}, dtype: {sample.dtype}")
+++        print(f"SH3D stats - mean: {sample.mean():.4f}, std: {sample.std():.4f}")
+++except Exception as e:
+++    print(f"Error loading dataset: {e}")
+++    raise
++ 
++ train_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])
++-# to see train_dataset values: print("train_dataset subset:", [train_dataset[i] for i in range(len(train_dataset))])
++ normalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None
++ 
++-train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
++-test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++train_loader = DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
+++test_loader = DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++
++ 
++-################################################################
+++# ==================== CODE TO INSPECT BATCH SHAPE ====================
+++print("\n" + "="*50)
+++print("Inspecting DataLoader Batch Shapes")
+++print("="*50)
+++# Get one batch of data from the train_loader
+++try:
+++    x_batch, y_batch = next(iter(train_loader))
+++    # Print the shape of the batch
+++    # This will be (batch_size, S, S, S, T_in) for input
+++    # and (batch_size, S, S, S, T_out) for target
+++    print(f"Shape of an input batch from DataLoader: {x_batch.shape}")
+++    print(f"Shape of a target batch from DataLoader: {y_batch.shape}")
+++except StopIteration:
+++    print("Train loader is empty. Cannot retrieve a batch.")
+++print("="*50 + "\n")
+++# =======================================================================
+++
+++############AA####################################################
++ # training and evaluation
++ ################################################################
++ sig = inspect.signature(network.__init__)
++@@ -118,19 +135,32 @@
++ elif network_name == 'FNO3d':
++     model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)
++ elif network_name == 'TNO3d':
++-    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)
+++    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(
+++        device)
+++elif network_name == 'FNO4d':
+++    model = network(
+++        modes1=cf.modes,
+++        modes2=cf.modes,
+++        modes3=cf.modes,
+++        modes4_internal =1, # cf.modes_t, # MUST BE 1
+++        width=cf.width,
+++        width_q=cf.width_q,
+++        T_in_channels=cf.T_in,
+++        n_layers=cf.n_layers
+++    ).to(device)
+++
+++
++ else:
++     raise Exception("network_name is not correct")
++ 
++-print(count_params(model))      # Print model parameters
++-train_mse_log, train_l2_log, test_l2_log = [], [], []       # Initialize logs
+++print(count_params(model))  # Print model parameters
+++train_mse_log, train_l2_log, test_l2_log = [], [], []  # Initialize logs
++ 
++ # Load the entire model and logs
++ if os.path.exists(model_path) and cf.load_model:
++     print(f"Loading pre-trained model from {model_path}")
++     checkpoint = torch.load(model_path, map_location=device)
++-    model.load_state_dict(checkpoint['model_state_dict']) # Use this line if you only save state_dict
++-    #model = checkpoint['model'] # Use this line if you save the entire model object
+++    model = checkpoint['model']
++     train_mse_log = checkpoint.get('train_mse_log', [])
++     train_l2_log = checkpoint.get('train_l2_log', [])
++     test_l2_log = checkpoint.get('test_l2_log', [])
++@@ -140,14 +170,19 @@
++ # Define optimizer, scheduler, and loss function
++ optimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)
++ scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)
++-myloss = LpLoss(size_average=False)
+++myloss = LpLoss(p=2, l1_weight=0.1, size_average=False) # size_average=True # False
+++# NEW: Instantiate SobolevLoss instead of LpLoss
+++# You can tune grad_weight. A good starting point is 0.1 or 1.0.
+++#myloss = SobolevLoss(d=3, p=2, grad_weight=0.1)
++ 
++-###
+++# COMPUTE THE DYNAMIC SCALER
+++# Use the train_loader to get a representative batch
+++
++ 
++ # Train the model
++ if cf.training:
++     print("\n--- Starting Training ---")
++-    if PINN_MODE:
+++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
++         grid_info = {
++             'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
++             'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
++@@ -159,18 +194,18 @@
++             print("Running PINN training loop with pde_weight=0 (Data-Driven only loss).")
++         else:
++             print(
++-                f"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {PDE_LOSS_SCALER:.2e}")
+++                f"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {pde_loss_scaler:.2e}")
++ 
++         model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (
++             train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                          optimizer, scheduler, cf.normalized, normalizers, device,
++                          PDE_WEIGHT, grid_info, cf.epsilon, problem,
++-                         pde_loss_scaler=PDE_LOSS_SCALER)
+++                         pde_loss_scaler=pde_loss_scaler)
++         )
++ 
++         print(f"Saving model and logs to {model_path}")
++         torch.save({
++-            'model_state_dict': model.state_dict(),
+++            'model': model,
++             'train_mse_log': train_mse_hybrid_log,
++             'train_l2_log': train_l2_hybrid_log,
++             'test_l2_log': test_data_log,
++@@ -180,32 +215,134 @@
++             'test_loss_hybrid_log': test_loss_hybrid_log
++         }, model_path)
++ 
++-    else:
++-        if network_name in ['FNO2d', 'FNO3d']:
+++    else:  # Original Data-Driven Mode
+++        if network_name == 'FNO2d' or network_name == 'FNO3d':
+++            model, train_l2_log, test_l2_log = (
+++                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                               optimizer, scheduler, cf.normalized, normalizers, device))
+++            train_mse_log = []
+++        elif network_name == 'FNO4d':
+++
+++            model, train_mse_log, train_l2_log, test_l2_log = (  # Add val logs
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++            # train_fno4d = train_fno
+++        else:
+++            model, train_mse_log, train_l2_log, test_l2_log = (
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++    print(f"Saving model and logs to {model_path}")
+++    torch.save({
+++        'model': model,
+++        'train_mse_log': train_mse_log,
+++        'train_l2_log': train_l2_log,
+++        'test_l2_log': test_l2_log
+++    }, model_path)
+++
+++
+++'''
+++# Train the model
+++if cf.training:
+++    print("\n--- Starting Training ---")
+++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
+++        grid_info = {
+++            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
+++            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
+++            'dt_model': cf.dt_model,
+++            'T_out': cf.T_out
+++        }
+++
+++        # --- NEW: Define the two stages for the training curriculum ---
+++        epochs_stage1 = 10
+++        scaler_stage1 = 1e-4
+++
+++        # Calculate remaining epochs for stage 2
+++        epochs_stage2 = cf.epochs - epochs_stage1
+++        scaler_stage2 = 1e-6
+++
+++        # --- Stage 1 Training ---
+++        print("\n--- Starting Training Stage 1 ---")
+++        print(f"Epochs: {epochs_stage1}, PDE Scaler: {scaler_stage1:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++        # Note: The 'model' object is updated in-place by the function call
+++        model, train_mse_s1, train_l2_s1, test_data_s1, test_pde_s1, train_data_s1, train_pde_scl_s1, test_loss_s1 = (
+++            train_hybrid(model, myloss, epochs_stage1, cf.batch_size, train_loader, test_loader,
+++                         optimizer, scheduler, cf.normalized, normalizers, device,
+++                         PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                         pde_loss_scaler=scaler_stage1)
+++        )
+++
+++        # --- Stage 2 Training (if there are remaining epochs) ---
+++        if epochs_stage2 > 0:
+++            print("\n--- Starting Training Stage 2 ---")
+++            print(f"Epochs: {epochs_stage2}, PDE Scaler: {scaler_stage2:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++            model, train_mse_s2, train_l2_s2, test_data_s2, test_pde_s2, train_data_s2, train_pde_scl_s2, test_loss_s2 = (
+++                train_hybrid(model, myloss, epochs_stage2, cf.batch_size, train_loader, test_loader,
+++                             optimizer, scheduler, cf.normalized, normalizers, device,
+++                             PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                             pde_loss_scaler=scaler_stage2)
+++            )
+++
+++            # Combine the logs from both stages for plotting and saving
+++            train_mse_hybrid_log = train_mse_s1 + train_mse_s2
+++            train_l2_hybrid_log = train_l2_s1 + train_l2_s2
+++            test_data_log = test_data_s1 + test_data_s2
+++            test_pde_loss_scaled_log = test_pde_s1 + test_pde_s2
+++            train_data_log = train_data_s1 + train_data_s2
+++            train_pde_scaled_log = train_pde_scl_s1 + train_pde_scl_s2
+++            test_loss_hybrid_log = test_loss_s1 + test_loss_s2
+++        else:
+++            # If only stage 1 was run, the final logs are just the stage 1 logs
+++            train_mse_hybrid_log = train_mse_s1
+++            train_l2_hybrid_log = train_l2_s1
+++            test_data_log = test_data_s1
+++            test_pde_loss_scaled_log = test_pde_s1
+++            train_data_log = train_data_s1
+++            train_pde_scaled_log = train_pde_scl_s1
+++            test_loss_hybrid_log = test_loss_s1
+++
+++        print(f"\n--- Training Finished. Saving model and logs to {model_path} ---")
+++        # The torch.save call remains the same, as the log variables have been correctly prepared
+++        torch.save({
+++            'model': model,
+++            'train_mse_log': train_mse_hybrid_log,
+++            'train_l2_log': train_l2_hybrid_log,
+++            'test_l2_log': test_data_log, # 'test_l2_log' is used by evaluator, it should contain data loss
+++            'test_pde_scaled_log': test_pde_loss_scaled_log,
+++            'train_data_log': train_data_log,
+++            'train_pde_scaled_log': train_pde_scaled_log,
+++            'test_loss_hybrid_log': test_loss_hybrid_log
+++        }, model_path)
+++
+++    else:  # Original Data-Driven Mode (This part remains unchanged)
+++        if network_name == 'FNO2d' or network_name == 'FNO3d':
++             model, train_l2_log, test_l2_log = (
++                 train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                                optimizer, scheduler, cf.normalized, normalizers, device))
++             train_mse_log = []
++         else:
++             model, train_mse_log, train_l2_log, test_l2_log = (
++-               train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++-                           optimizer, scheduler, cf.normalized, normalizers, device))
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
++ 
++         print(f"Saving model and logs to {model_path}")
++         torch.save({
++-            'model_state_dict': model.state_dict(),
+++            'model': model,
++             'train_mse_log': train_mse_log,
++             'train_l2_log': train_l2_log,
++             'test_l2_log': test_l2_log
++         }, model_path)
++-
+++'''
++ 
++ end_time = time.time()
++ Final_time = round(end_time - start_time, 2)
++ print(f"Total Execution Time: {Final_time} seconds")
++ 
++ evaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,
++-                           time_history=(network_name in ['FNO2d', 'FNO3d']))
+++                           time_history=(network_name == 'FNO2d'))
++ 
++ results = evaluator.evaluate(loss_fn=myloss)
++ inp = results['input']
++@@ -214,7 +351,8 @@
++ test_l2_avg = results["average"]
++ 
++ if PINN_MODE:
++-    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log]
+++    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log,
+++              train_pde_scaled_log]
++     labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']
++     plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)
++ else:
++@@ -222,7 +360,6 @@
++     labels = ['Train L2', 'Test L2']
++     plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)
++ 
++-
++ ################################################################
++ # post-processing
++ ################################################################
++@@ -231,115 +368,202 @@
++ u_exact = exact[cf.index]
++ error = u_pred - u_exact
++ 
+++print(f"DEBUG: Shape of u_exact passed to plotting function: {u_exact.shape}")
+++print(f"DEBUG: Shape of u_pred passed to plotting function: {u_pred.shape}")
+++
++ plot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]
++-print(f"Field shape: {u_exact.shape}")
+++
+++# =========================================================================================
+++# ===                START OF MODIFIED PLOTTING PREPARATION BLOCK                      ===
+++# =========================================================================================
+++
+++# 1. Get the initial condition (t=0) data for the chosen sample index
+++a_ind = inp[cf.index]
+++print(f"Shape of initial condition (t=0) data 'a_ind': {a_ind.shape}")
+++
+++# 2. Separate desired times into t=0 vs. future predictions
+++desired_times = cf.time_steps
+++future_times_to_plot = []
+++has_initial_condition = (0 in desired_times)
+++for t in desired_times:
+++    if t > 0:
+++        future_times_to_plot.append(t)
+++
+++# 3. Translate the FUTURE times to array indices
+++indices_to_plot = []
+++valid_future_times = []
+++for t in future_times_to_plot:
+++    if t <= cf.T_out:
+++        indices_to_plot.append(t - 1)
+++        valid_future_times.append(t)
+++    else:
+++        print(f"Warning: Time t={t} is out of valid prediction range. Skipping.")
+++print(f"Plotting for future times: {valid_future_times} --> which correspond to array indices: {indices_to_plot}")
+++
+++# 4. MOVE ALL DATA TO THE TARGET DEVICE BEFORE OPERATIONS
+++t0_data_cpu = a_ind
+++u_exact_cpu = u_exact
+++u_pred_cpu = u_pred
+++error_cpu = error
+++
+++t0_data_gpu = t0_data_cpu.to(device)
+++u_exact_gpu = u_exact_cpu.to(device)
+++u_pred_gpu = u_pred_cpu.to(device)
+++error_gpu = error_cpu.to(device)
+++indices_tensor_gpu = torch.tensor(indices_to_plot, device=device)
+++
+++# 5. PREPARE COMBINED TENSORS FOR PLOTTING on the GPU
+++if has_initial_condition:
+++    # --- ### FIXED DIMENSION HANDLING ### ---
+++    # `a_ind` has shape (sx, sy, sz, 1) where the last dim is a channel.
+++    # `u_exact_gpu` has shape (sx, sy, sz, T) where the last dim is time.
+++    # They are both 4D, so we can concatenate them directly if the last dimension is treated as the time dimension.
+++    # We don't need to do any reshaping. `t0_data_gpu` is already correct.
+++    t0_for_concat = t0_data_gpu
+++
+++    # Select the future time slices from the GPU tensors
+++    u_exact_selected = u_exact_gpu.index_select(-1, indices_tensor_gpu)
+++    u_pred_selected = u_pred_gpu.index_select(-1, indices_tensor_gpu)
+++    error_selected = error_gpu.index_select(-1, indices_tensor_gpu)
+++
+++    # Combine t=0 data with the selected future steps
+++    u_exact_for_plot = torch.cat((t0_for_concat, u_exact_selected), dim=-1)
+++    u_pred_for_plot = torch.cat((t0_for_concat, u_pred_selected), dim=-1)
+++
+++    # The error for t=0 is zero by definition
+++    error_t0 = torch.zeros_like(t0_for_concat)
+++    error_for_plot = torch.cat((error_t0, error_selected), dim=-1)
++ 
++-selected_time_steps = [0, 2, 4, 6, 8, 9]
+++    final_indices = list(range(len(desired_times)))
+++    final_labels = desired_times
+++else:
+++    u_exact_for_plot = u_exact_gpu
+++    u_pred_for_plot = u_pred_gpu
+++    error_for_plot = error_gpu
+++    final_indices = indices_to_plot
+++    final_labels = valid_future_times
++ 
++-# Plot exact solution
+++print(f"Final data prepared for plotting with shape: {u_exact_for_plot.shape}")
+++print(f"Final indices for plotting: {final_indices}")
+++print(f"Final labels for plotting: {final_labels}")
+++
+++
+++# =========================================================================================
+++# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===
+++# =========================================================================================
+++
+++################################################################
+++# Save Results to MATLAB .mat file
+++################################################################
+++print("\n--- Saving Results to .mat File ---")
+++mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
+++
+++# MODIFIED: Enhanced saving logic with fallbacks
+++def save_results(mat_filename, results_dict):
+++    try:
+++        # First try standard save
+++        scipy.io.savemat(mat_filename, results_dict)
+++        print(f"Saved with standard format to {mat_filename}")
+++    except ValueError as e:
+++        if "Format should be '4' or '5'" in str(e):
+++            print("Large data detected, trying v7.3 format...")
+++            try:
+++                scipy.io.savemat(mat_filename, results_dict, format='v7.3')
+++                print(f"Saved with v7.3 format to {mat_filename}")
+++            except Exception as e:
+++                print(f"v7.3 failed: {e}")
+++                # Fallback to HDF5
+++                h5_filename = mat_filename.replace('.mat', '.h5')
+++                with h5py.File(h5_filename, 'w') as f:
+++                    for k, v in results_dict.items():
+++                        f.create_dataset(k, data=v, compression='gzip')
+++                print(f"Saved as HDF5 to {h5_filename}")
+++        else:
+++            raise
+++
+++if PINN_MODE:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_hybrid_log, dtype=np.float32),  # MODIFIED: Added dtype
+++        'train_hybrid_loss': np.array(train_l2_hybrid_log, dtype=np.float32),
+++        'test_loss_hybrid_log': np.array(test_loss_hybrid_log, dtype=np.float32),
+++        'train_data_log': np.array(train_data_log, dtype=np.float32),
+++        'test_data_log': np.array(test_data_log, dtype=np.float32),
+++        'train_pde_scaled_log': np.array(train_pde_scaled_log, dtype=np.float32),
+++        'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),  # MODIFIED: Added astype
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_pde_weight': np.float32(PDE_WEIGHT),
+++        'config_pde_loss_scaler': np.float32(pde_loss_scaler),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++    }
+++else:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_log, dtype=np.float32),
+++        'train_l2_log': np.array(train_l2_log, dtype=np.float32),
+++        'test_l2_log': np.array(test_l2_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++    }
+++
+++# MODIFIED: Use the new save function
+++save_results(mat_filename, results_dict)
+++
+++# Plot XY-plane for the "Exact" solution trajectory (includes t=0)
+++
+++'''
++ plot_xy_plane_subplots(domain=cf.domain,
++-                      field=u_exact,
++-                      field_name='Exact Solution',
++-                      time_steps=selected_time_steps,
++-                      plot_range=plot_range[0],
++-                      problem=problem,
++-                      network_name=network_name)
+++                       field=u_exact_for_plot,
+++                       field_name='Exact Solution',
+++                       time_steps=final_indices,
+++                       desired_times=final_labels,
+++                       plot_range=plot_range[0],
+++                       problem=problem,
+++                       network_name=network_name)
++ 
++-# Plot predicted solution
+++# Plot XY-plane for the "Predicted" solution trajectory (includes t=0 from input)
++ plot_xy_plane_subplots(domain=cf.domain,
++-                      field=u_pred,
++-                      field_name='Predicted Solution',
++-                      time_steps=selected_time_steps,
++-                      plot_range=plot_range[1],
++-                      problem=problem,
++-                      network_name=network_name)
+++                       field=u_pred_for_plot,
+++                       field_name='Predicted Solution',
+++                       time_steps=final_indices,
+++                       desired_times=final_labels,
+++                       plot_range=plot_range[1],
+++                       problem=problem,
+++                       network_name=network_name)
++ 
++-# Plot error
+++# Plot XY-plane for the "Error" (error is 0 at t=0)
++ plot_xy_plane_subplots(domain=cf.domain,
++-                      field=error,
++-                      field_name='Error',
++-                      time_steps=selected_time_steps,
++-                      plot_range=plot_range[2],
++-                      problem=problem,
++-                      network_name=network_name)
++-
++-
++-# ==============================================================================
++-# NEW SECTION: PREDICT AND VISUALIZE A SINGLE TRAJECTORY EVOLUTION
++-# ==============================================================================
++-print("\n--- Generating Visualization for a Single Predicted Trajectory ---")
++-
++-# Ensure dt_simulation is defined in the config file.
++-if not hasattr(cf, 'dt_simulation'):
++-    raise AttributeError("Configuration file is missing 'dt_simulation'. Please add it (e.g., dt_simulation = 0.00002).")
++-
++-predicted_trajectory = u_pred # Shape: (s, s, s, T_out)
++-
++-# 1. Choose 4 suitable time frames for visualization from the predicted steps.
++-num_time_frames_to_plot = 4
++-total_predicted_steps = predicted_trajectory.shape[-1]  # This is T_out
++-
++-if total_predicted_steps < 1:
++-    print("No time steps to plot in the predicted trajectory.")
++-else:
++-    # Select 4 evenly spaced indices from the available time steps.
++-    time_indices_to_plot = np.linspace(0, total_predicted_steps - 1, num_time_frames_to_plot, dtype=int).tolist()
++-
++-    print(f"Selected time indices for plotting: {time_indices_to_plot}")
+++                       field=error_for_plot,
+++                       field_name='Error',
+++                       time_steps=final_indices,
+++                       desired_times=final_labels,
+++                       plot_range=plot_range[2],
+++                       problem=problem,
+++                       network_name=network_name)
+++'''
++ 
++-    # 2. Create the subplot (1 row, 4 columns) and save it.
++-    fig, axes = plt.subplots(1, num_time_frames_to_plot, figsize=(5 * num_time_frames_to_plot, 5), squeeze=False)
++-    axes = axes.flatten()
++-
++-    vmin = predicted_trajectory.cpu().numpy().min()
++-    vmax = predicted_trajectory.cpu().numpy().max()
++-    s = cf.s
++-    slice_index = s // 2  # Middle slice in the Z-direction
++-
++-    for i, t_idx in enumerate(time_indices_to_plot):
++-        # 3. Calculate the correct physical time for the label.
++-        # The prediction starts after T_in steps.
++-        physical_time = (cf.T_in + t_idx) * cf.dt_simulation
++-
++-        slice_2d = predicted_trajectory[:, :, slice_index, t_idx].cpu().numpy()
++-
++-        ax = axes[i]
++-        im = ax.imshow(slice_2d, cmap='viridis', vmin=vmin, vmax=vmax,
++-                       extent=[0, cf.Lx, 0, cf.Ly], origin='lower', interpolation='bicubic')
++-        ax.set_title(f'Predicted t={physical_time:.2e}') # Use scientific notation for time
++-        ax.set_xlabel('x')
++-        if i == 0:
++-            ax.set_ylabel('y')
++-
++-    fig.colorbar(im, ax=axes.tolist(), orientation='vertical', pad=0.02)
++-    z_coord = cf.Lx / s * (slice_index - s / 2)
++-    fig.suptitle(f'Predicted Evolution (Z-slice at z={z_coord:.2f})', fontsize=16)
++-    fig.tight_layout(rect=[0, 0, 1, 0.95])
++-
++-    subplot_filename = os.path.join(plot_dir, f'{model_run_name}_single_trajectory_subplot.png')
++-    plt.savefig(subplot_filename, dpi=300, bbox_inches='tight')
++-    print(f"Trajectory subplot saved to {subplot_filename}")
++-    plt.close(fig)
++-
++-# END OF NEW SECTION
++-# ==============================================================================
++-
++-# The p=2 explicitly specifies the L2 norm.
+++# Calculate L2 norm on original full prediction
++ l2_norm_error = torch.norm(u_pred - u_exact, p=2)
++-
++-# Calculate the L2 norm of the exact solution
++ l2_norm_exact = torch.norm(u_exact, p=2)
++-
++-# Calculate the relative L2 norm error
++ epsilon = 1e-8
++ if l2_norm_exact.item() > epsilon:
++     relative_l2_error = l2_norm_error / l2_norm_exact
++ else:
++-    if l2_norm_error.item() < epsilon:
++-        relative_l2_error = torch.tensor(0.0, device=u_pred.device, dtype=u_pred.dtype)
++-    else:
++-        print(f"Warning: L2 norm of exact solution is {l2_norm_exact.item()}, which is close to zero. L2 norm of error is {l2_norm_error.item()}.")
++-        relative_l2_error = torch.tensor(float('inf'), device=u_pred.device, dtype=u_pred.dtype)
+++    relative_l2_error = torch.tensor(0.0) if l2_norm_error.item() < epsilon else torch.tensor(float('inf'))
++ 
++ print(f"L2 norm of error: {l2_norm_error.item()}")
++ print(f"L2 norm of exact solution: {l2_norm_exact.item()}")
++@@ -347,93 +571,33 @@
++ relative_l2_error_percentage = (relative_l2_error * 100)
++ print(f"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%")
++ 
++-###
+++# Call the combined results plots with the prepared data
++ plot_combined_results(
++     domain=cf.domain,
++-    u_exact=u_exact,
++-    u_pred=u_pred,
++-    error=error,
++-    plot_ranges=[
++-        [-1.2, 1.2],
++-        [-1.2, 1.2],
++-        [-1.2, 1.2]
++-    ],
+++    u_exact=u_exact_for_plot,
+++    u_pred=u_pred_for_plot,
+++    error=error_for_plot,
+++    plot_ranges=plot_range,
++     problem=problem,
++     network_name=network_name,
++-    plot_dir = plot_dir,
++-    pde_weight = PDE_WEIGHT
+++    plot_dir=plot_dir,
+++    pde_weight=PDE_WEIGHT,
+++    time_steps_indices=final_indices,
+++    desired_times=final_labels
++ )
++ 
++ plot_combined_results_3d(
++     domain=cf.domain,
++-    u_exact=u_exact,
++-    u_pred=u_pred,
++-    error=error,
++-    plot_ranges=[
++-        [-1.2, 1.2],
++-        [-1.2, 1.2],
++-        [-1.2, 1.2]
++-    ],
+++    u_exact=u_exact_for_plot,
+++    u_pred=u_pred_for_plot,
+++    error=error_for_plot,
+++    plot_ranges=plot_range,
++     problem=problem,
++     network_name=network_name,
++-    plot_dir = plot_dir,
++-    pde_weight = PDE_WEIGHT
+++    plot_dir=plot_dir,
+++    pde_weight=PDE_WEIGHT,
+++    time_steps_indices=final_indices,
+++    desired_times=final_labels
++ )
++ 
++-################################################################
++-# Save Results to MATLAB .mat file
++-################################################################
++-print("\n--- Saving Results to .mat File ---")
++-
++-mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
++-
++-if PINN_MODE:
++-    try:
++-        results_dict = {
++-            'train_mse_log': train_mse_hybrid_log,
++-            'train_hybrid_loss': np.array(train_l2_hybrid_log),
++-            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),
++-            'train_data_log': np.array(train_data_log),
++-            'test_data_log': np.array(test_data_log),
++-            'train_pde_scaled_log': np.array(train_pde_scaled_log),
++-            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,
++-            'config_pde_loss_scaler': PDE_LOSS_SCALER if PINN_MODE else 0.0,
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-else:
++-    try:
++-        results_dict = {
++-            'train_mse_log': np.array(train_mse_log),
++-            'train_l2_log': np.array(train_l2_log),
++-            'test_l2_log': np.array(test_l2_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-
++ print("\n--- Script Finished ---")
++\ No newline at end of file
++Index: networks.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef get_grid_2d(shape, device):\n    batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n    gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n    gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n    return torch.cat((gridx, gridy), dim=-1).to(device)\n\n\ndef get_grid_3d(shape, device):\n    batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n    gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n    gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n    gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n    return torch.cat((gridx, gridy, gridz), dim=-1).to(device)\n\n\n# Complex multiplication\ndef compl_mul2d(inp, weights):\n    # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n    return torch.einsum(\"bixy,ioxy->boxy\", inp, weights)\n\n\ndef compl_mul3d(inp, weights):\n    # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n    return torch.einsum(\"bixyz,ioxyz->boxyz\", inp, weights)\n\n\nclass SpectralConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, modes1, modes2):\n        super(SpectralConv2d, self).__init__()\n\n        \"\"\"\n        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n        \"\"\"\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n        self.modes2 = modes2\n\n        self.scale = (1 / (in_channels * out_channels))\n        self.weights1 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n        self.weights2 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n\n    def forward(self, x):\n        batchsize = x.shape[0]\n        # Compute Fourier coefficients --  1. Compute Fourier Transform\n        # Now, instead of working with raw pixel/grid values, we work with frequency components\\\n        # Suppose the input x has shape (batch, in_channels, H, W)\n        # x_ft has shape: batchin_channelsH(W/2+1)\n        x_ft = torch.fft.rfft2(x) # 2D Fast Fourier Transform (FFT) --> v0 = F(v0)\n\n        # Multiply relevant Fourier modes -- 2. Apply Spectral Convolution\n        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat,\n                             device=x.device)\n        # v1(k1,k2)= W(k1,k2).v0(k1,k2) --> W(k1,k2) are learnable parameters that control how much each frequency mode contributes\n        out_ft[:, :, :self.modes1, :self.modes2] = \\\n            compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n            compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n\n        # Return to physical space\n        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1))) # Apply Inverse Fourier Transform (iFFT) --> v1(x,y) = F^(-1)[v1(k1,k2)]\n        return x\n\n\nclass SpectralConv3d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n        super(SpectralConv3d, self).__init__()\n\n        \"\"\"\n        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n        \"\"\"\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n        self.modes2 = modes2\n        self.modes3 = modes3\n\n        self.scale = (1 / (in_channels * out_channels))\n        self.weights1 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights2 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights3 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights4 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n\n    def forward(self, x):\n        batchsize = x.shape[0]\n        # Compute Fourier coefficients up to factor of e^(- something constant)\n        x_ft = torch.fft.rfftn(x, dim=[-3, -2, -1])\n\n        # Multiply relevant Fourier modes\n        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1) // 2 + 1,\n                             dtype=torch.cfloat, device=x.device)\n        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n\n        # Return to physical space\n        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n        return x\n\n\nclass MLP2d(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels, T=1, num_layers=2):\n        \"\"\"\n        Initialize the MLP2d class.\n        Parameters:\n        - in_channels: Number of input channels.\n        - out_channels: Number of output channels.\n        - mid_channels: Number of intermediate channels.\n        - T: Number of blocks (default=1).\n        - num_layers: Number of layers in each block (default=2).\n        \"\"\"\n        super(MLP2d, self).__init__()\n\n        self.num_layers = num_layers\n        self.layers = nn.ModuleList()\n\n        for _ in range(T):\n            self.layers.append(nn.Conv2d(in_channels, mid_channels, 1))\n            for _ in range(self.num_layers - 2):\n                self.layers.append(nn.Conv2d(mid_channels, mid_channels, 1))\n            self.layers.append(nn.Conv2d(mid_channels, out_channels, 1))\n\n    def forward(self, x, t=0):\n        start = t * self.num_layers\n        end = start + self.num_layers\n        for i in range(start, end - 1):\n            x = F.gelu(self.layers[i](x))\n        x = self.layers[end - 1](x)\n        return x\n\n\nclass MLP3d(MLP2d):\n    def __init__(self, in_channels, out_channels, mid_channels, T=1, num_layers=2):\n        super(MLP3d, self).__init__(in_channels, out_channels, mid_channels, T, num_layers)\n\n        self.layers = nn.ModuleList()\n        for _ in range(T):\n            self.layers.append(nn.Conv3d(in_channels, mid_channels, 1))\n            # After (3x3x3 kernel)\n            #self.layers.append(nn.Conv3d(in_channels, mid_channels, 3, padding=1))  ## Changed from 1*1*1 to 3*3*3\n            for _ in range(self.num_layers - 2):\n                self.layers.append(nn.Conv3d(mid_channels, mid_channels, 1))\n                #self.layers.append(nn.Conv3d(mid_channels, mid_channels, 3, padding=1))  ## Changed from 1 to 3\n            self.layers.append(nn.Conv3d(mid_channels, out_channels, 1))\n            #self.layers.append(nn.Conv3d(mid_channels, out_channels, 3, padding=1))  ## Changed from 1 to 3\n\n\nclass FNO2d(nn.Module):\n    def __init__(self, modes1, modes2, width, width_q, T_in, T_out, n_layers):\n        super(FNO2d, self).__init__()\n\n        \"\"\"\n        The overall network. It contains 4 layers of the Fourier layer.\n        1. Lift the input to the desire channel dimension by self.fc0 .\n        2. 4 layers of the integral operators u' = (W + K)(u).\n            W defined by self.w; K defined by self.conv .\n        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n\n        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n        input shape: (batchsize, x=64, y=64, c=12)\n        output: the solution of the next timestep\n        output shape: (batchsize, x=64, y=64, c=1)\n        \"\"\"\n\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.width = width\n        self.width_q = width_q\n        self.T_in = T_in\n        self.T_out = T_out\n        self.padding = 8  # pad the domain if input is non-periodic\n        self.n_layers = n_layers\n\n        self.p = nn.Linear(T_in + 2, self.width)  # We start with an input x == u(x,y) of shape (batch,x,y,c), We lift it to a higher-dimensional space using a linear layer\n        # v0(x,y) = p(x=u)\n        self.convs = nn.ModuleList(\n            [SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(n_layers)]) # 2D Fast Fourier Transform (FFT) --> v0 = F(v0)\n        self.mlps = nn.ModuleList([MLP2d(self.width, self.width, self.width) for _ in range(n_layers)])\n        self.ws = nn.ModuleList([nn.Conv2d(self.width, self.width, 1) for _ in range(n_layers)]) # Pointwise convolution layers\n        self.norm = nn.InstanceNorm2d(self.width)\n        self.q = MLP2d(self.width, 1, self.width_q)  # output channel is 1: u(x, y)\n\n    def forward(self, x):\n        grid = get_grid_2d(x.shape, x.device)\n        x = torch.cat((x, grid), dim=-1)\n        x = self.p(x)\n        x = x.permute(0, 3, 1, 2)\n        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            '''\n            x1 = self.mlps[i](x1): Local Mixing Using MLP: Since the Fourier convolution captures global dependencies,\n             we still need local interactions --> v_i+1 = sigma(W.vi  +  b), \n             which W and b are learnable parameters, and  is the activation function.\n            '''\n            x2 = self.ws[i](x)\n            '''\n             x2 = self.ws[i](x): applies a pointwise convolution (11 convolution) to the input tensor x.\n                self.ws is a list (nn.ModuleList) of 11 convolutional layers.\n                Each self.ws[i] is a 2D convolution layer (nn.Conv2d) with a kernel size of 1x1.\n                The purpose of these layers is to perform a linear transformation of the feature maps \n                without mixing spatial locations.\n\n            '''\n            x = x1 + x2 #  Merge Global and Local Representations\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n        x = self.q(x)\n        '''\n         Output Projection back to the desired shape using another MLP\n        v_out = Q.v_final(x,y)\n        Q is a learnable projection.\n\n        '''\n        x = x.permute(0, 2, 3, 1)\n        #The final shape of x is (batch,x,y,1), which represents the predicted function value at each spatial location.\n        return x\n\n\nclass TNO2d(FNO2d):\n    def __init__(self, modes1, modes2, width, width_q, width_h, T_in, T_out, n_layers, n_layers_q=2, n_layers_h=4):\n        super(TNO2d, self).__init__(modes1, modes2, width, width_q, T_in, T_out, n_layers)\n        '''\n         TNO2d extends FNO2d. It introduces temporal modeling by adding two MLP layers:\n        self.q  projects the Fourier features to output over time.\n        self.h  handles temporal dependencies between consecutive time steps.\n        New parameters added:\n        width_h  controls temporal memory features.\n        n_layers_q  depth of self.q (output MLP).\n        n_layers_h  depth of self.h (temporal evolution MLP).\n        '''\n        self.width_h = width_h\n        #self.q = MLP2d(self.width, 1, self.width, T_out) # for AC\n        #self.q2 = MLP2d(1, 1, self.width // 4, T_out - 1)\n        #self.q = MLP2d(self.width, 1, 2 * self.width, T_out)  # for CH\n        #self.q2 = MLP2d(1, 1, self.width, T_out - 1)\n        self.q = MLP2d(self.width, 1, self.width_q, T_out, n_layers_q)  # for CHNL\n        self.h = MLP2d(1, 1, self.width_h, T_out - 1, n_layers_h)\n\n    def forward(self, x):\n        grid = get_grid_2d(x.shape, x.device)\n        x = torch.cat((x, grid), dim=-1) # a(x) or= x : Input function (e.g., initial condition for a PDE)\n        x = self.p(x) # \tLifts input to a high-dimensional space\n        x = x.permute(0, 3, 1, 2)\n        # x = F.pad(x, [0, self.padding, 0, self.padding])\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x # x=GELU(FourierConv(x)+MLP(x)+PointwiseConv(x)\n\n        # x = x[..., :-self.padding, :-self.padding]\n        '''\n         Temporal Evolution Loop\n        Initial time step prediction:\n        Uses self.q(x) to generate the first time step.\n        Stores result in X[..., 0]\n        '''\n        X = torch.zeros(*grid.shape[:-1], self.T_out, device=x.device)\n        xt = self.q(x)\n        X[..., 0] = xt.permute(0, 2, 3, 1).squeeze(-1)\n\n        for t in range(1, self.T_out):\n            x1 = self.q(x, t) # Predicts the next step using Fourier features.  # Q_n(W_L+ K_L )...P(a(x)), Projects final Fourier features to outpu\n            x2 = self.h(xt, t - 1) # Uses previous output (xt) to refine the next state. # H_nG_ (x,t_(n-1) )(a(x)), Models dependency on past states\n            xt = x1 + x2 #  Solution at time t_n : x_t = G_ (x,t_n )(a(x))\n            X[..., t] = xt.permute(0, 2, 3, 1).squeeze(-1)\n            '''\n             Uses previous output (xt) to refine the next state.\n            Combines both predictions --> x_t=MLP_q(x)+MLP_h[(x t1)]\n            Stores result in X[..., t]\n            '''\n        return X\n\n\nclass FNO3d(nn.Module):\n    def __init__(self, modes1, modes2, modes3, width, width_q, T_in, T_out, n_layers, n_layers_q=2, n_layers_h=2):\n        super(FNO3d, self).__init__()\n\n        \"\"\"\n        The FNO3d class is a deep learning model designed for solving spatiotemporal problems. \n        The overall network. It contains 4 layers of the Fourier layer.\n        1. Lift the input to the desire channel dimension by self.fc0 .\n        2. 4 layers of the integral operators u' = (W + K)(u).\n            W defined by self.w; K defined by self.conv .\n        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n\n        input: the solution of the first 10 time_steps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n        input shape: (batchsize, x=64, y=64, t=40, c=13)\n        output: the solution of the next 40 time_steps\n        output shape: (batchsize, x=64, y=64, t=40, c=1)\n        \"\"\"\n\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.modes3 = modes3\n        self.width = width\n        self.width_q = width_q\n        self.T_in = T_in\n        self.T_out = T_out\n        self.padding = 6  # pad the domain if input is non-periodic\n        self.n_layers = n_layers\n\n        self.p = nn.Linear(self.T_in + 3, self.width)  # Lifting Layer: input channel is 12: the solution of the first 10 time_steps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n\n        self.convs = nn.ModuleList(\n            [SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3) for _ in range(n_layers)])\n        self.mlps = nn.ModuleList([MLP3d(self.width, self.width, self.width) for _ in range(n_layers)])\n        self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 1) for _ in range(n_layers)])\n        #self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 3, padding=1) for _ in range(n_layers)])  ## kernel changed\n        #self.q = MLP3d(self.width, 1, self.width)  # output channel is 1: u(x, y)\n        self.q = MLP3d(self.width, 1, self.width_q)  # output channel is 1: u(x, y)\n\n    def forward(self, x):\n        #x = x.unsqueeze(3).repeat([1, 1, 1, self.T_out, 1])\n        grid = get_grid_3d(x.shape, x.device)\n        #print(' x shape:', x.shape)\n        x = torch.cat((x, grid), dim=-1)\n        #print(' x shape after cat:', x.shape)\n        x = self.p(x)\n        x = x.permute(0, 4, 1, 2, 3)\n        #x = F.pad(x, [0, self.padding])  # pad the domain if input is non-periodic\n        #print(' x shape after permute:', x.shape)\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        #x = x[..., :-self.padding]\n        x = self.q(x)\n        #x = x.permute(0, 2, 3, 4, 1)[..., 0]  # pad the domain if input is non-periodic\n        x = x.permute(0, 2, 3, 4, 1)\n        #print('FNO3d return x shape:', x.shape)\n        return x\n\n\nclass TNO3d(FNO3d):\n    def __init__(self, modes1, modes2, modes3, width, width_q, width_h, T_in, T_out, n_layers):\n        super(TNO3d, self).__init__(modes1, modes2, modes3, width, width_q, T_in, T_out, n_layers)\n        \"\"\"\n        The super() function calls the parent class (FNO3d) constructor to initialize \n        the parameters that are inherited from the parent class.\n        input: the initial condition and locations (a(x, y, z), x, y, z)\n        input shape: (batchsize, x=s, y=s, z=s, c=4)\n        output: the solution \n        output shape: (batchsize, x=s, y=s, z=s, t=T)\n        \"\"\"\n        self.width_h = width_h\n\n        #self.q = MLP3d(self.width, 1, self.width, T_out)\n        #self.q2 = MLP3d(1, 1, self.width // 4, T_out - 1)\n        self.q = MLP3d(self.width, 1, self.width_q, T_out)\n        self.h = MLP3d(1, 1, self.width_h, T_out - 1)\n\n    def forward(self, x):\n        grid = get_grid_3d(x.shape, x.device)\n        #print('x shape: ',x.shape)\n        #print('grid shape: ', grid.shape)\n        x = torch.cat((x, grid), dim=-1)\n        x = self.p(x)\n        x = x.permute(0, 4, 1, 2, 3)\n        # x = F.pad(x, [0, self.padding, 0, self.padding])\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        # x = x[..., :-self.padding, :-self.padding]\n        X = torch.zeros(*grid.shape[:-1], self.T_out, device=x.device)\n        xt = self.q(x)\n        X[..., 0] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)\n        for t in range(1, self.T_out):\n            x1 = self.q(x, t)\n            x2 = self.h(xt, t - 1)\n            xt = x1 + x2\n            X[..., t] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)\n\n        #print('shape X for model TNO: ', X.shape)\n        return X\n\n\ndef compute_spatial_derivatives(field, coordinates):\n    \"\"\"\n    Computes first and second spatial derivatives of a field with respect to coordinates\n\n    Args:\n        field: Tensor of shape [batch, x, y, z]\n        coordinates: Tensor of shape [batch, x, y, z, 3] (must require grad)\n\n    Returns:\n        laplacian: Tensor of shape [batch, x, y, z] containing \n    \"\"\"\n    # Ensure we can compute gradients\n    field = field.clone().requires_grad_(True)\n    coordinates = coordinates.clone().requires_grad_(True)\n\n    # Compute first derivatives\n    grad_outputs = torch.ones_like(field)\n    grad_x, grad_y, grad_z = torch.autograd.grad(\n        outputs=field,\n        inputs=coordinates,\n        grad_outputs=grad_outputs,\n        create_graph=True,\n        retain_graph=True,\n        allow_unused=False\n    )[0].unbind(dim=-1)\n\n    # Compute second derivatives\n    laplacian = 0.0\n    for grad in [grad_x, grad_y, grad_z]:\n        grad_outputs = torch.ones_like(grad)\n        d2phi = torch.autograd.grad(\n            outputs=grad,\n            inputs=coordinates,\n            grad_outputs=grad_outputs,\n            create_graph=True,\n            retain_graph=True,\n            allow_unused=False\n        )[0].unbind(dim=-1)[0]  # Take derivative along same axis\n        laplacian += d2phi\n\n    return laplacian\ndef compute_allen_cahn_loss(predictions, coordinates, epsilon=0.05, delta_t=0.01):\n    \"\"\"\n    Robust physics loss calculation for Allen-Cahn equation\n\n    Args:\n        predictions: Model outputs [batch, x, y, z, time]\n        coordinates: Spatial coordinates [batch, x, y, z, 3]\n        epsilon: Interface width parameter\n        delta_t: Time step size\n\n    Returns:\n        pde_loss: PDE residual loss\n        bc_loss: Boundary condition loss\n    \"\"\"\n    batch_size = predictions.shape[0]\n    pde_loss = 0.0\n    bc_loss = 0.0\n\n    # Compute for each time step\n    for t in range(predictions.shape[-1]):\n        phi_t = predictions[..., t]\n\n        # Compute Laplacian\n        laplacian = compute_spatial_derivatives(phi_t, coordinates)\n\n        # Compute time derivative (finite difference)\n        if t == 0:\n            dt = (predictions[..., t + 1] - predictions[..., t]) / delta_t\n        elif t == predictions.shape[-1] - 1:\n            dt = (predictions[..., t] - predictions[..., t - 1]) / delta_t\n        else:\n            dt = (predictions[..., t + 1] - predictions[..., t - 1]) / (2 * delta_t)\n\n        # Allen-Cahn residual\n        residual = dt - (laplacian - (1 / epsilon ** 2) * (phi_t ** 3 - phi_t))\n        pde_loss += torch.mean(residual ** 2)\n\n        # Periodic boundary conditions\n        bc_loss += torch.mean((phi_t[..., 0, :, :] - phi_t[..., -1, :, :]) ** 2)\n        bc_loss += torch.mean((phi_t[..., :, 0, :] - phi_t[..., :, -1, :]) ** 2)\n        bc_loss += torch.mean((phi_t[..., :, :, 0] - phi_t[..., :, :, -1]) ** 2)\n\n    return pde_loss / predictions.shape[-1], bc_loss / (3 * predictions.shape[-1])
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/networks.py b/networks.py
++--- a/networks.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/networks.py	(date 1754475689239)
++@@ -410,8 +410,9 @@
++         xt = self.q(x)
++         X[..., 0] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)
++         for t in range(1, self.T_out):
++-            x1 = self.q(x, t)
++-            x2 = self.h(xt, t - 1)
+++            #  two special MLPs (self.q and self.h) to generate the forecast step-by-step.
+++            x1 = self.q(x, t) # A new prediction based on the original initial state.
+++            x2 = self.h(xt, t - 1) #  A "correction" or "update" based on the prediction from the previous step (Time=1).
++             xt = x1 + x2
++             X[..., t] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)
++ 
++@@ -419,87 +420,150 @@
++         return X
++ 
++ 
++-def compute_spatial_derivatives(field, coordinates):
++-    """
++-    Computes first and second spatial derivatives of a field with respect to coordinates
+++###############
+++###############
+++
+++
+++# Add to networks.py
+++''''
+++def get_grid_4d(shape, device):
+++    batchsize, size_x, size_y, size_z, size_t = shape[0], shape[1], shape[2], shape[3], shape[4]
+++    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
+++    gridx = gridx.reshape(1, size_x, 1, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, size_t, 1])
+++    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
+++    gridy = gridy.reshape(1, 1, size_y, 1, 1, 1).repeat([batchsize, size_x, 1, size_z, size_t, 1])
+++    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
+++    gridz = gridz.reshape(1, 1, 1, size_z, 1, 1).repeat([batchsize, size_x, size_y, 1, size_t, 1])
+++    gridt = torch.tensor(np.linspace(0, 1, size_t), dtype=torch.float)
+++    gridt = gridt.reshape(1, 1, 1, 1, size_t, 1).repeat([batchsize, size_x, size_y, size_z, 1, 1])
+++    return torch.cat((gridx, gridy, gridz, gridt), dim=-1).to(device)
+++'''
+++
+++def get_grid_4d(shape, device):
+++    batchsize, size_x, size_y, size_z, _ = shape  # Note: last dim is channels, not time
+++    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
+++    gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])
+++    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
+++    gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])
+++    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
+++    gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])
+++    return torch.cat((gridx, gridy, gridz), dim=-1).to(device)  # Returns (batch, x, y, z, 3)
+++
+++
+++def compl_mul4d(inp, weights):
+++    # (batch, in_channel, x,y,z,t), (in_channel, out_channel, x,y,z,t) -> (batch, out_channel, x,y,z,t)
+++    return torch.einsum("bixyzt,ioxyzt->boxyzt", inp, weights)
+++
+++
+++class SpectralConv4d(nn.Module):
+++    def __init__(self, in_channels, out_channels, modes1, modes2, modes3, modes4):
+++        super(SpectralConv4d, self).__init__()
++ 
++-    Args:
++-        field: Tensor of shape [batch, x, y, z]
++-        coordinates: Tensor of shape [batch, x, y, z, 3] (must require grad)
+++        self.in_channels = in_channels
+++        self.out_channels = out_channels
+++        self.modes1 = modes1  # Number of Fourier modes to multiply
+++        self.modes2 = modes2
+++        self.modes3 = modes3
+++        self.modes4 = modes4
++ 
++-    Returns:
++-        laplacian: Tensor of shape [batch, x, y, z] containing 
++-    """
++-    # Ensure we can compute gradients
++-    field = field.clone().requires_grad_(True)
++-    coordinates = coordinates.clone().requires_grad_(True)
+++        self.scale = (1 / (in_channels * out_channels))
+++        # We'll use 8 weights for 4D (similar to how 3D uses 4 weights)
+++        self.weights1 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights2 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights3 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights4 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights5 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights6 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights7 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights8 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
++ 
++-    # Compute first derivatives
++-    grad_outputs = torch.ones_like(field)
++-    grad_x, grad_y, grad_z = torch.autograd.grad(
++-        outputs=field,
++-        inputs=coordinates,
++-        grad_outputs=grad_outputs,
++-        create_graph=True,
++-        retain_graph=True,
++-        allow_unused=False
++-    )[0].unbind(dim=-1)
+++    def forward(self, x):
+++        batchsize = x.shape[0]
+++        # Compute Fourier coefficients
+++        x_ft = torch.fft.rfftn(x, dim=[-4, -3, -2, -1])  # FFT over spatial and time dimensions
++ 
++-    # Compute second derivatives
++-    laplacian = 0.0
++-    for grad in [grad_x, grad_y, grad_z]:
++-        grad_outputs = torch.ones_like(grad)
++-        d2phi = torch.autograd.grad(
++-            outputs=grad,
++-            inputs=coordinates,
++-            grad_outputs=grad_outputs,
++-            create_graph=True,
++-            retain_graph=True,
++-            allow_unused=False
++-        )[0].unbind(dim=-1)[0]  # Take derivative along same axis
++-        laplacian += d2phi
+++        # Multiply relevant Fourier modes
+++        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-4), x.size(-3), x.size(-2), x.size(-1) // 2 + 1,
+++                             dtype=torch.cfloat, device=x.device)
++ 
++-    return laplacian
++-def compute_allen_cahn_loss(predictions, coordinates, epsilon=0.05, delta_t=0.01):
++-    """
++-    Robust physics loss calculation for Allen-Cahn equation
+++        # Handle all combinations of modes
+++        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3, :self.modes4], self.weights1)
+++        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3, :self.modes4], self.weights2)
+++        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3, :self.modes4], self.weights3)
+++        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3, :self.modes4], self.weights4)
+++        out_ft[:, :, :self.modes1, :self.modes2, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, :self.modes2, -self.modes3:, :self.modes4], self.weights5)
+++        out_ft[:, :, -self.modes1:, :self.modes2, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, :self.modes2, -self.modes3:, :self.modes4], self.weights6)
+++        out_ft[:, :, :self.modes1, -self.modes2:, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, -self.modes2:, -self.modes3:, :self.modes4], self.weights7)
+++        out_ft[:, :, -self.modes1:, -self.modes2:, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, -self.modes2:, -self.modes3:, :self.modes4], self.weights8)
++ 
++-    Args:
++-        predictions: Model outputs [batch, x, y, z, time]
++-        coordinates: Spatial coordinates [batch, x, y, z, 3]
++-        epsilon: Interface width parameter
++-        delta_t: Time step size
+++        # Return to physical space
+++        x = torch.fft.irfftn(out_ft, s=(x.size(-4), x.size(-3), x.size(-2), x.size(-1)))
+++        return x
++ 
++-    Returns:
++-        pde_loss: PDE residual loss
++-        bc_loss: Boundary condition loss
++-    """
++-    batch_size = predictions.shape[0]
++-    pde_loss = 0.0
++-    bc_loss = 0.0
++ 
++-    # Compute for each time step
++-    for t in range(predictions.shape[-1]):
++-        phi_t = predictions[..., t]
+++class FNO4d(nn.Module):
+++    def __init__(self, modes1, modes2, modes3, modes4_internal, width, width_q, T_in_channels, n_layers):
+++        super(FNO4d, self).__init__()
++ 
++-        # Compute Laplacian
++-        laplacian = compute_spatial_derivatives(phi_t, coordinates)
+++        self.modes1 = modes1
+++        self.modes2 = modes2
+++        self.modes3 = modes3
+++        self.modes4 = modes4_internal
+++        self.width = width
+++        self.width_q = width_q
+++        self.T_in = T_in_channels
+++        self.n_layers = n_layers
+++        self.padding = 6
++ 
++-        # Compute time derivative (finite difference)
++-        if t == 0:
++-            dt = (predictions[..., t + 1] - predictions[..., t]) / delta_t
++-        elif t == predictions.shape[-1] - 1:
++-            dt = (predictions[..., t] - predictions[..., t - 1]) / delta_t
++-        else:
++-            dt = (predictions[..., t + 1] - predictions[..., t - 1]) / (2 * delta_t)
+++        # Input is (x,y,z) + time channels (t_in_channels) + 3 spatial coordinates
+++        self.p = nn.Linear(self.T_in + 3, self.width)  # +3 for (x,y,z) coordinates
++ 
++-        # Allen-Cahn residual
++-        residual = dt - (laplacian - (1 / epsilon ** 2) * (phi_t ** 3 - phi_t))
++-        pde_loss += torch.mean(residual ** 2)
+++        self.convs = nn.ModuleList([
+++            SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)
+++            for _ in range(n_layers)
+++        ])
+++        self.mlps = nn.ModuleList([MLP3d(self.width, self.width, self.width) for _ in range(n_layers)])
+++        self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 1) for _ in range(n_layers)])
+++        self.q = MLP3d(self.width, 1, self.width_q)  # Output channel is 1
++ 
++-        # Periodic boundary conditions
++-        bc_loss += torch.mean((phi_t[..., 0, :, :] - phi_t[..., -1, :, :]) ** 2)
++-        bc_loss += torch.mean((phi_t[..., :, 0, :] - phi_t[..., :, -1, :]) ** 2)
++-        bc_loss += torch.mean((phi_t[..., :, :, 0] - phi_t[..., :, :, -1]) ** 2)
+++    def forward(self, x):
+++        # Input shape: (batch, x, y, z, t_in_channels)
+++        grid = get_grid_4d(x.shape, x.device)
+++        x = torch.cat((x, grid), dim=-1)  # This is the key step where "time" is handled.  Now both are 5D: (batch, x, y, z, t_in_channels + 3)
+++        x = self.p(x)  # Lift to higher dimension
+++        x = x.permute(0, 4, 1, 2, 3)  # (batch, channels, x, y, z)
++ 
++-    return pde_loss / predictions.shape[-1], bc_loss / (3 * predictions.shape[-1])
++\ No newline at end of file
+++        for i in range(self.n_layers):
+++            x1 = self.convs[i](x)
+++            x1 = self.mlps[i](x1)
+++            x2 = self.ws[i](x)
+++            x = x1 + x2
+++            x = F.gelu(x) if i < self.n_layers - 1 else x
+++
+++        x = self.q(x)
+++        x = x.permute(0, 2, 3, 4, 1)  # (batch, x, y, z, 1)
+++        return x
++\ No newline at end of file
++Index: configs/config_SH3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:2'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 # 5250 # 7500\nnTest = 300 # 2250 #500\nbatch_size = 10 # 50 # 50\nlearning_rate = 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-4\nepochs = 30 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 16\nwidth =  12 #32\nwidth_q =   width # width # 2 * width #\nwidth_h = width//2  # width//4 # width #\nn_layers = 2 # 8\n\n# Discretization\ns = 32 # 32 # 64\nT_in = 1\nT_out = 91 # 100 # 100\n\n# Training Setting\nnormalized = True # False #True\ntraining = True # False  # True\nload_model = False # False #True\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results\n\n# Plotting\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\nLx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\nLy =Lx\nLz= Lx\n\nindex = 62  # 24 # 62\n#domain = [-np.pi, np.pi]  ######\ndomain = [-Lx/2, Lx/2]\n\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 50, 90]\n\n\n### Hybrid method\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\n#Lx = np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\n# domain = [-Lx/2, Lx/2] # Assuming centered domain\n\n# Time Discretization (from MATLAB)\ndt_sim = 0.0000002 # Simulation time step\nNt = 100 # Total simulation steps\nnum_saved_steps = 101 # Number of saved steps (includes t=0)\nns = Nt / (num_saved_steps - 1) # Interval between saved steps\ndt_model = ns * dt_sim # Effective time step between model outputs\n\n# PDE Parameters\nepsilon = 0.15\n#pde_weight = 0.3 # Example: 30% physics loss\npde_weight = 0.0 # Example: 70% physics loss\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\npde_loss_scaler = 1e-11\n###########################\n# ... rest of config ...
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_SH3D_FNO3d.py b/configs/config_SH3D_FNO3d.py
++--- a/configs/config_SH3D_FNO3d.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/configs/config_SH3D_FNO3d.py	(date 1754475689336)
++@@ -33,12 +33,12 @@
++ parent_dir = './data/'
++ #matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'
++ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
++-
+++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
++ # Plotting
++ 
++ # In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
++-Lx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++Lx = 15 # 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
++ Ly =Lx
++ Lz= Lx
++ 
++@@ -62,7 +62,7 @@
++ # domain = [-Lx/2, Lx/2] # Assuming centered domain
++ 
++ # Time Discretization (from MATLAB)
++-dt_sim = 0.0000002 # Simulation time step
+++dt_sim = 0.0002 # Simulation time step
++ Nt = 100 # Total simulation steps
++ num_saved_steps = 101 # Number of saved steps (includes t=0)
++ ns = Nt / (num_saved_steps - 1) # Interval between saved steps
++@@ -75,6 +75,6 @@
++ # Learning Rate Scheduler Parameters (for StepLR)
++ scheduler_step = 20  # Decay learning rate every 20 epochs
++ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++-pde_loss_scaler = 1e-11
+++pde_loss_scaler = 1e-0
++ ###########################
++ # ... rest of config ...
++\ No newline at end of file
++Index: configs/config_CH3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500\nnTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500\nbatch_size = 20 # 50 # 3 # 20 # 50 # 5 # 50\nlearning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-3 # 1e-4\nepochs = 100 # 500 # 1000 # 25 # 100 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 10 #12 # 14 # 16 # 10 # 16\nwidth = 12 # 8 #12 #14 # 12 # 16 # 32\nwidth_q = width # 2 * width #\nwidth_h = width//2 # width//4 # width #\nn_layers = 4 # 4 # 5 # 5 # 8\n\n# Discretization\n\ns = 64 # 64 #32 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False # True # False  # True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'\n\n\n# Plotting\nindex = 62  # 24 # 62\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_CH3D_TNO3d.py b/configs/config_CH3D_TNO3d.py
++--- a/configs/config_CH3D_TNO3d.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/configs/config_CH3D_TNO3d.py	(date 1754475689348)
++@@ -6,24 +6,24 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
++-nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
++-batch_size = 20 # 50 # 3 # 20 # 50 # 5 # 50
+++nTrain = 1200 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+++nTest =  300 # 300 # 100 # 2000 # 4000 #300 # 300 #500
+++batch_size = 20 # 15 # 50 # 3 # 20 # 50 # 5 # 50
++ learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
++ weight_decay = 1e-4 # 1e-3 # 1e-4
++-epochs = 100 # 500 # 1000 # 25 # 100 # 1000
+++epochs = 50 # 50 # 50 # 100 # 500 # 1000 # 25 # 100 # 1000
++ iterations = epochs * (nTrain // batch_size)
++-modes = 14 # 10 #12 # 14 # 16 # 10 # 16
++-width = 12 # 8 #12 #14 # 12 # 16 # 32
+++modes = 14 # 14 # 12 # 14 # 10 #12 # 14 # 16 # 10 # 16
+++width = 12 # 12 # 8 #12 #14 # 12 # 16 # 32
++ width_q = width # 2 * width #
++ width_h = width//2 # width//4 # width #
++-n_layers = 4 # 4 # 5 # 5 # 8
+++n_layers = 3 # 4 # 5 # 5 # 8
++ 
++ # Discretization
++ 
++-s = 64 # 64 #32 # 64
+++s = 32 # 64 # 64 #32 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -33,16 +33,46 @@
++ # Database
++ parent_dir = './data/'
++ #matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
++-
++-
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_32.mat'
+++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++ # Plotting
++ index = 62  # 24 # 62
++-domain = [-np.pi, np.pi]
+++Lx = 2 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
+++#domain = [-np.pi, np.pi]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.05 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_MBE3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_MBE3D_FNO4d.py b/configs/config_MBE3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1754475689374)
+++++ b/configs/config_MBE3D_FNO4d.py	(date 1754475689374)
++@@ -0,0 +1,75 @@
+++
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda:1'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1200 #1600 # 4000
+++nTest = 300  # 400
+++batch_size = 50 # 10 # 20 # 50# 25 #100
+++learning_rate = 0.001
+++weight_decay = 1e-4
+++epochs = 30 # 50 # 1000
+++iterations = epochs * (nTrain // batch_size)
+++modes = 14 # 12
+++width = 12 #32
+++width_q = width #32
+++width_h = width // 2 # width # 32
+++n_layers = 2 # 4
+++
+++# Discretization
+++s = 32
+++T_in = 1
+++T_out = 91 #20 #91 # 20 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True  # True  # True
+++load_model = False #True  # False  # False
+++
+++# Database
+++parent_dir = './data/'
+++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat'
+++
+++# Plotting
+++# Plotting
+++index = 62  # 72
+++#domain = [-np.pi, np.pi]
+++Lx = 2* np.pi  #10 # np.pi            # Domain size from MATLAB
+++domain = [-Lx/2, Lx/2]
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 59, 79]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_CH3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_CH3D_FNO4d.py b/configs/config_CH3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1754475689429)
+++++ b/configs/config_CH3D_FNO4d.py	(date 1754475689429)
++@@ -0,0 +1,77 @@
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda:3'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1300 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+++nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
+++batch_size = 20 # 10 # 20 # 20 # 50 # 3 # 20 # 50 # 5 # 50
+++learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
+++weight_decay = 1e-4 # 1e-3 # 1e-4
+++epochs = 50 # 100 # 500 # 1000 # 25 # 100 # 1000
+++iterations = epochs * (nTrain // batch_size)
+++modes = 14 # 10 #12 # 14 # 16 # 10 # 16
+++width = 12 # 8 #12 #14 # 12 # 16 # 32
+++width_q = width # 2 * width #
+++width_h = width//2 # width//4 # width #
+++n_layers = 3 # 2 # 4 # 5 # 5 # 8
+++
+++# Discretization
+++
+++s = 32 # 64 # 32 # 64 #32 # 64
+++T_in = 1
+++T_out = 91 # 20 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True # False # True # False  # True
+++load_model = False # True # False # False #True
+++
+++# Database
+++parent_dir = './data/'
+++
+++#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
+++# Plotting
+++index = 62  # 24 # 62
+++#domain = [-np.pi, np.pi]
+++Lx = 2 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.05  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: configs/config_MBE3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\nimport numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 #1600 # 4000\nnTest = 300  # 400\nbatch_size = 50# 25 #100\nlearning_rate = 0.005\nweight_decay = 1e-4\nepochs = 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 12\nwidth = 12 #32\nwidth_q = width #32\nwidth_h = width // 2 # width # 32\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # True  # True\nload_model = False #True  # False  # False\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'\nmatlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 9  # 72\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_MBE3D_FNO3d.py b/configs/config_MBE3D_FNO3d.py
++--- a/configs/config_MBE3D_FNO3d.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/configs/config_MBE3D_FNO3d.py	(date 1754475689472)
++@@ -9,21 +9,21 @@
++ # Network Parameters
++ nTrain = 1200 #1600 # 4000
++ nTest = 300  # 400
++-batch_size = 50# 25 #100
++-learning_rate = 0.005
+++batch_size = 10 # 20 # 50# 25 #100
+++learning_rate = 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 1000
+++epochs = 50 # 50 # 1000
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 # 12
++ width = 12 #32
++ width_q = width #32
++ width_h = width // 2 # width # 32
++-n_layers = 4
+++n_layers = 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -32,14 +32,44 @@
++ 
++ # Database
++ parent_dir = './data/'
++-#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'
++-matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat'
+++
+++# Plotting
++ # Plotting
++-index = 9  # 72
++-domain = [-np.pi, np.pi]
+++index = 62  # 72
+++#domain = [-np.pi, np.pi]
+++Lx = 10 # np.pi            # Domain size from MATLAB
+++domain = [-Lx/2, Lx/2]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: PFC3D/.idea/PFC3D.iml
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/PFC3D/.idea/PFC3D.iml b/PFC3D/.idea/PFC3D.iml
++new file mode 100644
++--- /dev/null	(date 1754475689304)
+++++ b/PFC3D/.idea/PFC3D.iml	(date 1754475689304)
++@@ -0,0 +1,8 @@
+++<?xml version="1.0" encoding="UTF-8"?>
+++<module type="PYTHON_MODULE" version="4">
+++  <component name="NewModuleRootManager">
+++    <content url="file://$MODULE_DIR$" />
+++    <orderEntry type="inheritedJdk" />
+++    <orderEntry type="sourceFolder" forTests="false" />
+++  </component>
+++</module>
++\ No newline at end of file
++Index: configs/config_AC3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1000 # 900 # 1000\nnTest = 300 # 100 # 100\nbatch_size = 50 # 20 #5 # 25\nlearning_rate = 0.001\nweight_decay = 1e-4\nepochs = 50 # 100 # 900  # 100\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 8 # last time modes =  8\nwidth =  12 # 32 # last time width =  32\nwidth_q = width\nwidth_h = width // 2 # width // 4 # last time\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # False\nload_model = False # True  # True\n\n# Database\nparent_dir = './data/'\n# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'\n#matlab_dataset = 'AC3D_32_1000.mat'\nmatlab_dataset = 'AC3D_32_1300.mat'\n# Plotting\nindex = 9 # 12\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 69]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]\n\n#############\nLx = np.pi            # Domain size from MATLAB\n# Time Discretization Parameters (from AC3D MATLAB)\ndt_sim = 0.0001     # Time step in the MATLAB simulation\nNt_sim = 50        # Total number of simulation steps in MATLAB\nnum_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)\n# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps\n# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output\n# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.\ndt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in\n# PDE Parameters for Allen-Cahn (AC3D)\n# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.\n# The PDE implemented in calculate_pde_residual was:\n# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)\nepsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter\n# PINN Specific Settings (if PINN_MODE is True in main.py)\npde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.\n# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\n\npde_loss_scaler = 1e-5
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_AC3D_FNO3d.py b/configs/config_AC3D_FNO3d.py
++--- a/configs/config_AC3D_FNO3d.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/configs/config_AC3D_FNO3d.py	(date 1754475689457)
++@@ -8,21 +8,21 @@
++ # Network Parameters
++ nTrain = 1000 # 900 # 1000
++ nTest = 300 # 100 # 100
++-batch_size = 50 # 20 #5 # 25
+++batch_size = 10 # 50 # 20 #5 # 25
++ learning_rate = 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 100 # 900  # 100
+++epochs = 20 # 50 # 100 # 900  # 100
++ iterations = epochs * (nTrain // batch_size)
++ modes =  14 # 8 # last time modes =  8
++ width =  12 # 32 # last time width =  32
++ width_q = width
++ width_h = width // 2 # width // 4 # last time
++-n_layers = 4
+++n_layers = 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -33,19 +33,25 @@
++ parent_dir = './data/'
++ # matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
++ #matlab_dataset = 'AC3D_32_1000.mat'
++-matlab_dataset = 'AC3D_32_1300.mat'
+++#matlab_dataset = 'AC3D_32_1300.mat'
+++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
++ # Plotting
++ index = 9 # 12
++-domain = [-np.pi, np.pi]
+++#domain = [-np.pi, np.pi]
+++Lx = 5 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
+++
++ # time_steps = [29, 69]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ # time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
+++time_steps = [0, 50, 90]
++ 
++ #############
++-Lx = np.pi            # Domain size from MATLAB
+++#Lx = np.pi            # Domain size from MATLAB
++ # Time Discretization Parameters (from AC3D MATLAB)
++ dt_sim = 0.0001     # Time step in the MATLAB simulation
++ Nt_sim = 50        # Total number of simulation steps in MATLAB
++Index: configs/config_MBE3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\nimport numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 #1600 # 4000\nnTest = 300  # 400\nbatch_size = 50# 25 #100\nlearning_rate = 0.005\nweight_decay = 1e-4\nepochs = 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 12\nwidth = 12 #32\nwidth_q = width #32\nwidth_h = width // 2 # width # 32\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # True  # True\nload_model = False #True  # False  # False\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'\nmatlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 9  # 72\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_MBE3D_TNO3d.py b/configs/config_MBE3D_TNO3d.py
++--- a/configs/config_MBE3D_TNO3d.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/configs/config_MBE3D_TNO3d.py	(date 1754475689177)
++@@ -7,23 +7,23 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 1200 #1600 # 4000
+++nTrain = 1300 #1600 # 4000
++ nTest = 300  # 400
++-batch_size = 50# 25 #100
++-learning_rate = 0.005
+++batch_size = 20 # 50# 25 #100
+++learning_rate = 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 1000
+++epochs =  50 # 25# 50 # 20 # 50 # 1000
++ iterations = epochs * (nTrain // batch_size)
++-modes = 14 # 12
++-width = 12 #32
+++modes = 14 # 14 # 12
+++width = 12 # 12 #32
++ width_q = width #32
++ width_h = width // 2 # width # 32
++-n_layers = 4
+++n_layers = 2 # 4 # 3 # 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -32,14 +32,45 @@
++ 
++ # Database
++ parent_dir = './data/'
++-#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'
++-matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'
+++
+++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat' # I got the result based on this Dataset!! epochs = 50 !! n_layers = 2 pde_loss_scaler = 1e-4 # 1e-3
+++#matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat' # not valid
+++
++ # Plotting
++-index = 9  # 72
++-domain = [-np.pi, np.pi]
+++index = 62  # 72
+++#domain = [-np.pi, np.pi]
+++Lx = 2* np.pi  # 6 # 2* np.pi            # Domain size from MATLAB
+++domain = [-Lx/2, Lx/2]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.001 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.1 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4 # 1e-3
++\ No newline at end of file
++Index: MatlabCode/AC3D.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>clc;\nclear;\n\n%% Parameter Initialization\n\nFigDraw = 0; % Set to 1 to enable visualization, 0 to disable\n\n\n% Spatial Parameters\nNx = 32;\nNy = Nx;\nNz = Nx;\nLx = 3;\nLy = 3;\nLz = 3;\nhx = Lx / Nx;\nhy = Ly / Ny;\nhz = Lz / Nz;\n\nx = linspace(-0.5 * Lx + hx, 0.5 * Lx, Nx);\ny = linspace(-0.5 * Ly + hy, 0.5 * Ly, Ny);\nz = linspace(-0.5 * Lz + hz, 0.5 * Lz, Nz);\n\n[xx, yy, zz] = ndgrid(x, y, z);\n\n% Interfacial energy constant\nepsilon = 0.1;\nCahn = epsilon^2;\n\n% Discrete Fourier Transform\nkx = 2 * pi / Lx * [0:Nx / 2 -Nx / 2 + 1:-1];\nky = 2 * pi / Ly * [0:Ny / 2 -Ny / 2 + 1:-1];\nkz = 2 * pi / Lz * [0:Nz / 2 -Nz / 2 + 1:-1];\nk2x = kx.^2;\nk2y = ky.^2;\nk2z = kz.^2;\n[kxx, kyy, kzz] = ndgrid(k2x, k2y, k2z);\n\n% Time Discretization\n%dt = 0.001;\n%T = 100 * 0.001;\n%Nt = round(T / dt);\n%ns = 1;\n\n\n% Time Discretization\ndt = 0.0001; % Time step\nNt = 100; % Number of time steps\nT = Nt * dt; % Total simulation time\nnum_saved_steps = 101;\nns = Nt / (num_saved_steps - 1);\n\n% Dataset\ndata_size = 1300;\nnum_saved_steps = Nt + 1; % Save all steps\nbinary_filename = \"AC3D_\" + num2str(Nx) + \"_\" + num2str(data_size) + \".bin\";\nmat_filename = \"AC3D_\" + num2str(Nx) + \"_\" + num2str(data_size) + \".mat\";\n\n%% Prepare Binary File\nfileID = fopen(binary_filename, 'wb');\nif fileID == -1\n    error(\"Cannot open binary file for writing.\");\nend\n\n%% Visualization (Plot Section)\n\n\nif FigDraw\n    figure;\nend\n\n%% Initial Condition\ntau = 321;\nalpha = 95;\n\nfor data_num = 1:data_size\n    disp(\"Data number = \" + num2str(data_num));\n\n    norm_a = GRF3D(alpha, tau, Nx);\n    norm_a = norm_a - 0.85 * std(norm_a(:));\n    u = ones(Nx, Nx, Nz);\n    u(norm_a < 0) = -1;\n\n    all_iterations = zeros(num_saved_steps, Nx, Ny, Nz, 'single');\n\n    %% Initial Preview\n    if FigDraw\n        clf;\n        p1 = patch(isosurface(xx, yy, zz, real(u), 0));\n        set(p1, 'FaceColor', 'r', 'EdgeColor', 'none'); % Blue color for the surface\n        daspect([1 1 1]);\n        camlight;\n        lighting phong;\n        box on;\n        axis image;\n        view(45, 45); % Set the viewing angle\n        pause(2);\n    end\n\n    %% Update\n    for iter = 1:Nt\n        if FigDraw && mod(iter, ns) == 0\n            figure(1);\n            clf;\n            p1 = patch(isosurface(xx, yy, zz, real(u), 0));\n            set(p1, 'FaceColor', 'r', 'EdgeColor', 'none'); % Blue color for the surface\n            daspect([1 1 1]);\n            camlight;\n            lighting phong;\n            box on;\n            axis image;\n            view(45, 45); % Maintain consistent view\n            pause(0.01);\n        end\n\n        all_iterations(iter, :, :, :) = u;\n        u = real(u);\n\n        s_hat = fftn(Cahn * u - dt * (u.^3 - 3 * u));\n        v_hat = s_hat ./ (Cahn + dt * (2 + Cahn * (kxx + kyy + kzz)));\n        u = ifftn(v_hat);\n    end\n    all_iterations(end, :, :, :) = u; % Save final step\n\n    % Write data to binary file\n    fwrite(fileID, all_iterations, 'single');\nend\n\nfclose(fileID);\n\n%% Convert Binary Data to MAT File\nfileID = fopen(binary_filename, 'rb');\nif fileID == -1\n    error(\"Cannot open binary file for reading.\");\nend\n\nphi_mat = matfile(mat_filename, 'Writable', true);\nphi_mat.phi = zeros([data_size, num_saved_steps, Nx, Ny, Nz], 'single');\n\nfor data_num = 1:data_size\n    disp(\"Saving dataset \" + num2str(data_num));\n    data_chunk = fread(fileID, num_saved_steps * Nx * Ny * Nz, 'single');\n    phi_mat.phi(data_num, :, :, :, :) = reshape(data_chunk, [1, num_saved_steps, Nx, Ny, Nz]);\nend\n\nfclose(fileID);\n
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/AC3D.m b/MatlabCode/AC3D.m
++--- a/MatlabCode/AC3D.m	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/MatlabCode/AC3D.m	(date 1754475690096)
++@@ -1,146 +1,35 @@
++-clc;
++ clear;
++-
++-%% Parameter Initialization
++-
++-FigDraw = 0; % Set to 1 to enable visualization, 0 to disable
++-
++-
++-% Spatial Parameters
++-Nx = 32;
++-Ny = Nx;
++-Nz = Nx;
++-Lx = 3;
++-Ly = 3;
++-Lz = 3;
++-hx = Lx / Nx;
++-hy = Ly / Ny;
++-hz = Lz / Nz;
++-
++-x = linspace(-0.5 * Lx + hx, 0.5 * Lx, Nx);
++-y = linspace(-0.5 * Ly + hy, 0.5 * Ly, Ny);
++-z = linspace(-0.5 * Lz + hz, 0.5 * Lz, Nz);
++-
++-[xx, yy, zz] = ndgrid(x, y, z);
++-
++-% Interfacial energy constant
++-epsilon = 0.1;
++-Cahn = epsilon^2;
++-
++-% Discrete Fourier Transform
++-kx = 2 * pi / Lx * [0:Nx / 2 -Nx / 2 + 1:-1];
++-ky = 2 * pi / Ly * [0:Ny / 2 -Ny / 2 + 1:-1];
++-kz = 2 * pi / Lz * [0:Nz / 2 -Nz / 2 + 1:-1];
++-k2x = kx.^2;
++-k2y = ky.^2;
++-k2z = kz.^2;
++-[kxx, kyy, kzz] = ndgrid(k2x, k2y, k2z);
++-
++-% Time Discretization
++-%dt = 0.001;
++-%T = 100 * 0.001;
++-%Nt = round(T / dt);
++-%ns = 1;
++-
++-
++-% Time Discretization
++-dt = 0.0001; % Time step
++-Nt = 100; % Number of time steps
++-T = Nt * dt; % Total simulation time
++-num_saved_steps = 101;
++-ns = Nt / (num_saved_steps - 1);
++-
++-% Dataset
++-data_size = 1300;
++-num_saved_steps = Nt + 1; % Save all steps
++-binary_filename = "AC3D_" + num2str(Nx) + "_" + num2str(data_size) + ".bin";
++-mat_filename = "AC3D_" + num2str(Nx) + "_" + num2str(data_size) + ".mat";
++-
++-%% Prepare Binary File
++-fileID = fopen(binary_filename, 'wb');
++-if fileID == -1
++-    error("Cannot open binary file for writing.");
++-end
++-
++-%% Visualization (Plot Section)
++-
++-
++-if FigDraw
++-    figure;
++-end
++-
++-%% Initial Condition
++-tau = 321;
++-alpha = 95;
++-
++-for data_num = 1:data_size
++-    disp("Data number = " + num2str(data_num));
++-
++-    norm_a = GRF3D(alpha, tau, Nx);
++-    norm_a = norm_a - 0.85 * std(norm_a(:));
++-    u = ones(Nx, Nx, Nz);
++-    u(norm_a < 0) = -1;
++-
++-    all_iterations = zeros(num_saved_steps, Nx, Ny, Nz, 'single');
++-
++-    %% Initial Preview
++-    if FigDraw
++-        clf;
++-        p1 = patch(isosurface(xx, yy, zz, real(u), 0));
++-        set(p1, 'FaceColor', 'r', 'EdgeColor', 'none'); % Blue color for the surface
++-        daspect([1 1 1]);
++-        camlight;
++-        lighting phong;
++-        box on;
++-        axis image;
++-        view(45, 45); % Set the viewing angle
++-        pause(2);
++-    end
++-
++-    %% Update
++-    for iter = 1:Nt
++-        if FigDraw && mod(iter, ns) == 0
++-            figure(1);
++-            clf;
++-            p1 = patch(isosurface(xx, yy, zz, real(u), 0));
++-            set(p1, 'FaceColor', 'r', 'EdgeColor', 'none'); % Blue color for the surface
++-            daspect([1 1 1]);
++-            camlight;
++-            lighting phong;
++-            box on;
++-            axis image;
++-            view(45, 45); % Maintain consistent view
++-            pause(0.01);
++-        end
++-
++-        all_iterations(iter, :, :, :) = u;
++-        u = real(u);
++-
++-        s_hat = fftn(Cahn * u - dt * (u.^3 - 3 * u));
++-        v_hat = s_hat ./ (Cahn + dt * (2 + Cahn * (kxx + kyy + kzz)));
++-        u = ifftn(v_hat);
++-    end
++-    all_iterations(end, :, :, :) = u; % Save final step
++-
++-    % Write data to binary file
++-    fwrite(fileID, all_iterations, 'single');
++-end
++-
++-fclose(fileID);
++-
++-%% Convert Binary Data to MAT File
++-fileID = fopen(binary_filename, 'rb');
++-if fileID == -1
++-    error("Cannot open binary file for reading.");
++-end
++-
++-phi_mat = matfile(mat_filename, 'Writable', true);
++-phi_mat.phi = zeros([data_size, num_saved_steps, Nx, Ny, Nz], 'single');
++-
++-for data_num = 1:data_size
++-    disp("Saving dataset " + num2str(data_num));
++-    data_chunk = fread(fileID, num_saved_steps * Nx * Ny * Nz, 'single');
++-    phi_mat.phi(data_num, :, :, :, :) = reshape(data_chunk, [1, num_saved_steps, Nx, Ny, Nz]);
++-end
++-
++-fclose(fileID);
+++Nx=128; Ny=128; Nz=128; Lx=1.2; Ly=1.2; Lz=1.2; hx=Lx/Nx; hy=Ly/Ny; hz=Lz/Nz;
+++x=linspace(-0.5*Lx+hx,0.5*Lx,Nx);
+++y=linspace(-0.5*Ly+hy,0.5*Ly,Ny);
+++z=linspace(-0.5*Lz+hz,0.5*Lz,Nz);
+++[xx,yy,zz]=ndgrid(x,y,z); epsilon=hx; Cahn=epsilon^2;
+++u=rand(Nx,Ny,Nz)-0.5;
+++kx=2*pi/Lx*[0:Nx/2 -Nx/2+1:-1];
+++ky=2*pi/Ly*[0:Ny/2 -Ny/2+1:-1];
+++kz=2*pi/Lz*[0:Nz/2 -Nz/2+1:-1];
+++k2x = kx.^2; k2y = ky.^2; k2z = kz.^2;
+++[kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);
+++dt=0.01; T=0.5; Nt=round(T/dt); ns=Nt/10;
+++for iter=1:Nt
+++    disp(['iteration = ', num2str(iter)])
+++    u=real(u);
+++    s_hat=fftn(Cahn*u-dt*(u.^3-3*u));
+++    v_hat=s_hat./(Cahn+dt*(2+Cahn*(kxx+kyy+kzz)));
+++    u=ifftn(v_hat);
+++    if mod(iter, ns) == 0
+++        if isempty(p1)
+++            % First-time setup
+++            p1 = patch(isosurface(xx, yy, zz, real(u), 0.));
+++            set(p1, 'FaceColor', 'g', 'EdgeColor', 'none');
+++            daspect([1 1 1]); 
+++            camlight; lighting flat; % Simplified lighting
+++            box on; axis image;
+++            view(45, 45);
+++        else
+++            % Update isosurface data
+++            iso = isosurface(xx, yy, zz, real(u), 0.);
+++            set(p1, 'Vertices', iso.vertices, 'Faces', iso.faces);
+++        end
+++    end
+++end
++\ No newline at end of file
++Index: MatlabCode/SH3D.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>clc;\nclear;\nclose all\n\n%% Parameter Initialization\n\n% Spatial Parameters\nNx=80; \nNy=80; \nNz=80; \nLx=90; \nLy=90; \nLz=90; \nhx=Lx/Nx; \nhy=Ly/Ny; \nhz=Lz/Nz;\nx=linspace(-0.5*Lx+hx,0.5*Lx,Nx);\ny=linspace(-0.5*Ly+hy,0.5*Ly,Ny);\nz=linspace(-0.5*Lz+hz,0.5*Lz,Nz);\n[xx,yy,zz]=ndgrid(x,y,z); \n\n% constant\nepsilon=0.15;\n\n% Discrete Fourier Transform\nkx=2*pi/Lx*[0:Nx/2 -Nx/2+1:-1];\nky=2*pi/Ly*[0:Ny/2 -Ny/2+1:-1];\nkz=2*pi/Lz*[0:Nz/2 -Nz/2+1:-1];\nk2x = kx.^2; \nk2y = ky.^2; \nk2z = kz.^2;\n[kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);\n\n% Time Discritization\ndt=0.01; \nT=5; \nNt=round(T/dt); \nns=Nt/10; \nt=0;\n\n%% Initial Condition\n% u=rand(Nx,Ny,Nz)-0.5;\n\ntau = 2;\nalpha = 3;\nu = GRF3D(alpha, tau, Nx);\n\n%% Initial Preview\n\nfor iter=1:Nt\n    disp(['Iteration = ' num2str(iter)]);\n    u=real(u);\n    s_hat=fftn(u/dt)-fftn(u.^3)+2*(kxx+kyy+kzz).*fftn(u);\n    v_hat=s_hat./(1.0/dt+(1-epsilon)+(kxx+kyy+kzz).^2);\n    u=ifftn(v_hat);\n    t=t+dt;\n\n    if mod(iter, ns) == 0 \n        % Extract mid-plane slices\n        slice_x = squeeze(u(Nx/2, :, :));\n        slice_y = squeeze(u(:, Ny/2, :));\n        slice_z = squeeze(u(:, :, Nz/2));\n\n        % Plot star layout\n        clf; % Clear current figure\n        hold on;\n        % Midplane along X\n        surf(squeeze(yy(Nx/2, :, :)), squeeze(zz(Nx/2, :, :)), slice_x, 'EdgeColor', 'none');\n        % Midplane along Y\n        surf(squeeze(xx(:, Ny/2, :)), squeeze(zz(:, Ny/2, :)), slice_y, 'EdgeColor', 'none');\n        % Midplane along Z\n        surf(squeeze(xx(:, :, Nz/2)), squeeze(yy(:, :, Nz/2)), slice_z, 'EdgeColor', 'none');\n\n        % Visualization settings\n        view(3); % 3D view\n        axis tight;\n        caxis([-0.6, 0.6]); % Adjust color range\n        colormap(jet);\n        colorbar;\n        title(['Time t = ', num2str(t, '%.2f')]);\n        drawnow; % Update the figure\n\n    end\n\nend
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/SH3D.m b/MatlabCode/SH3D.m
++--- a/MatlabCode/SH3D.m	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/MatlabCode/SH3D.m	(date 1754475721130)
++@@ -1,85 +1,146 @@
++ clc;
++ clear;
++-close all
+++close all;
+++fclose('all');
++ 
++ %% Parameter Initialization
+++FigDraw = 0 ; % Enable/Disable visualization (1 = On, 0 = Off)
++ 
++ % Spatial Parameters
++-Nx=80; 
++-Ny=80; 
++-Nz=80; 
++-Lx=90; 
++-Ly=90; 
++-Lz=90; 
++-hx=Lx/Nx; 
++-hy=Ly/Ny; 
++-hz=Lz/Nz;
++-x=linspace(-0.5*Lx+hx,0.5*Lx,Nx);
++-y=linspace(-0.5*Ly+hy,0.5*Ly,Ny);
++-z=linspace(-0.5*Lz+hz,0.5*Lz,Nz);
++-[xx,yy,zz]=ndgrid(x,y,z); 
+++Nx = 32; %80 % 64; % Grid size in x direction
+++Ny = Nx; %80; % 64; % Grid size in y direction
+++Nz = Nx; %80; % 64; % Grid size in z direction
+++Lx = 15; %90; % 64 % Domain size in x direction
+++Ly = Lx; % 10; %90; % 64; % Domain size in y direction
+++Lz = Lx; %90; % 64; % Domain size in z direction
+++hx = Lx / Nx;
+++hy = Ly / Ny;
+++hz = Lz / Nz;
+++
+++x = linspace(-0.5 * Lx + hx, 0.5 * Lx, Nx);
+++y = linspace(-0.5 * Ly + hy, 0.5 * Ly, Ny);
+++z = linspace(-0.5 * Lz + hz, 0.5 * Lz, Nz);
+++[xx, yy, zz] = ndgrid(x, y, z);
++ 
++-% constant
++-epsilon=0.15;
+++% Constant
+++epsilon = 0.15;
++ 
++ % Discrete Fourier Transform
++-kx=2*pi/Lx*[0:Nx/2 -Nx/2+1:-1];
++-ky=2*pi/Ly*[0:Ny/2 -Ny/2+1:-1];
++-kz=2*pi/Lz*[0:Nz/2 -Nz/2+1:-1];
++-k2x = kx.^2; 
++-k2y = ky.^2; 
+++kx = 2 * pi / Lx * [0:Nx/2, -Nx/2+1:-1];
+++ky = 2 * pi / Ly * [0:Ny/2, -Ny/2+1:-1];
+++kz = 2 * pi / Lz * [0:Nz/2, -Nz/2+1:-1];
+++k2x = kx.^2;
+++k2y = ky.^2;
++ k2z = kz.^2;
++-[kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);
+++[kxx, kyy, kzz] = ndgrid(k2x, k2y, k2z);
++ 
++-% Time Discritization
++-dt=0.01; 
++-T=5; 
++-Nt=round(T/dt); 
++-ns=Nt/10; 
++-t=0;
+++% Time Discretization
+++dt = 0.05; %0.00002; % Time step ******
+++Nt = 100; %1000; % Total number of time steps
+++num_saved_steps = 101; %101; % Number of saved time steps
+++ns = Nt / (num_saved_steps - 1); % Save interval
+++
+++% Dataset
+++data_size = 2000; % 1500; % Number of random datasets
+++binary_filename = "SH3D_grf3d_ff_" + num2str(data_size) + "_Nt_" + num2str(num_saved_steps) + ...
+++                  "_Nx_" + num2str(Nx) + ".bin";
+++mat_filename = "SH3D_grf3d_ff_" + num2str(data_size) + "_Nt_" + num2str(num_saved_steps) + ...
+++               "_Nx_" + num2str(Nx) + ".mat";
+++
+++%% Prepare Binary File
+++fileID = fopen(binary_filename, 'wb');
+++if fileID == -1
+++    error("Cannot open binary file for writing.");
+++end
+++
+++%% Simulation Loop
+++if FigDraw
+++    figure;
+++end
+++
+++for data_num = 1:data_size
+++    disp("Data number = " + num2str(data_num));
+++
+++    % ==================== MODIFIED IC SECTION (AS REQUESTED) ====================
+++    % Strategy: Randomize GRF parameters within the user-specified ranges
+++    % to create a rich and diverse dataset for robust NN training.
+++
+++    % 1. Define the min/max for the random ranges
+++    tau_min = 280;
+++    tau_max = 320;
+++    alpha_min = 80;
+++    alpha_max = 120;
+++    
+++    % 2. Generate a random value for tau and alpha in their respective ranges.
+++    % The formula is: min_val + (max_val - min_val) * rand()
+++    current_tau = tau_min + (tau_max - tau_min) * rand();
+++    current_alpha = alpha_min + (alpha_max - alpha_min) * rand();
++ 
++-%% Initial Condition
++-% u=rand(Nx,Ny,Nz)-0.5;
++-
++-tau = 2;
++-alpha = 3;
++-u = GRF3D(alpha, tau, Nx);
+++    % Generate the continuous random field with these new parameters
+++    norm_a = GRF3D(current_alpha, current_tau, Nx);
+++    
+++    % 3. Randomize the thresholding shift to vary the volume fraction.
+++    shift_factor = 0.6 + 0.5 * rand(); % Range: [0.7, 1.2]
+++    norm_a = norm_a - shift_factor * std(norm_a(:));
+++    
+++    % Threshold the field to create the binary initial condition
+++    u = ones(Nx,Ny,Nz);
+++    u(norm_a < 0) = -1;
+++    % ===================== END OF MODIFIED IC SECTION =====================
++ 
++-%% Initial Preview
+++    % Initialize storage for saving time steps
+++    all_iterations = zeros(num_saved_steps, Nx, Ny, Nz, 'single');
++ 
++-for iter=1:Nt
++-    disp(['Iteration = ' num2str(iter)]);
++-    u=real(u);
++-    s_hat=fftn(u/dt)-fftn(u.^3)+2*(kxx+kyy+kzz).*fftn(u);
++-    v_hat=s_hat./(1.0/dt+(1-epsilon)+(kxx+kyy+kzz).^2);
++-    u=ifftn(v_hat);
++-    t=t+dt;
+++    %% Update Loop
+++    save_idx = 1;
+++    for iter = 1:Nt
+++        if iter == 1 || mod(iter, ns) == 0 || iter == Nt
+++            all_iterations(save_idx, :, :, :) = u;
+++            save_idx = save_idx + 1;
+++        end
+++
+++        %% Visualization (Plot Section) - RESTORED TO ORIGINAL
+++        if FigDraw && mod(iter, ns) == 0
+++            clf;
+++            p1 = patch(isosurface(xx, yy, zz, real(u), 0));
+++            set(p1, 'FaceColor', 'r', 'EdgeColor', 'none'); % Red surface
+++            daspect([1 1 1]);
+++            camlight;
+++            lighting phong;
+++            box on;
+++            axis image;
+++            view(45, 45); % Consistent viewing angle
+++            pause(0.01); % Adjust for rendering speed
+++        end
+++
+++        % Time evolution of the SH3D equation
+++        u = real(u);
+++        s_hat = fftn(u / dt) - fftn(u.^3) + 2 * (kxx + kyy + kzz) .* fftn(u);
+++        v_hat = s_hat ./ (1.0 / dt + (1 - epsilon) + (kxx + kyy + kzz).^2);
+++        u = ifftn(v_hat);
+++    end
++ 
++-    if mod(iter, ns) == 0 
++-        % Extract mid-plane slices
++-        slice_x = squeeze(u(Nx/2, :, :));
++-        slice_y = squeeze(u(:, Ny/2, :));
++-        slice_z = squeeze(u(:, :, Nz/2));
+++    % Write this dataset to binary file
+++    fwrite(fileID, all_iterations, 'single');
+++end
++ 
++-        % Plot star layout
++-        clf; % Clear current figure
++-        hold on;
++-        % Midplane along X
++-        surf(squeeze(yy(Nx/2, :, :)), squeeze(zz(Nx/2, :, :)), slice_x, 'EdgeColor', 'none');
++-        % Midplane along Y
++-        surf(squeeze(xx(:, Ny/2, :)), squeeze(zz(:, Ny/2, :)), slice_y, 'EdgeColor', 'none');
++-        % Midplane along Z
++-        surf(squeeze(xx(:, :, Nz/2)), squeeze(yy(:, :, Nz/2)), slice_z, 'EdgeColor', 'none');
+++fclose(fileID);
++ 
++-        % Visualization settings
++-        view(3); % 3D view
++-        axis tight;
++-        caxis([-0.6, 0.6]); % Adjust color range
++-        colormap(jet);
++-        colorbar;
++-        title(['Time t = ', num2str(t, '%.2f')]);
++-        drawnow; % Update the figure
+++%% Convert Binary Data to MAT File
+++fileID = fopen(binary_filename, 'rb');
+++if fileID == -1
+++    error("Cannot open binary file for reading.");
+++end
++ 
++-    end
+++phi_mat = matfile(mat_filename, 'Writable', true);
+++phi_mat.phi = zeros([data_size, num_saved_steps, Nx, Ny, Nz], 'single');
+++
+++for data_num = 1:data_size
+++    disp("Saving dataset " + num2str(data_num));
+++    data_chunk = fread(fileID, num_saved_steps * Nx * Ny * Nz, 'single');
+++    phi_mat.phi(data_num, :, :, :, :) = reshape(data_chunk, [1, num_saved_steps, Nx, Ny, Nz]);
+++end
++ 
++-end
++\ No newline at end of file
+++fclose(fileID);
+++
+++disp('Simulation complete.');
++\ No newline at end of file
++Index: MatlabCode/CH3D.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>clc;\nclear;\nclose all\n\n%% Parameter Initialization\n\n% Spatial Parameters\nNx=32; \nNy=32; \nNz=32; \nLx=1.0; \nLy=1.0; \nLz=1.0; \nhx=Lx/Nx;\nhy=Ly/Ny;\nhz=Lz/Nz;\nx=linspace(-0.5*Lx+hx,0.5*Lx,Nx);\ny=linspace(-0.5*Ly+hy,0.5*Ly,Ny);\nz=linspace(-0.5*Lz+hz,0.5*Lz,Nz);\n[xx,yy,zz]=ndgrid(x,y,z);\n\n% Interfacial energy constant\n%epsilon=1/128; \nepsilon=0.0125; \nCahn=epsilon^2;\n\n% Discrete Fourier Transform\nkx=2*pi/Lx*[0:Nx/2 -Nx/2+1:-1];\nky=2*pi/Ly*[0:Ny/2 -Ny/2+1:-1];\nkz=2*pi/Lz*[0:Nz/2 -Nz/2+1:-1];\nk2x=kx.^2; \nk2y=ky.^2; \nk2z=kz.^2;\n[kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);\n\n% Time Discritization\ndt=0.001; \nT=10; \nNt=round(T/dt); \nns=100;\n\n%% Initial Condition\n%u=rand(Nx,Ny,Nz)-0.5;\n%u=-0.45 + 0.05*(2*rand(Nx,Ny,Nz)-1);\n%u=0.45 - 0.05*(2*rand(Nx,Ny,Nz)-1);\n\n%tau = 400;\n%alpha = 115;\ntau = 10;\nalpha = 5.5;\nnorm_a = GRF3D(alpha, tau, Nx);\nnorm_a = norm_a + 0.2 * std(norm_a(:));   \nu = ones(Nx,Ny,Nz);\nu(norm_a < 0) = -1;\n%u = GRF3D(alpha, tau, Nx);\n\n%% Initial Preview\n% figure(1);\n% clf;\n% p1=patch(isosurface(xx,yy,zz,real(u),0.));\n% set(p1,'FaceColor','g','EdgeColor','none'); \n% daspect([1 1 1])\n% camlight;\n% lighting phong; \n% box on; \n% axis image;\n% view(45,45);\n% pause(2)\n\n%% Update\nfor iter=1:Nt\n    disp(['Iteration = ' num2str(iter)]);\n    u=real(u);\n    s_hat=fftn(u)-dt*(kxx+kyy+kzz).*fftn(u.^3-3*u);\n    v_hat=s_hat./(1.0+dt*(2.0*(kxx+kyy+kzz)+Cahn*(kxx+kyy+kzz).^2));\n    u=ifftn(v_hat);\n    if (mod(iter,ns)==0)\n        figure(1);\n        clf;\n        p1=patch(isosurface(xx,yy,zz,real(u),0.));\n        set(p1,'FaceColor','g','EdgeColor','none'); \n        daspect([1 1 1])\n        camlight;\n        lighting phong; \n        box on; \n        axis image;\n        view(45,45);\n        pause(0.01)\n    end\nend
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/CH3D.m b/MatlabCode/CH3D.m
++--- a/MatlabCode/CH3D.m	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/MatlabCode/CH3D.m	(date 1754475721144)
++@@ -1,16 +1,22 @@
++ clc;
++ clear;
++ close all
++-
+++fclose('all');
+++disp('CH3D Random New File: ')
++ %% Parameter Initialization
++ 
+++FigDraw = 0; %1; % Set to 1 to enable visualization, 0 disable
+++% Start timing
+++tic;
+++
++ % Spatial Parameters
++-Nx=32; 
++-Ny=32; 
++-Nz=32; 
++-Lx=1.0; 
++-Ly=1.0; 
++-Lz=1.0; 
+++Nx=32; %32; %64; %32;
+++Ny=Nx; 
+++Nz=Nx; 
+++Lx=2; % 1.2; % 3; %1; %1.1;
+++Ly=Lx; % 3; %1; %1.1;
+++Lz=Lx; % 3; %1; %1.1;
+++
++ hx=Lx/Nx;
++ hy=Ly/Ny;
++ hz=Lz/Nz;
++@@ -20,8 +26,8 @@
++ [xx,yy,zz]=ndgrid(x,y,z);
++ 
++ % Interfacial energy constant
++-%epsilon=1/128; 
++-epsilon=0.0125; 
+++epsilon=0.05; % 0.0125; 
+++%epsilon = 2.5 * hx; % Based on photo (2.5h)
++ Cahn=epsilon^2;
++ 
++ % Discrete Fourier Transform
++@@ -33,58 +39,149 @@
++ k2z=kz.^2;
++ [kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);
++ 
++-% Time Discritization
++-dt=0.001; 
++-T=10; 
++-Nt=round(T/dt); 
++-ns=100;
+++% Time Discretization
+++dt = 0.0005; % Time step
+++Nt = 100; % Number of time steps
+++T = Nt * dt; % Total simulation time
+++num_saved_steps = 101;
+++ns = Nt / (num_saved_steps - 1);
+++
+++% Dataset
+++data_size = 1500;%8000;%5000 %12000; %1500; % 600; %1500; %2000 %8000;
+++binary_filename = "CH3D_" + num2str(data_size) + "_Nt_" + num2str(num_saved_steps) + ...
+++                  "_Nx_" + num2str(Nx) + ".bin";
+++mat_filename = "CH3D_" + num2str(data_size) + "_Nt_" + num2str(num_saved_steps) + ...
+++               "_Nx_" + num2str(Nx) + ".mat";
+++
+++%% Prepare Binary File
+++fileID = fopen(binary_filename, 'wb');
+++if fileID == -1
+++    error("Cannot open binary file for writing.");
+++end
++ 
++ %% Initial Condition
++-%u=rand(Nx,Ny,Nz)-0.5;
++-%u=-0.45 + 0.05*(2*rand(Nx,Ny,Nz)-1);
++-%u=0.45 - 0.05*(2*rand(Nx,Ny,Nz)-1);
+++tau = 65; %91;%141;% 400; %400; % 3.5; %5; %15; %45; % 400;
+++alpha = 9.5; %19%41; %115; %115; %2; %4 %11; %115;
++ 
++-%tau = 400;
++-%alpha = 115;
++-tau = 10;
++-alpha = 5.5;
++-norm_a = GRF3D(alpha, tau, Nx);
++-norm_a = norm_a + 0.2 * std(norm_a(:));   
++-u = ones(Nx,Ny,Nz);
++-u(norm_a < 0) = -1;
++-%u = GRF3D(alpha, tau, Nx);
+++if FigDraw
+++    figure;
+++end
+++
+++for data_num = 1:data_size
+++    disp("data number = " + num2str(data_num))
+++    
+++    
+++    %%%%%
+++    % ==================== MODIFIED IC SECTION (AS REQUESTED) ====================
+++    % Strategy: Randomize GRF parameters within the user-specified ranges
+++    % to create a rich and diverse dataset for robust NN training.
+++
+++    % 1. Define the min/max for the random ranges
+++    tau_min = 50;
+++    tau_max = 80;
+++    alpha_min = 5;
+++    alpha_max = 13;
+++    
+++    % 2. Generate a random value for tau and alpha in their respective ranges.
+++    % The formula is: min_val + (max_val - min_val) * rand()
+++    current_tau = tau_min + (tau_max - tau_min) * rand();
+++    current_alpha = alpha_min + (alpha_max - alpha_min) * rand();
+++
+++    % Generate the continuous random field with these new parameters
+++    norm_a = GRF3D(current_alpha, current_tau, Nx);
+++    
+++    % 3. Randomize the thresholding shift to vary the volume fraction.
+++    shift_factor = 0.7 - 0.4 * rand(); % Range: [0.7, 1.2]
+++    norm_a = norm_a - shift_factor * std(norm_a(:));
+++    
+++    % Threshold the field to create the binary initial condition
+++    u = ones(Nx,Ny,Nz);
+++    u(norm_a < 0) = -1;
+++    % ===================== END OF MODIFIED IC SECTION =====================
+++    %%%%
++ 
++-%% Initial Preview
++-% figure(1);
++-% clf;
++-% p1=patch(isosurface(xx,yy,zz,real(u),0.));
++-% set(p1,'FaceColor','g','EdgeColor','none'); 
++-% daspect([1 1 1])
++-% camlight;
++-% lighting phong; 
++-% box on; 
++-% axis image;
++-% view(45,45);
++-% pause(2)
+++    
+++    %%
+++    %norm_a = GRF3D(alpha, tau, Nx);
+++    %norm_a = norm_a - 0.85* std(norm_a(:));   %
+++    %u = ones(Nx,Ny,Nz);
+++    %u(norm_a < 0) = -1;
+++    %u = norm_a;
+++    %u(:,1,:)=1;
+++    %u(:,end,:)=1;
+++    %u(:,:,1)=1;
+++    %u(:,:,end)=1;
+++
+++    all_iterations = zeros(num_saved_steps, Nx, Ny, Nz, 'single');
+++    
+++    %% Initial Preview
+++    if FigDraw
+++        clf;
+++        p1 = patch(isosurface(xx, yy, zz, real(u), 0));
+++        set(p1, 'FaceColor', 'r', 'EdgeColor', 'none'); % Red color for the surface
+++        daspect([1 1 1]);
+++        camlight;
+++        lighting phong;
+++        box on;
+++        axis image;
+++        view(45, 45); % Set the viewing angle
+++        pause(2);
+++    end
++ 
++-%% Update
++-for iter=1:Nt
++-    disp(['Iteration = ' num2str(iter)]);
++-    u=real(u);
++-    s_hat=fftn(u)-dt*(kxx+kyy+kzz).*fftn(u.^3-3*u);
++-    v_hat=s_hat./(1.0+dt*(2.0*(kxx+kyy+kzz)+Cahn*(kxx+kyy+kzz).^2));
++-    u=ifftn(v_hat);
++-    if (mod(iter,ns)==0)
++-        figure(1);
++-        clf;
++-        p1=patch(isosurface(xx,yy,zz,real(u),0.));
++-        set(p1,'FaceColor','g','EdgeColor','none'); 
++-        daspect([1 1 1])
++-        camlight;
++-        lighting phong; 
++-        box on; 
++-        axis image;
++-        view(45,45);
++-        pause(0.01)
+++    %% Update
+++    save_idx = 1;
+++    for iter = 1:Nt
+++        if iter == 1 || mod(iter, ns) == 0 || iter == Nt
+++            all_iterations(save_idx, :, :, :) = u;
+++            save_idx = save_idx + 1;
+++        end
+++
+++        u = real(u);
+++        s_hat = fftn(u) - dt * (kxx + kyy + kzz) .* fftn(u.^3 - 3 * u);
+++        v_hat = s_hat ./ (1.0 + dt * (2.0 * (kxx + kyy + kzz) + Cahn * (kxx + kyy + kzz).^2));
+++        u = ifftn(v_hat);
+++
+++        % Update Visualization During Simulation
+++        if FigDraw && mod(iter, ns) == 0
+++            figure(1);
+++            clf;
+++            p1 = patch(isosurface(xx, yy, zz, real(u), 0));
+++            set(p1, 'FaceColor', 'r', 'EdgeColor', 'none'); % Red color for the surface
+++            daspect([1 1 1]);
+++            camlight;
+++            lighting phong;
+++            box on;
+++            axis image;
+++            view(45, 45); % Maintain consistent view
+++            pause(0.01);
+++        end
+++    
++     end
++-end
++\ No newline at end of file
+++
+++    fwrite(fileID, all_iterations, 'single');
+++end
+++
+++fclose(fileID);
+++
+++%% Convert Binary Data to MAT File
+++fileID = fopen(binary_filename, 'rb');
+++if fileID == -1
+++    error("Cannot open binary file for reading.");
+++end
+++
+++phi_mat = matfile(mat_filename, 'Writable', true);
+++phi_mat.phi = zeros([data_size, num_saved_steps, Nx, Ny, Nz], 'single');
+++
+++for data_num = 1:data_size
+++    disp("Saving dataset " +  num2str(data_num));
+++    data_chunk = fread(fileID, num_saved_steps * Nx * Ny * Nz, 'single');
+++    phi_mat.phi(data_num, :, :, :, :) = reshape(data_chunk, [1, num_saved_steps, Nx, Ny, Nz]);
+++end
+++
+++fclose(fileID);
+++
+++% End timing
+++elapsed_time_seconds = toc; % Total time in seconds
+++elapsed_time_minutes = elapsed_time_seconds / 60; % Convert to minutes
+++% Display runtime
+++disp(['Elapsed Time: ', num2str(elapsed_time_minutes, '%.2f'), ' minutes']);
++\ No newline at end of file
++Index: utilities.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport numpy as np\nimport scipy.io\nimport h5py\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport os\n\nimport operator\nfrom functools import reduce\nfrom functools import partial\n\n#################################################\n#\n# Utilities\n#\n#################################################\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# reading data\nclass MatReader(object):\n    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n        super(MatReader, self).__init__()\n\n        self.to_torch = to_torch\n        self.to_cuda = to_cuda\n        self.to_float = to_float\n\n        self.file_path = file_path\n\n        self.data = None\n        self.old_mat = None\n        self._load_file()\n\n    def _load_file(self):\n        try:\n            self.data = scipy.io.loadmat(self.file_path)\n            self.old_mat = True\n        except:\n            self.data = h5py.File(self.file_path)\n            self.old_mat = False\n\n    def load_file(self, file_path):\n        self.file_path = file_path\n        self._load_file()\n\n    def read_field(self, field):\n        print(f\"Available keys in self.data: {list(self.data.keys())}\")\n        x = self.data[field]\n\n        if not self.old_mat:\n            x = x[()]\n            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n\n        if self.to_float:\n            x = x.astype(np.float32)\n\n        if self.to_torch:\n            x = torch.from_numpy(x)\n\n            if self.to_cuda:\n                x = x.cuda()\n\n        return x\n\n    def set_cuda(self, to_cuda):\n        self.to_cuda = to_cuda\n\n    def set_torch(self, to_torch):\n        self.to_torch = to_torch\n\n    def set_float(self, to_float):\n        self.to_float = to_float\n\n\n# normalization, pointwise gaussian\nclass UnitGaussianNormalizer(object):\n    def __init__(self, x, eps=0.00001, time_last=True):\n        super(UnitGaussianNormalizer, self).__init__()\n\n        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T in 1D\n        # x could be in shape of ntrain*w*l or ntrain*T*w*l or ntrain*w*l*T in 2D\n        self.mean = torch.mean(x, 0)\n        self.std = torch.std(x, 0)\n        self.eps = eps\n        self.time_last = time_last  # if the time dimension is the last dim\n\n    def encode(self, x):\n        x = (x - self.mean) / (self.std + self.eps)\n        return x\n\n    def decode(self, x, sample_idx=None):\n        # sample_idx is the spatial sampling mask\n        #print('x shape in decode: ', x.shape)\n        global std, mean\n        if sample_idx is None:\n            std = self.std + self.eps  # n\n            mean = self.mean\n            #print(\"x shape:\", x.shape)\n            #print(\"std shape:\", std.shape)\n            #print(\"mean shape:\", mean.shape)\n        else:\n            if self.mean.ndim == sample_idx.ndim or self.time_last:\n                std = self.std[sample_idx] + self.eps  # batch*n\n                mean = self.mean[sample_idx]\n            if self.mean.ndim > sample_idx.ndim and not self.time_last:\n                std = self.std[..., sample_idx] + self.eps  # T*batch*n\n                mean = self.mean[..., sample_idx]\n        # x is in shape of batch*(spatial discretization size) or T*batch*(spatial discretization size)\n\n        x = (x * std) + mean\n        return x\n\n    def to(self, device):\n        if torch.is_tensor(self.mean):\n            self.mean = self.mean.to(device)\n            self.std = self.std.to(device)\n        else:\n            self.mean = torch.from_numpy(self.mean).to(device)\n            self.std = torch.from_numpy(self.std).to(device)\n        return self\n\n    def cuda(self):\n        self.mean = self.mean.cuda()\n        self.std = self.std.cuda()\n\n    def cpu(self):\n        self.mean = self.mean.cpu()\n        self.std = self.std.cpu()\n\n\n# normalization, Gaussian\nclass GaussianNormalizer(object):\n    def __init__(self, x, eps=0.00001):\n        super(GaussianNormalizer, self).__init__()\n\n        self.mean = torch.mean(x)\n        self.std = torch.std(x)\n        self.eps = eps\n\n    def encode(self, x):\n        x = (x - self.mean) / (self.std + self.eps)\n        return x\n\n    def decode(self, x, sample_idx=None):\n        x = (x * (self.std + self.eps)) + self.mean\n        return x\n\n    def cuda(self):\n        self.mean = self.mean.cuda()\n        self.std = self.std.cuda()\n\n    def cpu(self):\n        self.mean = self.mean.cpu()\n        self.std = self.std.cpu()\n\n\n# normalization, scaling by range\nclass RangeNormalizer(object):\n    def __init__(self, x, low=0.0, high=1.0):\n        super(RangeNormalizer, self).__init__()\n        mymin = torch.min(x, 0)[0].view(-1)\n        mymax = torch.max(x, 0)[0].view(-1)\n\n        self.a = (high - low) / (mymax - mymin)\n        self.b = -self.a * mymax + high\n\n    def encode(self, x):\n        s = x.size()\n        x = x.view(s[0], -1)\n        x = self.a * x + self.b\n        x = x.view(s)\n        return x\n\n    def decode(self, x):\n        s = x.size()\n        x = x.view(s[0], -1)\n        x = (x - self.b) / self.a\n        x = x.view(s)\n        return x\n\n\n# loss function with rel/abs Lp loss\nclass LpLoss(object):\n    #def __init__(self, d=2, p=2, size_average=True, reduction=True):\n    #    super(LpLoss, self).__init__()\n    def __init__(self, d=2, p=2, l1_weight=0.0, size_average=True, reduction=True):\n        super(LpLoss, self).__init__()\n        assert d > 0 and p > 0\n\n\n        # Dimension and Lp-norm type are postive\n        assert d > 0 and p > 0\n\n        self.d = d\n        self.p = p\n        self.l1_weight = l1_weight  # Weight for the L1 compon\n        self.reduction = reduction\n        self.size_average = size_average\n\n    def abs(self, x, y):\n        num_examples = x.size()[0] # number of rows\n\n        # Assume uniform mesh\n        h = 1.0 / (x.size()[1] - 1.0)\n\n        all_norms = (h ** (self.d / self.p)) * torch.norm(x.view(num_examples, -1) - y.view(num_examples, -1), self.p,\n                                                          1)\n\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(all_norms)\n            else:\n                return torch.sum(all_norms)\n\n        return all_norms\n\n    def rel(self, x, y):\n        num_examples = x.size()[0]\n\n        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(diff_norms / y_norms)\n            else:\n                return torch.sum(diff_norms / y_norms)\n\n        return diff_norms / y_norms\n\n    #def __call__(self, x, y):\n    #    return self.rel(x, y)\n    # --- UPDATE THE __call__ METHOD ---\n    def __call__(self, x, y):\n        # Calculate the primary loss (e.g., L2)\n        primary_loss = self.rel(x, y)\n\n        # If an L1 weight is specified, calculate and add the L1 loss\n        if self.l1_weight > 0:\n            # Temporarily set p=1 to calculate L1 loss\n            original_p = self.p\n            self.p = 1\n            l1_loss = self.rel(x, y)\n            self.p = original_p  # Restore original p\n\n            # Return the weighted combination\n            return (1.0 - self.l1_weight) * primary_loss + self.l1_weight * l1_loss\n        else:\n            # If no L1 weight, return the primary loss as before\n            return primary_loss\n\n\n# Sobolev norm (HS norm)\n# where we also compare the numerical derivatives between the output and target\nclass HsLoss(object):\n    def __init__(self, d=2, p=2, k=1, a=None, group=False, size_average=True, reduction=True):\n        super(HsLoss, self).__init__()\n\n        # Dimension and Lp-norm type are postive\n        assert d > 0 and p > 0\n\n        self.d = d\n        self.p = p\n        self.k = k\n        self.balanced = group\n        self.reduction = reduction\n        self.size_average = size_average\n\n        if a == None:\n            a = [1, ] * k\n        self.a = a\n\n    def rel(self, x, y):\n        num_examples = x.size()[0]\n        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(diff_norms / y_norms)\n            else:\n                return torch.sum(diff_norms / y_norms)\n        return diff_norms / y_norms\n\n    def __call__(self, x, y, a=None):\n        nx = x.size()[1]\n        ny = x.size()[2]\n        k = self.k\n        balanced = self.balanced\n        a = self.a\n        x = x.view(x.shape[0], nx, ny, -1)\n        y = y.view(y.shape[0], nx, ny, -1)\n\n        k_x = torch.cat((torch.arange(start=0, end=nx // 2, step=1), torch.arange(start=-nx // 2, end=0, step=1)),\n                        0).reshape(nx, 1).repeat(1, ny)\n        k_y = torch.cat((torch.arange(start=0, end=ny // 2, step=1), torch.arange(start=-ny // 2, end=0, step=1)),\n                        0).reshape(1, ny).repeat(nx, 1)\n        k_x = torch.abs(k_x).reshape(1, nx, ny, 1).to(x.device)\n        k_y = torch.abs(k_y).reshape(1, nx, ny, 1).to(x.device)\n\n        x = torch.fft.fftn(x, dim=[1, 2])\n        y = torch.fft.fftn(y, dim=[1, 2])\n\n        if balanced == False:\n            weight = 1\n            if k >= 1:\n                weight += a[0] ** 2 * (k_x ** 2 + k_y ** 2)\n            if k >= 2:\n                weight += a[1] ** 2 * (k_x ** 4 + 2 * k_x ** 2 * k_y ** 2 + k_y ** 4)\n            weight = torch.sqrt(weight)\n            loss = self.rel(x * weight, y * weight)\n        else:\n            loss = self.rel(x, y)\n            if k >= 1:\n                weight = a[0] * torch.sqrt(k_x ** 2 + k_y ** 2)\n                loss += self.rel(x * weight, y * weight)\n            if k >= 2:\n                weight = a[1] * torch.sqrt(k_x ** 4 + 2 * k_x ** 2 * k_y ** 2 + k_y ** 4)\n                loss += self.rel(x * weight, y * weight)\n            loss = loss / (k + 1)\n\n        return loss\n\n\n# A simple feedforward neural network\nclass DenseNet(torch.nn.Module):\n    def __init__(self, layers, nonlinearity, out_nonlinearity=None, normalize=False):\n        super(DenseNet, self).__init__()\n\n        self.n_layers = len(layers) - 1\n\n        assert self.n_layers >= 1\n\n        self.layers = nn.ModuleList()\n\n        for j in range(self.n_layers):\n            self.layers.append(nn.Linear(layers[j], layers[j + 1]))\n\n            if j != self.n_layers - 1:\n                if normalize:\n                    self.layers.append(nn.BatchNorm1d(layers[j + 1]))\n\n                self.layers.append(nonlinearity())\n\n        if out_nonlinearity is not None:\n            self.layers.append(out_nonlinearity())\n\n    def forward(self, x):\n        for _, l in enumerate(self.layers):\n            x = l(x)\n\n        return x\n\n\n# print the number of parameters\ndef count_params(model):\n    c = 0\n    for p in list(model.parameters()):\n        c += reduce(operator.mul, list(p.size() + (2,) if p.is_complex() else p.size()))\n    return c\n\n\nclass ImportDataset(Dataset):\n    def __init__(self, parent_dir, matlab_dataset, normalized, T_in, T_out):\n        self.y = None # Stores target\n        self.x = None # Stores input\n        '''\n        The values for x and y are not yet available but will be assigned later (inside the set_data() method).\n        '''\n        self.T_in = T_in\n        self.T_out = T_out\n        self.normalized = normalized\n        self.normalizer_x = None\n        self.normalizer_y = None\n\n        matlab_dataset = parent_dir + matlab_dataset\n        python_dataset = matlab_dataset.replace('.mat', '.pt')\n        #python_dataset = matlab_dataset.replace('.npz', '.pt')\n        os.makedirs(parent_dir, exist_ok=True)\n\n        if os.path.exists(python_dataset):\n            print(\"Found saved dataset at\", python_dataset)\n            self.data = torch.load(python_dataset)['data']\n        else:\n            reader = MatReader(matlab_dataset)\n            self.data = reader.read_field('phi')\n            torch.save({'data': self.data}, python_dataset)\n        self.set_data()\n\n    def set_data(self):\n        permute_order = list(range(self.data.ndim))\n        permute_order.append(permute_order.pop(1))  # Move the second dimension to the end\n        self.x = self.data[:, 0:self.T_in, *[slice(None)] * (self.data.ndim - 3)].permute(*permute_order)\n        self.y = self.data[:, self.T_in:self.T_in + self.T_out, *[slice(None)] * (\n                self.data.ndim - 3)].permute(*permute_order)\n       # print(self.x.shape)\n       # print(self.y.shape)\n        if self.normalized:\n            self.make_normal()\n\n    def make_normal(self):\n        self.normalizer_x = UnitGaussianNormalizer(self.x)\n        self.normalizer_y = UnitGaussianNormalizer(self.y)\n        self.x = self.normalizer_x.encode(self.x)\n        self.y = self.normalizer_y.encode(self.y)\n\n    def __len__(self):\n        return self.x.shape[0]\n\n    def __getitem__(self, idx):\n        return self.x[idx], self.y[idx]\n\n\nclass ModelEvaluator:\n    def __init__(self, model, test_dataset, s, T_in, T_out, device, normalized=False, normalizers=None,\n                 time_history=False):\n        self.model = model\n        self.test_dataset = test_dataset\n        self.s = s\n        self.T_in = T_in\n        self.T_out = T_out\n        self.device = device\n        self.normalized = normalized\n        self.time_history = time_history\n        self.normalizer_x = normalizers[0].to(self.device)\n        self.normalizer_y = normalizers[1].to(self.device)\n        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n        spatial_dims = [s] * (len(test_dataset[0][0].shape) - 1)\n        self.inp = torch.zeros((len(test_dataset), *spatial_dims, T_in))\n        self.exact = torch.zeros((len(test_dataset), *spatial_dims, T_out))\n        self.pred = torch.zeros((len(test_dataset), *spatial_dims, T_out))\n        self.test_l2_set = []\n\n    def evaluate(self, loss_fn):\n        if self.time_history:\n            index = 0\n            step = 1\n            with torch.no_grad():\n                for xx, yy in self.test_loader:\n                    self.inp[index] = xx.squeeze(0)\n                    xx, yy = xx.to(self.device), yy.to(self.device)\n\n                    for t in range(0, self.T_out, step):\n                        y = yy[..., t:t + step]\n                        im = self.model(xx)\n                        # loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n                        if t == 0:\n                            pred = im\n                        else:\n                            pred = torch.cat((pred, im), -1)\n                        xx = torch.cat((xx[..., step:], im), dim=-1)\n\n                    self.exact[index] = yy.squeeze(0)\n                    self.pred[index] = pred.squeeze(0)\n                    test_l2 = loss_fn(pred.view(1, -1), yy.view(1, -1)).item()\n                    self.test_l2_set.append(test_l2)\n                    #print(index, test_l2)\n                    index += 1\n\n        else:\n            index = 0\n            with torch.no_grad():\n                for x, y in self.test_loader:\n                    x, y = x.to(self.device), y.to(self.device)\n                    out = self.model(x)\n                    if self.normalized:\n                        out = self.normalizer_y.decode(out)\n                        y = self.normalizer_y.decode(y)\n                        x = self.normalizer_x.decode(x)\n                    self.inp[index] = x.squeeze(0)\n                    self.exact[index] = y.squeeze(0)\n                    self.pred[index] = out.squeeze(0)\n                    test_l2 = loss_fn(out.view(1, -1), y.view(1, -1)).item()\n                    self.test_l2_set.append(test_l2)\n                    #print(index, test_l2)\n                    index += 1\n\n        return self._compute_statistics()\n\n    def _compute_statistics(self):\n        self.test_l2_set = torch.tensor(self.test_l2_set)\n        test_l2_avg = torch.mean(self.test_l2_set)\n        test_l2_std = torch.std(self.test_l2_set)\n        test_l2_min, min_idx = torch.min(self.test_l2_set), torch.argmin(self.test_l2_set)\n        test_l2_max, max_idx = torch.max(self.test_l2_set), torch.argmax(self.test_l2_set)\n        test_l2_mode, mode_count = torch.mode(self.test_l2_set)\n        mode_indices = torch.nonzero(self.test_l2_set == test_l2_mode).squeeze().tolist()\n\n        print(\"The average testing error is\", test_l2_avg.item())\n        print(\"Std. deviation of testing error is\", test_l2_std.item())\n        print(\"Min testing error is\", test_l2_min.item(), \"at index\", min_idx.item())\n        print(\"Max testing error is\", test_l2_max.item(), \"at index\", max_idx.item())\n        print(\"Mode of testing errors is\", test_l2_mode.item(), \"appearing\", mode_count.item(), \"times at indices\",\n              mode_indices)\n\n        return {\n            \"input\": self.inp,\n            \"exact\": self.exact,\n            \"prediction\": self.pred,\n            \"average\": test_l2_avg.item(),\n            \"std_dev\": test_l2_std.item(),\n            \"min\": {\"value\": test_l2_min.item(), \"index\": min_idx.item()},\n            \"max\": {\"value\": test_l2_max.item(), \"index\": max_idx.item()},\n            \"mode\": {\"value\": test_l2_mode.item(), \"count\": mode_count.item(), \"indices\": mode_indices}\n        }\n
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/utilities.py b/utilities.py
++--- a/utilities.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/utilities.py	(date 1754475689365)
++@@ -252,6 +252,81 @@
++             return primary_loss
++ 
++ 
+++# Add this code to your utilities.py file
+++
+++import torch
+++import torch.nn.functional as F
+++
+++
+++# --- NEW SOBOLEV LOSS CLASS ---
+++class SobolevLoss(object):
+++    def __init__(self, d=3, p=2, grad_weight=0.1, size_average=False, reduction=True):
+++        super(SobolevLoss, self).__init__()
+++        # Ensure dimension and p-norm are valid
+++        assert d > 0 and p > 0
+++
+++        self.d = d
+++        self.p = p
+++        self.reduction = reduction
+++        self.size_average = size_average
+++        self.grad_weight = grad_weight  # Weight for the gradient loss component
+++
+++    def _compute_gradients(self, x):
+++        """
+++        Computes spatial gradients using a 3D Sobel filter.
+++        Assumes input x has shape (batch, sx, sy, sz, t)
+++        """
+++        # We need to operate on each time step independently
+++        # and on data with shape (B, C, D, H, W) for conv3d
+++
+++        # Permute to (batch, t, sx, sy, sz)
+++        x_permuted = x.permute(0, 4, 1, 2, 3)
+++        batch_size, T, sx, sy, sz = x_permuted.shape
+++
+++        # Reshape to treat time steps as part of the batch for convolution
+++        x_reshaped = x_permuted.reshape(batch_size * T, 1, sx, sy, sz)
+++
+++        # 3D Sobel filters
+++        sobel_x = torch.tensor([[[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]],
+++                                 [[-2, 0, 2], [-4, 0, 4], [-2, 0, 2]],
+++                                 [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]]],
+++                               dtype=torch.float32, device=x.device).unsqueeze(0)
+++        sobel_y = sobel_x.permute(0, 1, 3, 2, 4)
+++        sobel_z = sobel_x.permute(0, 1, 4, 3, 2)
+++
+++        grad_x = F.conv3d(x_reshaped, sobel_x, padding='same')
+++        grad_y = F.conv3d(x_reshaped, sobel_y, padding='same')
+++        grad_z = F.conv3d(x_reshaped, sobel_z, padding='same')
+++
+++        # Reshape back to (batch, t, sx, sy, sz, 3_grads)
+++        grads = torch.stack([grad_x, grad_y, grad_z], dim=-1)
+++        return grads.reshape(batch_size, T, sx, sy, sz, 3)
+++
+++    def __call__(self, x, y):
+++        """
+++        x: prediction, y: ground truth
+++        Assumes x and y have shape (batch, sx, sy, sz, T)
+++        """
+++        num_examples = x.size(0)
+++
+++        # 1. Standard L2 Data Loss (relative)
+++        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)
+++        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)
+++        data_loss = torch.mean(diff_norms / y_norms)
+++
+++        # 2. Gradient Loss
+++        if self.grad_weight > 0:
+++            pred_grads = self._compute_gradients(x)
+++            true_grads = self._compute_gradients(y)
+++            grad_loss = F.mse_loss(pred_grads, true_grads)
+++
+++            # Combine losses
+++            total_loss = data_loss + self.grad_weight * grad_loss
+++        else:
+++            total_loss = data_loss
+++
+++        return total_loss
+++
++ # Sobolev norm (HS norm)
++ # where we also compare the numerical derivatives between the output and target
++ class HsLoss(object):
++@@ -371,7 +446,7 @@
++         self.T_in = T_in
++         self.T_out = T_out
++         self.normalized = normalized
++-        self.normalizer_x = None
+++        self.normalizer_x =  None
++         self.normalizer_y = None
++ 
++         matlab_dataset = parent_dir + matlab_dataset
++@@ -432,6 +507,7 @@
++         self.pred = torch.zeros((len(test_dataset), *spatial_dims, T_out))
++         self.test_l2_set = []
++ 
+++    '''''
++     def evaluate(self, loss_fn):
++         if self.time_history:
++             index = 0
++@@ -477,7 +553,58 @@
++                     index += 1
++ 
++         return self._compute_statistics()
++-
+++    '''
+++
+++    # Replace the evaluate method in your ModelEvaluator class with this one.
+++
+++    def evaluate(self, loss_fn):
+++        if self.time_history:
+++            index = 0
+++            step = 1
+++            with torch.no_grad():
+++                for xx, yy in self.test_loader:
+++                    self.inp[index] = xx.squeeze(0)
+++                    xx, yy = xx.to(self.device), yy.to(self.device)
+++
+++                    for t in range(0, self.T_out, step):
+++                        y = yy[..., t:t + step]
+++                        im = self.model(xx)
+++                        if t == 0:
+++                            pred = im
+++                        else:
+++                            pred = torch.cat((pred, im), -1)
+++                        xx = torch.cat((xx[..., step:], im), dim=-1)
+++
+++                    self.exact[index] = yy.squeeze(0)
+++                    self.pred[index] = pred.squeeze(0)
+++
+++                    # --- CORRECTED LINE ---
+++                    # Pass the un-flattened tensors directly to the loss function
+++                    test_l2 = loss_fn(pred, yy).item()
+++                    self.test_l2_set.append(test_l2)
+++                    index += 1
+++
+++        else:
+++            index = 0
+++            with torch.no_grad():
+++                for x, y in self.test_loader:
+++                    x, y = x.to(self.device), y.to(self.device)
+++                    out = self.model(x)
+++                    if self.normalized:
+++                        out = self.normalizer_y.decode(out)
+++                        y = self.normalizer_y.decode(y)
+++                        x = self.normalizer_x.decode(x)
+++                    self.inp[index] = x.squeeze(0)
+++                    self.exact[index] = y.squeeze(0)
+++                    self.pred[index] = out.squeeze(0)
+++
+++                    # --- CORRECTED LINE ---
+++                    # Pass the un-flattened tensors directly to the loss function
+++                    test_l2 = loss_fn(out, y).item()
+++                    self.test_l2_set.append(test_l2)
+++                    index += 1
+++
+++        return self._compute_statistics()
++     def _compute_statistics(self):
++         self.test_l2_set = torch.tensor(self.test_l2_set)
++         test_l2_avg = torch.mean(self.test_l2_set)
++Index: MatlabCode/In_Distribution/3D_phase_evolution4GRF.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/In_Distribution/3D_phase_evolution4GRF.m b/MatlabCode/In_Distribution/3D_phase_evolution4GRF.m
++new file mode 100644
++--- /dev/null	(date 1754475689289)
+++++ b/MatlabCode/In_Distribution/3D_phase_evolution4GRF.m	(date 1754475689289)
++@@ -0,0 +1,324 @@
+++clc;
+++clear;
+++close all;
+++
+++%% ======================= Configuration =======================
+++% --- File Path ---
+++
+++% You can switch between these paths. The titles will update automatically.
+++
+++% SH3D
+++
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat';
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat';
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_FNO3d/FNO3d_SH3D_S32_T1to91_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_FNO4d/FNO4d_SH3D_S32_T1to91_width12_modes14_q12_h6_grf3d_NoMixed.pt_results.mat'
+++
+++
+++%AC3D
+++
+++mat_filepath = '//scratch/noqu8762/phase_field_equations_4d/AC3D/plots_TNO3d/TNO3d_AC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/AC3D/plots_FNO3d/FNO3d_AC3D_S32_T1to91_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/AC3D/plots_Data_Physics_TNO3d/TNO3d_AC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++
+++% AC3D Mixed
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/AC3D/plots_TNO3d/TNO3d_AC3D_S32_T1to100_width12_modes14_q12_h6_grf3d_Mixed.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/AC3D/plots_Data_Physics_TNO3d/TNO3d_AC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d_Mixed.pt_results.mat'
+++
+++% AC3d FNO4d
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/AC3D/plots_FNO4d/FNO4d_AC3D_S32_T1to91_width12_modes14_q12_h6_grf3d_NoMixed.pt_results.mat'
+++
+++% CH3D
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/CH3D/plots_TNO3d/TNO3d_CH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath ='/scratch/noqu8762/phase_field_equations_4d/CH3D/plots_Data_Physics_TNO3d/TNO3d_CH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/CH3D/plots_FNO3d/FNO3d_CH3D_S32_T1to91_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/CH3D/plots_FNO4d/FNO4d_CH3D_S32_T1to91_width12_modes14_q12_h6_grf3d_NoMixed.pt_results.mat'
+++
+++% MBE3D
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/plots_TNO3d/TNO3d_MBE3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/plots_Data_Physics_TNO3d/TNO3d_MBE3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat';
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/plots_FNO3d/FNO3d_MBE3D_S32_T1to91_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++
+++% MBE3D with FNO4d
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/plots_FNO4d/FNO4d_MBE3D_S32_T1to91_width12_modes14_q12_h6_grf3d_NoMixed.pt_results.mat'
+++
+++% PFC
+++mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_TNO3d/TNO3d_PFC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_Data_Physics_TNO3d/TNO3d_PFC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_FNO3d/FNO3d_PFC3D_S32_T1to91_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_Data_Physics_TNO3d/TNO3d_PFC3D_Mixed_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath ='/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_TNO3d/TNO3d_PFC3D_Mixed_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++ 
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_FNO4d/FNO4d_PFC3D_S32_T1to91_width12_modes14_q12_h6_grf3d_NoMixed.pt_results.mat'
+++
+++
+++% --- Visualization Parameters ---
+++time_steps_to_plot = [0, 50, 90];
+++sample_index_to_plot = 2; % set 2 for MBE model
+++iso_value = 0;
+++error_display_threshold_ratio = 0.20;
+++
+++%% ======================= Automatic Title Generation =======================
+++path_parts = strsplit(mat_filepath, '/');
+++problem_name = 'UnknownProblem'; 
+++base_dir_idx = find(strcmp(path_parts, 'phase_field_equations_4d'));
+++if ~isempty(base_dir_idx) && base_dir_idx < length(path_parts)
+++    problem_name = path_parts{base_dir_idx + 1};
+++end
+++model_name = 'UnknownModel';
+++if ~isempty(base_dir_idx) && (base_dir_idx + 1) < length(path_parts)
+++    plot_dir_name = path_parts{base_dir_idx + 2};
+++    switch plot_dir_name
+++        case 'plots_Data_Physics_TNO3d'
+++            model_name = 'Hybrid';
+++        case 'plots_TNO3d'
+++            model_name = 'MHNO';
+++        case 'plots_FNO3d'
+++            model_name = 'FNO\_3d';
+++        case 'plots_FNO4d'
+++            model_name = 'FNO\_4d';
+++            
+++    end
+++end
+++main_plot_title = sprintf('3D Phase Evolution of %s Based on %s Model', problem_name, model_name);
+++loss_plot_title = sprintf('Loss Progression for %s - %s Model', problem_name, model_name);
+++fprintf('Generated Plot Title: "%s"\n', main_plot_title);
+++
+++%% ======================= Load and Prepare Data =======================
+++fprintf('Loading data from: %s\n', mat_filepath);
+++if ~exist(mat_filepath, 'file')
+++    error('File not found! Please check the mat_filepath variable.');
+++end
+++results = load(mat_filepath);
+++disp('Data loaded successfully.');
+++
+++u_input_all = double(results.test_input);
+++u_exact_all = double(results.test_exact);
+++u_pred_all  = double(results.test_prediction);
+++u_error_all = u_pred_all - u_exact_all;
+++
+++% First, squeeze to extract the single sample we want to plot
+++u_input = squeeze(u_input_all(sample_index_to_plot, :, :, :, :));
+++u_exact = squeeze(u_exact_all(sample_index_to_plot, :, :, :, :));
+++u_pred = squeeze(u_pred_all(sample_index_to_plot, :, :, :, :));
+++u_error = squeeze(u_error_all(sample_index_to_plot, :, :, :, :));
+++
+++% Second, permute the dimensions of the extracted sample from (x,y,z,t) 
+++% to (y,x,z,t) to match the 'meshgrid' convention required by plotting functions.
+++u_input = permute(u_input, [2 1 3 4]);
+++u_exact = permute(u_exact, [2 1 3 4]);
+++u_pred  = permute(u_pred,  [2 1 3 4]);
+++u_error = permute(u_error, [2 1 3 4]);
+++Lx = double(results.config_Lx);
+++%Lx = 2*pi %double(results.config_Lx);
+++Ly = Lx;
+++Lz = Lx;
+++
+++% Get the new size after permutation (Note: Ny is now the first dimension)
+++[Ny, Nx, Nz, ~] = size(u_exact);
+++x = linspace(-Lx/2, Lx/2, Nx);
+++y = linspace(-Ly/2, Ly/2, Ny);
+++z = linspace(-Lz/2, Lz/2, Nz);
+++
+++% Use 'meshgrid' to create the grid, which is expected by functions like 'slice'.
+++[xx, yy, zz] = meshgrid(x, y, z);
+++
+++
+++%% ======================= Plot 1: Loss Curves (Generalized) =======================
+++fig1 = figure('Name', 'Loss vs. Epoch', 'NumberTitle', 'off', 'Position', [100, 400, 800, 600]);
+++if isfield(results, 'test_loss_hybrid_log')
+++    hybrid_loss = double(results.test_loss_hybrid_log);
+++    data_loss = double(results.test_data_log);
+++    epochs = 1:length(hybrid_loss);
+++    semilogy(epochs, hybrid_loss, 'b-', 'LineWidth', 2.5, 'DisplayName', 'Test Hybrid Loss');
+++    hold on;
+++    semilogy(epochs, data_loss, 'r--', 'LineWidth', 2.5, 'DisplayName', 'Test Data-Only Loss');
+++    hold off;
+++    legend('show', 'Location', 'northeast');
+++else
+++    test_loss = double(results.test_l2_log);
+++    epochs = 1:length(test_loss);
+++    semilogy(epochs, test_loss, 'g-', 'LineWidth', 2.5, 'DisplayName', 'Test L2 Loss');
+++    legend('show', 'Location', 'northeast');
+++end
+++grid on; box on;
+++xlabel('Epoch', 'FontWeight', 'bold');
+++ylabel('L2 Relative Loss', 'FontWeight', 'bold');
+++title(loss_plot_title, 'FontSize', 14);
+++set(gca, 'FontSize', 12, 'LineWidth', 1);
+++
+++%% ======================= Plot 2: 3D Subplots (FINAL - CORRECTED SPACING) =======================
+++num_times = length(time_steps_to_plot);
+++fig2 = figure('Name', '3D Field Comparison', 'NumberTitle', 'off', 'Position', [200, 100, 950, 800]); 
+++set(fig2, 'Color', [0.94 0.94 0.94]);
+++
+++tl = tiledlayout(3, num_times, 'TileSpacing', 'compact', 'Padding', 'normal');
+++title(tl, {main_plot_title; ''}, 'FontSize', 22, 'FontWeight', 'bold');
+++custom_error_map = [linspace(1,0,256)', linspace(1,1,256)', linspace(0.2,0,256)']; % Yellow->Green
+++
+++for i = 1:num_times
+++    t_step = time_steps_to_plot(i);
+++    
+++    if t_step == 0
+++        exact_slice = u_input;
+++        pred_slice  = u_input;
+++        title_time_str = 't = 0 (Input)';
+++        error_title_str = 't = 0';
+++    else
+++        exact_slice = u_exact(:, :, :, t_step);
+++        pred_slice  = u_pred(:, :, :, t_step);
+++        error_slice = u_error(:, :, :, t_step);
+++        title_time_str = sprintf('%d\\Deltat', t_step);
+++        norm_of_error = norm(error_slice(:));
+++        norm_of_exact = norm(exact_slice(:));
+++        relative_l2_error = (norm_of_exact > 1e-9) * (norm_of_error / norm_of_exact);
+++        error_title_str = sprintf('Rel. L2: %.2f', relative_l2_error);
+++    end
+++    
+++    % --- Exact Row ---
+++    ax1 = nexttile(i);
+++    plot_isosurface_with_fallback(ax1, xx, yy, zz, exact_slice, iso_value, [0.85, 0.25, 0.25]);
+++    title(ax1, title_time_str, 'FontSize', 20, 'FontWeight', 'bold'); 
+++    if i == 1 % for PFC only we set  ax1, -0.9, 0.5, , and the rest should be ax1, -0.7, 0.5, 
+++        text(ax1, -0.9, 0.5, 'Exact', 'FontSize', 22, 'FontWeight', 'bold', 'HorizontalAlignment', 'center', 'Rotation', 90, 'Units', 'normalized');
+++    end
+++
+++    % --- Predicted Row ---
+++    ax2 = nexttile(i + num_times);
+++    plot_isosurface_with_fallback(ax2, xx, yy, zz, pred_slice, iso_value, [0.25, 0.5, 0.85]);
+++    title(ax2, title_time_str, 'FontSize', 20, 'FontWeight', 'bold');
+++    if i == 1
+++        text(ax2, -0.9, 0.5, 'Predicted', 'FontSize', 22, 'FontWeight', 'bold', 'HorizontalAlignment', 'center', 'Rotation', 90, 'Units', 'normalized');
+++    end
+++
+++    % --- Error Row ---
+++    ax3 = nexttile(i + 2*num_times);
+++    if t_step == 0
+++        [x_grid, y_grid, z_grid] = meshgrid(linspace(min(x), max(x), 5), linspace(min(y), max(y), 5), linspace(min(z), max(z), 5));
+++        scatter3(ax3, x_grid(:), y_grid(:), z_grid(:), 40, [1 1 0.2], 'filled');
+++        colorbar(ax3, 'off');
+++    else
+++        abs_error = abs(u_error(:,:,:,t_step));
+++        max_abs_error = max(abs_error(:));
+++        error_threshold = error_display_threshold_ratio * max_abs_error;
+++        idx_to_plot = find(abs_error >= error_threshold);
+++        if isempty(idx_to_plot) || max_abs_error < 1e-9
+++            text(ax3, 0.5, 0.5, 'No significant error', 'HorizontalAlignment', 'center', 'FontSize', 14, 'Units', 'normalized', 'FontWeight', 'bold');
+++            axis(ax3, 'off');
+++        else
+++            x_err = xx(idx_to_plot); y_err = yy(idx_to_plot); z_err = zz(idx_to_plot);
+++            c_data = abs_error(idx_to_plot);
+++            scatter3(ax3, x_err, y_err, z_err, 40, c_data, 'filled');
+++            caxis(ax3, [error_threshold, max_abs_error]);
+++        end
+++    end
+++    
+++    title(ax3, error_title_str, 'FontSize', 16, 'FontWeight', 'bold'); 
+++    colormap(ax3, custom_error_map); 
+++    cb = colorbar(ax3); 
+++    ylabel(cb, 'Relative Error', 'FontSize', 14, 'FontWeight', 'bold'); 
+++    cb.FontSize = 14;
+++    cb.FontWeight = 'bold';
+++    
+++    plot_isosurface_with_fallback(ax3, [],[],[],[],[],[]); % Just use it to set axis properties
+++    if i == 1
+++        text(ax3, -0.9, 0.5, 'Error', 'FontSize', 20, 'FontWeight', 'bold', 'HorizontalAlignment', 'center', 'Rotation', 90, 'Units', 'normalized');
+++    end
+++end
+++
+++%% ======================= Save Plots to File =======================
+++fprintf('\nSaving generated plots...\n');
+++output_dir = 'saved_plots';
+++if ~exist(output_dir, 'dir'), mkdir(output_dir); end
+++loss_plot_filename = sprintf('%s_%s_loss_curve.png', problem_name, model_name);
+++field_plot_filename = sprintf('%s_%s_field_comparison_FINAL.png', problem_name, model_name);
+++
+++try
+++    exportgraphics(fig1, fullfile(output_dir, loss_plot_filename), 'Resolution', 300);
+++    fprintf('Saved loss plot to: %s\n', fullfile(output_dir, loss_plot_filename));
+++catch ME
+++    fprintf('Error saving loss plot: %s\n', ME.message);
+++end
+++
+++try
+++    exportgraphics(fig2, fullfile(output_dir, field_plot_filename), 'Resolution', 600);
+++    fprintf('Saved high-quality field plot to: %s\n', fullfile(output_dir, field_plot_filename));
+++catch ME
+++    fprintf('Error saving field plot with exportgraphics: %s\n', ME.message);
+++end
+++
+++disp('Visualization script finished.');
+++
+++%% ======================= MODIFIED Local Helper Function =======================
+++function plot_isosurface_with_fallback(ax, xx, yy, zz, data, iso_value, color)
+++    % This helper function plots a 3D surface. It first tries the specified
+++    % iso_value. If no surface is found, it automatically tries to plot the
+++    % "peaks" and "valleys" of the data to show its 3D structure.
+++
+++    if ~isempty(data)
+++        % --- Primary Plotting Attempt ---
+++        % Try to find the surface at the requested iso_value (usually 0).
+++        [faces, vertices] = isosurface(xx, yy, zz, data, iso_value);
+++
+++        if ~isempty(faces)
+++            % SUCCESS: The u=0 surface exists. Plot it.
+++            p = patch(ax, 'Faces', faces, 'Vertices', vertices);
+++            set(p, 'FaceColor', color, 'EdgeColor', 'none', 'FaceAlpha', 0.8);
+++            lighting(ax, 'gouraud'); material(ax, 'dull');
+++            camlight(ax);
+++        else
+++            % --- Fallback Plotting Logic ---
+++            % The u=0 surface does not exist. Let's visualize the data's
+++            % actual structure by plotting its peaks and valleys.
+++
+++            % Define new isosurface values based on the data's range.
+++            max_val = max(data(:));
+++            min_val = min(data(:));
+++            
+++            % Set thresholds to avoid plotting noise near zero.
+++            positive_iso = 0.3 * max_val;
+++            negative_iso = 0.3 * min_val;
+++            
+++            % Find the "peak" and "valley" surfaces.
+++            [faces_pos, vertices_pos] = isosurface(xx, yy, zz, data, positive_iso);
+++            [faces_neg, vertices_neg] = isosurface(xx, yy, zz, data, negative_iso);
+++
+++            if isempty(faces_pos) && isempty(faces_neg)
+++                % Fallback also failed (data is too flat). Show the old slice plot.
+++                slice(ax, xx, yy, zz, data, [], [], 0);
+++                shading(ax, 'interp'); caxis(ax, [-1.2, 1.2]); colorbar(ax);
+++                text(ax, 0.05, 0.95, 'No clear structure found.', 'Color', 'k', 'BackgroundColor', 'w', 'Margin', 2, 'VerticalAlignment', 'top', 'FontSize', 9, 'Units', 'normalized');
+++            else
+++                % SUCCESS: We found some structure. Plot it.
+++                hold(ax, 'on');
+++                % Plot positive surface (peaks)
+++                if ~isempty(faces_pos)
+++                    p_pos = patch(ax, 'Faces', faces_pos, 'Vertices', vertices_pos);
+++                    set(p_pos, 'FaceColor', color, 'EdgeColor', 'none', 'FaceAlpha', 0.8);
+++                end
+++                % Plot negative surface (valleys) using a slightly different shade for contrast
+++                if ~isempty(faces_neg)
+++                    p_neg = patch(ax, 'Faces', faces_neg, 'Vertices', vertices_neg);
+++                    % Use a complementary or darker/lighter color for the second surface
+++                    comp_color = color * 0.6; % A simple way to make it darker
+++                    set(p_neg, 'FaceColor', comp_color, 'EdgeColor', 'none', 'FaceAlpha', 0.8);
+++                end
+++                hold(ax, 'off');
+++                lighting(ax, 'gouraud'); material(ax, 'dull');
+++                camlight(ax);
+++            end
+++        end
+++    end
+++    
+++    % --- Universal Axis Formatting ---
+++    daspect(ax, [1 1 1]); view(ax, 45, 30);
+++    grid(ax, 'on'); box(ax, 'on'); axis(ax, 'tight');
+++    xlabel(ax, 'X', 'FontSize', 16, 'FontWeight', 'bold'); 
+++    ylabel(ax, 'Y', 'FontSize', 16, 'FontWeight', 'bold'); 
+++    zlabel(ax, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++    ax.FontSize = 14;
+++    ax.FontWeight = 'bold';
+++end
++Index: MatlabCode/Out_Distribution/AC3D_Spherical_Comparison.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/Out_Distribution/AC3D_Spherical_Comparison.m b/MatlabCode/Out_Distribution/AC3D_Spherical_Comparison.m
++new file mode 100644
++--- /dev/null	(date 1754475689261)
+++++ b/MatlabCode/Out_Distribution/AC3D_Spherical_Comparison.m	(date 1754475689261)
++@@ -0,0 +1,276 @@
+++clc;
+++clear;
+++close all;
+++fclose('all');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 1: CHOOSE IC & SETUP PARAMETERS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++
+++% --- CHOOSE THE INITIAL CONDITION ---
+++initial_condition_type = 'sphere'; % Options: 'sphere', 'dumbbell', 'star', 'heart'
+++
+++fprintf('Setting up comparison for Initial Condition: %s\n', upper(initial_condition_type));
+++
+++% --- Declare variables ---
+++python_data_file = '';
+++Nx=0; Ny=0; Nz=0; Lx=0; Ly=0; Lz=0;
+++epsilon = 0; Nt = 0; selected_frames = [];
+++u = [];
+++
+++% --- Setup based on selected initial condition ---
+++switch initial_condition_type
+++    case 'sphere'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/AC3D_python_predictions_sphere.mat';
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 5;  Ly = 5;  Lz = 5;
+++        epsilon = 0.15;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        radius = 0.5;
+++        interface_width = sqrt(2) * epsilon;
+++        u = tanh((radius - sqrt(xx.^2 + yy.^2 + zz.^2)) / interface_width);
+++
+++    case 'dumbbell'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/AC3D_python_predictions_dumbbell.mat';
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 2.0; Ly = 1.0; Lz = 1.0;
+++        epsilon = 0.05;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        x_grid = linspace(0, Lx, Nx);
+++        y_grid = linspace(0, Ly, Ny);
+++        z_grid = linspace(0, Lz, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        R0 = 0.25;
+++        interface_width = sqrt(2) * epsilon;
+++        r1 = sqrt((xx - 0.3).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        r2 = sqrt((xx - 1.7).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        u_spheres = tanh((R0 - r1) / interface_width) + tanh((R0 - r2) / interface_width) + 1;
+++        bar_mask = (xx > 0.4 & xx < 1.6 & yy > 0.4 & yy < 0.6 & zz > 0.4 & zz < 0.6);
+++        u = u_spheres;
+++        u(bar_mask) = 1.0;
+++        u = max(-1.0, min(1.0, u));
+++
+++    case 'star'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/AC3D_python_predictions_star.mat';
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 5.0; Ly = 5.0; Lz = 5.0;
+++        epsilon = 0.05;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        interface_width = sqrt(2.0) * epsilon;
+++        theta = atan2(zz, xx);
+++        R_theta = 0.7 + 0.2 * cos(6 * theta);
+++        dist = sqrt(xx.^2 + 2*yy.^2 + zz.^2);
+++        u = tanh((R_theta - dist) / interface_width);
+++
+++    case 'heart'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/AC3D_python_predictions_heart.mat';
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 3.0; Ly = 3.0; Lz = 3.0;
+++        epsilon = 0.05;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        % Equation from image: phi(x,y,z,0) = tanh( ( (x^2 + 9/4*y^2 + z^2 - 1)^3 - x^2*z^3 - 9/80*y^2*z^3 ) / sqrt(2*epsilon) )
+++        interface_term = sqrt(2*epsilon);
+++        numerator = (xx.^2 + (9/4)*yy.^2 + zz.^2 - 1).^3 - xx.^2.*zz.^3 - (9/80)*yy.^2.*zz.^3;
+++        u = tanh(numerator ./ interface_term);
+++
+++    otherwise
+++        error("Unknown initial_condition_type. Choose 'sphere', 'dumbbell', 'star', or 'heart'.");
+++end
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 2: LOAD PYTHON MODEL RESULTS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp(['Loading Python predictions from: ', python_data_file]);
+++try
+++    python_data = load(python_data_file);
+++    python_pred = squeeze(python_data.python_pred);
+++    [py_Nx, py_Ny, py_Nz, ~] = size(python_pred);
+++    if py_Nx ~= Nx || py_Ny ~= Ny || py_Nz ~= Nz
+++        error('Dimension Mismatch! Loaded Python data is [%d x %d x %d] but MATLAB grid is [%d x %d x %d].', ...
+++              py_Nx, py_Ny, py_Nz, Nx, Ny, Nz);
+++    end
+++    num_selected = length(selected_frames);
+++    if isfield(python_data, 'inference_time')
+++        python_inference_time = python_data.inference_time;
+++    else
+++        python_inference_time = 0.045;
+++    end
+++catch ME
+++    error('Could not load Python prediction file: %s. Error: %s', python_data_file, ME.message);
+++end
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 3: RUN MATLAB (DNS) EXACT SOLUTION FOR AC3D
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Starting MATLAB (DNS) simulation for AC3D...');
+++tic;
+++epsilon1 = 0.1;
+++Cahn = epsilon1^2;
+++dt = 0.0005;
+++
+++kx = 2*pi/Lx * [0:Nx/2, -Nx/2+1:-1];
+++ky = 2*pi/Ly * [0:Ny/2, -Ny/2+1:-1];
+++kz = 2*pi/Lz * [0:Nz/2, -Nz/2+1:-1];
+++[kxx, kyy, kzz] = ndgrid(kx.^2, ky.^2, kz.^2);
+++K2_laplace = kxx + kyy + kzz;
+++
+++all_iterations_dns = zeros(Nt + 1, Nx, Ny, Nz, 'single');
+++all_iterations_dns(1, :, :, :) = u;
+++
+++for iter = 1:Nt
+++    u = real(u);
+++    nonlinear_term_hat = fftn(u.^3 - u);
+++    u_hat = fftn(u);
+++    v_hat = (u_hat - (dt/Cahn) * nonlinear_term_hat) ./ (1 + dt * K2_laplace);
+++    u = real(ifftn(v_hat));
+++    all_iterations_dns(iter + 1, :, :, :) = u;
+++end
+++
+++matlab_simulation_time = toc;
+++disp(['MATLAB (DNS) simulation complete. Elapsed time: ', num2str(matlab_simulation_time), ' s']);
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 4: COMBINED VISUALIZATION (MODIFIED VERSION)
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Generating comparison plots...');
+++fig_width = 450 * num_selected;
+++fig_height = 900; 
+++fig = figure('Position', [100 100 fig_width fig_height]);
+++
+++sgtitle(sprintf('AC3D MHNO (%s)\nPrediction Time: %.2f s  vs.  Ground Truth Time: %.2f s', ...
+++                upper(initial_condition_type), python_inference_time, matlab_simulation_time), ...
+++                'FontSize', 20, 'FontWeight', 'bold');
+++
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    frame_idx = frame_to_plot + 1;
+++    
+++    % Python prediction isosurfaces (Top Row)
+++    ax1 = subplot(3, num_selected, i); 
+++    u_python = python_pred(:,:,:,frame_idx);
+++    [f, v] = isosurface(xx, yy, zz, u_python, 0);
+++    if ~isempty(v)
+++        patch(ax1, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax1, 'gouraud'); light(ax1, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax1, 'dull'); colormap(ax1, jet); view(45, 30); axis(ax1, 'tight', 'equal');
+++        title(ax1, sprintf('Prediction\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax1, sprintf('Prediction\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax1, 'tight', 'equal');
+++    end
+++    set(ax1, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax1, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax1, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax1, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++
+++    % MATLAB DNS isosurfaces (Middle Row)
+++    ax2 = subplot(3, num_selected, num_selected + i);
+++    u_matlab = squeeze(all_iterations_dns(frame_idx,:,:,:));
+++    [f, v] = isosurface(xx, yy, zz, u_matlab, 0);
+++    if ~isempty(v)
+++        patch(ax2, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax2, 'gouraud'); light(ax2, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax2, 'dull'); colormap(ax2, jet); view(45, 30); axis(ax2, 'tight', 'equal');
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax2, 'tight', 'equal');
+++    end
+++    set(ax2, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax2, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax2, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax2, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++end
+++
+++% === NEW PROFESSIONAL 1D PROFILE PLOT WITH ORGANIZED LEGEND (MODIFIED SECTION) ===
+++
+++% Get the centerline indices
+++center_y_idx = round(Ny/2); 
+++center_z_idx = round(Nz/2);
+++
+++% Define position for the combined 1D plot
+++ax_profile_pos = [0.1, 0.08, 0.85, 0.22]; 
+++ax_profile = axes('Position', ax_profile_pos);
+++
+++hold(ax_profile, 'on');
+++grid(ax_profile, 'on');
+++box(ax_profile, 'on'); 
+++
+++% Define line styles and colors
+++line_styles = {'-', '--'}; % Solid for Ground Truth, Dashed for Prediction
+++line_width = 2.5;
+++colors = get(ax_profile, 'ColorOrder');
+++
+++% Loop through selected time steps to plot the ACTUAL data
+++% NOTE: We remove the 'DisplayName' from here, as the legend will be custom-built.
+++for i = 1:num_selected
+++    frame_idx = selected_frames(i) + 1;
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++
+++    % Plot Ground Truth (DNS) Profile
+++    profile_dns = squeeze(all_iterations_dns(frame_idx, :, center_y_idx, center_z_idx));
+++    plot(ax_profile, x_grid, profile_dns, ...
+++        'LineStyle', line_styles{1}, 'Color', current_color, 'LineWidth', line_width);
+++        
+++    % Plot Prediction (SANO) Profile
+++    profile_py = squeeze(python_pred(:, center_y_idx, center_z_idx, frame_idx));
+++    plot(ax_profile, x_grid, profile_py, ...
+++        'LineStyle', line_styles{2}, 'Color', current_color, 'LineWidth', line_width);
+++end
+++
+++% --- Create Proxy Artists for a Clean, Organized Legend ---
+++% We create invisible plots that have the desired properties for our legend entries.
+++h_proxy = gobjects(2 + num_selected, 1); % Pre-allocate graphics object array
+++
+++% Proxy for Line Styles
+++h_proxy(1) = plot(NaN, NaN, 'LineStyle', line_styles{1}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Ground Truth');
+++h_proxy(2) = plot(NaN, NaN, 'LineStyle', line_styles{2}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Prediction');
+++
+++% Proxies for Time (Colors)
+++for i = 1:num_selected
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++    h_proxy(2+i) = plot(NaN, NaN, 'LineStyle', '-', 'Color', current_color, 'LineWidth', line_width, 'DisplayName', sprintf('t = %d', selected_frames(i)));
+++end
+++
+++hold(ax_profile, 'off');
+++
+++% --- Professional Formatting for the 1D Plot ---
+++title(ax_profile, '1D Centerline Profile Comparison', 'FontSize', 18, 'FontWeight', 'bold');
+++xlabel(ax_profile, 'Position along x-axis', 'FontSize', 16, 'FontWeight', 'bold');
+++ylabel(ax_profile, 'Field Value u', 'FontSize', 16, 'FontWeight', 'bold');
+++ylim(ax_profile, [-1.1, 1.1]);
+++xlim(ax_profile, [x_grid(1), x_grid(end)]);
+++set(ax_profile, 'FontSize', 16, 'FontWeight', 'bold', 'LineWidth', 1.5);
+++
+++% Generate the legend using ONLY the proxy artists
+++lgd = legend(h_proxy, 'Location', 'northeast', 'NumColumns', 1); % Single column is cleaner
+++set(lgd, 'FontSize', 14, 'FontWeight', 'bold', 'Box', 'on');
+++
+++disp('Comparison visualization complete.');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 5: SAVE THE FIGURE
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Saving the figure...');
+++filename = ['AC3D_Comparison_' initial_condition_type '.png'];
+++print(fig, filename, '-dpng', '-r300');
+++disp(['Figure saved as ', filename]);
++\ No newline at end of file
++Index: MatlabCode/Out_Distribution/SH3D_Spherical_Comparison.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/Out_Distribution/SH3D_Spherical_Comparison.m b/MatlabCode/Out_Distribution/SH3D_Spherical_Comparison.m
++new file mode 100644
++--- /dev/null	(date 1754475689250)
+++++ b/MatlabCode/Out_Distribution/SH3D_Spherical_Comparison.m	(date 1754475689250)
++@@ -0,0 +1,222 @@
+++clc; 
+++clear; 
+++close all; 
+++fclose('all');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 1: LOAD PYTHON (TNO) MODEL RESULTS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Loading Python (TNO) model predictions...');
+++
+++% --- MODIFIED SECTION ---
+++% Define the path and load the Python data file
+++python_data_file = '/scratch/noqu8762/phase_field_equations_4d/SH3D_python_predictions_sphere.mat';
+++try
+++    python_data = load(python_data_file);
+++    
+++    % Extract inference time from the loaded data, with a fallback default
+++    if isfield(python_data, 'inference_time')
+++        python_inference_time = python_data.inference_time;
+++    else
+++        disp('Warning: "inference_time" not found in .mat file. Using a default value.');
+++        python_inference_time = 0.045; % (seconds) - fallback value
+++    end
+++    
+++catch ME
+++    error('Could not load Python prediction file: %s. Error: %s', python_data_file, ME.message);
+++end
+++% --- END OF MODIFIED SECTION ---
+++
+++python_pred = squeeze(python_data.python_pred); % Remove batch dimension
+++selected_frames = python_data.selected_frames;
+++num_selected = length(selected_frames);
+++
+++% Spatial Parameters (must be consistent across both models)
+++Nx = 32; Lx = 15;
+++Ny = Nx; Ly = Lx;
+++Nz = Nx; Lz = Lx;
+++x = linspace(-Lx/2, Lx/2, Nx);
+++y = linspace(-Ly/2, Ly/2, Ny);
+++z = linspace(-Lz/2, Lz/2, Nz);
+++[xx, yy, zz] = ndgrid(x, y, z);
+++
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 2: RUN MATLAB (DNS) EXACT SOLUTION
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Starting MATLAB (DNS) simulation...');
+++tic; % Start the timer for the MATLAB simulation
+++
+++% --- PDE Parameters ---
+++epsilon = 0.15;
+++dt = 0.05;
+++Nt = 100;
+++num_saved_steps = 101;
+++ns = Nt/(num_saved_steps-1);
+++
+++% --- Create SMOOTH Spherical Initial Condition using tanh ---
+++% This is the key correction. Instead of a sharp step function, we
+++% create a smooth transition from +1 to -1.
+++radius = 2;
+++transition_width = 0.5; % Controls the smoothness of the boundary
+++r = sqrt(xx.^2 + yy.^2 + zz.^2);
+++u = tanh((radius - r) / transition_width);
+++
+++% --- Pre-calculate spectral terms (they don't change in the loop) ---
+++kx = 2*pi/Lx * [0:Nx/2, -Nx/2+1:-1];
+++ky = 2*pi/Ly * [0:Ny/2, -Ny/2+1:-1];
+++kz = 2*pi/Lz * [0:Nz/2, -Nz/2+1:-1];
+++[kxx,kyy,kzz] = ndgrid(kx.^2, ky.^2, kz.^2);
+++
+++% --- Initialize Storage for DNS results ---
+++all_iterations_dns = zeros(num_saved_steps, Nx, Ny, Nz, 'single');
+++
+++% --- Main Simulation Loop (Corrected Logic) ---
+++% First, store the true initial condition (t=0)
+++all_iterations_dns(1, :, :, :) = u;
+++
+++% Now, loop through time to compute and store subsequent frames
+++for iter = 1:Nt
+++    % Advance the solution by one time step
+++    u = real(u);
+++    s_hat = fftn(u/dt) - fftn(u.^3) + 2*(kxx + kyy + kzz).*fftn(u);
+++    v_hat = s_hat ./ (1.0/dt + (1-epsilon) + (kxx + kyy + kzz).^2);
+++    u = ifftn(v_hat);
+++
+++    % --- ADDED LINE: Cap values of u greater than +1 to be +1 ---
+++    %u(u > 1) = 1;
+++
+++    % Store the result in the correct slot. The array index is iter+1.
+++    all_iterations_dns(iter + 1, :, :, :) = u;
+++end
+++
+++
+++matlab_simulation_time = toc; % Stop the timer
+++disp(['MATLAB (DNS) simulation complete. Elapsed time: ', num2str(matlab_simulation_time), ' s']);
+++
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 3: COMBINED VISUALIZATION (MODIFIED TO MATCH CODE 1 STYLE)
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Generating comparison plots...');
+++fig_width = 450 * num_selected;
+++fig_height = 900; 
+++fig = figure('Position', [100 100 fig_width fig_height]);
+++
+++sgtitle(sprintf('SH3D MHNO (Sphere)\nPrediction Time: %.2f s  vs.  Ground Truth Time: %.2f s', ...
+++                python_inference_time, matlab_simulation_time), ...
+++                'FontSize', 20, 'FontWeight', 'bold');
+++
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    
+++    % --- Plot Python TNO results (TOP ROW) ---
+++    ax1 = subplot(3, num_selected, i); 
+++    frame_idx_py = frame_to_plot + 1; % Python index is direct
+++    u_python = python_pred(:,:,:,frame_idx_py);
+++    [f, v] = isosurface(xx, yy, zz, u_python, 0);
+++    if ~isempty(v)
+++        patch(ax1, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax1, 'gouraud'); light(ax1, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax1, 'dull'); colormap(ax1, jet); view(45, 30); axis(ax1, 'tight', 'equal');
+++        title(ax1, sprintf('Prediction\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax1, sprintf('Prediction\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax1, 'tight', 'equal');
+++    end
+++    set(ax1, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax1, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax1, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax1, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++
+++    % --- Plot MATLAB DNS results (MIDDLE ROW) ---
+++    ax2 = subplot(3, num_selected, num_selected + i);
+++    % ** ADAPTATION: Convert frame number to the saved index for the DNS array **
+++    frame_idx_dns = min(max(round(frame_to_plot / ns + 1), 1), num_saved_steps);
+++    u_matlab = squeeze(all_iterations_dns(frame_idx_dns,:,:,:));
+++    [f, v] = isosurface(xx, yy, zz, u_matlab, 0);
+++    if ~isempty(v)
+++        patch(ax2, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax2, 'gouraud'); light(ax2, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax2, 'dull'); colormap(ax2, jet); view(45, 30); axis(ax2, 'tight', 'equal');
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax2, 'tight', 'equal');
+++    end
+++    set(ax2, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax2, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax2, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax2, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++end
+++
+++% === PROFESSIONAL 1D PROFILE PLOT WS ORGANIZED LEGEND (FROM CODE 1) ===
+++
+++% Get the centerline indices
+++center_idx = round(Ny/2);
+++
+++% Define position for the combined 1D plot
+++ax_profile_pos = [0.1, 0.08, 0.85, 0.22]; 
+++ax_profile = axes('Position', ax_profile_pos);
+++
+++hold(ax_profile, 'on');
+++grid(ax_profile, 'on');
+++box(ax_profile, 'on'); 
+++
+++% Define line styles and colors
+++line_styles = {'-', '--'}; % Solid for Ground Truth, Dashed for Prediction
+++line_width = 2.5;
+++colors = get(ax_profile, 'ColorOrder');
+++
+++% Loop through selected time steps to plot the ACTUAL data
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++
+++    % Plot Ground Truth (DNS) Profile
+++    % ** ADAPTATION: Use correct DNS frame index and 'x' variable **
+++    frame_idx_dns = min(max(round(frame_to_plot / ns + 1), 1), num_saved_steps);
+++    profile_dns = squeeze(all_iterations_dns(frame_idx_dns, :, center_idx, center_idx));
+++    plot(ax_profile, x, profile_dns, ...
+++        'LineStyle', line_styles{1}, 'Color', current_color, 'LineWidth', line_width);
+++        
+++    % Plot Prediction (SANO) Profile
+++    % ** ADAPTATION: Use correct Python frame index and 'x' variable **
+++    frame_idx_py = frame_to_plot + 1;
+++    profile_py = squeeze(python_pred(:, center_idx, center_idx, frame_idx_py));
+++    plot(ax_profile, x, profile_py, ...
+++        'LineStyle', line_styles{2}, 'Color', current_color, 'LineWidth', line_width);
+++end
+++
+++% --- Create Proxy Artists for a Clean, Organized Legend ---
+++h_proxy = gobjects(2 + num_selected, 1); % Pre-allocate graphics object array
+++h_proxy(1) = plot(NaN, NaN, 'LineStyle', line_styles{1}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Ground Truth');
+++h_proxy(2) = plot(NaN, NaN, 'LineStyle', line_styles{2}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Prediction');
+++for i = 1:num_selected
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++    h_proxy(2+i) = plot(NaN, NaN, 'LineStyle', '-', 'Color', current_color, 'LineWidth', line_width, 'DisplayName', sprintf('t = %d', selected_frames(i)));
+++end
+++hold(ax_profile, 'off');
+++
+++% --- Professional Formatting for the 1D Plot ---
+++title(ax_profile, '1D Centerline Profile Comparison', 'FontSize', 18, 'FontWeight', 'bold');
+++xlabel(ax_profile, 'Position along x-axis', 'FontSize', 16, 'FontWeight', 'bold');
+++ylabel(ax_profile, 'Field Value u', 'FontSize', 16, 'FontWeight', 'bold');
+++ylim(ax_profile, [-1.1, 1.5]); % Adjusted Y-Limit to better fit the data
+++xlim(ax_profile, [x(1), x(end)]);
+++set(ax_profile, 'FontSize', 16, 'FontWeight', 'bold', 'LineWidth', 1.5);
+++lgd = legend(h_proxy, 'Location', 'northeast', 'NumColumns', 1);
+++set(lgd, 'FontSize', 14, 'FontWeight', 'bold', 'Box', 'on');
+++
+++disp('Comparison visualization complete.');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 4: SAVE THE FIGURE
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Saving the figure...');
+++% ** ADAPTATION: Using the original filename from Code 2 **
+++filename = 'SH3D_Comparison_Plot_Modified.png'; 
+++print(fig, filename, '-dpng', '-r300');
+++disp(['Figure saved as ', filename]);
++\ No newline at end of file
++Index: MatlabCode/Out_Distribution/CH3D_Star_Comparison.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/Out_Distribution/CH3D_Star_Comparison.m b/MatlabCode/Out_Distribution/CH3D_Star_Comparison.m
++new file mode 100644
++--- /dev/null	(date 1754475689279)
+++++ b/MatlabCode/Out_Distribution/CH3D_Star_Comparison.m	(date 1754475689279)
++@@ -0,0 +1,302 @@
+++clc;
+++clear;
+++close all;
+++fclose('all');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 1: CHOOSE IC & SETUP PARAMETERS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++
+++% --- CHOOSE THE INITIAL CONDITION ---
+++initial_condition_type = 'star';  % dumbbell, star, sphere, we validated for star for CH3D
+++
+++fprintf('Setting up comparison for CH3D Initial Condition: %s\n', upper(initial_condition_type));
+++
+++% --- Declare variables that will be set in the switch block ---
+++python_data_file = '';
+++Nx=0; Ny=0; Nz=0; Lx=0; Ly=0; Lz=0;
+++epsilon = 0; Nt = 0; selected_frames = [];
+++u = []; % The initial condition for the DNS
+++
+++% --- Setup based on selected initial condition ---
+++switch initial_condition_type
+++
+++    case 'heart'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/CH3D_python_predictions_heart.mat';
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 5.0; Ly = Lx; Lz = Lx;
+++        epsilon = 0.15;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        % Equation from image: phi(x,y,z,0) = tanh( ( (x^2 + 9/4*y^2 + z^2 - 1)^3 - x^2*z^3 - 9/80*y^2*z^3 ) / sqrt(2*epsilon) )
+++        interface_term = sqrt(2*epsilon);
+++        numerator = (xx.^2 + (9/4)*yy.^2 + zz.^2 - 1).^3 - xx.^2.*zz.^3 - (9/80)*yy.^2.*zz.^3;
+++        u = tanh(numerator ./ interface_term);
+++
+++    case 'sphere'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/CH3D_python_predictions_sphere.mat'; % <-- UPDATE THIS PATH
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 2;  Ly = 2;  Lz = 2;
+++        epsilon = 0.05;
+++        selected_frames = [0, 50, 90];
+++        
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++
+++        radius = 0.5;
+++        interface_width = sqrt(2) * epsilon;
+++        u = tanh((radius - sqrt(xx.^2 + yy.^2 + zz.^2)) / interface_width);
+++
+++    case 'dumbbell'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/CH3D_python_predictions_dumbbell.mat';
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 2.5; Ly = 1.0; Lz = 1.0;
+++        epsilon = 0.05;
+++        selected_frames = [0, 50, 90];
+++
+++        x_grid = linspace(0, Lx, Nx);
+++        y_grid = linspace(0, Ly, Ny);
+++        z_grid = linspace(0, Lz, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        
+++        R0 = 0.25;
+++        interface_width = sqrt(2) * epsilon;
+++        r1 = sqrt((xx - 0.3).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        r2 = sqrt((xx - 1.7).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        u_spheres = tanh((R0 - r1) / interface_width) + tanh((R0 - r2) / interface_width) + 1;
+++        bar_mask = (xx > 0.4 & xx < 1.6 & yy > 0.4 & yy < 0.6 & zz > 0.4 & zz < 0.6);
+++        u = u_spheres;
+++        u(bar_mask) = 1.0;
+++        u = max(-1.0, min(1.0, u));
+++
+++    case 'star'
+++        python_data_file = '//scratch/noqu8762/phase_field_equations_4d/CH3D_python_predictions_star.mat';
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        % Corrected Lx, Ly, Lz to match the plot's x-axis from -1 to 1
+++        Lx = 2.0; 
+++        Ly = Lx ; Lz = Lx ; 
+++        epsilon = 0.05;
+++        Cahn = epsilon^2;
+++        selected_frames = [0, 50, 90];
+++        
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        
+++        interface_width = sqrt(2.0) * epsilon;
+++        theta = atan2(zz, xx);
+++        R_theta = 0.7 + 0.2 * cos(6 * theta);
+++        dist = sqrt(xx.^2 + 2*yy.^2 + zz.^2);
+++        u = tanh((R_theta - dist) / interface_width);
+++        
+++    otherwise
+++        error("Unknown initial_condition_type. Choose 'sphere', 'dumbbell', or 'star'.");
+++end
+++
+++% Set total simulation time based on the last frame needed
+++Nt = max(selected_frames);
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 2: LOAD PYTHON MODEL RESULTS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp(['Loading Python predictions from: ', python_data_file]);
+++try
+++    python_data = load(python_data_file);
+++    python_pred = squeeze(python_data.python_pred);
+++    
+++    [py_Nx, py_Ny, py_Nz, ~] = size(python_pred);
+++    if py_Nx ~= Nx || py_Ny ~= Ny || py_Nz ~= Nz
+++        error('Dimension Mismatch! Loaded Python data is [%d x %d x %d] but MATLAB grid is [%d x %d x %d].', ...
+++              py_Nx, py_Ny, py_Nz, Nx, Ny, Nz);
+++    end
+++    
+++    % % ******** TEMPORARILY DISABLE THE FIX TO SEE RAW DATA ********
+++    % disp('Synchronizing t=0 frame between prediction and ground truth.');
+++    % python_pred(:,:,:,1) = u;
+++    % % ***************************************************************
+++    
+++    num_selected = length(selected_frames);
+++    
+++    if isfield(python_data, 'inference_time')
+++        python_inference_time = python_data.inference_time;
+++    else
+++        python_inference_time = 0.050; 
+++    end
+++    
+++catch ME
+++    error('Could not load Python prediction file: %s. Error: %s', python_data_file, ME.message);
+++end
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 3: RUN MATLAB (DNS) EXACT SOLUTION FOR CH3D
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Starting MATLAB (DNS) simulation for CH3D...');
+++tic; 
+++
+++% --- PDE and Solver Parameters ---
+++
+++dt = 0.0005; % Using the smaller dt from the original code 2
+++
+++% --- Fourier Constants ---
+++kx = 2*pi/Lx * [0:Nx/2, -Nx/2+1:-1];
+++ky = 2*pi/Ly * [0:Ny/2, -Ny/2+1:-1];
+++kz = 2*pi/Lz * [0:Nz/2, -Nz/2+1:-1];
+++[kxx,kyy,kzz] = ndgrid(kx.^2, ky.^2, kz.^2);
+++K2_laplace = kxx + kyy + kzz;
+++
+++% --- Simulation Loop ---
+++all_iterations_dns = zeros(Nt + 1, Nx, Ny, Nz, 'single');
+++all_iterations_dns(1, :, :, :) = u;
+++u_dns = u; % Use a separate variable for the simulation
+++
+++for iter = 1:Nt
+++    u_dns = real(u_dns);
+++    nonlinear_term_hat = fftn(u_dns.^3 - 3*u_dns);
+++    s_hat = fftn(u_dns) - dt * K2_laplace .* nonlinear_term_hat;
+++    v_hat = s_hat ./ (1.0 + dt * (2.0 * K2_laplace + Cahn * K2_laplace.^2));
+++    u_dns = real(ifftn(v_hat));
+++    all_iterations_dns(iter + 1, :, :, :) = u_dns;
+++end
+++
+++matlab_simulation_time = toc;
+++disp(['MATLAB (DNS) simulation complete. Elapsed time: ', num2str(matlab_simulation_time), ' s']);
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 4: COMBINED VISUALIZATION (MODIFIED VERSION)
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Generating comparison plots...');
+++fig_width = 450 * num_selected;
+++fig_height = 900; 
+++fig = figure('Position', [100 100 fig_width fig_height]);
+++
+++sgtitle(sprintf('CH3D: MHNO Method (%s)\nPrediction Time: %.2f s  vs.  Ground Truth Time: %.2f s', ...
+++                upper(initial_condition_type), python_inference_time, matlab_simulation_time), ...
+++                'FontSize', 20, 'FontWeight', 'bold');
+++
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    frame_idx = frame_to_plot + 1;
+++    
+++    % Python prediction isosurfaces (Top Row)
+++    ax1 = subplot(3, num_selected, i); 
+++    u_python = python_pred(:,:,:,frame_idx);
+++    [f, v] = isosurface(xx, yy, zz, u_python, 0);
+++    if ~isempty(v)
+++        patch(ax1, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax1, 'gouraud'); light(ax1, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax1, 'dull'); colormap(ax1, jet); view(45, 30); axis(ax1, 'tight', 'equal');
+++        title(ax1, sprintf('Prediction\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax1, sprintf('Prediction\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax1, 'tight', 'equal');
+++    end
+++    set(ax1, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax1, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax1, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax1, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++
+++    % MATLAB DNS isosurfaces (Middle Row)
+++    ax2 = subplot(3, num_selected, num_selected + i);
+++    u_matlab = squeeze(all_iterations_dns(frame_idx,:,:,:));
+++    [f, v] = isosurface(xx, yy, zz, u_matlab, 0);
+++    if ~isempty(v)
+++        patch(ax2, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax2, 'gouraud'); light(ax2, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax2, 'dull'); colormap(ax2, jet); view(45, 30); axis(ax2, 'tight', 'equal');
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax2, 'tight', 'equal');
+++    end
+++    set(ax2, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax2, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax2, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax2, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++end
+++
+++% === NEW PROFESSIONAL 1D PROFILE PLOT WITH ORGANIZED LEGEND (MODIFIED SECTION) ===
+++
+++% Get the centerline indices
+++center_y_idx = round(Ny/2); 
+++center_z_idx = round(Nz/2);
+++
+++% Define position for the combined 1D plot
+++ax_profile_pos = [0.1, 0.08, 0.85, 0.22]; 
+++ax_profile = axes('Position', ax_profile_pos);
+++
+++hold(ax_profile, 'on');
+++grid(ax_profile, 'on');
+++box(ax_profile, 'on'); 
+++
+++% Define line styles and colors
+++line_styles = {'-', '--'}; % Solid for Ground Truth, Dashed for Prediction
+++line_width = 2.5;
+++colors = get(ax_profile, 'ColorOrder');
+++
+++% Loop through selected time steps to plot the ACTUAL data
+++% NOTE: We remove the 'DisplayName' from here, as the legend will be custom-built.
+++for i = 1:num_selected
+++    frame_idx = selected_frames(i) + 1;
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++
+++    % Plot Ground Truth (DNS) Profile
+++    profile_dns = squeeze(all_iterations_dns(frame_idx, :, center_y_idx, center_z_idx));
+++    plot(ax_profile, x_grid, profile_dns, ...
+++        'LineStyle', line_styles{1}, 'Color', current_color, 'LineWidth', line_width);
+++        
+++    % Plot Prediction (SANO) Profile
+++    profile_py = squeeze(python_pred(:, center_y_idx, center_z_idx, frame_idx));
+++    plot(ax_profile, x_grid, profile_py, ...
+++        'LineStyle', line_styles{2}, 'Color', current_color, 'LineWidth', line_width);
+++end
+++
+++% --- Create Proxy Artists for a Clean, Organized Legend ---
+++% We create invisible plots that have the desired properties for our legend entries.
+++h_proxy = gobjects(2 + num_selected, 1); % Pre-allocate graphics object array
+++
+++% Proxy for Line Styles
+++h_proxy(1) = plot(NaN, NaN, 'LineStyle', line_styles{1}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Ground Truth');
+++h_proxy(2) = plot(NaN, NaN, 'LineStyle', line_styles{2}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Prediction');
+++
+++% Proxies for Time (Colors)
+++for i = 1:num_selected
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++    h_proxy(2+i) = plot(NaN, NaN, 'LineStyle', '-', 'Color', current_color, 'LineWidth', line_width, 'DisplayName', sprintf('t = %d', selected_frames(i)));
+++end
+++
+++hold(ax_profile, 'off');
+++
+++% --- Professional Formatting for the 1D Plot ---
+++title(ax_profile, '1D Centerline Profile Comparison', 'FontSize', 18, 'FontWeight', 'bold');
+++xlabel(ax_profile, 'Position along x-axis', 'FontSize', 16, 'FontWeight', 'bold');
+++ylabel(ax_profile, 'Field Value u', 'FontSize', 16, 'FontWeight', 'bold');
+++ylim(ax_profile, [-1.1, 1.1]);
+++xlim(ax_profile, [x_grid(1), x_grid(end)]);
+++set(ax_profile, 'FontSize', 16, 'FontWeight', 'bold', 'LineWidth', 1.5);
+++
+++% Generate the legend using ONLY the proxy artists
+++lgd = legend(h_proxy, 'Location', 'northeast', 'NumColumns', 1); % Single column is cleaner
+++set(lgd, 'FontSize', 14, 'FontWeight', 'bold', 'Box', 'on');
+++
+++disp('Comparison visualization complete.');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 5: SAVE THE FIGURE
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Saving the figure...');
+++filename = ['CH3D_Comparison_' initial_condition_type '.png'];
+++print(fig, filename, '-dpng', '-r300');
+++disp(['Figure saved as ', filename]);
++\ No newline at end of file
++Index: MatlabCode/Out_Distribution/PFC3D_Star_Comparison.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/Out_Distribution/PFC3D_Star_Comparison.m b/MatlabCode/Out_Distribution/PFC3D_Star_Comparison.m
++new file mode 100644
++--- /dev/null	(date 1754320720076)
+++++ b/MatlabCode/Out_Distribution/PFC3D_Star_Comparison.m	(date 1754320720076)
++@@ -0,0 +1,374 @@
+++clc;
+++clear;
+++close all;
+++fclose('all');
+++
+++disp('START Modified PFC3D Simulation and Comparison')
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 1: CHOOSE IC & SETUP PARAMETERS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++
+++% --- CHOOSE THE INITIAL CONDITION ---
+++initial_condition_type = 'star';  % Options: 'dumbbell', 'star', 'sphere', 'torus', 'separation'
+++
+++fprintf('Setting up comparison for PFC3D PDE with Initial Condition: %s\n', upper(initial_condition_type));
+++
+++% --- Declare variables that will be set in the switch block ---
+++python_data_file = '';
+++Nx=0; Ny=0; Nz=0; Lx=0; Ly=0; Lz=0;
+++epsilon=0; Nt=0; selected_frames=[];
+++u=[]; % This will hold the initial condition for the DNS
+++dt_dns = 0; % dt for the MATLAB simulation
+++
+++% --- Setup based on selected initial condition ---
+++switch initial_condition_type
+++    case 'sphere'
+++        % !!! IMPORTANT: UPDATE THIS PATH TO YOUR .MAT FILE !!!
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/PFC3D_python_predictions_sphere.mat'; % Assumes file is in current directory
+++
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 10*pi; Ly = Lx;  Lz = Lx; % Matched to Python script
+++        epsilon = 0.15;
+++        dt_dns = 0.05;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++
+++        radius = 6.0;
+++        interface_width = sqrt(2) * epsilon;
+++        u = tanh((radius - sqrt(xx.^2 + yy.^2 + zz.^2)) / interface_width);
+++
+++    case 'dumbbell'
+++        % !!! IMPORTANT: UPDATE THIS PATH TO YOUR .MAT FILE !!!
+++        python_data_file = 'PFC3D_python_predictions_dumbbell.mat';
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 40; Ly = 20; Lz = 20;
+++        epsilon = 0.05;
+++        dt_dns = 0.01;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++
+++        x_grid = linspace(0, Lx, Nx);
+++        y_grid = linspace(0, Ly, Ny);
+++        z_grid = linspace(0, Lz, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        
+++        R0 = 0.25;
+++        interface_width = sqrt(2) * epsilon;
+++        r1 = sqrt((xx - 0.3).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        r2 = sqrt((xx - 1.7).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        u_spheres = tanh((R0 - r1) / interface_width) + tanh((R0 - r2) / interface_width) + 1;
+++        bar_mask = (xx > 0.4 & xx < 1.6 & yy > 0.4 & yy < 0.6 & zz > 0.4 & zz < 0.6);
+++        u = u_spheres;
+++        u(bar_mask) = 1.0;
+++        u = max(-1.0, min(1.0, u));
+++
+++    case 'star'
+++        % !!! IMPORTANT: UPDATE THIS PATH TO YOUR .MAT FILE !!!
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/PFC3D_python_predictions_star.mat';
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 10*pi; Ly = Lx; Lz = Lx;
+++        epsilon = 0.5;
+++        dt_dns = 0.005;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        
+++        interface_width = sqrt(2.0) * epsilon;
+++        theta = atan2(zz, xx);
+++        R_theta = 5 + 1.0 * cos(6 * theta); 
+++        dist = sqrt(xx.^2 + 2*yy.^2 + zz.^2);
+++        u = tanh((R_theta - dist) / interface_width);
+++        
+++    case 'torus'
+++        % !!! IMPORTANT: UPDATE THIS PATH TO YOUR .MAT FILE !!!
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/PFC3D_python_predictions_torus.mat';
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 6*pi;  Ly = Lx;  Lz = Lx;
+++        epsilon = 0.5;
+++        dt_dns = 0.05;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++
+++        R = 5.5; % Major radius
+++        r = 3.5; % Minor radius
+++        interface_width = sqrt(2) * epsilon;
+++
+++        torus_dist = sqrt((sqrt(xx.^2 + yy.^2) - R).^2 + zz.^2);
+++        u = tanh((r - torus_dist) / interface_width);
+++
+++    case 'separation'
+++        % !!! IMPORTANT: UPDATE THIS PATH TO YOUR .MAT FILE !!!
+++        python_data_file = 'PFC3D_python_predictions_separation.mat';
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 2*pi;  Ly = Lx;  Lz = Lx;
+++        epsilon = 0.5;
+++        dt_dns = 0.0005;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++
+++        interface_width = sqrt(2) * epsilon;
+++        r1 = sqrt((xx + 1).^2 + yy.^2 + zz.^2);
+++        r2 = sqrt((xx - 1).^2 + yy.^2 + zz.^2);
+++        u = tanh((1 - r1) / interface_width) + tanh((1 - r2) / interface_width);
+++        
+++    otherwise
+++        error("Unknown initial_condition_type. Choose 'sphere', 'dumbbell', 'star', etc.");
+++end
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 2: LOAD PYTHON MODEL RESULTS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp(['Loading Python predictions from: ', python_data_file]);
+++try
+++    python_data = load(python_data_file);
+++    % Squeeze removes the leading singleton dimension from the Python save format
+++    % e.g., [1, 32, 32, 32, 101] becomes [32, 32, 32, 101]
+++    python_pred = squeeze(python_data.python_pred);
+++
+++    [py_Nx, py_Ny, py_Nz, ~] = size(python_pred);
+++    if py_Nx ~= Nx || py_Ny ~= Ny || py_Nz ~= Nz
+++        error('Dimension Mismatch! Loaded Python data is [%d x %d x %d] but MATLAB grid is [%d x %d x %d].', ...
+++              py_Nx, py_Ny, py_Nz, Nx, Ny, Nz);
+++    end
+++
+++    num_selected = length(selected_frames);
+++
+++    if isfield(python_data, 'inference_time')
+++        python_inference_time = python_data.inference_time;
+++    else
+++        python_inference_time = 0.045; % Default if not found in .mat file
+++    end
+++
+++catch ME
+++    error('Could not load Python prediction file: %s. Error: %s', python_data_file, ME.message);
+++end
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 3: RUN MATLAB (PFC) SIMULATION (UNCHANGED PDE)
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Starting MATLAB (PFC Ground Truth) simulation...');
+++tic; 
+++
+++% --- Discrete Fourier Transform (from original code 1) ---
+++p = 2*pi/Lx*[0:Nx/2 -Nx/2+1:-1];
+++q = 2*pi/Ly*[0:Ny/2 -Ny/2+1:-1];
+++r = 2*pi/Lz*[0:Nz/2 -Nz/2+1:-1];
+++p2 = p.^2;
+++q2 = q.^2;
+++r2 = r.^2;
+++[pp2, qq2, rr2] = ndgrid(p2, q2, r2);
+++
+++% --- Initialize storage ---
+++all_iterations_dns = zeros(max(selected_frames) + 1, Nx, Ny, Nz, 'single');
+++all_iterations_dns(1, :, :, :) = u; % Store initial condition (t=0)
+++
+++% --- Simulation Loop ---
+++for iter = 1:Nt
+++    
+++    u = real(u);
+++    s_hat = fftn(u/dt_dns) - (pp2 + qq2 + rr2) .* fftn(u.^3) + 2 * (pp2 + qq2 + rr2).^2 .* fftn(u);
+++    v_hat = s_hat ./ (1.0/dt_dns + (1 - epsilon) * (pp2 + qq2 + rr2) + (pp2 + qq2 + rr2).^3);
+++    u = ifftn(v_hat);
+++    
+++    if ismember(iter, selected_frames)
+++        all_iterations_dns(iter + 1, :, :, :) = u;
+++    end
+++    
+++    if isnan(sum(u(:)))
+++        error('Simulation diverged (NaN values found). Check parameters.');
+++    end
+++end
+++
+++matlab_simulation_time = toc;
+++disp(['MATLAB (PFC) simulation complete. Elapsed time: ', num2str(matlab_simulation_time), ' s']);
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 4: COMBINED VISUALIZATION (IDENTICAL TO CODE 2'S PLOT SECTION)
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Generating comparison plots...');
+++fig_width = 450 * num_selected;
+++fig_height = 1000; % Adapted from original code 1
+++fig = figure('Position', [100 100 fig_width fig_height]);
+++
+++% Title adapted for PFC3D context
+++sgtitle(sprintf('PFC3D MHNO (%s)\nPrediction Time: %.2f s vs. Ground Truth Time: %.2f s', ...
+++                upper(initial_condition_type), python_inference_time, matlab_simulation_time), ...
+++                'FontSize', 20, 'FontWeight', 'bold');
+++
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    frame_idx = frame_to_plot + 1;
+++    
+++    % Python prediction isosurfaces (Top Row)
+++    ax1 = subplot(3, num_selected, i); 
+++    u_python = python_pred(:,:,:,frame_idx);
+++    [f, v] = isosurface(xx, yy, zz, u_python, 0);
+++    if ~isempty(v)
+++        patch(ax1, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax1, 'gouraud'); light(ax1, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax1, 'dull'); colormap(ax1, jet); view(45, 30);
+++        % Use fixed axis limits to visualize shrinkage correctly (from original code 1)
+++        axis(ax1, [min(x_grid) max(x_grid) min(y_grid) max(y_grid) min(z_grid) max(z_grid)]);
+++        axis(ax1, 'equal');
+++        title(ax1, sprintf('Prediction\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax1, sprintf('Prediction\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax1, 'equal');
+++    end
+++    set(ax1, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax1, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax1, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax1, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++
+++    % MATLAB DNS isosurfaces (Middle Row)
+++    ax2 = subplot(3, num_selected, num_selected + i);
+++    u_matlab = real(squeeze(all_iterations_dns(frame_idx,:,:,:))); % Added real() for safety
+++    [f, v] = isosurface(xx, yy, zz, u_matlab, 0);
+++    if ~isempty(v)
+++        patch(ax2, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax2, 'gouraud'); light(ax2, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax2, 'dull'); colormap(ax2, jet); view(45, 30);
+++        % Use fixed axis limits to visualize shrinkage correctly (from original code 1)
+++        axis(ax2, [min(x_grid) max(x_grid) min(y_grid) max(y_grid) min(z_grid) max(z_grid)]);
+++        axis(ax2, 'equal');
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax2, 'equal');
+++    end
+++    set(ax2, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax2, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax2, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax2, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++end
+++
+++% === Combined 1D Profile Plot with Organized Legend ===
+++
+++% Get the centerline indices (using definitions from original code 1)
+++center_y_idx = floor(Ny/2) + 1; 
+++center_z_idx = floor(Nz/2) + 1;
+++
+++% Define position for the combined 1D plot
+++ax_profile_pos = [0.1, 0.08, 0.85, 0.22]; 
+++ax_profile = axes('Position', ax_profile_pos);
+++
+++hold(ax_profile, 'on');
+++grid(ax_profile, 'on');
+++box(ax_profile, 'on'); 
+++
+++% Define line styles and colors
+++line_styles = {'-', '--'}; % Solid for Ground Truth, Dashed for Prediction
+++line_width = 2.5;
+++colors = get(ax_profile, 'ColorOrder');
+++
+++% Loop through selected time steps to plot the ACTUAL data
+++for i = 1:num_selected
+++    frame_idx = selected_frames(i) + 1;
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++
+++    % Plot Ground Truth (DNS) Profile
+++    profile_dns = real(squeeze(all_iterations_dns(frame_idx, :, center_y_idx, center_z_idx))); % Added real()
+++    plot(ax_profile, x_grid, profile_dns, ...
+++        'LineStyle', line_styles{1}, 'Color', current_color, 'LineWidth', line_width);
+++        
+++    % Plot Prediction (SANO) Profile
+++    profile_py = squeeze(python_pred(:, center_y_idx, center_z_idx, frame_idx));
+++    plot(ax_profile, x_grid, profile_py, ...
+++        'LineStyle', line_styles{2}, 'Color', current_color, 'LineWidth', line_width);
+++end
+++
+++% --- Create Proxy Artists for a Clean, Organized Legend ---
+++h_proxy = gobjects(2 + num_selected, 1);
+++
+++h_proxy(1) = plot(NaN, NaN, 'LineStyle', line_styles{1}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Ground Truth');
+++h_proxy(2) = plot(NaN, NaN, 'LineStyle', line_styles{2}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Prediction');
+++
+++for i = 1:num_selected
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++    h_proxy(2+i) = plot(NaN, NaN, 'LineStyle', '-', 'Color', current_color, 'LineWidth', line_width, 'DisplayName', sprintf('t = %d', selected_frames(i)));
+++end
+++
+++hold(ax_profile, 'off');
+++
+++% --- Professional Formatting for the 1D Plot ---
+++title(ax_profile, '1D Centerline Profile Comparison', 'FontSize', 18, 'FontWeight', 'bold');
+++xlabel(ax_profile, 'Position along x-axis', 'FontSize', 16, 'FontWeight', 'bold');
+++ylabel(ax_profile, 'Field Value u', 'FontSize', 16, 'FontWeight', 'bold');
+++ylim(ax_profile, [-1.5, 2.5]); % Adapted from original code 1 for PFC
+++xlim(ax_profile, [x_grid(1), x_grid(end)]);
+++set(ax_profile, 'FontSize', 16, 'FontWeight', 'bold', 'LineWidth', 1.5);
+++
+++lgd = legend(h_proxy, 'Location', 'northeast', 'NumColumns', 1);
+++set(lgd, 'FontSize', 14, 'FontWeight', 'bold', 'Box', 'on');
+++
+++disp('Comparison visualization complete.');
+++
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 4.5: QUANTITATIVE ERROR CALCULATION
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Calculating Relative L2-Norm Error...');
+++
+++fprintf('\n--- Quantitative Error Analysis ---\n');
+++
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    frame_idx_matlab = frame_to_plot + 1;
+++    frame_idx_python = frame_to_plot + 1;
+++
+++    % Extract the corresponding data slices
+++    u_python = python_pred(:,:,:,frame_idx_python);
+++    u_matlab = squeeze(all_iterations_dns(frame_idx_matlab,:,:,:));
+++
+++    % --- This is the implementation of the formula from the image ---
+++    % Numerator: L2 norm of the difference
+++    error_vector = u_python(:) - u_matlab(:);
+++    numerator = norm(error_vector); % norm() function calculates L2-norm by default
+++
+++    % Denominator: L2 norm of the ground truth
+++    denominator = norm(u_matlab(:));
+++
+++    % Calculate relative error
+++    if denominator > 1e-9 % Avoid division by zero
+++        relative_l2_error = numerator / denominator;
+++    else
+++        relative_l2_error = numerator; % If true solution is zero, use absolute error
+++    end
+++    
+++    fprintf('Time Step %d: Relative L2 Error = %.6f\n', frame_to_plot, relative_l2_error);
+++end
+++fprintf('-------------------------------------\n\n');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 5: SAVE THE FIGURE
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Saving the figure...');
+++filename = ['PFC3D_Comparison_' initial_condition_type '.png'];
+++print(fig, filename, '-dpng', '-r300');
+++disp(['Figure saved as ', filename]);
++\ No newline at end of file
++Index: MatlabCode/Out_Distribution/MBE3D_Torus_Comparison.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/Out_Distribution/MBE3D_Torus_Comparison.m b/MatlabCode/Out_Distribution/MBE3D_Torus_Comparison.m
++new file mode 100644
++--- /dev/null	(date 1754485542389)
+++++ b/MatlabCode/Out_Distribution/MBE3D_Torus_Comparison.m	(date 1754485542389)
++@@ -0,0 +1,337 @@
+++Sclc;
+++clear;
+++close all;
+++fclose('all');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 1: CHOOSE IC & SETUP PARAMETERS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++
+++% --- CHOOSE THE INITIAL CONDITION ---
+++% Options: 'sphere', 'dumbbell', 'star', torus
+++initial_condition_type = 'torus'; % <-- CHANGE THIS VALUE TO RUN A DIFFERENT COMPARISON
+++
+++fprintf('Setting up comparison for Initial Condition: %s\n', upper(initial_condition_type));
+++
+++% --- Declare variables that will be set in the switch block ---
+++python_data_file = '';
+++Nx=0; Ny=0; Nz=0; Lx=0; Ly=0; Lz=0;
+++epsilon = 0; Nt = 0; selected_frames = [];
+++u = []; % The initial condition for the DNS
+++
+++% --- Setup based on selected initial condition (MATCHING MBE3D PYTHON REFERENCE) ---
+++switch initial_condition_type
+++    case 'sphere'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/MBE3D_python_predictions_sphere.mat'; % Corrected path for MBE3D sphere
+++
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 2*pi; Ly = Lx; Lz = Lx; % From original MBE3D Matlab code for sphere
+++        epsilon = 0.5; % From original MBE3D Matlab code for sphere
+++        dt_dns = 0.0001; % dt for DNS simulation, from original MBE3D Matlab code for sphere
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++
+++        radius = 1.5; % From original MBE3D Matlab code for sphere
+++        interface_width = sqrt(2) * epsilon;
+++        u = tanh((radius - sqrt(xx.^2 + yy.^2 + zz.^2)) / interface_width);
+++
+++    case 'torus'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/MBE3D_python_predictions_torus.mat';
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 2*pi;  Ly = Lx;  Lz = Lx;
+++        epsilon = 0.1;
+++        dt_dns = 0.001;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++
+++        R = 2.1; % Major radius
+++        r = 0.7; % Minor radius
+++        interface_width = sqrt(2) * epsilon;
+++
+++        torus_dist = sqrt((sqrt(xx.^2 + yy.^2) - R).^2 + zz.^2);
+++        u = tanh((r - torus_dist) / interface_width);
+++        
+++    case 'dumbbell'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/MBE3D_python_predictions_dumbbell.mat'; % Corrected path for MBE3D dumbbell
+++
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 40; Ly = 20; Lz = 20; % From original MBE3D Matlab code for dumbbell
+++        epsilon = 0.05; % From original MBE3D Matlab code for dumbbell
+++        dt_dns = 0.01; % dt for DNS simulation, from original MBE3D Matlab code for dumbbell
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++
+++        x_grid = linspace(0, Lx, Nx);
+++        y_grid = linspace(0, Ly, Ny);
+++        z_grid = linspace(0, Lz, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++
+++        R0 = 0.25; % From original MBE3D Matlab code for dumbbell
+++        interface_width = sqrt(2) * epsilon;
+++        r1 = sqrt((xx - 0.3).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        r2 = sqrt((xx - 1.7).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        u_spheres = tanh((R0 - r1) / interface_width) + tanh((R0 - r2) / interface_width) + 1;
+++        bar_mask = (xx > 0.4 & xx < 1.6 & yy > 0.4 & yy < 0.6 & zz > 0.4 & zz < 0.6);
+++        u = u_spheres;
+++        u(bar_mask) = 1.0;
+++        u = max(-1.0, min(1.0, u));
+++
+++    case 'star'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/PFC3D_python_predictions_star.mat'; % CORRECTED PATH FOR MBE3D STAR
+++
+++        Nx = 32; Ny = 32; Nz = 32;
+++        %Lx = 2*pi; % From original MBE3D Matlab code for star
+++        Lx = 10*pi % PFC
+++        Ly = Lx; Lz = Lx; % From original MBE3D Matlab code for star
+++        epsilon = 0.5; % From original MBE3D Matlab code for star
+++        %dt_dns = 0.0005; % dt for DNS simulation, from original MBE3D Matlab code for star
+++        dt_dns = 0.005; % PFC
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++
+++        interface_width = sqrt(2.0) * epsilon;
+++        theta = atan2(zz, xx);
+++        %R_theta = 1.5 + 0.4 * cos(6 * theta);
+++        R_theta = 5.0 + 1.0 * cos(6 * theta);
+++        dist = sqrt(xx.^2 + 2*yy.^2 + zz.^2);
+++        u = tanh((R_theta - dist) / interface_width);
+++
+++    otherwise
+++        error("Unknown initial_condition_type. Choose 'sphere', 'dumbbell', or 'star'.");
+++end
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 2: LOAD PYTHON MODEL RESULTS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp(['Loading Python predictions from: ', python_data_file]);
+++try
+++    python_data = load(python_data_file);
+++    python_pred = squeeze(python_data.python_pred);
+++
+++    [py_Nx, py_Ny, py_Nz, ~] = size(python_pred);
+++    if py_Nx ~= Nx || py_Ny ~= Ny || py_Nz ~= Nz
+++        error('Dimension Mismatch! Loaded Python data is [%d x %d x %d] but MATLAB grid is [%d x %d x %d].', ...
+++              py_Nx, py_Ny, py_Nz, Nx, Ny, Nz);
+++    end
+++
+++    num_selected = length(selected_frames);
+++
+++    if isfield(python_data, 'inference_time')
+++        python_inference_time = python_data.inference_time;
+++    else
+++        python_inference_time = 0.045; % Default if not found in .mat file
+++    end
+++
+++catch ME
+++    error('Could not load Python prediction file: %s. Error: %s', python_data_file, ME.message);
+++end
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 3: RUN MATLAB (DNS) EXACT SOLUTION FOR MBE3D (MODIFIED)
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Starting MATLAB (DNS) simulation for MBE3D...');
+++tic;
+++
+++% --- Define Fourier multipliers (Unchanged) ---
+++kx_fft = 1i * 2 * pi / Lx * [0:Nx/2 -Nx/2+1:-1];
+++ky_fft = 1i * 2 * pi / Ly * [0:Ny/2 -Ny/2+1:-1];
+++kz_fft = 1i * 2 * pi / Lz * [0:Nz/2 -Nz/2+1:-1];
+++[kxx_fft, kyy_fft, kzz_fft] = ndgrid(kx_fft, ky_fft, kz_fft);
+++
+++k2x_fft = (2 * pi / Lx * [0:Nx/2 -Nx/2+1:-1]).^2;
+++k2y_fft = (2 * pi / Ly * [0:Ny/2 -Ny/2+1:-1]).^2;
+++k2z_fft = (2 * pi / Lz * [0:Nz/2 -Nz/2+1:-1]).^2;
+++[kxx2_fft, kyy2_fft, kzz2_fft] = ndgrid(k2x_fft, k2y_fft, k2z_fft);
+++
+++%%%%%%%%%%%%%%%%%%%%%%%% MODIFICATION START %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++% --- Define the ISOTROPIC Laplacian operator in Fourier space ---
+++% This is changed from anisotropic to isotropic to match Code 1.
+++Lap_f = (kxx2_fft + kyy2_fft + kzz2_fft);
+++%%%%%%%%%%%%%%%%%%%%%%%% MODIFICATION END %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++
+++% --- Initialize storage ---
+++all_iterations_dns = zeros(Nt + 1, Nx, Ny, Nz, 'single');
+++all_iterations_dns(1, :, :, :) = u;
+++
+++for iter = 1:Nt
+++    u = real(u);
+++    tu = fftn(u);
+++    
+++    % --- Calculate gradients (Unchanged) ---
+++    fx = real(ifftn(kxx_fft .* tu));
+++    fy = real(ifftn(kyy_fft .* tu));
+++    fz = real(ifftn(kzz_fft .* tu));
+++
+++    %%%%%%%%%%%%%%%%%%%%%%%% MODIFICATION START %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++    % --- Calculate the ISOTROPIC non-linear term ---
+++    % This is changed from anisotropic to isotropic to match Code 1.
+++    grad_sq = (fx.^2 + fy.^2 + fz.^2);
+++    f1 = grad_sq .* fx;
+++    f2 = grad_sq .* fy;
+++    f3 = grad_sq .* fz;
+++    %%%%%%%%%%%%%%%%%%%%%%%% MODIFICATION END %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++    
+++    % --- Divergence of the non-linear term (Unchanged) ---
+++    s_hat_nonlinear_part = (kxx_fft .* fftn(f1) + kyy_fft .* fftn(f2) + kzz_fft .* fftn(f3));
+++    
+++    % --- Full update equation ---
+++    s_hat = fftn(u / dt_dns) + s_hat_nonlinear_part;
+++    
+++    %%%%%%%%%%%%%%%%%%%%%%%% MODIFICATION START %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++    % Use the ISOTROPIC Laplacian for the linear part of the update
+++    v_hat = s_hat ./ (1 / dt_dns - Lap_f + epsilon * Lap_f.^2);
+++    %%%%%%%%%%%%%%%%%%%%%%%% MODIFICATION END %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++    
+++    u = ifftn(v_hat);
+++    all_iterations_dns(iter + 1, :, :, :) = u;
+++end
+++
+++matlab_simulation_time = toc;
+++disp(['MATLAB (DNS) simulation complete. Elapsed time: ', num2str(matlab_simulation_time), ' s']);
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 4: COMBINED VISUALIZATION (MODIFIED VERSION FROM CODE 1)
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Generating comparison plots...');
+++fig_width = 450 * num_selected;
+++fig_height = 900; 
+++fig = figure('Position', [100 100 fig_width fig_height]);
+++
+++% Note: Changed "CH3D" to "MBE3D" for consistency with this script
+++sgtitle(sprintf('MBE3D: MHNO Method (%s)\nPrediction Time: %.2f s  vs.  Ground Truth Time: %.2f s', ...
+++                upper(initial_condition_type), python_inference_time, matlab_simulation_time), ...
+++                'FontSize', 20, 'FontWeight', 'bold');
+++
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    frame_idx = frame_to_plot + 1;
+++    
+++    % Python prediction isosurfaces (Top Row)
+++    ax1 = subplot(3, num_selected, i); 
+++    u_python = python_pred(:,:,:,frame_idx);
+++    [f, v] = isosurface(xx, yy, zz, u_python, 0);
+++    if ~isempty(v)
+++        patch(ax1, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax1, 'gouraud'); light(ax1, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax1, 'dull'); colormap(ax1, jet); view(45, 30); axis(ax1, 'tight', 'equal');
+++        title(ax1, sprintf('Prediction\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax1, sprintf('Prediction\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax1, 'tight', 'equal');
+++    end
+++    set(ax1, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax1, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax1, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax1, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++
+++    % MATLAB DNS isosurfaces (Middle Row)
+++    ax2 = subplot(3, num_selected, num_selected + i);
+++    u_matlab = squeeze(all_iterations_dns(frame_idx,:,:,:));
+++    [f, v] = isosurface(xx, yy, zz, u_matlab, 0);
+++    if ~isempty(v)
+++        patch(ax2, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax2, 'gouraud'); light(ax2, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax2, 'dull'); colormap(ax2, jet); view(45, 30); axis(ax2, 'tight', 'equal');
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax2, 'tight', 'equal');
+++    end
+++    set(ax2, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax2, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax2, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax2, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++end
+++
+++% === NEW PROFESSIONAL 1D PROFILE PLOT WITH ORGANIZED LEGEND (MODIFIED SECTION) ===
+++
+++% Get the centerline indices
+++center_y_idx = round(Ny/2); 
+++center_z_idx = round(Nz/2);
+++
+++% Define position for the combined 1D plot
+++ax_profile_pos = [0.1, 0.08, 0.85, 0.22]; 
+++ax_profile = axes('Position', ax_profile_pos);
+++
+++hold(ax_profile, 'on');
+++grid(ax_profile, 'on');
+++box(ax_profile, 'on'); 
+++
+++% Define line styles and colors
+++line_styles = {'-', '--'}; % Solid for Ground Truth, Dashed for Prediction
+++line_width = 2.5;
+++colors = get(ax_profile, 'ColorOrder');
+++
+++% Loop through selected time steps to plot the ACTUAL data
+++% NOTE: We remove the 'DisplayName' from here, as the legend will be custom-built.
+++for i = 1:num_selected
+++    frame_idx = selected_frames(i) + 1;
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++
+++    % Plot Ground Truth (DNS) Profile
+++    profile_dns = squeeze(all_iterations_dns(frame_idx, :, center_y_idx, center_z_idx));
+++    plot(ax_profile, x_grid, profile_dns, ...
+++        'LineStyle', line_styles{1}, 'Color', current_color, 'LineWidth', line_width);
+++        
+++    % Plot Prediction (SANO) Profile
+++    profile_py = squeeze(python_pred(:, center_y_idx, center_z_idx, frame_idx));
+++    plot(ax_profile, x_grid, profile_py, ...
+++        'LineStyle', line_styles{2}, 'Color', current_color, 'LineWidth', line_width);
+++end
+++
+++% --- Create Proxy Artists for a Clean, Organized Legend ---
+++% We create invisible plots that have the desired properties for our legend entries.
+++h_proxy = gobjects(2 + num_selected, 1); % Pre-allocate graphics object array
+++
+++% Proxy for Line Styles
+++h_proxy(1) = plot(NaN, NaN, 'LineStyle', line_styles{1}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Ground Truth');
+++h_proxy(2) = plot(NaN, NaN, 'LineStyle', line_styles{2}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Prediction');
+++
+++% Proxies for Time (Colors)
+++for i = 1:num_selected
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++    h_proxy(2+i) = plot(NaN, NaN, 'LineStyle', '-', 'Color', current_color, 'LineWidth', line_width, 'DisplayName', sprintf('t = %d', selected_frames(i)));
+++end
+++
+++hold(ax_profile, 'off');
+++
+++% --- Professional Formatting for the 1D Plot ---
+++title(ax_profile, '1D Centerline Profile Comparison', 'FontSize', 18, 'FontWeight', 'bold');
+++xlabel(ax_profile, 'Position along x-axis', 'FontSize', 16, 'FontWeight', 'bold');
+++ylabel(ax_profile, 'Field Value u', 'FontSize', 16, 'FontWeight', 'bold');
+++ylim(ax_profile, [-1.2, 1.1]);
+++xlim(ax_profile, [x_grid(1), x_grid(end)]);
+++set(ax_profile, 'FontSize', 16, 'FontWeight', 'bold', 'LineWidth', 1.5);
+++
+++% Generate the legend using ONLY the proxy artists
+++lgd = legend(h_proxy, 'Location', 'northeast', 'NumColumns', 1); % Single column is cleaner
+++set(lgd, 'FontSize', 14, 'FontWeight', 'bold', 'Box', 'on');
+++
+++disp('Comparison visualization complete.');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 5: SAVE THE FIGURE
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Saving the figure...');
+++filename = ['PFC3D_Comparison_' initial_condition_type '.png']; % Updated filename
+++print(fig, filename, '-dpng', '-r300');
+++disp(['Figure saved as ', filename]);
++\ No newline at end of file
++Index: .idea/workspace.xml
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"TNO3d vs FNO3d\">\n      <change afterPath=\"$PROJECT_DIR$/run_inference.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/vcs.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/vcs.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/main.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/main.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/networks.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/networks.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/post_processing.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/post_processing.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/training.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/training.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/utilities.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/utilities.py\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <excluded-from-favorite>\n      <branch-storage>\n        <map>\n          <entry type=\"LOCAL\">\n            <value>\n              <list>\n                <branch-info repo=\"$PROJECT_DIR$\" source=\"master\" />\n              </list>\n            </value>\n          </entry>\n        </map>\n      </branch-storage>\n    </excluded-from-favorite>\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\n      <map>\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\n      </map>\n    </option>\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n    <option name=\"ROOT_SYNC\" value=\"DONT_SYNC\" />\n  </component>\n  <component name=\"GitHubPullRequestSearchHistory\">{\n  &quot;lastFilter&quot;: {\n    &quot;state&quot;: &quot;OPEN&quot;,\n    &quot;assignee&quot;: &quot;MBamdad&quot;\n  }\n}</component>\n  <component name=\"GithubPullRequestsUISettings\">{\n  &quot;selectedUrlAndAccountId&quot;: {\n    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,\n    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;\n  }\n}</component>\n  <component name=\"ProjectColorInfo\">{\n  &quot;associatedIndex&quot;: 1\n}</component>\n  <component name=\"ProjectId\" id=\"2p11NySvsgjZ8eu9d53SI84567l\" />\n  <component name=\"ProjectReloadState\">\n    <option name=\"STATE\" value=\"1\" />\n  </component>\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">{\n  &quot;keyToString&quot;: {\n    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.main.executor&quot;: &quot;Run&quot;,\n    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.networks.executor&quot;: &quot;Run&quot;,\n    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,\n    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,\n    &quot;Python.test1.executor&quot;: &quot;Run&quot;,\n    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,\n    &quot;git-widget-placeholder&quot;: &quot;main&quot;,\n    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,\n    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,\n    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,\n    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,\n    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,\n    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,\n    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,\n    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;\n  },\n  &quot;keyToStringList&quot;: {\n    &quot;ChangesTree.GroupingKeys&quot;: [\n      &quot;directory&quot;\n    ]\n  }\n}</component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$/configs\" />\n      <recent name=\"$PROJECT_DIR$/AC2Dtest/models\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code/AC2D\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code\" />\n    </key>\n    <key name=\"MoveFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.AC3D_TNO3d\">\n    <configuration name=\"AC3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_TNO3d_hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"MBE3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d_Hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <list>\n      <item itemvalue=\"Python.AC3D_TNO3d\" />\n      <item itemvalue=\"Python.AC3d_FNO3d\" />\n      <item itemvalue=\"Python.AC3d_TNO3d_hybrid\" />\n      <item itemvalue=\"Python.CH3D_TNO3d\" />\n      <item itemvalue=\"Python.MBE3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_FNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d_Hybrid\" />\n    </list>\n  </component>\n  <component name=\"SharedIndexes\">\n    <attachedChunks>\n      <set>\n        <option value=\"bundled-js-predefined-1d06a55b98c1-0b3e54e931b4-JavaScript-PY-241.18034.82\" />\n        <option value=\"bundled-python-sdk-975db3bf15a3-2767605e8bc2-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-241.18034.82\" />\n      </set>\n    </attachedChunks>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"\" />\n      <created>1731918731711</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1731918731711</updated>\n      <workItem from=\"1731918732726\" duration=\"17070000\" />\n      <workItem from=\"1732010735784\" duration=\"777000\" />\n      <workItem from=\"1732011520582\" duration=\"8000\" />\n      <workItem from=\"1732011538945\" duration=\"13153000\" />\n      <workItem from=\"1732106481018\" duration=\"3721000\" />\n      <workItem from=\"1732480846034\" duration=\"2889000\" />\n      <workItem from=\"1732483872465\" duration=\"14926000\" />\n      <workItem from=\"1732567216112\" duration=\"964000\" />\n      <workItem from=\"1732765090621\" duration=\"5000\" />\n      <workItem from=\"1732765102609\" duration=\"12000\" />\n      <workItem from=\"1732765345288\" duration=\"10000\" />\n      <workItem from=\"1732903897716\" duration=\"3074000\" />\n      <workItem from=\"1732911303920\" duration=\"27201000\" />\n      <workItem from=\"1732999179592\" duration=\"8241000\" />\n      <workItem from=\"1733039613684\" duration=\"6792000\" />\n      <workItem from=\"1733095843263\" duration=\"10000\" />\n      <workItem from=\"1733140600841\" duration=\"6993000\" />\n      <workItem from=\"1733150993229\" duration=\"184000\" />\n      <workItem from=\"1733151279786\" duration=\"6000\" />\n      <workItem from=\"1733151296310\" duration=\"16875000\" />\n      <workItem from=\"1733233230739\" duration=\"5172000\" />\n      <workItem from=\"1733246997923\" duration=\"15986000\" />\n      <workItem from=\"1733349590652\" duration=\"1949000\" />\n      <workItem from=\"1733352121741\" duration=\"6332000\" />\n      <workItem from=\"1733405466233\" duration=\"12731000\" />\n      <workItem from=\"1733557048829\" duration=\"5541000\" />\n      <workItem from=\"1733583489891\" duration=\"16419000\" />\n      <workItem from=\"1733859258781\" duration=\"7356000\" />\n      <workItem from=\"1733995059967\" duration=\"7899000\" />\n      <workItem from=\"1734011167665\" duration=\"991000\" />\n      <workItem from=\"1734029966470\" duration=\"25769000\" />\n      <workItem from=\"1734205412700\" duration=\"7689000\" />\n      <workItem from=\"1734644992163\" duration=\"5017000\" />\n      <workItem from=\"1734788130789\" duration=\"2312000\" />\n      <workItem from=\"1734863751114\" duration=\"9000\" />\n      <workItem from=\"1734863775073\" duration=\"9221000\" />\n      <workItem from=\"1734880034791\" duration=\"57000\" />\n      <workItem from=\"1734880213539\" duration=\"15000\" />\n      <workItem from=\"1734880329890\" duration=\"30000\" />\n      <workItem from=\"1734880369064\" duration=\"31312000\" />\n      <workItem from=\"1734983129135\" duration=\"55000\" />\n      <workItem from=\"1735034212628\" duration=\"2274000\" />\n      <workItem from=\"1735049036048\" duration=\"5309000\" />\n      <workItem from=\"1735126261413\" duration=\"75000\" />\n      <workItem from=\"1735356723104\" duration=\"1208000\" />\n      <workItem from=\"1735422837186\" duration=\"1387000\" />\n      <workItem from=\"1735719009558\" duration=\"561000\" />\n      <workItem from=\"1736101930735\" duration=\"570000\" />\n      <workItem from=\"1736102511675\" duration=\"4000\" />\n      <workItem from=\"1736161159525\" duration=\"7670000\" />\n      <workItem from=\"1736237907904\" duration=\"111000\" />\n      <workItem from=\"1736519480236\" duration=\"1867000\" />\n      <workItem from=\"1737577034938\" duration=\"3945000\" />\n      <workItem from=\"1737590448155\" duration=\"6145000\" />\n      <workItem from=\"1738310597042\" duration=\"2502000\" />\n      <workItem from=\"1738316162773\" duration=\"726000\" />\n      <workItem from=\"1738326887364\" duration=\"4500000\" />\n      <workItem from=\"1738586797583\" duration=\"600000\" />\n      <workItem from=\"1738663690532\" duration=\"4505000\" />\n      <workItem from=\"1738668267214\" duration=\"5368000\" />\n      <workItem from=\"1738685509837\" duration=\"74000\" />\n      <workItem from=\"1738703726377\" duration=\"1677000\" />\n      <workItem from=\"1738774383038\" duration=\"2249000\" />\n      <workItem from=\"1738787637783\" duration=\"7013000\" />\n      <workItem from=\"1738962434877\" duration=\"1153000\" />\n      <workItem from=\"1738967049524\" duration=\"782000\" />\n      <workItem from=\"1739275350614\" duration=\"312000\" />\n      <workItem from=\"1739464522072\" duration=\"12498000\" />\n      <workItem from=\"1739572784568\" duration=\"1228000\" />\n      <workItem from=\"1739626528163\" duration=\"5778000\" />\n      <workItem from=\"1739689815626\" duration=\"10399000\" />\n      <workItem from=\"1739812786805\" duration=\"48519000\" />\n      <workItem from=\"1740212626723\" duration=\"1263000\" />\n      <workItem from=\"1740213932190\" duration=\"644000\" />\n      <workItem from=\"1741475492994\" duration=\"40894000\" />\n      <workItem from=\"1741690305204\" duration=\"339000\" />\n      <workItem from=\"1741705983516\" duration=\"604000\" />\n      <workItem from=\"1741713165753\" duration=\"1198000\" />\n      <workItem from=\"1741861318912\" duration=\"2286000\" />\n      <workItem from=\"1742201562752\" duration=\"618000\" />\n      <workItem from=\"1742209067924\" duration=\"383000\" />\n      <workItem from=\"1742226300133\" duration=\"2432000\" />\n      <workItem from=\"1743071528350\" duration=\"9513000\" />\n      <workItem from=\"1743490058046\" duration=\"9000\" />\n      <workItem from=\"1743587112942\" duration=\"1188000\" />\n      <workItem from=\"1748900986740\" duration=\"1771000\" />\n      <workItem from=\"1748931928220\" duration=\"446000\" />\n      <workItem from=\"1748932436127\" duration=\"20890000\" />\n      <workItem from=\"1748970706276\" duration=\"3719000\" />\n      <workItem from=\"1748988822181\" duration=\"59000\" />\n      <workItem from=\"1749200290051\" duration=\"680000\" />\n      <workItem from=\"1749203502833\" duration=\"1349000\" />\n      <workItem from=\"1749213099437\" duration=\"3082000\" />\n      <workItem from=\"1750057109660\" duration=\"10453000\" />\n      <workItem from=\"1750070416210\" duration=\"46415000\" />\n    </task>\n    <task id=\"LOCAL-00001\" summary=\"Initial Commit\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732484343908</created>\n      <option name=\"number\" value=\"00001\" />\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732484343908</updated>\n    </task>\n    <task id=\"LOCAL-00002\" summary=\"added TransformerFNO\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732497990642</created>\n      <option name=\"number\" value=\"00002\" />\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732497990642</updated>\n    </task>\n    <task id=\"LOCAL-00003\" summary=\"added the connection between time steps - the model development is finished\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732910153380</created>\n      <option name=\"number\" value=\"00003\" />\n      <option name=\"presentableId\" value=\"LOCAL-00003\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732910153380</updated>\n    </task>\n    <task id=\"LOCAL-00004\" summary=\"Finished Allen-Cahn Problem\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733176021525</created>\n      <option name=\"number\" value=\"00004\" />\n      <option name=\"presentableId\" value=\"LOCAL-00004\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733176021525</updated>\n    </task>\n    <task id=\"LOCAL-00005\" summary=\"Added Allen-Cahn 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733583274023</created>\n      <option name=\"number\" value=\"00005\" />\n      <option name=\"presentableId\" value=\"LOCAL-00005\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733583274023</updated>\n    </task>\n    <task id=\"LOCAL-00006\" summary=\"added save_vtk\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733995237535</created>\n      <option name=\"number\" value=\"00006\" />\n      <option name=\"presentableId\" value=\"LOCAL-00006\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733995237535</updated>\n    </task>\n    <task id=\"LOCAL-00007\" summary=\"added MATLAB codes for creating database\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1734788540933</created>\n      <option name=\"number\" value=\"00007\" />\n      <option name=\"presentableId\" value=\"LOCAL-00007\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1734788540933</updated>\n    </task>\n    <task id=\"LOCAL-00008\" summary=\"added CH2DNL\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735126332032</created>\n      <option name=\"number\" value=\"00008\" />\n      <option name=\"presentableId\" value=\"LOCAL-00008\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735126332032</updated>\n    </task>\n    <task id=\"LOCAL-00009\" summary=\"added SH2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735719422931</created>\n      <option name=\"number\" value=\"00009\" />\n      <option name=\"presentableId\" value=\"LOCAL-00009\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735719422931</updated>\n    </task>\n    <task id=\"LOCAL-00010\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1736237977029</created>\n      <option name=\"number\" value=\"00010\" />\n      <option name=\"presentableId\" value=\"LOCAL-00010\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1736237977029</updated>\n    </task>\n    <task id=\"LOCAL-00011\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738788849261</created>\n      <option name=\"number\" value=\"00011\" />\n      <option name=\"presentableId\" value=\"LOCAL-00011\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738788849261</updated>\n    </task>\n    <task id=\"LOCAL-00012\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738789326593</created>\n      <option name=\"number\" value=\"00012\" />\n      <option name=\"presentableId\" value=\"LOCAL-00012\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738789326593</updated>\n    </task>\n    <task id=\"LOCAL-00013\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738796104012</created>\n      <option name=\"number\" value=\"00013\" />\n      <option name=\"presentableId\" value=\"LOCAL-00013\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738796104012</updated>\n    </task>\n    <task id=\"LOCAL-00014\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962464719</created>\n      <option name=\"number\" value=\"00014\" />\n      <option name=\"presentableId\" value=\"LOCAL-00014\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962464719</updated>\n    </task>\n    <task id=\"LOCAL-00015\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962748829</created>\n      <option name=\"number\" value=\"00015\" />\n      <option name=\"presentableId\" value=\"LOCAL-00015\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962748829</updated>\n    </task>\n    <task id=\"LOCAL-00016\" summary=\"Turn Nx to 64\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738967163754</created>\n      <option name=\"number\" value=\"00016\" />\n      <option name=\"presentableId\" value=\"LOCAL-00016\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738967163754</updated>\n    </task>\n    <task id=\"LOCAL-00017\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275401458</created>\n      <option name=\"number\" value=\"00017\" />\n      <option name=\"presentableId\" value=\"LOCAL-00017\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275401458</updated>\n    </task>\n    <task id=\"LOCAL-00018\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275433418</created>\n      <option name=\"number\" value=\"00018\" />\n      <option name=\"presentableId\" value=\"LOCAL-00018\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275433418</updated>\n    </task>\n    <task id=\"LOCAL-00019\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690373369</created>\n      <option name=\"number\" value=\"00019\" />\n      <option name=\"presentableId\" value=\"LOCAL-00019\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690373369</updated>\n    </task>\n    <task id=\"LOCAL-00020\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690420059</created>\n      <option name=\"number\" value=\"00020\" />\n      <option name=\"presentableId\" value=\"LOCAL-00020\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690420059</updated>\n    </task>\n    <task id=\"LOCAL-00021\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1743587271259</created>\n      <option name=\"number\" value=\"00021\" />\n      <option name=\"presentableId\" value=\"LOCAL-00021\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1743587271259</updated>\n    </task>\n    <option name=\"localTasksCounter\" value=\"22\" />\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"Vcs.Log.Tabs.Properties\">\n    <option name=\"RECENT_FILTERS\">\n      <map>\n        <entry key=\"Branch\">\n          <value>\n            <list>\n              <RecentGroup>\n                <option name=\"FILTER_VALUES\">\n                  <option value=\"main\" />\n                </option>\n              </RecentGroup>\n            </list>\n          </value>\n        </entry>\n      </map>\n    </option>\n    <option name=\"TAB_STATES\">\n      <map>\n        <entry key=\"MAIN\">\n          <value>\n            <State>\n              <option name=\"FILTERS\">\n                <map>\n                  <entry key=\"branch\">\n                    <value>\n                      <list>\n                        <option value=\"main\" />\n                      </list>\n                    </value>\n                  </entry>\n                </map>\n              </option>\n            </State>\n          </value>\n        </entry>\n      </map>\n    </option>\n  </component>\n  <component name=\"VcsManagerConfiguration\">\n    <MESSAGE value=\"Initial Commit\" />\n    <MESSAGE value=\"added TransformerFNO\" />\n    <MESSAGE value=\"added the connection between time steps - the model development is finished\" />\n    <MESSAGE value=\"refactored\" />\n    <MESSAGE value=\"Finished Allen-Cahn Problem\" />\n    <MESSAGE value=\"Added Allen-Cahn 3D\" />\n    <MESSAGE value=\"added save_vtk\" />\n    <MESSAGE value=\"added MATLAB codes for creating database\" />\n    <MESSAGE value=\"seperated the number of layers in fourier part and convolutional part\" />\n    <MESSAGE value=\"added CH2DNL\" />\n    <MESSAGE value=\"added SH2D\" />\n    <MESSAGE value=\"added PFC2D\" />\n    <MESSAGE value=\"Turn Nx to 64\" />\n    <MESSAGE value=\"update to 3D\" />\n    <MESSAGE value=\"TNO3d vs FNO3d\" />\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"TNO3d vs FNO3d\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>142</line>\n          <option name=\"timeStamp\" value=\"17\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>163</line>\n          <option name=\"timeStamp\" value=\"18\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>134</line>\n          <option name=\"timeStamp\" value=\"19\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>327</line>\n          <option name=\"timeStamp\" value=\"20\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>243</line>\n          <option name=\"timeStamp\" value=\"21\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_2.py</url>\n          <line>333</line>\n          <option name=\"timeStamp\" value=\"27\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>\n          <line>371</line>\n          <option name=\"timeStamp\" value=\"44\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>\n          <line>338</line>\n          <option name=\"timeStamp\" value=\"54\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>53</line>\n          <option name=\"timeStamp\" value=\"128\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>30</line>\n          <option name=\"timeStamp\" value=\"129\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>25</line>\n          <option name=\"timeStamp\" value=\"133\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>18</line>\n          <option name=\"timeStamp\" value=\"135\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>\n          <line>44</line>\n          <option name=\"timeStamp\" value=\"138\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test2.py</url>\n          <line>16</line>\n          <option name=\"timeStamp\" value=\"144\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/utilities.py</url>\n          <line>98</line>\n          <option name=\"timeStamp\" value=\"170\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/main.py</url>\n          <line>157</line>\n          <option name=\"timeStamp\" value=\"177\" />\n        </line-breakpoint>\n      </breakpoints>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n  </component>\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test3.coverage\" NAME=\"Test3 Coverage Results\" MODIFIED=\"1739273938386\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage\" NAME=\"config_AC2D_FNO3d Coverage Results\" MODIFIED=\"1733233385695\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1743065376798\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_2.coverage\" NAME=\"AC2D_Net2D_2 Coverage Results\" MODIFIED=\"1732904114403\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$test2.coverage\" NAME=\"test2 Coverage Results\" MODIFIED=\"1742889074336\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1741561715014\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage\" NAME=\"config_SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254757455\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$backend_interagg.coverage\" NAME=\"backend_interagg Coverage Results\" MODIFIED=\"1737630366471\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript3.coverage\" NAME=\"RunScript3 Coverage Results\" MODIFIED=\"1736368081257\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_2.coverage\" NAME=\"AC2D_2 Coverage Results\" MODIFIED=\"1732483323689\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1733086051390\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main_TF.coverage\" NAME=\"main_TF Coverage Results\" MODIFIED=\"1738704014479\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1741538869064\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$THFNO.coverage\" NAME=\"THFNO Coverage Results\" MODIFIED=\"1732911474644\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/networks\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1740088478224\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$PFC3D.coverage\" NAME=\"PFC3D Coverage Results\" MODIFIED=\"1740083613128\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1741603428589\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$run_inference.coverage\" NAME=\"run_inference Coverage Results\" MODIFIED=\"1750323709039\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1738663765959\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$post_processing.coverage\" NAME=\"post_processing Coverage Results\" MODIFIED=\"1733557098801\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage\" NAME=\"config_CH2D_TNO2d Coverage Results\" MODIFIED=\"1734086207850\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1748933697533\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1750255151255\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript2.coverage\" NAME=\"RunScript2 Coverage Results\" MODIFIED=\"1736369209710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1742215946758\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_3.coverage\" NAME=\"AC2D_Net2D_3 Coverage Results\" MODIFIED=\"1732974697103\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_FNO3d.coverage\" NAME=\"AC3d_FNO3d Coverage Results\" MODIFIED=\"1749017845623\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D.coverage\" NAME=\"AC2D Coverage Results\" MODIFIED=\"1733088640665\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/Archive_Code\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D.coverage\" NAME=\"AC2D_Net2D Coverage Results\" MODIFIED=\"1732567473230\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1740054182408\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage\" NAME=\"MBE3D_TNO3d Coverage Results\" MODIFIED=\"1741562061391\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_AC3D_TNO3d.coverage\" NAME=\"config_AC3D_TNO3d Coverage Results\" MODIFIED=\"1737644605063\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D.coverage\" NAME=\"MBE3D Coverage Results\" MODIFIED=\"1739283566145\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1741605347375\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1743071672425\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1736268192289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage\" NAME=\"PFC3D_TNO3d Coverage Results\" MODIFIED=\"1741564210973\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage\" NAME=\"config_CH2DNL_TNO2d Coverage Results\" MODIFIED=\"1735052490996\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$MBE2D.coverage\" NAME=\"MBE2D Coverage Results\" MODIFIED=\"1732278526731\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1739914172084\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test_Run.coverage\" NAME=\"Test_Run Coverage Results\" MODIFIED=\"1738945320139\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1741561294310\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741861381348\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1743081225414\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage\" NAME=\"PFV3D_FNO3d Coverage Results\" MODIFIED=\"1741564487710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript1.coverage\" NAME=\"RunScript1 Coverage Results\" MODIFIED=\"1736368790622\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$SH2D.coverage\" NAME=\"SH2D Coverage Results\" MODIFIED=\"1732347080402\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$PFC2D.coverage\" NAME=\"PFC2D Coverage Results\" MODIFIED=\"1732278679485\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$CH2D.coverage\" NAME=\"CH2D Coverage Results\" MODIFIED=\"1732347055915\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_FNO3d.coverage\" NAME=\"AC3D_FNO3d Coverage Results\" MODIFIED=\"1741561435127\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D.coverage\" NAME=\"SH3D Coverage Results\" MODIFIED=\"1739044808411\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test.coverage\" NAME=\"Test Coverage Results\" MODIFIED=\"1739459206236\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741547133078\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage\" NAME=\"config_AC2D_FNO2d Coverage Results\" MODIFIED=\"1733393903488\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$AC3D.coverage\" NAME=\"AC3D Coverage Results\" MODIFIED=\"1740041515520\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_CH3D_TNO3d.coverage\" NAME=\"config_CH3D_TNO3d Coverage Results\" MODIFIED=\"1738089807566\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test2.coverage\" NAME=\"Test2 Coverage Results\" MODIFIED=\"1739283715182\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_FNO3d.coverage\" NAME=\"CH3D_FNO3d Coverage Results\" MODIFIED=\"1741628529142\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage\" NAME=\"AC3d_TNO3d_hybrid Coverage Results\" MODIFIED=\"1748989478372\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1737899062785\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D.coverage\" NAME=\"config_AC2D Coverage Results\" MODIFIED=\"1733087276180\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_1.coverage\" NAME=\"AC2D_Net2D_1 Coverage Results\" MODIFIED=\"1732535211383\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1736520700819\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$fourier_3d.coverage\" NAME=\"fourier_3d Coverage Results\" MODIFIED=\"1732221600628\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1750254767095\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage\" NAME=\"SH3D_TNO3d_Hybrid Coverage Results\" MODIFIED=\"1749216389646\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1748990262244\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$test1.coverage\" NAME=\"test1 Coverage Results\" MODIFIED=\"1733413325318\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_2.coverage\" NAME=\"CH3D_2 Coverage Results\" MODIFIED=\"1739918355289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254975290\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage\" NAME=\"config_MBE2D_TNO2d Coverage Results\" MODIFIED=\"1736261397712\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n  </component>\n</project>
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/.idea/workspace.xml b/.idea/workspace.xml
++--- a/.idea/workspace.xml	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/.idea/workspace.xml	(date 1754547647978)
++@@ -4,29 +4,80 @@
++     <option name="autoReloadType" value="SELECTIVE" />
++   </component>
++   <component name="ChangeListManager">
++-    <list default="true" id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="TNO3d vs FNO3d">
++-      <change afterPath="$PROJECT_DIR$/run_inference.py" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/.idea/vcs.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />
+++    <list default="true" id="4e84c369-97f3-4301-a9fc-5fc5327e1a8a" name="Changes" comment="3d_phase_evolution">
+++      <change afterPath="$PROJECT_DIR$/MBE3D/plots_Data_Physics_TNO3d/MBE3D_Hybrid.jpg" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/MatlabCode/In_Distribution/3D_phase_evolution4GRF.m" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/MatlabCode/Out_Distribution/AC3D_Spherical_Comparison.m" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/MatlabCode/Out_Distribution/CH3D_Star_Comparison.m" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/MatlabCode/Out_Distribution/MBE3D_Torus_Comparison.m" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/MatlabCode/Out_Distribution/PFC3D_Star_Comparison.m" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/MatlabCode/Out_Distribution/SH3D_Spherical_Comparison.m" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/PFC3D.iml" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_CH3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_MBE3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_PFC3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO4d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_FNO3d/combined_results.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/AC3D.m" beforeDir="false" afterPath="$PROJECT_DIR$/MatlabCode/AC3D.m" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D.m" beforeDir="false" afterPath="$PROJECT_DIR$/MatlabCode/CH3D.m" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_random_new.asv" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_random_new.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_test.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/GRF.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/GRF3D.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/GRFtest.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/MBE2D.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/MBE2D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/MBE3D_rand.asv" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/MBE3D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/PFC2D.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/PFC2D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/PFC3D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH2D.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH2D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH3D.m" beforeDir="false" afterPath="$PROJECT_DIR$/MatlabCode/SH3D.m" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH3D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/middle.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_loss_curve_mixed.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison_FINAL.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_loss_curve.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/combined_results.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison_mixed.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_loss_curve_mixed.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/combined_results.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/SH3D_Comparison_Plot_Modified_PIMHNO.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" beforeDir="false" afterPath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" beforeDir="false" afterPath="$PROJECT_DIR$/SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/CH3D_Comparison_star_SANO.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_Comparison_Plot_Modified.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_SANO_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_CH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_CH3D_FNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_CH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_CH3D_TNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_MBE3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_MBE3D_FNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_MBE3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_MBE3D_TNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_PFC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_PFC3D_FNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/main.py" beforeDir="false" afterPath="$PROJECT_DIR$/main.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/main1.py" beforeDir="false" afterPath="$PROJECT_DIR$/main1.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/networks.py" beforeDir="false" afterPath="$PROJECT_DIR$/networks.py" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/post_processing.py" beforeDir="false" afterPath="$PROJECT_DIR$/post_processing.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/run_interface3.py" beforeDir="false" afterPath="$PROJECT_DIR$/run_interface3.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/training.py" beforeDir="false" afterPath="$PROJECT_DIR$/training.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/utilities.py" beforeDir="false" afterPath="$PROJECT_DIR$/utilities.py" afterDir="false" />
++     </list>
++@@ -43,163 +94,49 @@
++     </option>
++   </component>
++   <component name="Git.Settings">
++-    <excluded-from-favorite>
++-      <branch-storage>
++-        <map>
++-          <entry type="LOCAL">
++-            <value>
++-              <list>
++-                <branch-info repo="$PROJECT_DIR$" source="master" />
++-              </list>
++-            </value>
++-          </entry>
++-        </map>
++-      </branch-storage>
++-    </excluded-from-favorite>
++-    <option name="RECENT_BRANCH_BY_REPOSITORY">
++-      <map>
++-        <entry key="$PROJECT_DIR$" value="main" />
++-      </map>
++-    </option>
++     <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
++-    <option name="ROOT_SYNC" value="DONT_SYNC" />
++   </component>
++-  <component name="GitHubPullRequestSearchHistory">{
++-  &quot;lastFilter&quot;: {
++-    &quot;state&quot;: &quot;OPEN&quot;,
++-    &quot;assignee&quot;: &quot;MBamdad&quot;
++-  }
++-}</component>
++-  <component name="GithubPullRequestsUISettings">{
++-  &quot;selectedUrlAndAccountId&quot;: {
++-    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,
++-    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;
++-  }
++-}</component>
++   <component name="ProjectColorInfo">{
+++  &quot;customColor&quot;: &quot;&quot;,
++   &quot;associatedIndex&quot;: 1
++ }</component>
++-  <component name="ProjectId" id="2p11NySvsgjZ8eu9d53SI84567l" />
++-  <component name="ProjectReloadState">
++-    <option name="STATE" value="1" />
++-  </component>
+++  <component name="ProjectId" id="30Ji1A2o7U8uDkwC8cwxQfRFc4k" />
++   <component name="ProjectViewState">
++     <option name="hideEmptyMiddlePackages" value="true" />
++     <option name="showLibraryContents" value="true" />
++   </component>
++   <component name="PropertiesComponent">{
++   &quot;keyToString&quot;: {
++-    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.Test.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.CH3D_FNO4d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.PFC3D_FNO4d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.SH3D_FNO4d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.SH3D_Hybrid.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.SH3D_TNO3D.executor&quot;: &quot;Run&quot;,
++     &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,
++     &quot;Python.main.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.networks.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.test1.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.main1.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.run_interface3.executor&quot;: &quot;Run&quot;,
++     &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
++     &quot;git-widget-placeholder&quot;: &quot;main&quot;,
++-    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,
+++    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_TNO3d&quot;,
++     &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
++-    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,
++     &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
++     &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,
++     &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,
++-    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,
++     &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;
++-  },
++-  &quot;keyToStringList&quot;: {
++-    &quot;ChangesTree.GroupingKeys&quot;: [
++-      &quot;directory&quot;
++-    ]
++   }
++ }</component>
++   <component name="RecentsManager">
++     <key name="CopyFile.RECENT_KEYS">
++-      <recent name="$PROJECT_DIR$/data" />
++-      <recent name="$PROJECT_DIR$/configs" />
++-      <recent name="$PROJECT_DIR$/AC2Dtest/models" />
++-      <recent name="$PROJECT_DIR$/Archive_Code/AC2D" />
++-      <recent name="$PROJECT_DIR$/Archive_Code" />
++-    </key>
++-    <key name="MoveFile.RECENT_KEYS">
++-      <recent name="$PROJECT_DIR$/data" />
+++      <recent name="$PROJECT_DIR$/SH3D/plots_TNO3d" />
+++      <recent name="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d" />
++       <recent name="$PROJECT_DIR$" />
+++      <recent name="$PROJECT_DIR$/SH3D/plots_FNO4d" />
+++      <recent name="$PROJECT_DIR$/MatlabCode" />
++     </key>
++   </component>
++-  <component name="RunManager" selected="Python.AC3D_TNO3d">
++-    <configuration name="AC3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="AC3d_FNO3d" type="PythonConfigurationType" factoryName="Python">
+++  <component name="RunManager" selected="Python.CH3D_FNO4d">
+++    <configuration name="CH3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
++       <module name="PhaseFieldNet" />
++       <option name="ENV_FILES" value="" />
++       <option name="INTERPRETER_OPTIONS" value="" />
++@@ -223,7 +160,7 @@
++       <option name="INPUT_FILE" value="" />
++       <method v="2" />
++     </configuration>
++-    <configuration name="AC3d_TNO3d_hybrid" type="PythonConfigurationType" factoryName="Python">
+++    <configuration name="PFC3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
++       <module name="PhaseFieldNet" />
++       <option name="ENV_FILES" value="" />
++       <option name="INTERPRETER_OPTIONS" value="" />
++@@ -247,31 +184,7 @@
++       <option name="INPUT_FILE" value="" />
++       <method v="2" />
++     </configuration>
++-    <configuration name="CH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="CH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
+++    <configuration name="SH3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
++       <module name="PhaseFieldNet" />
++       <option name="ENV_FILES" value="" />
++       <option name="INTERPRETER_OPTIONS" value="" />
++@@ -280,103 +193,7 @@
++         <env name="PYTHONUNBUFFERED" value="1" />
++       </envs>
++       <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="MBE3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="SH3D_FNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="SH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="SH3D_TNO3d_Hybrid" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
+++      <option name="SDK_NAME" value="torch_env" />
++       <option name="WORKING_DIRECTORY" value="" />
++       <option name="IS_MODULE_SDK" value="false" />
++       <option name="ADD_CONTENT_ROOTS" value="true" />
++@@ -392,14 +209,9 @@
++       <method v="2" />
++     </configuration>
++     <list>
++-      <item itemvalue="Python.AC3D_TNO3d" />
++-      <item itemvalue="Python.AC3d_FNO3d" />
++-      <item itemvalue="Python.AC3d_TNO3d_hybrid" />
++-      <item itemvalue="Python.CH3D_TNO3d" />
++-      <item itemvalue="Python.MBE3D_TNO3d" />
++-      <item itemvalue="Python.SH3D_FNO3d" />
++-      <item itemvalue="Python.SH3D_TNO3d" />
++-      <item itemvalue="Python.SH3D_TNO3d_Hybrid" />
+++      <item itemvalue="Python.CH3D_FNO4d" />
+++      <item itemvalue="Python.PFC3D_FNO4d" />
+++      <item itemvalue="Python.SH3D_FNO4d" />
++     </list>
++   </component>
++   <component name="SharedIndexes">
++@@ -413,501 +225,354 @@
++   <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
++   <component name="TaskManager">
++     <task active="true" id="Default" summary="Default task">
++-      <changelist id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="" />
++-      <created>1731918731711</created>
+++      <changelist id="4e84c369-97f3-4301-a9fc-5fc5327e1a8a" name="Changes" comment="3d_phase_evolution" />
+++      <created>1753351859462</created>
++       <option name="number" value="Default" />
++       <option name="presentableId" value="Default" />
++-      <updated>1731918731711</updated>
++-      <workItem from="1731918732726" duration="17070000" />
++-      <workItem from="1732010735784" duration="777000" />
++-      <workItem from="1732011520582" duration="8000" />
++-      <workItem from="1732011538945" duration="13153000" />
++-      <workItem from="1732106481018" duration="3721000" />
++-      <workItem from="1732480846034" duration="2889000" />
++-      <workItem from="1732483872465" duration="14926000" />
++-      <workItem from="1732567216112" duration="964000" />
++-      <workItem from="1732765090621" duration="5000" />
++-      <workItem from="1732765102609" duration="12000" />
++-      <workItem from="1732765345288" duration="10000" />
++-      <workItem from="1732903897716" duration="3074000" />
++-      <workItem from="1732911303920" duration="27201000" />
++-      <workItem from="1732999179592" duration="8241000" />
++-      <workItem from="1733039613684" duration="6792000" />
++-      <workItem from="1733095843263" duration="10000" />
++-      <workItem from="1733140600841" duration="6993000" />
++-      <workItem from="1733150993229" duration="184000" />
++-      <workItem from="1733151279786" duration="6000" />
++-      <workItem from="1733151296310" duration="16875000" />
++-      <workItem from="1733233230739" duration="5172000" />
++-      <workItem from="1733246997923" duration="15986000" />
++-      <workItem from="1733349590652" duration="1949000" />
++-      <workItem from="1733352121741" duration="6332000" />
++-      <workItem from="1733405466233" duration="12731000" />
++-      <workItem from="1733557048829" duration="5541000" />
++-      <workItem from="1733583489891" duration="16419000" />
++-      <workItem from="1733859258781" duration="7356000" />
++-      <workItem from="1733995059967" duration="7899000" />
++-      <workItem from="1734011167665" duration="991000" />
++-      <workItem from="1734029966470" duration="25769000" />
++-      <workItem from="1734205412700" duration="7689000" />
++-      <workItem from="1734644992163" duration="5017000" />
++-      <workItem from="1734788130789" duration="2312000" />
++-      <workItem from="1734863751114" duration="9000" />
++-      <workItem from="1734863775073" duration="9221000" />
++-      <workItem from="1734880034791" duration="57000" />
++-      <workItem from="1734880213539" duration="15000" />
++-      <workItem from="1734880329890" duration="30000" />
++-      <workItem from="1734880369064" duration="31312000" />
++-      <workItem from="1734983129135" duration="55000" />
++-      <workItem from="1735034212628" duration="2274000" />
++-      <workItem from="1735049036048" duration="5309000" />
++-      <workItem from="1735126261413" duration="75000" />
++-      <workItem from="1735356723104" duration="1208000" />
++-      <workItem from="1735422837186" duration="1387000" />
++-      <workItem from="1735719009558" duration="561000" />
++-      <workItem from="1736101930735" duration="570000" />
++-      <workItem from="1736102511675" duration="4000" />
++-      <workItem from="1736161159525" duration="7670000" />
++-      <workItem from="1736237907904" duration="111000" />
++-      <workItem from="1736519480236" duration="1867000" />
++-      <workItem from="1737577034938" duration="3945000" />
++-      <workItem from="1737590448155" duration="6145000" />
++-      <workItem from="1738310597042" duration="2502000" />
++-      <workItem from="1738316162773" duration="726000" />
++-      <workItem from="1738326887364" duration="4500000" />
++-      <workItem from="1738586797583" duration="600000" />
++-      <workItem from="1738663690532" duration="4505000" />
++-      <workItem from="1738668267214" duration="5368000" />
++-      <workItem from="1738685509837" duration="74000" />
++-      <workItem from="1738703726377" duration="1677000" />
++-      <workItem from="1738774383038" duration="2249000" />
++-      <workItem from="1738787637783" duration="7013000" />
++-      <workItem from="1738962434877" duration="1153000" />
++-      <workItem from="1738967049524" duration="782000" />
++-      <workItem from="1739275350614" duration="312000" />
++-      <workItem from="1739464522072" duration="12498000" />
++-      <workItem from="1739572784568" duration="1228000" />
++-      <workItem from="1739626528163" duration="5778000" />
++-      <workItem from="1739689815626" duration="10399000" />
++-      <workItem from="1739812786805" duration="48519000" />
++-      <workItem from="1740212626723" duration="1263000" />
++-      <workItem from="1740213932190" duration="644000" />
++-      <workItem from="1741475492994" duration="40894000" />
++-      <workItem from="1741690305204" duration="339000" />
++-      <workItem from="1741705983516" duration="604000" />
++-      <workItem from="1741713165753" duration="1198000" />
++-      <workItem from="1741861318912" duration="2286000" />
++-      <workItem from="1742201562752" duration="618000" />
++-      <workItem from="1742209067924" duration="383000" />
++-      <workItem from="1742226300133" duration="2432000" />
++-      <workItem from="1743071528350" duration="9513000" />
++-      <workItem from="1743490058046" duration="9000" />
++-      <workItem from="1743587112942" duration="1188000" />
++-      <workItem from="1748900986740" duration="1771000" />
++-      <workItem from="1748931928220" duration="446000" />
++-      <workItem from="1748932436127" duration="20890000" />
++-      <workItem from="1748970706276" duration="3719000" />
++-      <workItem from="1748988822181" duration="59000" />
++-      <workItem from="1749200290051" duration="680000" />
++-      <workItem from="1749203502833" duration="1349000" />
++-      <workItem from="1749213099437" duration="3082000" />
++-      <workItem from="1750057109660" duration="10453000" />
++-      <workItem from="1750070416210" duration="46415000" />
+++      <updated>1753351859462</updated>
+++      <workItem from="1753351861131" duration="6344000" />
+++      <workItem from="1753438320712" duration="13353000" />
+++      <workItem from="1753603965993" duration="23907000" />
+++      <workItem from="1753709105378" duration="8957000" />
+++      <workItem from="1753783502864" duration="521000" />
+++      <workItem from="1753784038079" duration="2184000" />
+++      <workItem from="1753792651870" duration="5722000" />
+++      <workItem from="1753867421329" duration="923000" />
+++      <workItem from="1753871809956" duration="11925000" />
+++      <workItem from="1754025478167" duration="1649000" />
+++      <workItem from="1754054724448" duration="1159000" />
+++      <workItem from="1754317580682" duration="1098000" />
+++      <workItem from="1754384107227" duration="613000" />
+++      <workItem from="1754485399433" duration="303000" />
+++      <workItem from="1754503724767" duration="4050000" />
++     </task>
++-    <task id="LOCAL-00001" summary="Initial Commit">
+++    <task id="LOCAL-00001" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1732484343908</created>
+++      <created>1753438388631</created>
++       <option name="number" value="00001" />
++       <option name="presentableId" value="LOCAL-00001" />
++       <option name="project" value="LOCAL" />
++-      <updated>1732484343908</updated>
+++      <updated>1753438388631</updated>
++     </task>
++-    <task id="LOCAL-00002" summary="added TransformerFNO">
+++    <task id="LOCAL-00002" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1732497990642</created>
+++      <created>1753444583988</created>
++       <option name="number" value="00002" />
++       <option name="presentableId" value="LOCAL-00002" />
++       <option name="project" value="LOCAL" />
++-      <updated>1732497990642</updated>
+++      <updated>1753444583988</updated>
++     </task>
++-    <task id="LOCAL-00003" summary="added the connection between time steps - the model development is finished">
+++    <task id="LOCAL-00003" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1732910153380</created>
+++      <created>1753529013551</created>
++       <option name="number" value="00003" />
++       <option name="presentableId" value="LOCAL-00003" />
++       <option name="project" value="LOCAL" />
++-      <updated>1732910153380</updated>
+++      <updated>1753529013551</updated>
++     </task>
++-    <task id="LOCAL-00004" summary="Finished Allen-Cahn Problem">
+++    <task id="LOCAL-00004" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1733176021525</created>
+++      <created>1753539586020</created>
++       <option name="number" value="00004" />
++       <option name="presentableId" value="LOCAL-00004" />
++       <option name="project" value="LOCAL" />
++-      <updated>1733176021525</updated>
+++      <updated>1753539586020</updated>
++     </task>
++-    <task id="LOCAL-00005" summary="Added Allen-Cahn 3D">
+++    <task id="LOCAL-00005" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1733583274023</created>
+++      <created>1753640098974</created>
++       <option name="number" value="00005" />
++       <option name="presentableId" value="LOCAL-00005" />
++       <option name="project" value="LOCAL" />
++-      <updated>1733583274023</updated>
+++      <updated>1753640098974</updated>
++     </task>
++-    <task id="LOCAL-00006" summary="added save_vtk">
+++    <task id="LOCAL-00006" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1733995237535</created>
+++      <created>1753713910794</created>
++       <option name="number" value="00006" />
++       <option name="presentableId" value="LOCAL-00006" />
++       <option name="project" value="LOCAL" />
++-      <updated>1733995237535</updated>
+++      <updated>1753713910794</updated>
++     </task>
++-    <task id="LOCAL-00007" summary="added MATLAB codes for creating database">
+++    <task id="LOCAL-00007" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1734788540933</created>
+++      <created>1753722333819</created>
++       <option name="number" value="00007" />
++       <option name="presentableId" value="LOCAL-00007" />
++       <option name="project" value="LOCAL" />
++-      <updated>1734788540933</updated>
+++      <updated>1753722333819</updated>
++     </task>
++-    <task id="LOCAL-00008" summary="added CH2DNL">
+++    <task id="LOCAL-00008" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1735126332032</created>
+++      <created>1753789147535</created>
++       <option name="number" value="00008" />
++       <option name="presentableId" value="LOCAL-00008" />
++       <option name="project" value="LOCAL" />
++-      <updated>1735126332032</updated>
+++      <updated>1753789147535</updated>
++     </task>
++-    <task id="LOCAL-00009" summary="added SH2D">
+++    <task id="LOCAL-00009" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1735719422931</created>
+++      <created>1753867478797</created>
++       <option name="number" value="00009" />
++       <option name="presentableId" value="LOCAL-00009" />
++       <option name="project" value="LOCAL" />
++-      <updated>1735719422931</updated>
+++      <updated>1753867478797</updated>
++     </task>
++-    <task id="LOCAL-00010" summary="added PFC2D">
+++    <task id="LOCAL-00010" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1736237977029</created>
+++      <created>1753872227989</created>
++       <option name="number" value="00010" />
++       <option name="presentableId" value="LOCAL-00010" />
++       <option name="project" value="LOCAL" />
++-      <updated>1736237977029</updated>
+++      <updated>1753872227989</updated>
++     </task>
++-    <task id="LOCAL-00011" summary="added PFC2D">
+++    <task id="LOCAL-00011" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738788849261</created>
+++      <created>1753974441825</created>
++       <option name="number" value="00011" />
++       <option name="presentableId" value="LOCAL-00011" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738788849261</updated>
+++      <updated>1753974441825</updated>
++     </task>
++-    <task id="LOCAL-00012" summary="added PFC2D">
+++    <task id="LOCAL-00012" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738789326593</created>
+++      <created>1753976447489</created>
++       <option name="number" value="00012" />
++       <option name="presentableId" value="LOCAL-00012" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738789326593</updated>
+++      <updated>1753976447489</updated>
++     </task>
++-    <task id="LOCAL-00013" summary="added PFC2D">
+++    <task id="LOCAL-00013" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738796104012</created>
+++      <created>1753976663822</created>
++       <option name="number" value="00013" />
++       <option name="presentableId" value="LOCAL-00013" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738796104012</updated>
+++      <updated>1753976663822</updated>
++     </task>
++-    <task id="LOCAL-00014" summary="added PFC2D">
+++    <task id="LOCAL-00014" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738962464719</created>
+++      <created>1753984140485</created>
++       <option name="number" value="00014" />
++       <option name="presentableId" value="LOCAL-00014" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738962464719</updated>
+++      <updated>1753984140485</updated>
++     </task>
++-    <task id="LOCAL-00015" summary="added PFC2D">
+++    <task id="LOCAL-00015" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738962748829</created>
+++      <created>1754027236458</created>
++       <option name="number" value="00015" />
++       <option name="presentableId" value="LOCAL-00015" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738962748829</updated>
+++      <updated>1754027236458</updated>
++     </task>
++-    <task id="LOCAL-00016" summary="Turn Nx to 64">
+++    <task id="LOCAL-00016" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738967163754</created>
+++      <created>1754056009830</created>
++       <option name="number" value="00016" />
++       <option name="presentableId" value="LOCAL-00016" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738967163754</updated>
+++      <updated>1754056009830</updated>
++     </task>
++-    <task id="LOCAL-00017" summary="update to 3D">
+++    <task id="LOCAL-00017" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1739275401458</created>
+++      <created>1754317665438</created>
++       <option name="number" value="00017" />
++       <option name="presentableId" value="LOCAL-00017" />
++       <option name="project" value="LOCAL" />
++-      <updated>1739275401458</updated>
+++      <updated>1754317665438</updated>
++     </task>
++-    <task id="LOCAL-00018" summary="update to 3D">
+++    <task id="LOCAL-00018" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1739275433418</created>
+++      <created>1754320089838</created>
++       <option name="number" value="00018" />
++       <option name="presentableId" value="LOCAL-00018" />
++       <option name="project" value="LOCAL" />
++-      <updated>1739275433418</updated>
+++      <updated>1754320089838</updated>
++     </task>
++-    <task id="LOCAL-00019" summary="TNO3d vs FNO3d">
+++    <task id="LOCAL-00019" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1741690373369</created>
+++      <created>1754320859423</created>
++       <option name="number" value="00019" />
++       <option name="presentableId" value="LOCAL-00019" />
++       <option name="project" value="LOCAL" />
++-      <updated>1741690373369</updated>
+++      <updated>1754320859423</updated>
++     </task>
++-    <task id="LOCAL-00020" summary="TNO3d vs FNO3d">
+++    <task id="LOCAL-00020" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1741690420059</created>
+++      <created>1754323071886</created>
++       <option name="number" value="00020" />
++       <option name="presentableId" value="LOCAL-00020" />
++       <option name="project" value="LOCAL" />
++-      <updated>1741690420059</updated>
+++      <updated>1754323071886</updated>
++     </task>
++-    <task id="LOCAL-00021" summary="TNO3d vs FNO3d">
+++    <task id="LOCAL-00021" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1743587271259</created>
+++      <created>1754486043769</created>
++       <option name="number" value="00021" />
++       <option name="presentableId" value="LOCAL-00021" />
++       <option name="project" value="LOCAL" />
++-      <updated>1743587271259</updated>
+++      <updated>1754486043769</updated>
+++    </task>
+++    <task id="LOCAL-00022" summary="3d_phase_evolution">
+++      <option name="closed" value="true" />
+++      <created>1754486850188</created>
+++      <option name="number" value="00022" />
+++      <option name="presentableId" value="LOCAL-00022" />
+++      <option name="project" value="LOCAL" />
+++      <updated>1754486850188</updated>
+++    </task>
+++    <task id="LOCAL-00023" summary="3d_phase_evolution">
+++      <option name="closed" value="true" />
+++      <created>1754494436539</created>
+++      <option name="number" value="00023" />
+++      <option name="presentableId" value="LOCAL-00023" />
+++      <option name="project" value="LOCAL" />
+++      <updated>1754494436539</updated>
++     </task>
++-    <option name="localTasksCounter" value="22" />
+++    <task id="LOCAL-00024" summary="3d_phase_evolution">
+++      <option name="closed" value="true" />
+++      <created>1754512595519</created>
+++      <option name="number" value="00024" />
+++      <option name="presentableId" value="LOCAL-00024" />
+++      <option name="project" value="LOCAL" />
+++      <updated>1754512595519</updated>
+++    </task>
+++    <task id="LOCAL-00025" summary="3d_phase_evolution">
+++      <option name="closed" value="true" />
+++      <created>1754512937472</created>
+++      <option name="number" value="00025" />
+++      <option name="presentableId" value="LOCAL-00025" />
+++      <option name="project" value="LOCAL" />
+++      <updated>1754512937472</updated>
+++    </task>
+++    <option name="localTasksCounter" value="26" />
++     <servers />
++   </component>
++   <component name="TypeScriptGeneratedFilesManager">
++     <option name="version" value="3" />
++   </component>
++-  <component name="Vcs.Log.Tabs.Properties">
++-    <option name="RECENT_FILTERS">
++-      <map>
++-        <entry key="Branch">
++-          <value>
++-            <list>
++-              <RecentGroup>
++-                <option name="FILTER_VALUES">
++-                  <option value="main" />
++-                </option>
++-              </RecentGroup>
++-            </list>
++-          </value>
++-        </entry>
++-      </map>
++-    </option>
++-    <option name="TAB_STATES">
++-      <map>
++-        <entry key="MAIN">
++-          <value>
++-            <State>
++-              <option name="FILTERS">
++-                <map>
++-                  <entry key="branch">
++-                    <value>
++-                      <list>
++-                        <option value="main" />
++-                      </list>
++-                    </value>
++-                  </entry>
++-                </map>
++-              </option>
++-            </State>
++-          </value>
++-        </entry>
++-      </map>
++-    </option>
++-  </component>
++   <component name="VcsManagerConfiguration">
++-    <MESSAGE value="Initial Commit" />
++-    <MESSAGE value="added TransformerFNO" />
++-    <MESSAGE value="added the connection between time steps - the model development is finished" />
++-    <MESSAGE value="refactored" />
++-    <MESSAGE value="Finished Allen-Cahn Problem" />
++-    <MESSAGE value="Added Allen-Cahn 3D" />
++-    <MESSAGE value="added save_vtk" />
++-    <MESSAGE value="added MATLAB codes for creating database" />
++-    <MESSAGE value="seperated the number of layers in fourier part and convolutional part" />
++-    <MESSAGE value="added CH2DNL" />
++-    <MESSAGE value="added SH2D" />
++-    <MESSAGE value="added PFC2D" />
++-    <MESSAGE value="Turn Nx to 64" />
++-    <MESSAGE value="update to 3D" />
++-    <MESSAGE value="TNO3d vs FNO3d" />
++-    <option name="LAST_COMMIT_MESSAGE" value="TNO3d vs FNO3d" />
+++    <MESSAGE value="3d_phase_evolution" />
+++    <option name="LAST_COMMIT_MESSAGE" value="3d_phase_evolution" />
++   </component>
++   <component name="XDebuggerManager">
++     <breakpoint-manager>
++       <breakpoints>
++         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>142</line>
++-          <option name="timeStamp" value="17" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>163</line>
++-          <option name="timeStamp" value="18" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>134</line>
++-          <option name="timeStamp" value="19" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>327</line>
++-          <option name="timeStamp" value="20" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>243</line>
++-          <option name="timeStamp" value="21" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/AC2D_2.py</url>
++-          <line>333</line>
++-          <option name="timeStamp" value="27" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>
++-          <line>371</line>
++-          <option name="timeStamp" value="44" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>
++-          <line>338</line>
++-          <option name="timeStamp" value="54" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>53</line>
++-          <option name="timeStamp" value="128" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>30</line>
++-          <option name="timeStamp" value="129" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>25</line>
++-          <option name="timeStamp" value="133" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>18</line>
++-          <option name="timeStamp" value="135" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>
++-          <line>44</line>
++-          <option name="timeStamp" value="138" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test2.py</url>
++-          <line>16</line>
++-          <option name="timeStamp" value="144" />
+++          <url>file://$PROJECT_DIR$/training.py</url>
+++          <line>217</line>
+++          <option name="timeStamp" value="1" />
++         </line-breakpoint>
++         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/utilities.py</url>
++-          <line>98</line>
++-          <option name="timeStamp" value="170" />
+++          <url>file://$PROJECT_DIR$/networks.py</url>
+++          <line>373</line>
+++          <option name="timeStamp" value="5" />
++         </line-breakpoint>
++         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/main.py</url>
++-          <line>157</line>
++-          <option name="timeStamp" value="177" />
+++          <url>file://$PROJECT_DIR$/networks.py</url>
+++          <line>252</line>
+++          <option name="timeStamp" value="6" />
++         </line-breakpoint>
++       </breakpoints>
++-      <default-breakpoints>
++-        <breakpoint type="python-exception">
++-          <properties notifyOnTerminate="true" exception="BaseException">
++-            <option name="notifyOnTerminate" value="true" />
++-          </properties>
++-        </breakpoint>
++-      </default-breakpoints>
++     </breakpoint-manager>
++   </component>
++   <component name="com.intellij.coverage.CoverageDataManagerImpl">
++-    <SUITE FILE_PATH="coverage/PhaseField1$Test3.coverage" NAME="Test3 Coverage Results" MODIFIED="1739273938386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO4d.coverage" NAME="SH3D_FNO4d Coverage Results" MODIFIED="1753633990803" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage" NAME="config_AC2D_FNO3d Coverage Results" MODIFIED="1733233385695" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$main.coverage" NAME="main Coverage Results" MODIFIED="1743065376798" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_2.coverage" NAME="AC2D_Net2D_2 Coverage Results" MODIFIED="1732904114403" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_PFC3D_TNO3d.coverage" NAME="config_PFC3D_TNO3d Coverage Results" MODIFIED="1752681001873" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$test2.coverage" NAME="test2 Coverage Results" MODIFIED="1742889074336" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1741561715014" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage" NAME="config_SH3D_TNO3d Coverage Results" MODIFIED="1750254757455" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3D.coverage" NAME="SH3D_TNO3D Coverage Results" MODIFIED="1753359664305" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$networks.coverage" NAME="networks Coverage Results" MODIFIED="1733086051390" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1740088478224" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1741603428589" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3d_TNO3d_hybrid.coverage" NAME="PFC3d_TNO3d_hybrid Coverage Results" MODIFIED="1753174544263" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$main.coverage" NAME="main Coverage Results" MODIFIED="1738663765959" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$post_processing.coverage" NAME="post_processing Coverage Results" MODIFIED="1733557098801" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1751364899601" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_Hybrid.coverage" NAME="SH3D_Hybrid Coverage Results" MODIFIED="1753435630879" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D.coverage" NAME="AC2D Coverage Results" MODIFIED="1733088640665" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Archive_Code" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D.coverage" NAME="AC2D_Net2D Coverage Results" MODIFIED="1732567473230" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1740054182408" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1753174449133" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1737644605063" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1741605347375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$main.coverage" NAME="main Coverage Results" MODIFIED="1736268192289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1741564210973" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage" NAME="config_CH2DNL_TNO2d Coverage Results" MODIFIED="1735052490996" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$Test_Run.coverage" NAME="Test_Run Coverage Results" MODIFIED="1738945320139" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1741561294310" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_Hybrid.coverage" NAME="PFC3D_Hybrid Coverage Results" MODIFIED="1752753153734" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1743081225414" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1752763076697" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$PFC2D.coverage" NAME="PFC2D Coverage Results" MODIFIED="1732278679485" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$CH2D.coverage" NAME="CH2D Coverage Results" MODIFIED="1732347055915" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_FNO3d.coverage" NAME="AC3D_FNO3d Coverage Results" MODIFIED="1741561435127" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_hybrid.coverage" NAME="MBE3D_hybrid Coverage Results" MODIFIED="1753449172728" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741547133078" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_FNO4d.coverage" NAME="PFC3D_FNO4d Coverage Results" MODIFIED="1753634100431" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$AC3D.coverage" NAME="AC3D Coverage Results" MODIFIED="1740041515520" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$Test2.coverage" NAME="Test2 Coverage Results" MODIFIED="1739283715182" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1751535690856" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D.coverage" NAME="config_AC2D Coverage Results" MODIFIED="1733087276180" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_1.coverage" NAME="AC2D_Net2D_1 Coverage Results" MODIFIED="1732535211383" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1736520700819" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$fourier_3d.coverage" NAME="fourier_3d Coverage Results" MODIFIED="1732221600628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_interface3.coverage" NAME="run_interface3 Coverage Results" MODIFIED="1754546519931" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1751390276789" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1753270153654" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1753435969375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$test1.coverage" NAME="test1 Coverage Results" MODIFIED="1733413325318" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_TNO3d_Hybrid.coverage" NAME="PFC3D_TNO3d_Hybrid Coverage Results" MODIFIED="1752850166757" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$Test3.coverage" NAME="Test3 Coverage Results" MODIFIED="1739273938386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_2.coverage" NAME="AC2D_Net2D_2 Coverage Results" MODIFIED="1732904114403" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_MBE3D_TNO3d.coverage" NAME="config_MBE3D_TNO3d Coverage Results" MODIFIED="1753524263103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage" NAME="config_SH3D_TNO3d Coverage Results" MODIFIED="1753348599806" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseField1$backend_interagg.coverage" NAME="backend_interagg Coverage Results" MODIFIED="1737630366471" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript3.coverage" NAME="RunScript3 Coverage Results" MODIFIED="1736368081257" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_2.coverage" NAME="AC2D_2 Coverage Results" MODIFIED="1732483323689" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$networks.coverage" NAME="networks Coverage Results" MODIFIED="1733086051390" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField1$main_TF.coverage" NAME="main_TF Coverage Results" MODIFIED="1738704014479" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1741538869064" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$THFNO.coverage" NAME="THFNO Coverage Results" MODIFIED="1732911474644" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/networks" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1740088478224" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$PFC3D.coverage" NAME="PFC3D Coverage Results" MODIFIED="1740083613128" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1741603428589" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_inference.coverage" NAME="run_inference Coverage Results" MODIFIED="1750323709039" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$main.coverage" NAME="main Coverage Results" MODIFIED="1738663765959" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$post_processing.coverage" NAME="post_processing Coverage Results" MODIFIED="1733557098801" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$CH3D_FNO4d.coverage" NAME="CH3D_FNO4d Coverage Results" MODIFIED="1754322861793" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_AC3D_FNO3d.coverage" NAME="config_AC3D_FNO3d Coverage Results" MODIFIED="1751958646687" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_inference.coverage" NAME="run_inference Coverage Results" MODIFIED="1751264322005" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage" NAME="config_CH2D_TNO2d Coverage Results" MODIFIED="1734086207850" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/phase_field_equations_4d$networks.coverage" NAME="networks Coverage Results" MODIFIED="1748933697533" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1750255151255" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript2.coverage" NAME="RunScript2 Coverage Results" MODIFIED="1736369209710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1742215946758" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_3.coverage" NAME="AC2D_Net2D_3 Coverage Results" MODIFIED="1732974697103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_FNO3d.coverage" NAME="AC3d_FNO3d Coverage Results" MODIFIED="1749017845623" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D.coverage" NAME="AC2D Coverage Results" MODIFIED="1733088640665" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Archive_Code" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D.coverage" NAME="AC2D_Net2D Coverage Results" MODIFIED="1732567473230" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1740054182408" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$utilities.coverage" NAME="utilities Coverage Results" MODIFIED="1752595653294" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_FNO3d.coverage" NAME="AC3d_FNO3d Coverage Results" MODIFIED="1751961986602" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1741562061391" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1737644605063" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_TNO.coverage" NAME="MBE3D_TNO Coverage Results" MODIFIED="1753438703018" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$MBE3D.coverage" NAME="MBE3D Coverage Results" MODIFIED="1739283566145" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1741605347375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1743071672425" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$main.coverage" NAME="main Coverage Results" MODIFIED="1736268192289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1741564210973" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage" NAME="config_CH2DNL_TNO2d Coverage Results" MODIFIED="1735052490996" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FO.coverage" NAME="SH3D_FO Coverage Results" MODIFIED="1753438614882" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$MBE2D.coverage" NAME="MBE2D Coverage Results" MODIFIED="1732278526731" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField1$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1739914172084" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$Test_Run.coverage" NAME="Test_Run Coverage Results" MODIFIED="1738945320139" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1741561294310" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3d_hybrid.coverage" NAME="MBE3d_hybrid Coverage Results" MODIFIED="1753458461671" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741861381348" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1743081225414" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage" NAME="PFV3D_FNO3d Coverage Results" MODIFIED="1741564487710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$training.coverage" NAME="training Coverage Results" MODIFIED="1751968651692" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_Hybrid.coverage" NAME="MBE3D_Hybrid Coverage Results" MODIFIED="1753516430619" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript1.coverage" NAME="RunScript1 Coverage Results" MODIFIED="1736368790622" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$SH2D.coverage" NAME="SH2D Coverage Results" MODIFIED="1732347080402" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$PFC2D.coverage" NAME="PFC2D Coverage Results" MODIFIED="1732278679485" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$CH2D.coverage" NAME="CH2D Coverage Results" MODIFIED="1732347055915" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_FNO3d.coverage" NAME="AC3D_FNO3d Coverage Results" MODIFIED="1741561435127" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_FNO3d.coverage" NAME="PFC3D_FNO3d Coverage Results" MODIFIED="1753174772461" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$SH3D.coverage" NAME="SH3D Coverage Results" MODIFIED="1739044808411" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$Test.coverage" NAME="Test Coverage Results" MODIFIED="1739459206236" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741547133078" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$CH3D_TNO3d_Hybrid.coverage" NAME="CH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1752411744994" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage" NAME="config_AC2D_FNO2d Coverage Results" MODIFIED="1733393903488" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$AC3D.coverage" NAME="AC3D Coverage Results" MODIFIED="1740041515520" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$config_CH3D_TNO3d.coverage" NAME="config_CH3D_TNO3d Coverage Results" MODIFIED="1738089807566" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$Test2.coverage" NAME="Test2 Coverage Results" MODIFIED="1739283715182" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_FNO3d.coverage" NAME="CH3D_FNO3d Coverage Results" MODIFIED="1741628529142" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage" NAME="AC3d_TNO3d_hybrid Coverage Results" MODIFIED="1748989478372" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage" NAME="AC3d_TNO3d_hybrid Coverage Results" MODIFIED="1751963486807" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1737899062785" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D.coverage" NAME="config_AC2D Coverage Results" MODIFIED="1733087276180" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_1.coverage" NAME="AC2D_Net2D_1 Coverage Results" MODIFIED="1732535211383" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1736520700819" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$fourier_3d.coverage" NAME="fourier_3d Coverage Results" MODIFIED="1732221600628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1750254767095" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1749216389646" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1748990262244" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$test1.coverage" NAME="test1 Coverage Results" MODIFIED="1733413325318" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1754503754902" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main1.coverage" NAME="main1 Coverage Results" MODIFIED="1753709191839" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField1$CH3D_2.coverage" NAME="CH3D_2 Coverage Results" MODIFIED="1739918355289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1750254975290" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage" NAME="config_MBE2D_TNO2d Coverage Results" MODIFIED="1736261397712" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++   </component>
++ </project>
++\ No newline at end of file
++Index: configs/config_SH3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_SH3D_FNO4d.py b/configs/config_SH3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1754475689396)
+++++ b/configs/config_SH3D_FNO4d.py	(date 1754475689396)
++@@ -0,0 +1,80 @@
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda:2'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1200 # 5250 # 7500
+++nTest = 300 # 2250 #500
+++batch_size = 20 # 10 # 50 # 50
+++learning_rate = 0.001 # 0.005 # 0.001
+++weight_decay = 1e-4 # 1e-4
+++epochs = 30 # 1000
+++iterations = epochs * (nTrain // batch_size)
+++modes =  14 # 16
+++width =  12 #32
+++width_q =   width # width # 2 * width #
+++width_h = width//2  # width//4 # width #
+++n_layers = 2 # 8
+++
+++# Discretization
+++s = 32 # 32 # 64
+++T_in = 1
+++T_out = 91 # 100 # 100
+++
+++# Training Setting
+++normalized = True # False #True
+++training = True # False  # True
+++load_model = False # False #True
+++
+++# Database
+++parent_dir = './data/'
+++#matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
+++# Plotting
+++
+++# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
+++Lx = 15 # 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++Ly =Lx
+++Lz= Lx
+++
+++index = 62  # 24 # 62
+++#domain = [-np.pi, np.pi]  ######
+++domain = [-Lx/2, Lx/2]
+++
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++### Hybrid method
+++
+++# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
+++#Lx = np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++# domain = [-Lx/2, Lx/2] # Assuming centered domain
+++
+++# Time Discretization (from MATLAB)
+++dt_sim = 0.0002 # Simulation time step
+++Nt = 100 # Total simulation steps
+++num_saved_steps = 101 # Number of saved steps (includes t=0)
+++ns = Nt / (num_saved_steps - 1) # Interval between saved steps
+++dt_model = ns * dt_sim # Effective time step between model outputs
+++
+++# PDE Parameters
+++epsilon = 0.15
+++#pde_weight = 0.3 # Example: 30% physics loss
+++pde_weight = 0.0 # Example: 70% physics loss
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++pde_loss_scaler = 1e-0
+++###########################
+++# ... rest of config ...
++\ No newline at end of file
++Index: configs/config_PFC3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_PFC3D_FNO4d.py b/configs/config_PFC3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1754475689499)
+++++ b/configs/config_PFC3D_FNO4d.py	(date 1754475689499)
++@@ -0,0 +1,81 @@
+++import numpy as np
+++
+++# General SettingnTrain = 1200 # 5250 # 7500
+++
+++gpu_number = 'cuda:1'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1200
+++nTest = 300
+++batch_size = 20 # 15 # 100
+++learning_rate = 0.001
+++weight_decay = 1e-4 # 1e-4
+++epochs = 30 # 50
+++iterations = epochs * (nTrain // batch_size)
+++modes = 14 #12
+++width = 12 # 16 # 32
+++width_q = width # 32
+++width_h = width//2 # 16
+++n_layers = 2 # 4
+++
+++'''
+++tau = 315;
+++alpha = 115; 
+++'''
+++
+++# Discretization
+++s = 32 # 64 # 64
+++T_in = 1
+++T_out = 91 # 20 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True # False  # True
+++load_model = False # True # False # True  # False
+++
+++# Database
+++parent_dir = './data/'
+++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
+++# Plotting
+++
+++# Plotting
+++index = 69  # 110  # 200
+++Lx = 10*np.pi
+++domain = [-5*np.pi, 5*np.pi]
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++# time_steps = [0, 2, 4, 6, 8, 9]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.05 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_AC3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_AC3D_FNO4d.py b/configs/config_AC3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1754475689441)
+++++ b/configs/config_AC3D_FNO4d.py	(date 1754475689441)
++@@ -0,0 +1,76 @@
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1000 # 900 # 1000
+++nTest = 300 # 100 # 100
+++batch_size = 20 # 10 # 50 # 20 #5 # 25
+++learning_rate = 0.001
+++weight_decay = 1e-4
+++epochs = 20 # 50 # 100 # 900  # 100
+++iterations = epochs * (nTrain // batch_size)
+++modes =  14 # 8 # last time modes =  8
+++width =  12 # 32 # last time width =  32
+++width_q = width
+++width_h = width // 2 # width // 4 # last time
+++n_layers = 2 # 4
+++
+++# Discretization
+++s = 32
+++T_in = 1
+++T_out = 91 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True # False  # False
+++load_model = False # True  # True
+++
+++# Database
+++parent_dir = './data/'
+++# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'AC3D_32_1000.mat'
+++#matlab_dataset = 'AC3D_32_1300.mat'
+++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
+++# Plotting
+++index = 9 # 12
+++#domain = [-np.pi, np.pi]
+++Lx = 5 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
+++
+++# time_steps = [29, 69]
+++#time_steps = [39, 49, 59, 69, 79, 89, 99]
+++# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++#############
+++#Lx = np.pi            # Domain size from MATLAB
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0001     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-5
++\ No newline at end of file
++Index: configs/config_AC3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1000 # 900 # 1000\nnTest = 300 # 100 # 100\nbatch_size = 10 # 50 # 20 #5 # 25\nlearning_rate = 0.001\nweight_decay = 1e-4\nepochs = 50 # 100 # 900  # 100\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 8 # last time modes =  8\nwidth =  12 # 32 # last time width =  32\nwidth_q = width\nwidth_h = width // 2 # width // 4 # last time\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # False #  False\nload_model = False # True  #  True  # True\n\n# Database\nparent_dir = './data/'\n# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'\n#matlab_dataset = 'AC3D_32_1000.mat'\nmatlab_dataset = 'AC3D_32_1300.mat'\n# Plotting\nindex = 9 # 12\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 69]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]\n\n\n#############\nLx = np.pi            # Domain size from MATLAB\n# Time Discretization Parameters (from AC3D MATLAB)\ndt_sim = 0.0001     # Time step in the MATLAB simulation\nNt_sim = 50        # Total number of simulation steps in MATLAB\nnum_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)\n# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps\n# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output\n# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.\ndt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in\n# PDE Parameters for Allen-Cahn (AC3D)\n# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.\n# The PDE implemented in calculate_pde_residual was:\n# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)\nepsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter\n# PINN Specific Settings (if PINN_MODE is True in main.py)\npde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.\n# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\n\npde_loss_scaler = 1e-3
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_AC3D_TNO3d.py b/configs/config_AC3D_TNO3d.py
++--- a/configs/config_AC3D_TNO3d.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/configs/config_AC3D_TNO3d.py	(date 1754475689513)
++@@ -6,23 +6,23 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 1000 # 900 # 1000
+++nTrain = 1200 # 900 # 1000
++ nTest = 300 # 100 # 100
++-batch_size = 10 # 50 # 20 #5 # 25
++-learning_rate = 0.001
+++batch_size = 20 # 20 # 50 # 20 #5 # 25
+++learning_rate = 0.001 # 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 100 # 900  # 100
+++epochs = 20 # 50 #  # 100 # 900  # 100
++ iterations = epochs * (nTrain // batch_size)
++ modes =  14 # 8 # last time modes =  8
++-width =  12 # 32 # last time width =  32
+++width =  12 # 12 # 32 # last time width =  32
++ width_q = width
++ width_h = width // 2 # width // 4 # last time
++-n_layers = 4
+++n_layers = 2 # 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -31,24 +31,26 @@
++ 
++ # Database
++ parent_dir = './data/'
++-# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
++-#matlab_dataset = 'AC3D_32_1000.mat'
++-matlab_dataset = 'AC3D_32_1300.mat'
+++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
+++#matlab_dataset ='AC3D_32_1500_Augmented.mat' # mixed --> 75% GRF and 25% sphere...
++ # Plotting
++ index = 9 # 12
++-domain = [-np.pi, np.pi]
+++Lx = 5 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
++ # time_steps = [29, 69]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ # time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
+++time_steps = [1, 50, 90]
++ 
++ 
++ #############
++-Lx = np.pi            # Domain size from MATLAB
+++
++ # Time Discretization Parameters (from AC3D MATLAB)
++-dt_sim = 0.0001     # Time step in the MATLAB simulation
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
++ Nt_sim = 50        # Total number of simulation steps in MATLAB
++ num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++ # ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++@@ -61,11 +63,11 @@
++ # du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++ epsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++ # PINN Specific Settings (if PINN_MODE is True in main.py)
++-pde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++ # PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++ 
++ # Learning Rate Scheduler Parameters (for StepLR)
++ scheduler_step = 20  # Decay learning rate every 20 epochs
++ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++ 
++-pde_loss_scaler = 1e-3
++\ No newline at end of file
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: configs/config_PFC3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\"\"\"\nDevice:  cuda:0\nmodel = TNO2d_PFC2D_S64_T1to100_width32_modes12_q32_h16.pt\nnumber of epoch = 1000\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n2539703\n\nThe average testing error is 0.027059923857450485\nStd. deviation of testing error is 0.01980009116232395\n----------------------------------------------\nmodel = TNO2d_PFC2D_S64_T1to50_width16_modes12_q32_h16.pt\nnumber of epoch = 200\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n651059\n\nThe average testing error is 0.005057875066995621\nStd. deviation of testing error is 0.0021678071934729815\n----------------------------------------------\n\n\n\"\"\"\n\nimport numpy as np\n\n# General SettingnTrain = 1200 # 5250 # 7500\n\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200\nnTest = 300\nbatch_size = 50 # 100\nlearning_rate = 0.005\nweight_decay = 1e-4 # 1e-4\nepochs = 50\niterations = epochs * (nTrain // batch_size)\nmodes = 14 #12\nwidth = 12 # 16 # 32\nwidth_q = width # 32\nwidth_h = width//2 # 16\nn_layers = 4\n\n'''\ntau = 315;\nalpha = 115; \n'''\n\n# Discretization\ns = 32 # 64 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # True\nload_model = False # True # False # True  # False\n\n# Database\nparent_dir = './data/'\nmatlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 200  # 110  # 200\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n# time_steps = [0, 2, 4, 6, 8, 9]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_PFC3D_FNO3d.py b/configs/config_PFC3D_FNO3d.py
++--- a/configs/config_PFC3D_FNO3d.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/configs/config_PFC3D_FNO3d.py	(date 1754475689483)
++@@ -43,16 +43,16 @@
++ # Network Parameters
++ nTrain = 1200
++ nTest = 300
++-batch_size = 50 # 100
++-learning_rate = 0.005
+++batch_size = 15 # 100
+++learning_rate = 0.001
++ weight_decay = 1e-4 # 1e-4
++-epochs = 50
+++epochs = 30 # 50
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 #12
++ width = 12 # 16 # 32
++ width_q = width # 32
++ width_h = width//2 # 16
++-n_layers = 4
+++n_layers = 2 # 4
++ 
++ '''
++ tau = 315;
++@@ -62,7 +62,7 @@
++ # Discretization
++ s = 32 # 64 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -71,14 +71,45 @@
++ 
++ # Database
++ parent_dir = './data/'
++-matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
++ # Plotting
++-index = 200  # 110  # 200
++-domain = [-np.pi, np.pi]
+++
+++# Plotting
+++index = 69  # 110  # 200
+++Lx = 10*np.pi
+++domain = [-5*np.pi, 5*np.pi]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ # time_steps = [0, 2, 4, 6, 8, 9]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.05 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_PFC3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\"\"\"\nDevice:  cuda:0\nmodel = TNO2d_PFC2D_S64_T1to100_width32_modes12_q32_h16.pt\nnumber of epoch = 1000\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n2539703\n\nThe average testing error is 0.027059923857450485\nStd. deviation of testing error is 0.01980009116232395\n----------------------------------------------\nmodel = TNO2d_PFC2D_S64_T1to50_width16_modes12_q32_h16.pt\nnumber of epoch = 200\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n651059\n\nThe average testing error is 0.005057875066995621\nStd. deviation of testing error is 0.0021678071934729815\n----------------------------------------------\n\n\n\"\"\"\n\nimport numpy as np\n\n# General SettingnTrain = 1200 # 5250 # 7500\n\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200\nnTest = 300\nbatch_size = 50 # 100\nlearning_rate = 0.005\nweight_decay = 1e-4 # 1e-4\nepochs = 50\niterations = epochs * (nTrain // batch_size)\nmodes = 14 #12\nwidth = 12 # 16 # 32\nwidth_q = width # 32\nwidth_h = width//2 # 16\nn_layers = 4\n\n'''\ntau = 315;\nalpha = 115; \n'''\n\n# Discretization\ns = 32 # 64 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # True\nload_model = False # True # False # True  # False\n\n# Database\nparent_dir = './data/'\nmatlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 200  # 110  # 200\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n# time_steps = [0, 2, 4, 6, 8, 9]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_PFC3D_TNO3d.py b/configs/config_PFC3D_TNO3d.py
++--- a/configs/config_PFC3D_TNO3d.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/configs/config_PFC3D_TNO3d.py	(date 1754475689117)
++@@ -43,26 +43,21 @@
++ # Network Parameters
++ nTrain = 1200
++ nTest = 300
++-batch_size = 50 # 100
++-learning_rate = 0.005
+++batch_size = 20 #50# 100
+++learning_rate = 0.001 # 0.005
++ weight_decay = 1e-4 # 1e-4
++-epochs = 50
+++epochs = 30 # 20 # 50
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 #12
++ width = 12 # 16 # 32
++ width_q = width # 32
++ width_h = width//2 # 16
++-n_layers = 4
++-
++-'''
++-tau = 315;
++-alpha = 115; 
++-'''
+++n_layers = 2 # 4
++ 
++ # Discretization
++ s = 32 # 64 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -71,14 +66,44 @@
++ 
++ # Database
++ parent_dir = './data/'
++-matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
+++
++ # Plotting
++-index = 200  # 110  # 200
++-domain = [-np.pi, np.pi]
+++index = 69  # 110  # 200
+++Lx = 10*np.pi
+++domain = [-5*np.pi, 5*np.pi]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ # time_steps = [0, 2, 4, 6, 8, 9]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.005 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: configs/config_CH3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:3'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500\nnTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500\nbatch_size = 2 # 20 # 50 # 3 # 20 # 50 # 5 # 50\nlearning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-3 # 1e-4\nepochs = 100 # 500 # 1000 # 25 # 100 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 10 #12 # 14 # 16 # 10 # 16\nwidth = 12 # 8 #12 #14 # 12 # 16 # 32\nwidth_q = width # 2 * width #\nwidth_h = width//2 # width//4 # width #\nn_layers = 4 # 4 # 5 # 5 # 8\n\n# Discretization\n\ns = 64 # 32 # 64 #32 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False # True # False  # True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n\n#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'\n\n# Plotting\nindex = 62  # 24 # 62\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_CH3D_FNO3d.py b/configs/config_CH3D_FNO3d.py
++--- a/configs/config_CH3D_FNO3d.py	(revision 6cbdb236b26f30169ad82dc3bb42c93534621884)
+++++ b/configs/config_CH3D_FNO3d.py	(date 1754475689324)
++@@ -6,24 +6,24 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+++nTrain = 1300 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
++ nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
++-batch_size = 2 # 20 # 50 # 3 # 20 # 50 # 5 # 50
+++batch_size = 10 # 20 # 20 # 50 # 3 # 20 # 50 # 5 # 50
++ learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
++ weight_decay = 1e-4 # 1e-3 # 1e-4
++-epochs = 100 # 500 # 1000 # 25 # 100 # 1000
+++epochs = 50 # 100 # 500 # 1000 # 25 # 100 # 1000
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 # 10 #12 # 14 # 16 # 10 # 16
++ width = 12 # 8 #12 #14 # 12 # 16 # 32
++ width_q = width # 2 * width #
++ width_h = width//2 # width//4 # width #
++-n_layers = 4 # 4 # 5 # 5 # 8
+++n_layers = 3 # 2 # 4 # 5 # 5 # 8
++ 
++ # Discretization
++ 
++-s = 64 # 32 # 64 #32 # 64
+++s = 32 # 64 # 32 # 64 #32 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -34,15 +34,44 @@
++ parent_dir = './data/'
++ 
++ #matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
++-
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++ # Plotting
++ index = 62  # 24 # 62
++-domain = [-np.pi, np.pi]
+++#domain = [-np.pi, np.pi]
+++Lx = 2 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.05  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
+Index: PFC3D/.idea/inspectionProfiles/Project_Default.xml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/PFC3D/.idea/inspectionProfiles/Project_Default.xml b/PFC3D/.idea/inspectionProfiles/Project_Default.xml
+new file mode 100644
+--- /dev/null	(date 1752127452494)
++++ b/PFC3D/.idea/inspectionProfiles/Project_Default.xml	(date 1752127452494)
+@@ -0,0 +1,24 @@
++<component name="InspectionProjectProfileManager">
++  <profile version="1.0">
++    <option name="myName" value="Project Default" />
++    <inspection_tool class="DuplicatedCode" enabled="true" level="WEAK WARNING" enabled_by_default="true">
++      <Languages>
++        <language minSize="71" name="Python" />
++      </Languages>
++    </inspection_tool>
++    <inspection_tool class="PyPep8Inspection" enabled="true" level="WEAK WARNING" enabled_by_default="true">
++      <option name="ignoredErrors">
++        <list>
++          <option value="W292" />
++        </list>
++      </option>
++    </inspection_tool>
++    <inspection_tool class="PyPep8NamingInspection" enabled="true" level="WEAK WARNING" enabled_by_default="true">
++      <option name="ignoredErrors">
++        <list>
++          <option value="N802" />
++        </list>
++      </option>
++    </inspection_tool>
++  </profile>
++</component>
+\ No newline at end of file
+Index: PFC3D/.idea/inspectionProfiles/profiles_settings.xml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/PFC3D/.idea/inspectionProfiles/profiles_settings.xml b/PFC3D/.idea/inspectionProfiles/profiles_settings.xml
+new file mode 100644
+--- /dev/null	(date 1752127452604)
++++ b/PFC3D/.idea/inspectionProfiles/profiles_settings.xml	(date 1752127452604)
+@@ -0,0 +1,6 @@
++<component name="InspectionProjectProfileManager">
++  <settings>
++    <option name="USE_PROJECT_PROFILE" value="false" />
++    <version value="1.0" />
++  </settings>
++</component>
+\ No newline at end of file
+Index: .idea/shelf/Uncommitted_changes_before_Update_at_8_7_25__8_23_AM__Changes_.xml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25__8_23_AM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25__8_23_AM__Changes_.xml
+new file mode 100644
+--- /dev/null	(date 1754578056886)
++++ b/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25__8_23_AM__Changes_.xml	(date 1754578056886)
+@@ -0,0 +1,219 @@
++<changelist name="Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]" date="1754547784715" recycled="true" deleted="true">
++  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/shelved.patch" />
++  <option name="DESCRIPTION" value="Uncommitted changes before Update at 8/7/25, 8:23 AM [Changes]" />
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/MBE2D.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/SH3D_Comparison_Plot_Modified.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/combined_results.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/SH2D.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" />
++    <option name="AFTER_PATH" value="MBE3D/plots_Data_Physics_TNO3d/MBE3D_Hybrid.jpg" />
++    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/MBE3D_Hybrid.jpg" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/MBE3D_rand.asv" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_loss_curve.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison_FINAL.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/combined_results.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison_mixed.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" />
++    <option name="AFTER_PATH" value="SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" />
++    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/SH3D_FNO_field_comparison.png" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH3D_random_new.asv" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/middle.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/PFC3D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/GRF.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/3d_phase_evolution.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/MBE3D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/PFC2D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_loss_curve_mixed.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" />
++    <option name="AFTER_PATH" value="SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" />
++    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/SH3D_Hybrid_field_comparison.png" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/PFC2D.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/SH3D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/SH2D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH3D_test.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/CH3D_Comparison_star_SANO.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/MBE2D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_loss_curve_mixed.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH3D_random_new.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MBE3D/plots_FNO3d/3d_phase_evolution.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/SH3D_Comparison_Plot_Modified_PIMHNO.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MBE3D/plots_TNO3d/3d_phase_evolution.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/GRF3D.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/SH3D_SANO_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MBE3D/plots_FNO3d/combined_results.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/CH3D_rand.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="MatlabCode/GRFtest.m" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++  <binary>
++    <option name="BEFORE_PATH" value="SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" />
++    <option name="AFTER_PATH" />
++    <option name="SHELVED_PATH" />
++  </binary>
++</changelist>
+\ No newline at end of file
+Index: utilities.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>import torch\nimport numpy as np\nimport scipy.io\nimport h5py\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport os\n\nimport operator\nfrom functools import reduce\nfrom functools import partial\n\n#################################################\n#\n# Utilities\n#\n#################################################\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# reading data\nclass MatReader(object):\n    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n        super(MatReader, self).__init__()\n\n        self.to_torch = to_torch\n        self.to_cuda = to_cuda\n        self.to_float = to_float\n\n        self.file_path = file_path\n\n        self.data = None\n        self.old_mat = None\n        self._load_file()\n\n    def _load_file(self):\n        try:\n            self.data = scipy.io.loadmat(self.file_path)\n            self.old_mat = True\n        except:\n            self.data = h5py.File(self.file_path)\n            self.old_mat = False\n\n    def load_file(self, file_path):\n        self.file_path = file_path\n        self._load_file()\n\n    def read_field(self, field):\n        print(f\"Available keys in self.data: {list(self.data.keys())}\")\n        x = self.data[field]\n\n        if not self.old_mat:\n            x = x[()]\n            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n\n        if self.to_float:\n            x = x.astype(np.float32)\n\n        if self.to_torch:\n            x = torch.from_numpy(x)\n\n            if self.to_cuda:\n                x = x.cuda()\n\n        return x\n\n    def set_cuda(self, to_cuda):\n        self.to_cuda = to_cuda\n\n    def set_torch(self, to_torch):\n        self.to_torch = to_torch\n\n    def set_float(self, to_float):\n        self.to_float = to_float\n\n\n# normalization, pointwise gaussian\nclass UnitGaussianNormalizer(object):\n    def __init__(self, x, eps=0.00001, time_last=True):\n        super(UnitGaussianNormalizer, self).__init__()\n\n        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T in 1D\n        # x could be in shape of ntrain*w*l or ntrain*T*w*l or ntrain*w*l*T in 2D\n        self.mean = torch.mean(x, 0)\n        self.std = torch.std(x, 0)\n        self.eps = eps\n        self.time_last = time_last  # if the time dimension is the last dim\n\n    def encode(self, x):\n        x = (x - self.mean) / (self.std + self.eps)\n        return x\n\n    def decode(self, x, sample_idx=None):\n        # sample_idx is the spatial sampling mask\n        #print('x shape in decode: ', x.shape)\n        global std, mean\n        if sample_idx is None:\n            std = self.std + self.eps  # n\n            mean = self.mean\n            #print(\"x shape:\", x.shape)\n            #print(\"std shape:\", std.shape)\n            #print(\"mean shape:\", mean.shape)\n        else:\n            if self.mean.ndim == sample_idx.ndim or self.time_last:\n                std = self.std[sample_idx] + self.eps  # batch*n\n                mean = self.mean[sample_idx]\n            if self.mean.ndim > sample_idx.ndim and not self.time_last:\n                std = self.std[..., sample_idx] + self.eps  # T*batch*n\n                mean = self.mean[..., sample_idx]\n        # x is in shape of batch*(spatial discretization size) or T*batch*(spatial discretization size)\n\n        x = (x * std) + mean\n        return x\n\n    def to(self, device):\n        if torch.is_tensor(self.mean):\n            self.mean = self.mean.to(device)\n            self.std = self.std.to(device)\n        else:\n            self.mean = torch.from_numpy(self.mean).to(device)\n            self.std = torch.from_numpy(self.std).to(device)\n        return self\n\n    def cuda(self):\n        self.mean = self.mean.cuda()\n        self.std = self.std.cuda()\n\n    def cpu(self):\n        self.mean = self.mean.cpu()\n        self.std = self.std.cpu()\n\n\n# normalization, Gaussian\nclass GaussianNormalizer(object):\n    def __init__(self, x, eps=0.00001):\n        super(GaussianNormalizer, self).__init__()\n\n        self.mean = torch.mean(x)\n        self.std = torch.std(x)\n        self.eps = eps\n\n    def encode(self, x):\n        x = (x - self.mean) / (self.std + self.eps)\n        return x\n\n    def decode(self, x, sample_idx=None):\n        x = (x * (self.std + self.eps)) + self.mean\n        return x\n\n    def cuda(self):\n        self.mean = self.mean.cuda()\n        self.std = self.std.cuda()\n\n    def cpu(self):\n        self.mean = self.mean.cpu()\n        self.std = self.std.cpu()\n\n\n# normalization, scaling by range\nclass RangeNormalizer(object):\n    def __init__(self, x, low=0.0, high=1.0):\n        super(RangeNormalizer, self).__init__()\n        mymin = torch.min(x, 0)[0].view(-1)\n        mymax = torch.max(x, 0)[0].view(-1)\n\n        self.a = (high - low) / (mymax - mymin)\n        self.b = -self.a * mymax + high\n\n    def encode(self, x):\n        s = x.size()\n        x = x.view(s[0], -1)\n        x = self.a * x + self.b\n        x = x.view(s)\n        return x\n\n    def decode(self, x):\n        s = x.size()\n        x = x.view(s[0], -1)\n        x = (x - self.b) / self.a\n        x = x.view(s)\n        return x\n\n\n# loss function with rel/abs Lp loss\nclass LpLoss(object):\n    #def __init__(self, d=2, p=2, size_average=True, reduction=True):\n    #    super(LpLoss, self).__init__()\n    def __init__(self, d=2, p=2, l1_weight=0.0, size_average=True, reduction=True):\n        super(LpLoss, self).__init__()\n        assert d > 0 and p > 0\n\n\n        # Dimension and Lp-norm type are postive\n        assert d > 0 and p > 0\n\n        self.d = d\n        self.p = p\n        self.l1_weight = l1_weight  # Weight for the L1 compon\n        self.reduction = reduction\n        self.size_average = size_average\n\n    def abs(self, x, y):\n        num_examples = x.size()[0] # number of rows\n\n        # Assume uniform mesh\n        h = 1.0 / (x.size()[1] - 1.0)\n\n        all_norms = (h ** (self.d / self.p)) * torch.norm(x.view(num_examples, -1) - y.view(num_examples, -1), self.p,\n                                                          1)\n\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(all_norms)\n            else:\n                return torch.sum(all_norms)\n\n        return all_norms\n\n    def rel(self, x, y):\n        num_examples = x.size()[0]\n\n        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(diff_norms / y_norms)\n            else:\n                return torch.sum(diff_norms / y_norms)\n\n        return diff_norms / y_norms\n\n    #def __call__(self, x, y):\n    #    return self.rel(x, y)\n    # --- UPDATE THE __call__ METHOD ---\n    def __call__(self, x, y):\n        # Calculate the primary loss (e.g., L2)\n        primary_loss = self.rel(x, y)\n\n        # If an L1 weight is specified, calculate and add the L1 loss\n        if self.l1_weight > 0:\n            # Temporarily set p=1 to calculate L1 loss\n            original_p = self.p\n            self.p = 1\n            l1_loss = self.rel(x, y)\n            self.p = original_p  # Restore original p\n\n            # Return the weighted combination\n            return (1.0 - self.l1_weight) * primary_loss + self.l1_weight * l1_loss\n        else:\n            # If no L1 weight, return the primary loss as before\n            return primary_loss\n\n\n# Sobolev norm (HS norm)\n# where we also compare the numerical derivatives between the output and target\nclass HsLoss(object):\n    def __init__(self, d=2, p=2, k=1, a=None, group=False, size_average=True, reduction=True):\n        super(HsLoss, self).__init__()\n\n        # Dimension and Lp-norm type are postive\n        assert d > 0 and p > 0\n\n        self.d = d\n        self.p = p\n        self.k = k\n        self.balanced = group\n        self.reduction = reduction\n        self.size_average = size_average\n\n        if a == None:\n            a = [1, ] * k\n        self.a = a\n\n    def rel(self, x, y):\n        num_examples = x.size()[0]\n        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(diff_norms / y_norms)\n            else:\n                return torch.sum(diff_norms / y_norms)\n        return diff_norms / y_norms\n\n    def __call__(self, x, y, a=None):\n        nx = x.size()[1]\n        ny = x.size()[2]\n        k = self.k\n        balanced = self.balanced\n        a = self.a\n        x = x.view(x.shape[0], nx, ny, -1)\n        y = y.view(y.shape[0], nx, ny, -1)\n\n        k_x = torch.cat((torch.arange(start=0, end=nx // 2, step=1), torch.arange(start=-nx // 2, end=0, step=1)),\n                        0).reshape(nx, 1).repeat(1, ny)\n        k_y = torch.cat((torch.arange(start=0, end=ny // 2, step=1), torch.arange(start=-ny // 2, end=0, step=1)),\n                        0).reshape(1, ny).repeat(nx, 1)\n        k_x = torch.abs(k_x).reshape(1, nx, ny, 1).to(x.device)\n        k_y = torch.abs(k_y).reshape(1, nx, ny, 1).to(x.device)\n\n        x = torch.fft.fftn(x, dim=[1, 2])\n        y = torch.fft.fftn(y, dim=[1, 2])\n\n        if balanced == False:\n            weight = 1\n            if k >= 1:\n                weight += a[0] ** 2 * (k_x ** 2 + k_y ** 2)\n            if k >= 2:\n                weight += a[1] ** 2 * (k_x ** 4 + 2 * k_x ** 2 * k_y ** 2 + k_y ** 4)\n            weight = torch.sqrt(weight)\n            loss = self.rel(x * weight, y * weight)\n        else:\n            loss = self.rel(x, y)\n            if k >= 1:\n                weight = a[0] * torch.sqrt(k_x ** 2 + k_y ** 2)\n                loss += self.rel(x * weight, y * weight)\n            if k >= 2:\n                weight = a[1] * torch.sqrt(k_x ** 4 + 2 * k_x ** 2 * k_y ** 2 + k_y ** 4)\n                loss += self.rel(x * weight, y * weight)\n            loss = loss / (k + 1)\n\n        return loss\n\n\n# A simple feedforward neural network\nclass DenseNet(torch.nn.Module):\n    def __init__(self, layers, nonlinearity, out_nonlinearity=None, normalize=False):\n        super(DenseNet, self).__init__()\n\n        self.n_layers = len(layers) - 1\n\n        assert self.n_layers >= 1\n\n        self.layers = nn.ModuleList()\n\n        for j in range(self.n_layers):\n            self.layers.append(nn.Linear(layers[j], layers[j + 1]))\n\n            if j != self.n_layers - 1:\n                if normalize:\n                    self.layers.append(nn.BatchNorm1d(layers[j + 1]))\n\n                self.layers.append(nonlinearity())\n\n        if out_nonlinearity is not None:\n            self.layers.append(out_nonlinearity())\n\n    def forward(self, x):\n        for _, l in enumerate(self.layers):\n            x = l(x)\n\n        return x\n\n\n# print the number of parameters\ndef count_params(model):\n    c = 0\n    for p in list(model.parameters()):\n        c += reduce(operator.mul, list(p.size() + (2,) if p.is_complex() else p.size()))\n    return c\n\n\nclass ImportDataset(Dataset):\n    def __init__(self, parent_dir, matlab_dataset, normalized, T_in, T_out):\n        self.y = None # Stores target\n        self.x = None # Stores input\n        '''\n        The values for x and y are not yet available but will be assigned later (inside the set_data() method).\n        '''\n        self.T_in = T_in\n        self.T_out = T_out\n        self.normalized = normalized\n        self.normalizer_x = None\n        self.normalizer_y = None\n\n        matlab_dataset = parent_dir + matlab_dataset\n        python_dataset = matlab_dataset.replace('.mat', '.pt')\n        #python_dataset = matlab_dataset.replace('.npz', '.pt')\n        os.makedirs(parent_dir, exist_ok=True)\n\n        if os.path.exists(python_dataset):\n            print(\"Found saved dataset at\", python_dataset)\n            self.data = torch.load(python_dataset)['data']\n        else:\n            reader = MatReader(matlab_dataset)\n            self.data = reader.read_field('phi')\n            torch.save({'data': self.data}, python_dataset)\n        self.set_data()\n\n    def set_data(self):\n        permute_order = list(range(self.data.ndim))\n        permute_order.append(permute_order.pop(1))  # Move the second dimension to the end\n        self.x = self.data[:, 0:self.T_in, *[slice(None)] * (self.data.ndim - 3)].permute(*permute_order)\n        self.y = self.data[:, self.T_in:self.T_in + self.T_out, *[slice(None)] * (\n                self.data.ndim - 3)].permute(*permute_order)\n       # print(self.x.shape)\n       # print(self.y.shape)\n        if self.normalized:\n            self.make_normal()\n\n    def make_normal(self):\n        self.normalizer_x = UnitGaussianNormalizer(self.x)\n        self.normalizer_y = UnitGaussianNormalizer(self.y)\n        self.x = self.normalizer_x.encode(self.x)\n        self.y = self.normalizer_y.encode(self.y)\n\n    def __len__(self):\n        return self.x.shape[0]\n\n    def __getitem__(self, idx):\n        return self.x[idx], self.y[idx]\n\n\nclass ModelEvaluator:\n    def __init__(self, model, test_dataset, s, T_in, T_out, device, normalized=False, normalizers=None,\n                 time_history=False):\n        self.model = model\n        self.test_dataset = test_dataset\n        self.s = s\n        self.T_in = T_in\n        self.T_out = T_out\n        self.device = device\n        self.normalized = normalized\n        self.time_history = time_history\n        self.normalizer_x = normalizers[0].to(self.device)\n        self.normalizer_y = normalizers[1].to(self.device)\n        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n        spatial_dims = [s] * (len(test_dataset[0][0].shape) - 1)\n        self.inp = torch.zeros((len(test_dataset), *spatial_dims, T_in))\n        self.exact = torch.zeros((len(test_dataset), *spatial_dims, T_out))\n        self.pred = torch.zeros((len(test_dataset), *spatial_dims, T_out))\n        self.test_l2_set = []\n\n    def evaluate(self, loss_fn):\n        if self.time_history:\n            index = 0\n            step = 1\n            with torch.no_grad():\n                for xx, yy in self.test_loader:\n                    self.inp[index] = xx.squeeze(0)\n                    xx, yy = xx.to(self.device), yy.to(self.device)\n\n                    for t in range(0, self.T_out, step):\n                        y = yy[..., t:t + step]\n                        im = self.model(xx)\n                        # loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n                        if t == 0:\n                            pred = im\n                        else:\n                            pred = torch.cat((pred, im), -1)\n                        xx = torch.cat((xx[..., step:], im), dim=-1)\n\n                    self.exact[index] = yy.squeeze(0)\n                    self.pred[index] = pred.squeeze(0)\n                    test_l2 = loss_fn(pred.view(1, -1), yy.view(1, -1)).item()\n                    self.test_l2_set.append(test_l2)\n                    #print(index, test_l2)\n                    index += 1\n\n        else:\n            index = 0\n            with torch.no_grad():\n                for x, y in self.test_loader:\n                    x, y = x.to(self.device), y.to(self.device)\n                    out = self.model(x)\n                    if self.normalized:\n                        out = self.normalizer_y.decode(out)\n                        y = self.normalizer_y.decode(y)\n                        x = self.normalizer_x.decode(x)\n                    self.inp[index] = x.squeeze(0)\n                    self.exact[index] = y.squeeze(0)\n                    self.pred[index] = out.squeeze(0)\n                    test_l2 = loss_fn(out.view(1, -1), y.view(1, -1)).item()\n                    self.test_l2_set.append(test_l2)\n                    #print(index, test_l2)\n                    index += 1\n\n        return self._compute_statistics()\n\n    def _compute_statistics(self):\n        self.test_l2_set = torch.tensor(self.test_l2_set)\n        test_l2_avg = torch.mean(self.test_l2_set)\n        test_l2_std = torch.std(self.test_l2_set)\n        test_l2_min, min_idx = torch.min(self.test_l2_set), torch.argmin(self.test_l2_set)\n        test_l2_max, max_idx = torch.max(self.test_l2_set), torch.argmax(self.test_l2_set)\n        test_l2_mode, mode_count = torch.mode(self.test_l2_set)\n        mode_indices = torch.nonzero(self.test_l2_set == test_l2_mode).squeeze().tolist()\n\n        print(\"The average testing error is\", test_l2_avg.item())\n        print(\"Std. deviation of testing error is\", test_l2_std.item())\n        print(\"Min testing error is\", test_l2_min.item(), \"at index\", min_idx.item())\n        print(\"Max testing error is\", test_l2_max.item(), \"at index\", max_idx.item())\n        print(\"Mode of testing errors is\", test_l2_mode.item(), \"appearing\", mode_count.item(), \"times at indices\",\n              mode_indices)\n\n        return {\n            \"input\": self.inp,\n            \"exact\": self.exact,\n            \"prediction\": self.pred,\n            \"average\": test_l2_avg.item(),\n            \"std_dev\": test_l2_std.item(),\n            \"min\": {\"value\": test_l2_min.item(), \"index\": min_idx.item()},\n            \"max\": {\"value\": test_l2_max.item(), \"index\": max_idx.item()},\n            \"mode\": {\"value\": test_l2_mode.item(), \"count\": mode_count.item(), \"indices\": mode_indices}\n        }\n
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/utilities.py b/utilities.py
+--- a/utilities.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/utilities.py	(date 1754547784115)
+@@ -252,6 +252,81 @@
+             return primary_loss
+ 
+ 
++# Add this code to your utilities.py file
++
++import torch
++import torch.nn.functional as F
++
++
++# --- NEW SOBOLEV LOSS CLASS ---
++class SobolevLoss(object):
++    def __init__(self, d=3, p=2, grad_weight=0.1, size_average=False, reduction=True):
++        super(SobolevLoss, self).__init__()
++        # Ensure dimension and p-norm are valid
++        assert d > 0 and p > 0
++
++        self.d = d
++        self.p = p
++        self.reduction = reduction
++        self.size_average = size_average
++        self.grad_weight = grad_weight  # Weight for the gradient loss component
++
++    def _compute_gradients(self, x):
++        """
++        Computes spatial gradients using a 3D Sobel filter.
++        Assumes input x has shape (batch, sx, sy, sz, t)
++        """
++        # We need to operate on each time step independently
++        # and on data with shape (B, C, D, H, W) for conv3d
++
++        # Permute to (batch, t, sx, sy, sz)
++        x_permuted = x.permute(0, 4, 1, 2, 3)
++        batch_size, T, sx, sy, sz = x_permuted.shape
++
++        # Reshape to treat time steps as part of the batch for convolution
++        x_reshaped = x_permuted.reshape(batch_size * T, 1, sx, sy, sz)
++
++        # 3D Sobel filters
++        sobel_x = torch.tensor([[[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]],
++                                 [[-2, 0, 2], [-4, 0, 4], [-2, 0, 2]],
++                                 [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]]],
++                               dtype=torch.float32, device=x.device).unsqueeze(0)
++        sobel_y = sobel_x.permute(0, 1, 3, 2, 4)
++        sobel_z = sobel_x.permute(0, 1, 4, 3, 2)
++
++        grad_x = F.conv3d(x_reshaped, sobel_x, padding='same')
++        grad_y = F.conv3d(x_reshaped, sobel_y, padding='same')
++        grad_z = F.conv3d(x_reshaped, sobel_z, padding='same')
++
++        # Reshape back to (batch, t, sx, sy, sz, 3_grads)
++        grads = torch.stack([grad_x, grad_y, grad_z], dim=-1)
++        return grads.reshape(batch_size, T, sx, sy, sz, 3)
++
++    def __call__(self, x, y):
++        """
++        x: prediction, y: ground truth
++        Assumes x and y have shape (batch, sx, sy, sz, T)
++        """
++        num_examples = x.size(0)
++
++        # 1. Standard L2 Data Loss (relative)
++        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)
++        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)
++        data_loss = torch.mean(diff_norms / y_norms)
++
++        # 2. Gradient Loss
++        if self.grad_weight > 0:
++            pred_grads = self._compute_gradients(x)
++            true_grads = self._compute_gradients(y)
++            grad_loss = F.mse_loss(pred_grads, true_grads)
++
++            # Combine losses
++            total_loss = data_loss + self.grad_weight * grad_loss
++        else:
++            total_loss = data_loss
++
++        return total_loss
++
+ # Sobolev norm (HS norm)
+ # where we also compare the numerical derivatives between the output and target
+ class HsLoss(object):
+@@ -371,7 +446,7 @@
+         self.T_in = T_in
+         self.T_out = T_out
+         self.normalized = normalized
+-        self.normalizer_x = None
++        self.normalizer_x =  None
+         self.normalizer_y = None
+ 
+         matlab_dataset = parent_dir + matlab_dataset
+@@ -432,6 +507,7 @@
+         self.pred = torch.zeros((len(test_dataset), *spatial_dims, T_out))
+         self.test_l2_set = []
+ 
++    '''''
+     def evaluate(self, loss_fn):
+         if self.time_history:
+             index = 0
+@@ -477,7 +553,58 @@
+                     index += 1
+ 
+         return self._compute_statistics()
+-
++    '''
++
++    # Replace the evaluate method in your ModelEvaluator class with this one.
++
++    def evaluate(self, loss_fn):
++        if self.time_history:
++            index = 0
++            step = 1
++            with torch.no_grad():
++                for xx, yy in self.test_loader:
++                    self.inp[index] = xx.squeeze(0)
++                    xx, yy = xx.to(self.device), yy.to(self.device)
++
++                    for t in range(0, self.T_out, step):
++                        y = yy[..., t:t + step]
++                        im = self.model(xx)
++                        if t == 0:
++                            pred = im
++                        else:
++                            pred = torch.cat((pred, im), -1)
++                        xx = torch.cat((xx[..., step:], im), dim=-1)
++
++                    self.exact[index] = yy.squeeze(0)
++                    self.pred[index] = pred.squeeze(0)
++
++                    # --- CORRECTED LINE ---
++                    # Pass the un-flattened tensors directly to the loss function
++                    test_l2 = loss_fn(pred, yy).item()
++                    self.test_l2_set.append(test_l2)
++                    index += 1
++
++        else:
++            index = 0
++            with torch.no_grad():
++                for x, y in self.test_loader:
++                    x, y = x.to(self.device), y.to(self.device)
++                    out = self.model(x)
++                    if self.normalized:
++                        out = self.normalizer_y.decode(out)
++                        y = self.normalizer_y.decode(y)
++                        x = self.normalizer_x.decode(x)
++                    self.inp[index] = x.squeeze(0)
++                    self.exact[index] = y.squeeze(0)
++                    self.pred[index] = out.squeeze(0)
++
++                    # --- CORRECTED LINE ---
++                    # Pass the un-flattened tensors directly to the loss function
++                    test_l2 = loss_fn(out, y).item()
++                    self.test_l2_set.append(test_l2)
++                    index += 1
++
++        return self._compute_statistics()
+     def _compute_statistics(self):
+         self.test_l2_set = torch.tensor(self.test_l2_set)
+         test_l2_avg = torch.mean(self.test_l2_set)
+Index: .idea/workspace.xml
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"TNO3d vs FNO3d\">\n      <change afterPath=\"$PROJECT_DIR$/run_inference.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/vcs.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/vcs.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/main.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/main.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/networks.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/networks.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/post_processing.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/post_processing.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/training.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/training.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/utilities.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/utilities.py\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <excluded-from-favorite>\n      <branch-storage>\n        <map>\n          <entry type=\"LOCAL\">\n            <value>\n              <list>\n                <branch-info repo=\"$PROJECT_DIR$\" source=\"master\" />\n              </list>\n            </value>\n          </entry>\n        </map>\n      </branch-storage>\n    </excluded-from-favorite>\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\n      <map>\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\n      </map>\n    </option>\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n    <option name=\"ROOT_SYNC\" value=\"DONT_SYNC\" />\n  </component>\n  <component name=\"GitHubPullRequestSearchHistory\">{\n  &quot;lastFilter&quot;: {\n    &quot;state&quot;: &quot;OPEN&quot;,\n    &quot;assignee&quot;: &quot;MBamdad&quot;\n  }\n}</component>\n  <component name=\"GithubPullRequestsUISettings\">{\n  &quot;selectedUrlAndAccountId&quot;: {\n    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,\n    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;\n  }\n}</component>\n  <component name=\"ProjectColorInfo\">{\n  &quot;associatedIndex&quot;: 1\n}</component>\n  <component name=\"ProjectId\" id=\"2p11NySvsgjZ8eu9d53SI84567l\" />\n  <component name=\"ProjectReloadState\">\n    <option name=\"STATE\" value=\"1\" />\n  </component>\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">{\n  &quot;keyToString&quot;: {\n    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.main.executor&quot;: &quot;Run&quot;,\n    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.networks.executor&quot;: &quot;Run&quot;,\n    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,\n    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,\n    &quot;Python.test1.executor&quot;: &quot;Run&quot;,\n    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,\n    &quot;git-widget-placeholder&quot;: &quot;main&quot;,\n    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,\n    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,\n    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,\n    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,\n    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,\n    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,\n    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,\n    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;\n  },\n  &quot;keyToStringList&quot;: {\n    &quot;ChangesTree.GroupingKeys&quot;: [\n      &quot;directory&quot;\n    ]\n  }\n}</component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$/configs\" />\n      <recent name=\"$PROJECT_DIR$/AC2Dtest/models\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code/AC2D\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code\" />\n    </key>\n    <key name=\"MoveFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.AC3D_TNO3d\">\n    <configuration name=\"AC3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_TNO3d_hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"MBE3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d_Hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <list>\n      <item itemvalue=\"Python.AC3D_TNO3d\" />\n      <item itemvalue=\"Python.AC3d_FNO3d\" />\n      <item itemvalue=\"Python.AC3d_TNO3d_hybrid\" />\n      <item itemvalue=\"Python.CH3D_TNO3d\" />\n      <item itemvalue=\"Python.MBE3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_FNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d_Hybrid\" />\n    </list>\n  </component>\n  <component name=\"SharedIndexes\">\n    <attachedChunks>\n      <set>\n        <option value=\"bundled-js-predefined-1d06a55b98c1-0b3e54e931b4-JavaScript-PY-241.18034.82\" />\n        <option value=\"bundled-python-sdk-975db3bf15a3-2767605e8bc2-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-241.18034.82\" />\n      </set>\n    </attachedChunks>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"\" />\n      <created>1731918731711</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1731918731711</updated>\n      <workItem from=\"1731918732726\" duration=\"17070000\" />\n      <workItem from=\"1732010735784\" duration=\"777000\" />\n      <workItem from=\"1732011520582\" duration=\"8000\" />\n      <workItem from=\"1732011538945\" duration=\"13153000\" />\n      <workItem from=\"1732106481018\" duration=\"3721000\" />\n      <workItem from=\"1732480846034\" duration=\"2889000\" />\n      <workItem from=\"1732483872465\" duration=\"14926000\" />\n      <workItem from=\"1732567216112\" duration=\"964000\" />\n      <workItem from=\"1732765090621\" duration=\"5000\" />\n      <workItem from=\"1732765102609\" duration=\"12000\" />\n      <workItem from=\"1732765345288\" duration=\"10000\" />\n      <workItem from=\"1732903897716\" duration=\"3074000\" />\n      <workItem from=\"1732911303920\" duration=\"27201000\" />\n      <workItem from=\"1732999179592\" duration=\"8241000\" />\n      <workItem from=\"1733039613684\" duration=\"6792000\" />\n      <workItem from=\"1733095843263\" duration=\"10000\" />\n      <workItem from=\"1733140600841\" duration=\"6993000\" />\n      <workItem from=\"1733150993229\" duration=\"184000\" />\n      <workItem from=\"1733151279786\" duration=\"6000\" />\n      <workItem from=\"1733151296310\" duration=\"16875000\" />\n      <workItem from=\"1733233230739\" duration=\"5172000\" />\n      <workItem from=\"1733246997923\" duration=\"15986000\" />\n      <workItem from=\"1733349590652\" duration=\"1949000\" />\n      <workItem from=\"1733352121741\" duration=\"6332000\" />\n      <workItem from=\"1733405466233\" duration=\"12731000\" />\n      <workItem from=\"1733557048829\" duration=\"5541000\" />\n      <workItem from=\"1733583489891\" duration=\"16419000\" />\n      <workItem from=\"1733859258781\" duration=\"7356000\" />\n      <workItem from=\"1733995059967\" duration=\"7899000\" />\n      <workItem from=\"1734011167665\" duration=\"991000\" />\n      <workItem from=\"1734029966470\" duration=\"25769000\" />\n      <workItem from=\"1734205412700\" duration=\"7689000\" />\n      <workItem from=\"1734644992163\" duration=\"5017000\" />\n      <workItem from=\"1734788130789\" duration=\"2312000\" />\n      <workItem from=\"1734863751114\" duration=\"9000\" />\n      <workItem from=\"1734863775073\" duration=\"9221000\" />\n      <workItem from=\"1734880034791\" duration=\"57000\" />\n      <workItem from=\"1734880213539\" duration=\"15000\" />\n      <workItem from=\"1734880329890\" duration=\"30000\" />\n      <workItem from=\"1734880369064\" duration=\"31312000\" />\n      <workItem from=\"1734983129135\" duration=\"55000\" />\n      <workItem from=\"1735034212628\" duration=\"2274000\" />\n      <workItem from=\"1735049036048\" duration=\"5309000\" />\n      <workItem from=\"1735126261413\" duration=\"75000\" />\n      <workItem from=\"1735356723104\" duration=\"1208000\" />\n      <workItem from=\"1735422837186\" duration=\"1387000\" />\n      <workItem from=\"1735719009558\" duration=\"561000\" />\n      <workItem from=\"1736101930735\" duration=\"570000\" />\n      <workItem from=\"1736102511675\" duration=\"4000\" />\n      <workItem from=\"1736161159525\" duration=\"7670000\" />\n      <workItem from=\"1736237907904\" duration=\"111000\" />\n      <workItem from=\"1736519480236\" duration=\"1867000\" />\n      <workItem from=\"1737577034938\" duration=\"3945000\" />\n      <workItem from=\"1737590448155\" duration=\"6145000\" />\n      <workItem from=\"1738310597042\" duration=\"2502000\" />\n      <workItem from=\"1738316162773\" duration=\"726000\" />\n      <workItem from=\"1738326887364\" duration=\"4500000\" />\n      <workItem from=\"1738586797583\" duration=\"600000\" />\n      <workItem from=\"1738663690532\" duration=\"4505000\" />\n      <workItem from=\"1738668267214\" duration=\"5368000\" />\n      <workItem from=\"1738685509837\" duration=\"74000\" />\n      <workItem from=\"1738703726377\" duration=\"1677000\" />\n      <workItem from=\"1738774383038\" duration=\"2249000\" />\n      <workItem from=\"1738787637783\" duration=\"7013000\" />\n      <workItem from=\"1738962434877\" duration=\"1153000\" />\n      <workItem from=\"1738967049524\" duration=\"782000\" />\n      <workItem from=\"1739275350614\" duration=\"312000\" />\n      <workItem from=\"1739464522072\" duration=\"12498000\" />\n      <workItem from=\"1739572784568\" duration=\"1228000\" />\n      <workItem from=\"1739626528163\" duration=\"5778000\" />\n      <workItem from=\"1739689815626\" duration=\"10399000\" />\n      <workItem from=\"1739812786805\" duration=\"48519000\" />\n      <workItem from=\"1740212626723\" duration=\"1263000\" />\n      <workItem from=\"1740213932190\" duration=\"644000\" />\n      <workItem from=\"1741475492994\" duration=\"40894000\" />\n      <workItem from=\"1741690305204\" duration=\"339000\" />\n      <workItem from=\"1741705983516\" duration=\"604000\" />\n      <workItem from=\"1741713165753\" duration=\"1198000\" />\n      <workItem from=\"1741861318912\" duration=\"2286000\" />\n      <workItem from=\"1742201562752\" duration=\"618000\" />\n      <workItem from=\"1742209067924\" duration=\"383000\" />\n      <workItem from=\"1742226300133\" duration=\"2432000\" />\n      <workItem from=\"1743071528350\" duration=\"9513000\" />\n      <workItem from=\"1743490058046\" duration=\"9000\" />\n      <workItem from=\"1743587112942\" duration=\"1188000\" />\n      <workItem from=\"1748900986740\" duration=\"1771000\" />\n      <workItem from=\"1748931928220\" duration=\"446000\" />\n      <workItem from=\"1748932436127\" duration=\"20890000\" />\n      <workItem from=\"1748970706276\" duration=\"3719000\" />\n      <workItem from=\"1748988822181\" duration=\"59000\" />\n      <workItem from=\"1749200290051\" duration=\"680000\" />\n      <workItem from=\"1749203502833\" duration=\"1349000\" />\n      <workItem from=\"1749213099437\" duration=\"3082000\" />\n      <workItem from=\"1750057109660\" duration=\"10453000\" />\n      <workItem from=\"1750070416210\" duration=\"46415000\" />\n    </task>\n    <task id=\"LOCAL-00001\" summary=\"Initial Commit\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732484343908</created>\n      <option name=\"number\" value=\"00001\" />\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732484343908</updated>\n    </task>\n    <task id=\"LOCAL-00002\" summary=\"added TransformerFNO\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732497990642</created>\n      <option name=\"number\" value=\"00002\" />\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732497990642</updated>\n    </task>\n    <task id=\"LOCAL-00003\" summary=\"added the connection between time steps - the model development is finished\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732910153380</created>\n      <option name=\"number\" value=\"00003\" />\n      <option name=\"presentableId\" value=\"LOCAL-00003\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732910153380</updated>\n    </task>\n    <task id=\"LOCAL-00004\" summary=\"Finished Allen-Cahn Problem\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733176021525</created>\n      <option name=\"number\" value=\"00004\" />\n      <option name=\"presentableId\" value=\"LOCAL-00004\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733176021525</updated>\n    </task>\n    <task id=\"LOCAL-00005\" summary=\"Added Allen-Cahn 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733583274023</created>\n      <option name=\"number\" value=\"00005\" />\n      <option name=\"presentableId\" value=\"LOCAL-00005\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733583274023</updated>\n    </task>\n    <task id=\"LOCAL-00006\" summary=\"added save_vtk\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733995237535</created>\n      <option name=\"number\" value=\"00006\" />\n      <option name=\"presentableId\" value=\"LOCAL-00006\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733995237535</updated>\n    </task>\n    <task id=\"LOCAL-00007\" summary=\"added MATLAB codes for creating database\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1734788540933</created>\n      <option name=\"number\" value=\"00007\" />\n      <option name=\"presentableId\" value=\"LOCAL-00007\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1734788540933</updated>\n    </task>\n    <task id=\"LOCAL-00008\" summary=\"added CH2DNL\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735126332032</created>\n      <option name=\"number\" value=\"00008\" />\n      <option name=\"presentableId\" value=\"LOCAL-00008\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735126332032</updated>\n    </task>\n    <task id=\"LOCAL-00009\" summary=\"added SH2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735719422931</created>\n      <option name=\"number\" value=\"00009\" />\n      <option name=\"presentableId\" value=\"LOCAL-00009\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735719422931</updated>\n    </task>\n    <task id=\"LOCAL-00010\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1736237977029</created>\n      <option name=\"number\" value=\"00010\" />\n      <option name=\"presentableId\" value=\"LOCAL-00010\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1736237977029</updated>\n    </task>\n    <task id=\"LOCAL-00011\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738788849261</created>\n      <option name=\"number\" value=\"00011\" />\n      <option name=\"presentableId\" value=\"LOCAL-00011\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738788849261</updated>\n    </task>\n    <task id=\"LOCAL-00012\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738789326593</created>\n      <option name=\"number\" value=\"00012\" />\n      <option name=\"presentableId\" value=\"LOCAL-00012\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738789326593</updated>\n    </task>\n    <task id=\"LOCAL-00013\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738796104012</created>\n      <option name=\"number\" value=\"00013\" />\n      <option name=\"presentableId\" value=\"LOCAL-00013\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738796104012</updated>\n    </task>\n    <task id=\"LOCAL-00014\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962464719</created>\n      <option name=\"number\" value=\"00014\" />\n      <option name=\"presentableId\" value=\"LOCAL-00014\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962464719</updated>\n    </task>\n    <task id=\"LOCAL-00015\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962748829</created>\n      <option name=\"number\" value=\"00015\" />\n      <option name=\"presentableId\" value=\"LOCAL-00015\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962748829</updated>\n    </task>\n    <task id=\"LOCAL-00016\" summary=\"Turn Nx to 64\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738967163754</created>\n      <option name=\"number\" value=\"00016\" />\n      <option name=\"presentableId\" value=\"LOCAL-00016\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738967163754</updated>\n    </task>\n    <task id=\"LOCAL-00017\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275401458</created>\n      <option name=\"number\" value=\"00017\" />\n      <option name=\"presentableId\" value=\"LOCAL-00017\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275401458</updated>\n    </task>\n    <task id=\"LOCAL-00018\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275433418</created>\n      <option name=\"number\" value=\"00018\" />\n      <option name=\"presentableId\" value=\"LOCAL-00018\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275433418</updated>\n    </task>\n    <task id=\"LOCAL-00019\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690373369</created>\n      <option name=\"number\" value=\"00019\" />\n      <option name=\"presentableId\" value=\"LOCAL-00019\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690373369</updated>\n    </task>\n    <task id=\"LOCAL-00020\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690420059</created>\n      <option name=\"number\" value=\"00020\" />\n      <option name=\"presentableId\" value=\"LOCAL-00020\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690420059</updated>\n    </task>\n    <task id=\"LOCAL-00021\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1743587271259</created>\n      <option name=\"number\" value=\"00021\" />\n      <option name=\"presentableId\" value=\"LOCAL-00021\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1743587271259</updated>\n    </task>\n    <option name=\"localTasksCounter\" value=\"22\" />\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"Vcs.Log.Tabs.Properties\">\n    <option name=\"RECENT_FILTERS\">\n      <map>\n        <entry key=\"Branch\">\n          <value>\n            <list>\n              <RecentGroup>\n                <option name=\"FILTER_VALUES\">\n                  <option value=\"main\" />\n                </option>\n              </RecentGroup>\n            </list>\n          </value>\n        </entry>\n      </map>\n    </option>\n    <option name=\"TAB_STATES\">\n      <map>\n        <entry key=\"MAIN\">\n          <value>\n            <State>\n              <option name=\"FILTERS\">\n                <map>\n                  <entry key=\"branch\">\n                    <value>\n                      <list>\n                        <option value=\"main\" />\n                      </list>\n                    </value>\n                  </entry>\n                </map>\n              </option>\n            </State>\n          </value>\n        </entry>\n      </map>\n    </option>\n  </component>\n  <component name=\"VcsManagerConfiguration\">\n    <MESSAGE value=\"Initial Commit\" />\n    <MESSAGE value=\"added TransformerFNO\" />\n    <MESSAGE value=\"added the connection between time steps - the model development is finished\" />\n    <MESSAGE value=\"refactored\" />\n    <MESSAGE value=\"Finished Allen-Cahn Problem\" />\n    <MESSAGE value=\"Added Allen-Cahn 3D\" />\n    <MESSAGE value=\"added save_vtk\" />\n    <MESSAGE value=\"added MATLAB codes for creating database\" />\n    <MESSAGE value=\"seperated the number of layers in fourier part and convolutional part\" />\n    <MESSAGE value=\"added CH2DNL\" />\n    <MESSAGE value=\"added SH2D\" />\n    <MESSAGE value=\"added PFC2D\" />\n    <MESSAGE value=\"Turn Nx to 64\" />\n    <MESSAGE value=\"update to 3D\" />\n    <MESSAGE value=\"TNO3d vs FNO3d\" />\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"TNO3d vs FNO3d\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>142</line>\n          <option name=\"timeStamp\" value=\"17\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>163</line>\n          <option name=\"timeStamp\" value=\"18\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>134</line>\n          <option name=\"timeStamp\" value=\"19\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>327</line>\n          <option name=\"timeStamp\" value=\"20\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>243</line>\n          <option name=\"timeStamp\" value=\"21\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_2.py</url>\n          <line>333</line>\n          <option name=\"timeStamp\" value=\"27\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>\n          <line>371</line>\n          <option name=\"timeStamp\" value=\"44\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>\n          <line>338</line>\n          <option name=\"timeStamp\" value=\"54\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>53</line>\n          <option name=\"timeStamp\" value=\"128\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>30</line>\n          <option name=\"timeStamp\" value=\"129\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>25</line>\n          <option name=\"timeStamp\" value=\"133\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>18</line>\n          <option name=\"timeStamp\" value=\"135\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>\n          <line>44</line>\n          <option name=\"timeStamp\" value=\"138\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test2.py</url>\n          <line>16</line>\n          <option name=\"timeStamp\" value=\"144\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/utilities.py</url>\n          <line>98</line>\n          <option name=\"timeStamp\" value=\"170\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/main.py</url>\n          <line>157</line>\n          <option name=\"timeStamp\" value=\"177\" />\n        </line-breakpoint>\n      </breakpoints>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n  </component>\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test3.coverage\" NAME=\"Test3 Coverage Results\" MODIFIED=\"1739273938386\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage\" NAME=\"config_AC2D_FNO3d Coverage Results\" MODIFIED=\"1733233385695\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1743065376798\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_2.coverage\" NAME=\"AC2D_Net2D_2 Coverage Results\" MODIFIED=\"1732904114403\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$test2.coverage\" NAME=\"test2 Coverage Results\" MODIFIED=\"1742889074336\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1741561715014\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage\" NAME=\"config_SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254757455\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$backend_interagg.coverage\" NAME=\"backend_interagg Coverage Results\" MODIFIED=\"1737630366471\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript3.coverage\" NAME=\"RunScript3 Coverage Results\" MODIFIED=\"1736368081257\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_2.coverage\" NAME=\"AC2D_2 Coverage Results\" MODIFIED=\"1732483323689\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1733086051390\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main_TF.coverage\" NAME=\"main_TF Coverage Results\" MODIFIED=\"1738704014479\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1741538869064\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$THFNO.coverage\" NAME=\"THFNO Coverage Results\" MODIFIED=\"1732911474644\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/networks\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1740088478224\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$PFC3D.coverage\" NAME=\"PFC3D Coverage Results\" MODIFIED=\"1740083613128\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1741603428589\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$run_inference.coverage\" NAME=\"run_inference Coverage Results\" MODIFIED=\"1750323709039\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1738663765959\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$post_processing.coverage\" NAME=\"post_processing Coverage Results\" MODIFIED=\"1733557098801\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage\" NAME=\"config_CH2D_TNO2d Coverage Results\" MODIFIED=\"1734086207850\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1748933697533\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1750255151255\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript2.coverage\" NAME=\"RunScript2 Coverage Results\" MODIFIED=\"1736369209710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1742215946758\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_3.coverage\" NAME=\"AC2D_Net2D_3 Coverage Results\" MODIFIED=\"1732974697103\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_FNO3d.coverage\" NAME=\"AC3d_FNO3d Coverage Results\" MODIFIED=\"1749017845623\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D.coverage\" NAME=\"AC2D Coverage Results\" MODIFIED=\"1733088640665\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/Archive_Code\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D.coverage\" NAME=\"AC2D_Net2D Coverage Results\" MODIFIED=\"1732567473230\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1740054182408\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage\" NAME=\"MBE3D_TNO3d Coverage Results\" MODIFIED=\"1741562061391\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_AC3D_TNO3d.coverage\" NAME=\"config_AC3D_TNO3d Coverage Results\" MODIFIED=\"1737644605063\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D.coverage\" NAME=\"MBE3D Coverage Results\" MODIFIED=\"1739283566145\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1741605347375\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1743071672425\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1736268192289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage\" NAME=\"PFC3D_TNO3d Coverage Results\" MODIFIED=\"1741564210973\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage\" NAME=\"config_CH2DNL_TNO2d Coverage Results\" MODIFIED=\"1735052490996\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$MBE2D.coverage\" NAME=\"MBE2D Coverage Results\" MODIFIED=\"1732278526731\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1739914172084\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test_Run.coverage\" NAME=\"Test_Run Coverage Results\" MODIFIED=\"1738945320139\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1741561294310\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741861381348\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1743081225414\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage\" NAME=\"PFV3D_FNO3d Coverage Results\" MODIFIED=\"1741564487710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript1.coverage\" NAME=\"RunScript1 Coverage Results\" MODIFIED=\"1736368790622\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$SH2D.coverage\" NAME=\"SH2D Coverage Results\" MODIFIED=\"1732347080402\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$PFC2D.coverage\" NAME=\"PFC2D Coverage Results\" MODIFIED=\"1732278679485\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$CH2D.coverage\" NAME=\"CH2D Coverage Results\" MODIFIED=\"1732347055915\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_FNO3d.coverage\" NAME=\"AC3D_FNO3d Coverage Results\" MODIFIED=\"1741561435127\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D.coverage\" NAME=\"SH3D Coverage Results\" MODIFIED=\"1739044808411\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test.coverage\" NAME=\"Test Coverage Results\" MODIFIED=\"1739459206236\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741547133078\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage\" NAME=\"config_AC2D_FNO2d Coverage Results\" MODIFIED=\"1733393903488\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$AC3D.coverage\" NAME=\"AC3D Coverage Results\" MODIFIED=\"1740041515520\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_CH3D_TNO3d.coverage\" NAME=\"config_CH3D_TNO3d Coverage Results\" MODIFIED=\"1738089807566\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test2.coverage\" NAME=\"Test2 Coverage Results\" MODIFIED=\"1739283715182\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_FNO3d.coverage\" NAME=\"CH3D_FNO3d Coverage Results\" MODIFIED=\"1741628529142\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage\" NAME=\"AC3d_TNO3d_hybrid Coverage Results\" MODIFIED=\"1748989478372\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1737899062785\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D.coverage\" NAME=\"config_AC2D Coverage Results\" MODIFIED=\"1733087276180\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_1.coverage\" NAME=\"AC2D_Net2D_1 Coverage Results\" MODIFIED=\"1732535211383\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1736520700819\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$fourier_3d.coverage\" NAME=\"fourier_3d Coverage Results\" MODIFIED=\"1732221600628\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1750254767095\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage\" NAME=\"SH3D_TNO3d_Hybrid Coverage Results\" MODIFIED=\"1749216389646\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1748990262244\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$test1.coverage\" NAME=\"test1 Coverage Results\" MODIFIED=\"1733413325318\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_2.coverage\" NAME=\"CH3D_2 Coverage Results\" MODIFIED=\"1739918355289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254975290\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage\" NAME=\"config_MBE2D_TNO2d Coverage Results\" MODIFIED=\"1736261397712\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n  </component>\n</project>
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/.idea/workspace.xml b/.idea/workspace.xml
+--- a/.idea/workspace.xml	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/.idea/workspace.xml	(date 1754639509665)
+@@ -4,29 +4,84 @@
+     <option name="autoReloadType" value="SELECTIVE" />
+   </component>
+   <component name="ChangeListManager">
+-    <list default="true" id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="TNO3d vs FNO3d">
+-      <change afterPath="$PROJECT_DIR$/run_inference.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/.idea/vcs.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />
++    <list default="true" id="4e84c369-97f3-4301-a9fc-5fc5327e1a8a" name="Changes" comment="update matlab code">
++      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/MBE3D_Hybrid.jpg" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25,_3_40_PM_[Changes]/shelved.patch" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_1_25__3_40_PM__Changes_.xml" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/MBE3D_Hybrid.jpg" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/shelved.patch" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25__12_21_PM__Changes_.xml" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/MBE3D_Hybrid.jpg" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25,_8_23_AM_[Changes]/shelved.patch" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_7_25__8_23_AM__Changes_.xml" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/MBE3D/plots_Data_Physics_TNO3d/MBE3D_Hybrid.jpg" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/.gitignore" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/PFC3D.iml" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/inspectionProfiles/Project_Default.xml" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/inspectionProfiles/profiles_settings.xml" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/misc.xml" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/modules.xml" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/vcs.xml" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.h5" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO4d.py" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/configs/config_CH3D_FNO4d.py" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/configs/config_MBE3D_FNO4d.py" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/configs/config_PFC3D_FNO4d.py" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO4d.py" afterDir="false" />
++      <change afterPath="$PROJECT_DIR$/run_interface.py" afterDir="false" />
+       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png" beforeDir="false" />
+-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_FNO3d/combined_results.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_rand.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_random_new.asv" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_random_new.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_test.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/MBE2D.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/MBE2D_rand.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/PFC2D.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/PFC2D_rand.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH2D.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH2D_rand.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH3D_rand.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/MatlabCode/middle.m" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_field_comparison.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_loss_curve_mixed.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison_FINAL.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_loss_curve.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/combined_results.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison_mixed.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_loss_curve_mixed.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/combined_results.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/SH3D_Comparison_Plot_Modified_PIMHNO.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" beforeDir="false" afterPath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" afterDir="false" />
++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" beforeDir="false" afterPath="$PROJECT_DIR$/SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" afterDir="false" />
++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/CH3D_Comparison_star_SANO.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_Comparison_Plot_Modified.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_SANO_field_comparison.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
+       <change beforePath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" afterDir="false" />
+       <change beforePath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" afterDir="false" />
++      <change beforePath="$PROJECT_DIR$/configs/config_CH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_CH3D_FNO3d.py" afterDir="false" />
++      <change beforePath="$PROJECT_DIR$/configs/config_CH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_CH3D_TNO3d.py" afterDir="false" />
++      <change beforePath="$PROJECT_DIR$/configs/config_MBE3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_MBE3D_FNO3d.py" afterDir="false" />
++      <change beforePath="$PROJECT_DIR$/configs/config_MBE3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_MBE3D_TNO3d.py" afterDir="false" />
++      <change beforePath="$PROJECT_DIR$/configs/config_PFC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_PFC3D_FNO3d.py" afterDir="false" />
++      <change beforePath="$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py" afterDir="false" />
+       <change beforePath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" afterDir="false" />
+       <change beforePath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" afterDir="false" />
+       <change beforePath="$PROJECT_DIR$/main.py" beforeDir="false" afterPath="$PROJECT_DIR$/main.py" afterDir="false" />
++      <change beforePath="$PROJECT_DIR$/main1.py" beforeDir="false" afterPath="$PROJECT_DIR$/main1.py" afterDir="false" />
+       <change beforePath="$PROJECT_DIR$/networks.py" beforeDir="false" afterPath="$PROJECT_DIR$/networks.py" afterDir="false" />
+-      <change beforePath="$PROJECT_DIR$/post_processing.py" beforeDir="false" afterPath="$PROJECT_DIR$/post_processing.py" afterDir="false" />
++      <change beforePath="$PROJECT_DIR$/run_inference.py" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/run_interface2.py" beforeDir="false" />
++      <change beforePath="$PROJECT_DIR$/run_interface3.py" beforeDir="false" />
+       <change beforePath="$PROJECT_DIR$/training.py" beforeDir="false" afterPath="$PROJECT_DIR$/training.py" afterDir="false" />
+       <change beforePath="$PROJECT_DIR$/utilities.py" beforeDir="false" afterPath="$PROJECT_DIR$/utilities.py" afterDir="false" />
+     </list>
+@@ -43,163 +98,49 @@
+     </option>
+   </component>
+   <component name="Git.Settings">
+-    <excluded-from-favorite>
+-      <branch-storage>
+-        <map>
+-          <entry type="LOCAL">
+-            <value>
+-              <list>
+-                <branch-info repo="$PROJECT_DIR$" source="master" />
+-              </list>
+-            </value>
+-          </entry>
+-        </map>
+-      </branch-storage>
+-    </excluded-from-favorite>
+-    <option name="RECENT_BRANCH_BY_REPOSITORY">
+-      <map>
+-        <entry key="$PROJECT_DIR$" value="main" />
+-      </map>
+-    </option>
+     <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
+-    <option name="ROOT_SYNC" value="DONT_SYNC" />
+   </component>
+-  <component name="GitHubPullRequestSearchHistory">{
+-  &quot;lastFilter&quot;: {
+-    &quot;state&quot;: &quot;OPEN&quot;,
+-    &quot;assignee&quot;: &quot;MBamdad&quot;
+-  }
+-}</component>
+-  <component name="GithubPullRequestsUISettings">{
+-  &quot;selectedUrlAndAccountId&quot;: {
+-    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,
+-    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;
+-  }
+-}</component>
+   <component name="ProjectColorInfo">{
++  &quot;customColor&quot;: &quot;&quot;,
+   &quot;associatedIndex&quot;: 1
+ }</component>
+-  <component name="ProjectId" id="2p11NySvsgjZ8eu9d53SI84567l" />
+-  <component name="ProjectReloadState">
+-    <option name="STATE" value="1" />
+-  </component>
++  <component name="ProjectId" id="30Ji1A2o7U8uDkwC8cwxQfRFc4k" />
+   <component name="ProjectViewState">
+     <option name="hideEmptyMiddlePackages" value="true" />
+     <option name="showLibraryContents" value="true" />
+   </component>
+   <component name="PropertiesComponent">{
+   &quot;keyToString&quot;: {
+-    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,
+-    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,
+-    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,
+-    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.Test.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,
+-    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,
+-    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,
+-    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,
++    &quot;Python.CH3D_FNO4d.executor&quot;: &quot;Run&quot;,
++    &quot;Python.PFC3D_FNO4d.executor&quot;: &quot;Run&quot;,
++    &quot;Python.SH3D_FNO4d.executor&quot;: &quot;Run&quot;,
++    &quot;Python.SH3D_Hybrid.executor&quot;: &quot;Run&quot;,
++    &quot;Python.SH3D_TNO3D.executor&quot;: &quot;Run&quot;,
+     &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,
+     &quot;Python.main.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,
+-    &quot;Python.networks.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,
+-    &quot;Python.test1.executor&quot;: &quot;Run&quot;,
++    &quot;Python.main1.executor&quot;: &quot;Run&quot;,
++    &quot;Python.run_interface3.executor&quot;: &quot;Run&quot;,
+     &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
+     &quot;git-widget-placeholder&quot;: &quot;main&quot;,
+-    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,
++    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/MatlabCode&quot;,
+     &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
+-    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,
+     &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
+     &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,
+     &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,
+-    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,
+     &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;
+-  },
+-  &quot;keyToStringList&quot;: {
+-    &quot;ChangesTree.GroupingKeys&quot;: [
+-      &quot;directory&quot;
+-    ]
+   }
+ }</component>
+   <component name="RecentsManager">
+     <key name="CopyFile.RECENT_KEYS">
+-      <recent name="$PROJECT_DIR$/data" />
+-      <recent name="$PROJECT_DIR$/configs" />
+-      <recent name="$PROJECT_DIR$/AC2Dtest/models" />
+-      <recent name="$PROJECT_DIR$/Archive_Code/AC2D" />
+-      <recent name="$PROJECT_DIR$/Archive_Code" />
+-    </key>
+-    <key name="MoveFile.RECENT_KEYS">
+-      <recent name="$PROJECT_DIR$/data" />
+-      <recent name="$PROJECT_DIR$" />
++      <recent name="$PROJECT_DIR$/MatlabCode" />
++      <recent name="$PROJECT_DIR$/MatlabCode/Out_Distribution" />
++      <recent name="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d" />
++      <recent name="$PROJECT_DIR$/PFC3D/plots_TNO3d" />
++      <recent name="$PROJECT_DIR$/MBE3D/plots_Data_Physics_TNO3d" />
+     </key>
+   </component>
+-  <component name="RunManager" selected="Python.AC3D_TNO3d">
+-    <configuration name="AC3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
+-      <module name="PhaseFieldNet" />
+-      <option name="ENV_FILES" value="" />
+-      <option name="INTERPRETER_OPTIONS" value="" />
+-      <option name="PARENT_ENVS" value="true" />
+-      <envs>
+-        <env name="PYTHONUNBUFFERED" value="1" />
+-      </envs>
+-      <option name="SDK_HOME" value="" />
+-      <option name="SDK_NAME" value="torch_env (2)" />
+-      <option name="WORKING_DIRECTORY" value="" />
+-      <option name="IS_MODULE_SDK" value="false" />
+-      <option name="ADD_CONTENT_ROOTS" value="true" />
+-      <option name="ADD_SOURCE_ROOTS" value="true" />
+-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
+-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
+-      <option name="PARAMETERS" value="" />
+-      <option name="SHOW_COMMAND_LINE" value="false" />
+-      <option name="EMULATE_TERMINAL" value="false" />
+-      <option name="MODULE_MODE" value="false" />
+-      <option name="REDIRECT_INPUT" value="false" />
+-      <option name="INPUT_FILE" value="" />
+-      <method v="2" />
+-    </configuration>
+-    <configuration name="AC3d_FNO3d" type="PythonConfigurationType" factoryName="Python">
++  <component name="RunManager" selected="Python.SH3D_FNO4d">
++    <configuration name="CH3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
+       <module name="PhaseFieldNet" />
+       <option name="ENV_FILES" value="" />
+       <option name="INTERPRETER_OPTIONS" value="" />
+@@ -223,7 +164,7 @@
+       <option name="INPUT_FILE" value="" />
+       <method v="2" />
+     </configuration>
+-    <configuration name="AC3d_TNO3d_hybrid" type="PythonConfigurationType" factoryName="Python">
++    <configuration name="PFC3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
+       <module name="PhaseFieldNet" />
+       <option name="ENV_FILES" value="" />
+       <option name="INTERPRETER_OPTIONS" value="" />
+@@ -247,103 +188,7 @@
+       <option name="INPUT_FILE" value="" />
+       <method v="2" />
+     </configuration>
+-    <configuration name="CH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
+-      <module name="PhaseFieldNet" />
+-      <option name="ENV_FILES" value="" />
+-      <option name="INTERPRETER_OPTIONS" value="" />
+-      <option name="PARENT_ENVS" value="true" />
+-      <envs>
+-        <env name="PYTHONUNBUFFERED" value="1" />
+-      </envs>
+-      <option name="SDK_HOME" value="" />
+-      <option name="SDK_NAME" value="torch_env (2)" />
+-      <option name="WORKING_DIRECTORY" value="" />
+-      <option name="IS_MODULE_SDK" value="false" />
+-      <option name="ADD_CONTENT_ROOTS" value="true" />
+-      <option name="ADD_SOURCE_ROOTS" value="true" />
+-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
+-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
+-      <option name="PARAMETERS" value="" />
+-      <option name="SHOW_COMMAND_LINE" value="false" />
+-      <option name="EMULATE_TERMINAL" value="false" />
+-      <option name="MODULE_MODE" value="false" />
+-      <option name="REDIRECT_INPUT" value="false" />
+-      <option name="INPUT_FILE" value="" />
+-      <method v="2" />
+-    </configuration>
+-    <configuration name="CH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
+-      <module name="PhaseFieldNet" />
+-      <option name="ENV_FILES" value="" />
+-      <option name="INTERPRETER_OPTIONS" value="" />
+-      <option name="PARENT_ENVS" value="true" />
+-      <envs>
+-        <env name="PYTHONUNBUFFERED" value="1" />
+-      </envs>
+-      <option name="SDK_HOME" value="" />
+-      <option name="SDK_NAME" value="torch_env (2)" />
+-      <option name="WORKING_DIRECTORY" value="" />
+-      <option name="IS_MODULE_SDK" value="false" />
+-      <option name="ADD_CONTENT_ROOTS" value="true" />
+-      <option name="ADD_SOURCE_ROOTS" value="true" />
+-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
+-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
+-      <option name="PARAMETERS" value="" />
+-      <option name="SHOW_COMMAND_LINE" value="false" />
+-      <option name="EMULATE_TERMINAL" value="false" />
+-      <option name="MODULE_MODE" value="false" />
+-      <option name="REDIRECT_INPUT" value="false" />
+-      <option name="INPUT_FILE" value="" />
+-      <method v="2" />
+-    </configuration>
+-    <configuration name="MBE3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
+-      <module name="PhaseFieldNet" />
+-      <option name="ENV_FILES" value="" />
+-      <option name="INTERPRETER_OPTIONS" value="" />
+-      <option name="PARENT_ENVS" value="true" />
+-      <envs>
+-        <env name="PYTHONUNBUFFERED" value="1" />
+-      </envs>
+-      <option name="SDK_HOME" value="" />
+-      <option name="SDK_NAME" value="torch_env (2)" />
+-      <option name="WORKING_DIRECTORY" value="" />
+-      <option name="IS_MODULE_SDK" value="false" />
+-      <option name="ADD_CONTENT_ROOTS" value="true" />
+-      <option name="ADD_SOURCE_ROOTS" value="true" />
+-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
+-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
+-      <option name="PARAMETERS" value="" />
+-      <option name="SHOW_COMMAND_LINE" value="false" />
+-      <option name="EMULATE_TERMINAL" value="false" />
+-      <option name="MODULE_MODE" value="false" />
+-      <option name="REDIRECT_INPUT" value="false" />
+-      <option name="INPUT_FILE" value="" />
+-      <method v="2" />
+-    </configuration>
+-    <configuration name="SH3D_FNO3d" type="PythonConfigurationType" factoryName="Python">
+-      <module name="PhaseFieldNet" />
+-      <option name="ENV_FILES" value="" />
+-      <option name="INTERPRETER_OPTIONS" value="" />
+-      <option name="PARENT_ENVS" value="true" />
+-      <envs>
+-        <env name="PYTHONUNBUFFERED" value="1" />
+-      </envs>
+-      <option name="SDK_HOME" value="" />
+-      <option name="SDK_NAME" value="torch_env (2)" />
+-      <option name="WORKING_DIRECTORY" value="" />
+-      <option name="IS_MODULE_SDK" value="false" />
+-      <option name="ADD_CONTENT_ROOTS" value="true" />
+-      <option name="ADD_SOURCE_ROOTS" value="true" />
+-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
+-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
+-      <option name="PARAMETERS" value="" />
+-      <option name="SHOW_COMMAND_LINE" value="false" />
+-      <option name="EMULATE_TERMINAL" value="false" />
+-      <option name="MODULE_MODE" value="false" />
+-      <option name="REDIRECT_INPUT" value="false" />
+-      <option name="INPUT_FILE" value="" />
+-      <method v="2" />
+-    </configuration>
+-    <configuration name="SH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++    <configuration name="SH3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
+       <module name="PhaseFieldNet" />
+       <option name="ENV_FILES" value="" />
+       <option name="INTERPRETER_OPTIONS" value="" />
+@@ -352,31 +197,7 @@
+         <env name="PYTHONUNBUFFERED" value="1" />
+       </envs>
+       <option name="SDK_HOME" value="" />
+-      <option name="SDK_NAME" value="torch_env (2)" />
+-      <option name="WORKING_DIRECTORY" value="" />
+-      <option name="IS_MODULE_SDK" value="false" />
+-      <option name="ADD_CONTENT_ROOTS" value="true" />
+-      <option name="ADD_SOURCE_ROOTS" value="true" />
+-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
+-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
+-      <option name="PARAMETERS" value="" />
+-      <option name="SHOW_COMMAND_LINE" value="false" />
+-      <option name="EMULATE_TERMINAL" value="false" />
+-      <option name="MODULE_MODE" value="false" />
+-      <option name="REDIRECT_INPUT" value="false" />
+-      <option name="INPUT_FILE" value="" />
+-      <method v="2" />
+-    </configuration>
+-    <configuration name="SH3D_TNO3d_Hybrid" type="PythonConfigurationType" factoryName="Python">
+-      <module name="PhaseFieldNet" />
+-      <option name="ENV_FILES" value="" />
+-      <option name="INTERPRETER_OPTIONS" value="" />
+-      <option name="PARENT_ENVS" value="true" />
+-      <envs>
+-        <env name="PYTHONUNBUFFERED" value="1" />
+-      </envs>
+-      <option name="SDK_HOME" value="" />
+-      <option name="SDK_NAME" value="torch_env (2)" />
++      <option name="SDK_NAME" value="torch_env" />
+       <option name="WORKING_DIRECTORY" value="" />
+       <option name="IS_MODULE_SDK" value="false" />
+       <option name="ADD_CONTENT_ROOTS" value="true" />
+@@ -392,14 +213,9 @@
+       <method v="2" />
+     </configuration>
+     <list>
+-      <item itemvalue="Python.AC3D_TNO3d" />
+-      <item itemvalue="Python.AC3d_FNO3d" />
+-      <item itemvalue="Python.AC3d_TNO3d_hybrid" />
+-      <item itemvalue="Python.CH3D_TNO3d" />
+-      <item itemvalue="Python.MBE3D_TNO3d" />
+-      <item itemvalue="Python.SH3D_FNO3d" />
+-      <item itemvalue="Python.SH3D_TNO3d" />
+-      <item itemvalue="Python.SH3D_TNO3d_Hybrid" />
++      <item itemvalue="Python.CH3D_FNO4d" />
++      <item itemvalue="Python.PFC3D_FNO4d" />
++      <item itemvalue="Python.SH3D_FNO4d" />
+     </list>
+   </component>
+   <component name="SharedIndexes">
+@@ -413,501 +229,404 @@
+   <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
+   <component name="TaskManager">
+     <task active="true" id="Default" summary="Default task">
+-      <changelist id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="" />
+-      <created>1731918731711</created>
++      <changelist id="4e84c369-97f3-4301-a9fc-5fc5327e1a8a" name="Changes" comment="3d_phase_evolution" />
++      <created>1753351859462</created>
+       <option name="number" value="Default" />
+       <option name="presentableId" value="Default" />
+-      <updated>1731918731711</updated>
+-      <workItem from="1731918732726" duration="17070000" />
+-      <workItem from="1732010735784" duration="777000" />
+-      <workItem from="1732011520582" duration="8000" />
+-      <workItem from="1732011538945" duration="13153000" />
+-      <workItem from="1732106481018" duration="3721000" />
+-      <workItem from="1732480846034" duration="2889000" />
+-      <workItem from="1732483872465" duration="14926000" />
+-      <workItem from="1732567216112" duration="964000" />
+-      <workItem from="1732765090621" duration="5000" />
+-      <workItem from="1732765102609" duration="12000" />
+-      <workItem from="1732765345288" duration="10000" />
+-      <workItem from="1732903897716" duration="3074000" />
+-      <workItem from="1732911303920" duration="27201000" />
+-      <workItem from="1732999179592" duration="8241000" />
+-      <workItem from="1733039613684" duration="6792000" />
+-      <workItem from="1733095843263" duration="10000" />
+-      <workItem from="1733140600841" duration="6993000" />
+-      <workItem from="1733150993229" duration="184000" />
+-      <workItem from="1733151279786" duration="6000" />
+-      <workItem from="1733151296310" duration="16875000" />
+-      <workItem from="1733233230739" duration="5172000" />
+-      <workItem from="1733246997923" duration="15986000" />
+-      <workItem from="1733349590652" duration="1949000" />
+-      <workItem from="1733352121741" duration="6332000" />
+-      <workItem from="1733405466233" duration="12731000" />
+-      <workItem from="1733557048829" duration="5541000" />
+-      <workItem from="1733583489891" duration="16419000" />
+-      <workItem from="1733859258781" duration="7356000" />
+-      <workItem from="1733995059967" duration="7899000" />
+-      <workItem from="1734011167665" duration="991000" />
+-      <workItem from="1734029966470" duration="25769000" />
+-      <workItem from="1734205412700" duration="7689000" />
+-      <workItem from="1734644992163" duration="5017000" />
+-      <workItem from="1734788130789" duration="2312000" />
+-      <workItem from="1734863751114" duration="9000" />
+-      <workItem from="1734863775073" duration="9221000" />
+-      <workItem from="1734880034791" duration="57000" />
+-      <workItem from="1734880213539" duration="15000" />
+-      <workItem from="1734880329890" duration="30000" />
+-      <workItem from="1734880369064" duration="31312000" />
+-      <workItem from="1734983129135" duration="55000" />
+-      <workItem from="1735034212628" duration="2274000" />
+-      <workItem from="1735049036048" duration="5309000" />
+-      <workItem from="1735126261413" duration="75000" />
+-      <workItem from="1735356723104" duration="1208000" />
+-      <workItem from="1735422837186" duration="1387000" />
+-      <workItem from="1735719009558" duration="561000" />
+-      <workItem from="1736101930735" duration="570000" />
+-      <workItem from="1736102511675" duration="4000" />
+-      <workItem from="1736161159525" duration="7670000" />
+-      <workItem from="1736237907904" duration="111000" />
+-      <workItem from="1736519480236" duration="1867000" />
+-      <workItem from="1737577034938" duration="3945000" />
+-      <workItem from="1737590448155" duration="6145000" />
+-      <workItem from="1738310597042" duration="2502000" />
+-      <workItem from="1738316162773" duration="726000" />
+-      <workItem from="1738326887364" duration="4500000" />
+-      <workItem from="1738586797583" duration="600000" />
+-      <workItem from="1738663690532" duration="4505000" />
+-      <workItem from="1738668267214" duration="5368000" />
+-      <workItem from="1738685509837" duration="74000" />
+-      <workItem from="1738703726377" duration="1677000" />
+-      <workItem from="1738774383038" duration="2249000" />
+-      <workItem from="1738787637783" duration="7013000" />
+-      <workItem from="1738962434877" duration="1153000" />
+-      <workItem from="1738967049524" duration="782000" />
+-      <workItem from="1739275350614" duration="312000" />
+-      <workItem from="1739464522072" duration="12498000" />
+-      <workItem from="1739572784568" duration="1228000" />
+-      <workItem from="1739626528163" duration="5778000" />
+-      <workItem from="1739689815626" duration="10399000" />
+-      <workItem from="1739812786805" duration="48519000" />
+-      <workItem from="1740212626723" duration="1263000" />
+-      <workItem from="1740213932190" duration="644000" />
+-      <workItem from="1741475492994" duration="40894000" />
+-      <workItem from="1741690305204" duration="339000" />
+-      <workItem from="1741705983516" duration="604000" />
+-      <workItem from="1741713165753" duration="1198000" />
+-      <workItem from="1741861318912" duration="2286000" />
+-      <workItem from="1742201562752" duration="618000" />
+-      <workItem from="1742209067924" duration="383000" />
+-      <workItem from="1742226300133" duration="2432000" />
+-      <workItem from="1743071528350" duration="9513000" />
+-      <workItem from="1743490058046" duration="9000" />
+-      <workItem from="1743587112942" duration="1188000" />
+-      <workItem from="1748900986740" duration="1771000" />
+-      <workItem from="1748931928220" duration="446000" />
+-      <workItem from="1748932436127" duration="20890000" />
+-      <workItem from="1748970706276" duration="3719000" />
+-      <workItem from="1748988822181" duration="59000" />
+-      <workItem from="1749200290051" duration="680000" />
+-      <workItem from="1749203502833" duration="1349000" />
+-      <workItem from="1749213099437" duration="3082000" />
+-      <workItem from="1750057109660" duration="10453000" />
+-      <workItem from="1750070416210" duration="46415000" />
++      <updated>1753351859462</updated>
++      <workItem from="1753351861131" duration="6344000" />
++      <workItem from="1753438320712" duration="13353000" />
++      <workItem from="1753603965993" duration="23907000" />
++      <workItem from="1753709105378" duration="8957000" />
++      <workItem from="1753783502864" duration="521000" />
++      <workItem from="1753784038079" duration="2184000" />
++      <workItem from="1753792651870" duration="5722000" />
++      <workItem from="1753867421329" duration="923000" />
++      <workItem from="1753871809956" duration="11925000" />
++      <workItem from="1754025478167" duration="1649000" />
++      <workItem from="1754054724448" duration="1159000" />
++      <workItem from="1754317580682" duration="1098000" />
++      <workItem from="1754384107227" duration="613000" />
++      <workItem from="1754485399433" duration="303000" />
++      <workItem from="1754503724767" duration="4050000" />
++      <workItem from="1754547605829" duration="10909000" />
+     </task>
+-    <task id="LOCAL-00001" summary="Initial Commit">
++    <task id="LOCAL-00001" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1732484343908</created>
++      <created>1753438388631</created>
+       <option name="number" value="00001" />
+       <option name="presentableId" value="LOCAL-00001" />
+       <option name="project" value="LOCAL" />
+-      <updated>1732484343908</updated>
++      <updated>1753438388631</updated>
+     </task>
+-    <task id="LOCAL-00002" summary="added TransformerFNO">
++    <task id="LOCAL-00002" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1732497990642</created>
++      <created>1753444583988</created>
+       <option name="number" value="00002" />
+       <option name="presentableId" value="LOCAL-00002" />
+       <option name="project" value="LOCAL" />
+-      <updated>1732497990642</updated>
++      <updated>1753444583988</updated>
+     </task>
+-    <task id="LOCAL-00003" summary="added the connection between time steps - the model development is finished">
++    <task id="LOCAL-00003" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1732910153380</created>
++      <created>1753529013551</created>
+       <option name="number" value="00003" />
+       <option name="presentableId" value="LOCAL-00003" />
+       <option name="project" value="LOCAL" />
+-      <updated>1732910153380</updated>
++      <updated>1753529013551</updated>
+     </task>
+-    <task id="LOCAL-00004" summary="Finished Allen-Cahn Problem">
++    <task id="LOCAL-00004" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1733176021525</created>
++      <created>1753539586020</created>
+       <option name="number" value="00004" />
+       <option name="presentableId" value="LOCAL-00004" />
+       <option name="project" value="LOCAL" />
+-      <updated>1733176021525</updated>
++      <updated>1753539586020</updated>
+     </task>
+-    <task id="LOCAL-00005" summary="Added Allen-Cahn 3D">
++    <task id="LOCAL-00005" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1733583274023</created>
++      <created>1753640098974</created>
+       <option name="number" value="00005" />
+       <option name="presentableId" value="LOCAL-00005" />
+       <option name="project" value="LOCAL" />
+-      <updated>1733583274023</updated>
++      <updated>1753640098974</updated>
+     </task>
+-    <task id="LOCAL-00006" summary="added save_vtk">
++    <task id="LOCAL-00006" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1733995237535</created>
++      <created>1753713910794</created>
+       <option name="number" value="00006" />
+       <option name="presentableId" value="LOCAL-00006" />
+       <option name="project" value="LOCAL" />
+-      <updated>1733995237535</updated>
++      <updated>1753713910794</updated>
+     </task>
+-    <task id="LOCAL-00007" summary="added MATLAB codes for creating database">
++    <task id="LOCAL-00007" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1734788540933</created>
++      <created>1753722333819</created>
+       <option name="number" value="00007" />
+       <option name="presentableId" value="LOCAL-00007" />
+       <option name="project" value="LOCAL" />
+-      <updated>1734788540933</updated>
++      <updated>1753722333819</updated>
+     </task>
+-    <task id="LOCAL-00008" summary="added CH2DNL">
++    <task id="LOCAL-00008" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1735126332032</created>
++      <created>1753789147535</created>
+       <option name="number" value="00008" />
+       <option name="presentableId" value="LOCAL-00008" />
+       <option name="project" value="LOCAL" />
+-      <updated>1735126332032</updated>
++      <updated>1753789147535</updated>
+     </task>
+-    <task id="LOCAL-00009" summary="added SH2D">
++    <task id="LOCAL-00009" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1735719422931</created>
++      <created>1753867478797</created>
+       <option name="number" value="00009" />
+       <option name="presentableId" value="LOCAL-00009" />
+       <option name="project" value="LOCAL" />
+-      <updated>1735719422931</updated>
++      <updated>1753867478797</updated>
+     </task>
+-    <task id="LOCAL-00010" summary="added PFC2D">
++    <task id="LOCAL-00010" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1736237977029</created>
++      <created>1753872227989</created>
+       <option name="number" value="00010" />
+       <option name="presentableId" value="LOCAL-00010" />
+       <option name="project" value="LOCAL" />
+-      <updated>1736237977029</updated>
++      <updated>1753872227989</updated>
+     </task>
+-    <task id="LOCAL-00011" summary="added PFC2D">
++    <task id="LOCAL-00011" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1738788849261</created>
++      <created>1753974441825</created>
+       <option name="number" value="00011" />
+       <option name="presentableId" value="LOCAL-00011" />
+       <option name="project" value="LOCAL" />
+-      <updated>1738788849261</updated>
++      <updated>1753974441825</updated>
+     </task>
+-    <task id="LOCAL-00012" summary="added PFC2D">
++    <task id="LOCAL-00012" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1738789326593</created>
++      <created>1753976447489</created>
+       <option name="number" value="00012" />
+       <option name="presentableId" value="LOCAL-00012" />
+       <option name="project" value="LOCAL" />
+-      <updated>1738789326593</updated>
++      <updated>1753976447489</updated>
+     </task>
+-    <task id="LOCAL-00013" summary="added PFC2D">
++    <task id="LOCAL-00013" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1738796104012</created>
++      <created>1753976663822</created>
+       <option name="number" value="00013" />
+       <option name="presentableId" value="LOCAL-00013" />
+       <option name="project" value="LOCAL" />
+-      <updated>1738796104012</updated>
++      <updated>1753976663822</updated>
+     </task>
+-    <task id="LOCAL-00014" summary="added PFC2D">
++    <task id="LOCAL-00014" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1738962464719</created>
++      <created>1753984140485</created>
+       <option name="number" value="00014" />
+       <option name="presentableId" value="LOCAL-00014" />
+       <option name="project" value="LOCAL" />
+-      <updated>1738962464719</updated>
++      <updated>1753984140485</updated>
+     </task>
+-    <task id="LOCAL-00015" summary="added PFC2D">
++    <task id="LOCAL-00015" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1738962748829</created>
++      <created>1754027236458</created>
+       <option name="number" value="00015" />
+       <option name="presentableId" value="LOCAL-00015" />
+       <option name="project" value="LOCAL" />
+-      <updated>1738962748829</updated>
++      <updated>1754027236458</updated>
+     </task>
+-    <task id="LOCAL-00016" summary="Turn Nx to 64">
++    <task id="LOCAL-00016" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1738967163754</created>
++      <created>1754056009830</created>
+       <option name="number" value="00016" />
+       <option name="presentableId" value="LOCAL-00016" />
+       <option name="project" value="LOCAL" />
+-      <updated>1738967163754</updated>
++      <updated>1754056009830</updated>
+     </task>
+-    <task id="LOCAL-00017" summary="update to 3D">
++    <task id="LOCAL-00017" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1739275401458</created>
++      <created>1754317665438</created>
+       <option name="number" value="00017" />
+       <option name="presentableId" value="LOCAL-00017" />
+       <option name="project" value="LOCAL" />
+-      <updated>1739275401458</updated>
++      <updated>1754317665438</updated>
+     </task>
+-    <task id="LOCAL-00018" summary="update to 3D">
++    <task id="LOCAL-00018" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1739275433418</created>
++      <created>1754320089838</created>
+       <option name="number" value="00018" />
+       <option name="presentableId" value="LOCAL-00018" />
+       <option name="project" value="LOCAL" />
+-      <updated>1739275433418</updated>
++      <updated>1754320089838</updated>
+     </task>
+-    <task id="LOCAL-00019" summary="TNO3d vs FNO3d">
++    <task id="LOCAL-00019" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1741690373369</created>
++      <created>1754320859423</created>
+       <option name="number" value="00019" />
+       <option name="presentableId" value="LOCAL-00019" />
+       <option name="project" value="LOCAL" />
+-      <updated>1741690373369</updated>
++      <updated>1754320859423</updated>
+     </task>
+-    <task id="LOCAL-00020" summary="TNO3d vs FNO3d">
++    <task id="LOCAL-00020" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1741690420059</created>
++      <created>1754323071886</created>
+       <option name="number" value="00020" />
+       <option name="presentableId" value="LOCAL-00020" />
+       <option name="project" value="LOCAL" />
+-      <updated>1741690420059</updated>
++      <updated>1754323071886</updated>
+     </task>
+-    <task id="LOCAL-00021" summary="TNO3d vs FNO3d">
++    <task id="LOCAL-00021" summary="3d_phase_evolution">
+       <option name="closed" value="true" />
+-      <created>1743587271259</created>
++      <created>1754486043769</created>
+       <option name="number" value="00021" />
+       <option name="presentableId" value="LOCAL-00021" />
+       <option name="project" value="LOCAL" />
+-      <updated>1743587271259</updated>
++      <updated>1754486043769</updated>
++    </task>
++    <task id="LOCAL-00022" summary="3d_phase_evolution">
++      <option name="closed" value="true" />
++      <created>1754486850188</created>
++      <option name="number" value="00022" />
++      <option name="presentableId" value="LOCAL-00022" />
++      <option name="project" value="LOCAL" />
++      <updated>1754486850188</updated>
++    </task>
++    <task id="LOCAL-00023" summary="3d_phase_evolution">
++      <option name="closed" value="true" />
++      <created>1754494436539</created>
++      <option name="number" value="00023" />
++      <option name="presentableId" value="LOCAL-00023" />
++      <option name="project" value="LOCAL" />
++      <updated>1754494436539</updated>
++    </task>
++    <task id="LOCAL-00024" summary="3d_phase_evolution">
++      <option name="closed" value="true" />
++      <created>1754512595519</created>
++      <option name="number" value="00024" />
++      <option name="presentableId" value="LOCAL-00024" />
++      <option name="project" value="LOCAL" />
++      <updated>1754512595519</updated>
++    </task>
++    <task id="LOCAL-00025" summary="3d_phase_evolution">
++      <option name="closed" value="true" />
++      <created>1754512937472</created>
++      <option name="number" value="00025" />
++      <option name="presentableId" value="LOCAL-00025" />
++      <option name="project" value="LOCAL" />
++      <updated>1754512937472</updated>
++    </task>
++    <task id="LOCAL-00026" summary="3d_phase_evolution">
++      <option name="closed" value="true" />
++      <created>1754547763545</created>
++      <option name="number" value="00026" />
++      <option name="presentableId" value="LOCAL-00026" />
++      <option name="project" value="LOCAL" />
++      <updated>1754547763545</updated>
++    </task>
++    <task id="LOCAL-00027" summary="3d_phase_evolution">
++      <option name="closed" value="true" />
++      <created>1754548502963</created>
++      <option name="number" value="00027" />
++      <option name="presentableId" value="LOCAL-00027" />
++      <option name="project" value="LOCAL" />
++      <updated>1754548502963</updated>
++    </task>
++    <task id="LOCAL-00028" summary="3d_phase_evolution">
++      <option name="closed" value="true" />
++      <created>1754548778704</created>
++      <option name="number" value="00028" />
++      <option name="presentableId" value="LOCAL-00028" />
++      <option name="project" value="LOCAL" />
++      <updated>1754548778704</updated>
++    </task>
++    <task id="LOCAL-00029" summary="3d_phase_evolution">
++      <option name="closed" value="true" />
++      <created>1754548850651</created>
++      <option name="number" value="00029" />
++      <option name="presentableId" value="LOCAL-00029" />
++      <option name="project" value="LOCAL" />
++      <updated>1754548850651</updated>
++    </task>
++    <task id="LOCAL-00030" summary="3d_phase_evolution">
++      <option name="closed" value="true" />
++      <created>1754551135753</created>
++      <option name="number" value="00030" />
++      <option name="presentableId" value="LOCAL-00030" />
++      <option name="project" value="LOCAL" />
++      <updated>1754551135753</updated>
+     </task>
+-    <option name="localTasksCounter" value="22" />
++    <task id="LOCAL-00031" summary="update matlab code">
++      <option name="closed" value="true" />
++      <created>1754639187290</created>
++      <option name="number" value="00031" />
++      <option name="presentableId" value="LOCAL-00031" />
++      <option name="project" value="LOCAL" />
++      <updated>1754639187290</updated>
++    </task>
++    <option name="localTasksCounter" value="32" />
+     <servers />
+   </component>
+   <component name="TypeScriptGeneratedFilesManager">
+     <option name="version" value="3" />
+   </component>
+-  <component name="Vcs.Log.Tabs.Properties">
+-    <option name="RECENT_FILTERS">
+-      <map>
+-        <entry key="Branch">
+-          <value>
+-            <list>
+-              <RecentGroup>
+-                <option name="FILTER_VALUES">
+-                  <option value="main" />
+-                </option>
+-              </RecentGroup>
+-            </list>
+-          </value>
+-        </entry>
+-      </map>
+-    </option>
+-    <option name="TAB_STATES">
+-      <map>
+-        <entry key="MAIN">
+-          <value>
+-            <State>
+-              <option name="FILTERS">
+-                <map>
+-                  <entry key="branch">
+-                    <value>
+-                      <list>
+-                        <option value="main" />
+-                      </list>
+-                    </value>
+-                  </entry>
+-                </map>
+-              </option>
+-            </State>
+-          </value>
+-        </entry>
+-      </map>
+-    </option>
+-  </component>
+   <component name="VcsManagerConfiguration">
+-    <MESSAGE value="Initial Commit" />
+-    <MESSAGE value="added TransformerFNO" />
+-    <MESSAGE value="added the connection between time steps - the model development is finished" />
+-    <MESSAGE value="refactored" />
+-    <MESSAGE value="Finished Allen-Cahn Problem" />
+-    <MESSAGE value="Added Allen-Cahn 3D" />
+-    <MESSAGE value="added save_vtk" />
+-    <MESSAGE value="added MATLAB codes for creating database" />
+-    <MESSAGE value="seperated the number of layers in fourier part and convolutional part" />
+-    <MESSAGE value="added CH2DNL" />
+-    <MESSAGE value="added SH2D" />
+-    <MESSAGE value="added PFC2D" />
+-    <MESSAGE value="Turn Nx to 64" />
+-    <MESSAGE value="update to 3D" />
+-    <MESSAGE value="TNO3d vs FNO3d" />
+-    <option name="LAST_COMMIT_MESSAGE" value="TNO3d vs FNO3d" />
++    <MESSAGE value="3d_phase_evolution" />
++    <MESSAGE value="update matlab code" />
++    <option name="LAST_COMMIT_MESSAGE" value="update matlab code" />
+   </component>
+   <component name="XDebuggerManager">
+     <breakpoint-manager>
+       <breakpoints>
+         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/SH2D.py</url>
+-          <line>142</line>
+-          <option name="timeStamp" value="17" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/SH2D.py</url>
+-          <line>163</line>
+-          <option name="timeStamp" value="18" />
++          <url>file://$PROJECT_DIR$/training.py</url>
++          <line>217</line>
++          <option name="timeStamp" value="1" />
+         </line-breakpoint>
+         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/SH2D.py</url>
+-          <line>134</line>
+-          <option name="timeStamp" value="19" />
++          <url>file://$PROJECT_DIR$/networks.py</url>
++          <line>373</line>
++          <option name="timeStamp" value="5" />
+         </line-breakpoint>
+         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/SH2D.py</url>
+-          <line>327</line>
+-          <option name="timeStamp" value="20" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/SH2D.py</url>
+-          <line>243</line>
+-          <option name="timeStamp" value="21" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/AC2D_2.py</url>
+-          <line>333</line>
+-          <option name="timeStamp" value="27" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>
+-          <line>371</line>
+-          <option name="timeStamp" value="44" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>
+-          <line>338</line>
+-          <option name="timeStamp" value="54" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/Test.py</url>
+-          <line>53</line>
+-          <option name="timeStamp" value="128" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/Test.py</url>
+-          <line>30</line>
+-          <option name="timeStamp" value="129" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/Test.py</url>
+-          <line>25</line>
+-          <option name="timeStamp" value="133" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/Test.py</url>
+-          <line>18</line>
+-          <option name="timeStamp" value="135" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>
+-          <line>44</line>
+-          <option name="timeStamp" value="138" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/Test2.py</url>
+-          <line>16</line>
+-          <option name="timeStamp" value="144" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/utilities.py</url>
+-          <line>98</line>
+-          <option name="timeStamp" value="170" />
+-        </line-breakpoint>
+-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+-          <url>file://$PROJECT_DIR$/main.py</url>
+-          <line>157</line>
+-          <option name="timeStamp" value="177" />
++          <url>file://$PROJECT_DIR$/networks.py</url>
++          <line>252</line>
++          <option name="timeStamp" value="6" />
+         </line-breakpoint>
+       </breakpoints>
+-      <default-breakpoints>
+-        <breakpoint type="python-exception">
+-          <properties notifyOnTerminate="true" exception="BaseException">
+-            <option name="notifyOnTerminate" value="true" />
+-          </properties>
+-        </breakpoint>
+-      </default-breakpoints>
+     </breakpoint-manager>
+   </component>
+   <component name="com.intellij.coverage.CoverageDataManagerImpl">
+-    <SUITE FILE_PATH="coverage/PhaseField1$Test3.coverage" NAME="Test3 Coverage Results" MODIFIED="1739273938386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage" NAME="config_AC2D_FNO3d Coverage Results" MODIFIED="1733233385695" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO4d.coverage" NAME="SH3D_FNO4d Coverage Results" MODIFIED="1754559003332" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$main.coverage" NAME="main Coverage Results" MODIFIED="1743065376798" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_2.coverage" NAME="AC2D_Net2D_2 Coverage Results" MODIFIED="1732904114403" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_PFC3D_TNO3d.coverage" NAME="config_PFC3D_TNO3d Coverage Results" MODIFIED="1752681001873" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$test2.coverage" NAME="test2 Coverage Results" MODIFIED="1742889074336" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+     <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1741561715014" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage" NAME="config_SH3D_TNO3d Coverage Results" MODIFIED="1750254757455" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3D.coverage" NAME="SH3D_TNO3D Coverage Results" MODIFIED="1753359664305" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$networks.coverage" NAME="networks Coverage Results" MODIFIED="1733086051390" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/PhaseField1$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1740088478224" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1741603428589" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3d_TNO3d_hybrid.coverage" NAME="PFC3d_TNO3d_hybrid Coverage Results" MODIFIED="1753174544263" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseField1$main.coverage" NAME="main Coverage Results" MODIFIED="1738663765959" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$post_processing.coverage" NAME="post_processing Coverage Results" MODIFIED="1733557098801" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1751364899601" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_Hybrid.coverage" NAME="SH3D_Hybrid Coverage Results" MODIFIED="1753435630879" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D.coverage" NAME="AC2D Coverage Results" MODIFIED="1733088640665" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Archive_Code" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D.coverage" NAME="AC2D_Net2D Coverage Results" MODIFIED="1732567473230" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/PhaseField1$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1740054182408" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1753174449133" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseField1$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1737644605063" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1741605347375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$main.coverage" NAME="main Coverage Results" MODIFIED="1736268192289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1741564210973" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage" NAME="config_CH2DNL_TNO2d Coverage Results" MODIFIED="1735052490996" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++    <SUITE FILE_PATH="coverage/PhaseField1$Test_Run.coverage" NAME="Test_Run Coverage Results" MODIFIED="1738945320139" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1741561294310" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1743081225414" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_Hybrid.coverage" NAME="PFC3D_Hybrid Coverage Results" MODIFIED="1752753153734" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1752763076697" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$PFC2D.coverage" NAME="PFC2D Coverage Results" MODIFIED="1732278679485" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$CH2D.coverage" NAME="CH2D Coverage Results" MODIFIED="1732347055915" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_FNO3d.coverage" NAME="AC3D_FNO3d Coverage Results" MODIFIED="1741561435127" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741547133078" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_hybrid.coverage" NAME="MBE3D_hybrid Coverage Results" MODIFIED="1753449172728" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_FNO4d.coverage" NAME="PFC3D_FNO4d Coverage Results" MODIFIED="1753634100431" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseField1$AC3D.coverage" NAME="AC3D Coverage Results" MODIFIED="1740041515520" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseField1$Test2.coverage" NAME="Test2 Coverage Results" MODIFIED="1739283715182" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1751535690856" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D.coverage" NAME="config_AC2D Coverage Results" MODIFIED="1733087276180" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_1.coverage" NAME="AC2D_Net2D_1 Coverage Results" MODIFIED="1732535211383" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$fourier_3d.coverage" NAME="fourier_3d Coverage Results" MODIFIED="1732221600628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1736520700819" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_interface3.coverage" NAME="run_interface3 Coverage Results" MODIFIED="1754551855088" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1751390276789" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1753270153654" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$test1.coverage" NAME="test1 Coverage Results" MODIFIED="1733413325318" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1753435969375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_TNO3d_Hybrid.coverage" NAME="PFC3D_TNO3d_Hybrid Coverage Results" MODIFIED="1752850166757" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseField1$Test3.coverage" NAME="Test3 Coverage Results" MODIFIED="1739273938386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_2.coverage" NAME="AC2D_Net2D_2 Coverage Results" MODIFIED="1732904114403" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_MBE3D_TNO3d.coverage" NAME="config_MBE3D_TNO3d Coverage Results" MODIFIED="1753524263103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage" NAME="config_SH3D_TNO3d Coverage Results" MODIFIED="1753348599806" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+     <SUITE FILE_PATH="coverage/PhaseField1$backend_interagg.coverage" NAME="backend_interagg Coverage Results" MODIFIED="1737630366471" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript3.coverage" NAME="RunScript3 Coverage Results" MODIFIED="1736368081257" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_2.coverage" NAME="AC2D_2 Coverage Results" MODIFIED="1732483323689" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$networks.coverage" NAME="networks Coverage Results" MODIFIED="1733086051390" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+     <SUITE FILE_PATH="coverage/PhaseField1$main_TF.coverage" NAME="main_TF Coverage Results" MODIFIED="1738704014479" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+     <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1741538869064" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$THFNO.coverage" NAME="THFNO Coverage Results" MODIFIED="1732911474644" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/networks" />
+-    <SUITE FILE_PATH="coverage/PhaseField1$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1740088478224" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField1$PFC3D.coverage" NAME="PFC3D Coverage Results" MODIFIED="1740083613128" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1741603428589" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_inference.coverage" NAME="run_inference Coverage Results" MODIFIED="1750323709039" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/PhaseField1$main.coverage" NAME="main Coverage Results" MODIFIED="1738663765959" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$post_processing.coverage" NAME="post_processing Coverage Results" MODIFIED="1733557098801" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$CH3D_FNO4d.coverage" NAME="CH3D_FNO4d Coverage Results" MODIFIED="1754322861793" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_AC3D_FNO3d.coverage" NAME="config_AC3D_FNO3d Coverage Results" MODIFIED="1751958646687" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_inference.coverage" NAME="run_inference Coverage Results" MODIFIED="1751264322005" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage" NAME="config_CH2D_TNO2d Coverage Results" MODIFIED="1734086207850" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+     <SUITE FILE_PATH="coverage/phase_field_equations_4d$networks.coverage" NAME="networks Coverage Results" MODIFIED="1748933697533" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1750255151255" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript2.coverage" NAME="RunScript2 Coverage Results" MODIFIED="1736369209710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1742215946758" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_3.coverage" NAME="AC2D_Net2D_3 Coverage Results" MODIFIED="1732974697103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_FNO3d.coverage" NAME="AC3d_FNO3d Coverage Results" MODIFIED="1749017845623" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D.coverage" NAME="AC2D Coverage Results" MODIFIED="1733088640665" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Archive_Code" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D.coverage" NAME="AC2D_Net2D Coverage Results" MODIFIED="1732567473230" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/PhaseField1$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1740054182408" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$utilities.coverage" NAME="utilities Coverage Results" MODIFIED="1752595653294" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_FNO3d.coverage" NAME="AC3d_FNO3d Coverage Results" MODIFIED="1751961986602" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1741562061391" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseField1$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1737644605063" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_TNO.coverage" NAME="MBE3D_TNO Coverage Results" MODIFIED="1753438703018" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField1$MBE3D.coverage" NAME="MBE3D Coverage Results" MODIFIED="1739283566145" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1741605347375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1743071672425" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$main.coverage" NAME="main Coverage Results" MODIFIED="1736268192289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1741564210973" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage" NAME="config_CH2DNL_TNO2d Coverage Results" MODIFIED="1735052490996" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FO.coverage" NAME="SH3D_FO Coverage Results" MODIFIED="1753438614882" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$MBE2D.coverage" NAME="MBE2D Coverage Results" MODIFIED="1732278526731" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+     <SUITE FILE_PATH="coverage/PhaseField1$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1739914172084" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseField1$Test_Run.coverage" NAME="Test_Run Coverage Results" MODIFIED="1738945320139" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1741561294310" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3d_hybrid.coverage" NAME="MBE3d_hybrid Coverage Results" MODIFIED="1753458461671" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741861381348" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1743081225414" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage" NAME="PFV3D_FNO3d Coverage Results" MODIFIED="1741564487710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$training.coverage" NAME="training Coverage Results" MODIFIED="1751968651692" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_Hybrid.coverage" NAME="MBE3D_Hybrid Coverage Results" MODIFIED="1753516430619" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript1.coverage" NAME="RunScript1 Coverage Results" MODIFIED="1736368790622" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$SH2D.coverage" NAME="SH2D Coverage Results" MODIFIED="1732347080402" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$PFC2D.coverage" NAME="PFC2D Coverage Results" MODIFIED="1732278679485" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$CH2D.coverage" NAME="CH2D Coverage Results" MODIFIED="1732347055915" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_FNO3d.coverage" NAME="AC3D_FNO3d Coverage Results" MODIFIED="1741561435127" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_FNO3d.coverage" NAME="PFC3D_FNO3d Coverage Results" MODIFIED="1753174772461" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField1$SH3D.coverage" NAME="SH3D Coverage Results" MODIFIED="1739044808411" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField1$Test.coverage" NAME="Test Coverage Results" MODIFIED="1739459206236" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741547133078" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$CH3D_TNO3d_Hybrid.coverage" NAME="CH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1752411744994" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage" NAME="config_AC2D_FNO2d Coverage Results" MODIFIED="1733393903488" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+-    <SUITE FILE_PATH="coverage/PhaseField1$AC3D.coverage" NAME="AC3D Coverage Results" MODIFIED="1740041515520" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField1$config_CH3D_TNO3d.coverage" NAME="config_CH3D_TNO3d Coverage Results" MODIFIED="1738089807566" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+-    <SUITE FILE_PATH="coverage/PhaseField1$Test2.coverage" NAME="Test2 Coverage Results" MODIFIED="1739283715182" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+     <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_FNO3d.coverage" NAME="CH3D_FNO3d Coverage Results" MODIFIED="1741628529142" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage" NAME="AC3d_TNO3d_hybrid Coverage Results" MODIFIED="1748989478372" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage" NAME="AC3d_TNO3d_hybrid Coverage Results" MODIFIED="1751963486807" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseField1$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1737899062785" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D.coverage" NAME="config_AC2D Coverage Results" MODIFIED="1733087276180" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_1.coverage" NAME="AC2D_Net2D_1 Coverage Results" MODIFIED="1732535211383" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1736520700819" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$fourier_3d.coverage" NAME="fourier_3d Coverage Results" MODIFIED="1732221600628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1750254767095" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1749216389646" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1748990262244" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/PhaseFieldNet$test1.coverage" NAME="test1 Coverage Results" MODIFIED="1733413325318" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1754558969424" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main1.coverage" NAME="main1 Coverage Results" MODIFIED="1753709191839" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+     <SUITE FILE_PATH="coverage/PhaseField1$CH3D_2.coverage" NAME="CH3D_2 Coverage Results" MODIFIED="1739918355289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1750254975290" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage" NAME="config_MBE2D_TNO2d Coverage Results" MODIFIED="1736261397712" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+   </component>
+ </project>
+\ No newline at end of file
+Index: configs/config_AC3D_TNO3d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1000 # 900 # 1000\nnTest = 300 # 100 # 100\nbatch_size = 10 # 50 # 20 #5 # 25\nlearning_rate = 0.001\nweight_decay = 1e-4\nepochs = 50 # 100 # 900  # 100\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 8 # last time modes =  8\nwidth =  12 # 32 # last time width =  32\nwidth_q = width\nwidth_h = width // 2 # width // 4 # last time\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # False #  False\nload_model = False # True  #  True  # True\n\n# Database\nparent_dir = './data/'\n# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'\n#matlab_dataset = 'AC3D_32_1000.mat'\nmatlab_dataset = 'AC3D_32_1300.mat'\n# Plotting\nindex = 9 # 12\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 69]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]\n\n\n#############\nLx = np.pi            # Domain size from MATLAB\n# Time Discretization Parameters (from AC3D MATLAB)\ndt_sim = 0.0001     # Time step in the MATLAB simulation\nNt_sim = 50        # Total number of simulation steps in MATLAB\nnum_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)\n# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps\n# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output\n# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.\ndt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in\n# PDE Parameters for Allen-Cahn (AC3D)\n# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.\n# The PDE implemented in calculate_pde_residual was:\n# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)\nepsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter\n# PINN Specific Settings (if PINN_MODE is True in main.py)\npde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.\n# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\n\npde_loss_scaler = 1e-3
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_AC3D_TNO3d.py b/configs/config_AC3D_TNO3d.py
+--- a/configs/config_AC3D_TNO3d.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/configs/config_AC3D_TNO3d.py	(date 1754579159678)
+@@ -6,23 +6,23 @@
+ numpy_seed = 0
+ 
+ # Network Parameters
+-nTrain = 1000 # 900 # 1000
++nTrain = 1200 # 900 # 1000
+ nTest = 300 # 100 # 100
+-batch_size = 10 # 50 # 20 #5 # 25
+-learning_rate = 0.001
++batch_size = 20 # 20 # 50 # 20 #5 # 25
++learning_rate = 0.001 # 0.001
+ weight_decay = 1e-4
+-epochs = 50 # 100 # 900  # 100
++epochs = 20 # 50 #  # 100 # 900  # 100
+ iterations = epochs * (nTrain // batch_size)
+ modes =  14 # 8 # last time modes =  8
+-width =  12 # 32 # last time width =  32
++width =  12 # 12 # 32 # last time width =  32
+ width_q = width
+ width_h = width // 2 # width // 4 # last time
+-n_layers = 4
++n_layers = 2 # 2 # 4
+ 
+ # Discretization
+ s = 32
+ T_in = 1
+-T_out = 20 # 100
++T_out = 100 # 20 # 100
+ 
+ # Training Setting
+ normalized = True
+@@ -31,24 +31,26 @@
+ 
+ # Database
+ parent_dir = './data/'
+-# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
+-#matlab_dataset = 'AC3D_32_1000.mat'
+-matlab_dataset = 'AC3D_32_1300.mat'
++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
++
+ # Plotting
+ index = 9 # 12
+-domain = [-np.pi, np.pi]
++Lx = 5 # np.pi            # Domain size from MATLAB
++#domain = [-np.pi, np.pi]
++domain = [-Lx/2, Lx/2]
++
+ # time_steps = [29, 69]
+ #time_steps = [39, 49, 59, 69, 79, 89, 99]
+ # time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+ #               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+ #time_steps = [39, 59, 79]
+-time_steps = [0, 9, 19]
++time_steps = [1, 50, 90]
+ 
+ 
+ #############
+-Lx = np.pi            # Domain size from MATLAB
++
+ # Time Discretization Parameters (from AC3D MATLAB)
+-dt_sim = 0.0001     # Time step in the MATLAB simulation
++dt_sim = 0.0005     # Time step in the MATLAB simulation
+ Nt_sim = 50        # Total number of simulation steps in MATLAB
+ num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+ # ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+@@ -61,11 +63,11 @@
+ # du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+ epsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+ # PINN Specific Settings (if PINN_MODE is True in main.py)
+-pde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.
++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+ # PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+ 
+ # Learning Rate Scheduler Parameters (for StepLR)
+ scheduler_step = 20  # Decay learning rate every 20 epochs
+ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+ 
+-pde_loss_scaler = 1e-3
+\ No newline at end of file
++pde_loss_scaler = 1e-4
+\ No newline at end of file
+Index: configs/config_PFC3D_FNO3d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>\"\"\"\nDevice:  cuda:0\nmodel = TNO2d_PFC2D_S64_T1to100_width32_modes12_q32_h16.pt\nnumber of epoch = 1000\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n2539703\n\nThe average testing error is 0.027059923857450485\nStd. deviation of testing error is 0.01980009116232395\n----------------------------------------------\nmodel = TNO2d_PFC2D_S64_T1to50_width16_modes12_q32_h16.pt\nnumber of epoch = 200\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n651059\n\nThe average testing error is 0.005057875066995621\nStd. deviation of testing error is 0.0021678071934729815\n----------------------------------------------\n\n\n\"\"\"\n\nimport numpy as np\n\n# General SettingnTrain = 1200 # 5250 # 7500\n\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200\nnTest = 300\nbatch_size = 50 # 100\nlearning_rate = 0.005\nweight_decay = 1e-4 # 1e-4\nepochs = 50\niterations = epochs * (nTrain // batch_size)\nmodes = 14 #12\nwidth = 12 # 16 # 32\nwidth_q = width # 32\nwidth_h = width//2 # 16\nn_layers = 4\n\n'''\ntau = 315;\nalpha = 115; \n'''\n\n# Discretization\ns = 32 # 64 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # True\nload_model = False # True # False # True  # False\n\n# Database\nparent_dir = './data/'\nmatlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 200  # 110  # 200\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n# time_steps = [0, 2, 4, 6, 8, 9]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_PFC3D_FNO3d.py b/configs/config_PFC3D_FNO3d.py
+--- a/configs/config_PFC3D_FNO3d.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/configs/config_PFC3D_FNO3d.py	(date 1754547784274)
+@@ -43,16 +43,16 @@
+ # Network Parameters
+ nTrain = 1200
+ nTest = 300
+-batch_size = 50 # 100
+-learning_rate = 0.005
++batch_size = 15 # 100
++learning_rate = 0.001
+ weight_decay = 1e-4 # 1e-4
+-epochs = 50
++epochs = 30 # 50
+ iterations = epochs * (nTrain // batch_size)
+ modes = 14 #12
+ width = 12 # 16 # 32
+ width_q = width # 32
+ width_h = width//2 # 16
+-n_layers = 4
++n_layers = 2 # 4
+ 
+ '''
+ tau = 315;
+@@ -62,7 +62,7 @@
+ # Discretization
+ s = 32 # 64 # 64
+ T_in = 1
+-T_out = 20 # 100
++T_out = 91 # 20 # 100
+ 
+ # Training Setting
+ normalized = True
+@@ -71,14 +71,45 @@
+ 
+ # Database
+ parent_dir = './data/'
+-matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
+ # Plotting
+-index = 200  # 110  # 200
+-domain = [-np.pi, np.pi]
++
++# Plotting
++index = 69  # 110  # 200
++Lx = 10*np.pi
++domain = [-5*np.pi, 5*np.pi]
+ # time_steps = [29, 35, 39, 45, 49]
+ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+ # time_steps = [0, 2, 4, 6, 8, 9]
+ #time_steps = [39, 59, 79]
+-time_steps = [0, 9, 19]
+\ No newline at end of file
++time_steps = [0, 50, 90]
++
++
++
++#############
++
++# Time Discretization Parameters (from AC3D MATLAB)
++dt_sim = 0.05 # 0.1     # Time step in the MATLAB simulation
++Nt_sim = 50        # Total number of simulation steps in MATLAB
++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
++# PDE Parameters for Allen-Cahn (AC3D)
++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
++# The PDE implemented in calculate_pde_residual was:
++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++# PINN Specific Settings (if PINN_MODE is True in main.py)
++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++
++pde_loss_scaler = 1e-6
+\ No newline at end of file
+Index: .idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/shelved.patch
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/shelved.patch
+new file mode 100644
+--- /dev/null	(date 1754475687047)
++++ b/.idea/shelf/Uncommitted_changes_before_Update_at_8_6_25,_12_21_PM_[Changes]/shelved.patch	(date 1754475687047)
+@@ -0,0 +1,7334 @@
++Index: configs/config_PFC3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\"\"\"\nDevice:  cuda:0\nmodel = TNO2d_PFC2D_S64_T1to100_width32_modes12_q32_h16.pt\nnumber of epoch = 1000\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n2539703\n\nThe average testing error is 0.027059923857450485\nStd. deviation of testing error is 0.01980009116232395\n----------------------------------------------\nmodel = TNO2d_PFC2D_S64_T1to50_width16_modes12_q32_h16.pt\nnumber of epoch = 200\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n651059\n\nThe average testing error is 0.005057875066995621\nStd. deviation of testing error is 0.0021678071934729815\n----------------------------------------------\n\n\n\"\"\"\n\nimport numpy as np\n\n# General SettingnTrain = 1200 # 5250 # 7500\n\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200\nnTest = 300\nbatch_size = 50 # 100\nlearning_rate = 0.005\nweight_decay = 1e-4 # 1e-4\nepochs = 50\niterations = epochs * (nTrain // batch_size)\nmodes = 14 #12\nwidth = 12 # 16 # 32\nwidth_q = width # 32\nwidth_h = width//2 # 16\nn_layers = 4\n\n'''\ntau = 315;\nalpha = 115; \n'''\n\n# Discretization\ns = 32 # 64 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # True\nload_model = False # True # False # True  # False\n\n# Database\nparent_dir = './data/'\nmatlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 200  # 110  # 200\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n# time_steps = [0, 2, 4, 6, 8, 9]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_PFC3D_TNO3d.py b/configs/config_PFC3D_TNO3d.py
++--- a/configs/config_PFC3D_TNO3d.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/configs/config_PFC3D_TNO3d.py	(date 1754055606752)
++@@ -43,26 +43,21 @@
++ # Network Parameters
++ nTrain = 1200
++ nTest = 300
++-batch_size = 50 # 100
++-learning_rate = 0.005
+++batch_size = 20 #50# 100
+++learning_rate = 0.001 # 0.005
++ weight_decay = 1e-4 # 1e-4
++-epochs = 50
+++epochs = 30 # 20 # 50
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 #12
++ width = 12 # 16 # 32
++ width_q = width # 32
++ width_h = width//2 # 16
++-n_layers = 4
++-
++-'''
++-tau = 315;
++-alpha = 115; 
++-'''
+++n_layers = 2 # 4
++ 
++ # Discretization
++ s = 32 # 64 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -71,14 +66,44 @@
++ 
++ # Database
++ parent_dir = './data/'
++-matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
+++
++ # Plotting
++-index = 200  # 110  # 200
++-domain = [-np.pi, np.pi]
+++index = 69  # 110  # 200
+++Lx = 10*np.pi
+++domain = [-5*np.pi, 5*np.pi]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ # time_steps = [0, 2, 4, 6, 8, 9]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.005 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: main.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import os\nimport importlib\nimport torch\nimport inspect\nimport numpy as np\nimport matplotlib\n\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom training import train_fno, train_fno_time, train_hybrid, compute_initial_loss_scaler\nfrom torch.utils.data import DataLoader, random_split\nfrom utilities import ImportDataset, count_params, LpLoss, ModelEvaluator\nfrom post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \\\n    make_video, save_vtk, plot_xy_plane_subplots\nimport time  # Import the time module at the beginning of the script\nfrom torch_optimizer import Lamb\n\n################################################################\n# Problem Definition\n################################################################\n# problem = 'AC2D'\n# problem = 'AC3D'\n# problem = 'CH2DNL'\n# problem = 'SH2D'\nproblem = 'SH3D'\n# problem = 'PFC2D'\n# problem = 'PFC3D'\n# problem = 'MBE2D'\n# problem = 'MBE3D'\n# problem = 'CH2D'\n# problem = 'CH3D'\n\n# network_name = 'TNO2d'\n# network_name = 'FNO2d'\n#network_name = 'FNO3d'\nnetwork_name = 'TNO3d'\n\nPINN_MODE =  True #False #  False #  False  # False #\n\nprint(f\"problem = {problem}\")\nprint(f\"network = {network_name}\")\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\")  # configuration file\n# above line means: import configs.config_PFC3D_TNO3d as cf\nnetwork = getattr(importlib.import_module('networks'), network_name)  # from networks import TNO3d\ntorch.manual_seed(cf.torch_seed)\nnp.random.seed(cf.numpy_seed)\n# device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')\ndevice = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)\n# --- Define Output Directory ---\n\n\nPDE_WEIGHT = cf.pde_weight\n#PDE_LOSS_SCALER = cf.pde_loss_scaler\n\nif PINN_MODE:\n    run_descriptor = f\"PINN_w{int(PDE_WEIGHT * 100)}\"\n    output_subdir = f\"plots_Data_Physics_{network_name}\"  # Specific PINN output\nelse:\n    run_descriptor = \"DataDriven\"\n    output_subdir = f\"plots_{network_name}\"  # Original data-driven output\n\n# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'\n# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_SH3D_random_sphere_finial.pt'\nmodel_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d.pt'\nmodel_dir = os.path.join(problem, 'models')  # models_smpooth\nmodel_name = f'{model_run_name}'\nmodel_path = os.path.join(model_dir, model_name)\n\nplot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir\nos.makedirs(model_dir, exist_ok=True)\nos.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists\n\nprint(f\"Model Run Name: {model_run_name}\")\nprint(f\"Model Path: {model_path}\")\nprint(f\"Plot Directory: {plot_dir}\")\n\n# width_q = 32\nstart_time = time.time()\n\n################################################################\n# load data and data normalization\n################################################################\n# model_dir = problem + '/models'\n\nprint(f\"model = {model_name}\")\nprint(f\"number of epoch = {cf.epochs}\")\nprint(f\"batch size = {cf.batch_size}\")\nprint(f\"nTrain = {cf.nTrain}\")\nprint(f\"nTest = {cf.nTest}\")\nprint(f\"learning_rate = {cf.learning_rate}\")\nprint(f\"n_layers = {cf.n_layers}\")\nprint(f\"width_q = {cf.width_q}\")\nprint(f\"width_h = {cf.width_h}\")\n\nmodel_path = os.path.join(model_dir, model_name)\nos.makedirs(model_dir, exist_ok=True)\n# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\ntrain_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])\n# to see train_dataset values: print(\"train_dataset subset:\", [train_dataset[i] for i in range(len(train_dataset))])\nnormalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)\n\n############AA####################################################\n# training and evaluation\n################################################################\nsig = inspect.signature(network.__init__)\nrequired_args = [param.name for param in sig.parameters.values()\n                 if param.default == inspect.Parameter.empty and param.name != \"self\"]\nif network_name == 'FNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'FNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(\n        device)\nelse:\n    raise Exception(\"network_name is not correct\")\n\nprint(count_params(model))  # Print model parameters\ntrain_mse_log, train_l2_log, test_l2_log = [], [], []  # Initialize logs\n\n# Load the entire model and logs\nif os.path.exists(model_path) and cf.load_model:\n    print(f\"Loading pre-trained model from {model_path}\")\n    checkpoint = torch.load(model_path, map_location=device)\n    model = checkpoint['model']\n    train_mse_log = checkpoint.get('train_mse_log', [])\n    train_l2_log = checkpoint.get('train_l2_log', [])\n    test_l2_log = checkpoint.get('test_l2_log', [])\nelse:\n    print(\"No pre-trained model loaded. Initializing a new model.\")\n\n# Define optimizer, scheduler, and loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)\nmyloss = LpLoss(p=2, l1_weight=0.0, size_average=False)\n\n# COMPUTE THE DYNAMIC SCALER\n# Use the train_loader to get a representative batch\n\n\n# Train the model\nif cf.training:\n    print(\"\\n--- Starting Training ---\")\n    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)\n        grid_info = {\n            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,\n            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,\n            'dt_model': cf.dt_model,\n            'T_out': cf.T_out\n        }\n\n        pde_loss_scaler = compute_initial_loss_scaler(\n            model,\n            train_loader,\n            myloss,\n            cf.normalized,\n            normalizers,\n            device,\n            grid_info,\n            cf.epsilon,\n            problem\n        )\n\n\n        if PDE_WEIGHT == 0.0:\n            print(\"Running PINN training loop with pde_weight=0 (Data-Driven only loss).\")\n        else:\n            print(\n                f\"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {pde_loss_scaler:.2e}\")\n\n        model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (\n            train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                         optimizer, scheduler, cf.normalized, normalizers, device,\n                         PDE_WEIGHT, grid_info, cf.epsilon, problem,\n                         pde_loss_scaler=pde_loss_scaler)\n        )\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model': model,\n            'train_mse_log': train_mse_hybrid_log,\n            'train_l2_log': train_l2_hybrid_log,\n            'test_l2_log': test_data_log,\n            'test_pde_scaled_log': test_pde_loss_scaled_log,\n            'train_data_log': train_data_log,\n            'train_pde_scaled_log': train_pde_scaled_log,\n            'test_loss_hybrid_log': test_loss_hybrid_log\n        }, model_path)\n\n    else:  # Original Data-Driven Mode\n        if network_name == 'FNO2d' or network_name == 'FNO3d':\n            model, train_l2_log, test_l2_log = (\n                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                               optimizer, scheduler, cf.normalized, normalizers, device))\n            train_mse_log = []\n        else:\n            model, train_mse_log, train_l2_log, test_l2_log = (\n                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                          optimizer, scheduler, cf.normalized, normalizers, device))\n\n    print(f\"Saving model and logs to {model_path}\")\n    torch.save({\n        'model': model,\n        'train_mse_log': train_mse_log,\n        'train_l2_log': train_l2_log,\n        'test_l2_log': test_l2_log\n    }, model_path)\n\nend_time = time.time()\nFinal_time = round(end_time - start_time, 2)\nprint(f\"Total Execution Time: {Final_time} seconds\")\n\nevaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,\n                           time_history=(network_name == 'FNO2d'))\n\nresults = evaluator.evaluate(loss_fn=myloss)\ninp = results['input']\npred = results['prediction']\nexact = results['exact']\ntest_l2_avg = results[\"average\"]\n\nif PINN_MODE:\n    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log,\n              train_pde_scaled_log]\n    labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\nelse:\n    losses = [train_l2_log, test_l2_log]\n    labels = ['Train L2', 'Test L2']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\n\n################################################################\n# post-processing\n################################################################\na_ind = inp[cf.index]\nu_pred = pred[cf.index]\nu_exact = exact[cf.index]\nerror = u_pred - u_exact\n\nprint(f\"DEBUG: Shape of u_exact passed to plotting function: {u_exact.shape}\")\nprint(f\"DEBUG: Shape of u_pred passed to plotting function: {u_pred.shape}\")\n\nplot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]\n\n# =========================================================================================\n# ===                START OF MODIFIED PLOTTING PREPARATION BLOCK                      ===\n# =========================================================================================\n\n# 1. Get the initial condition (t=0) data for the chosen sample index\na_ind = inp[cf.index]\nprint(f\"Shape of initial condition (t=0) data 'a_ind': {a_ind.shape}\")\n\n# 2. Separate desired times into t=0 vs. future predictions\ndesired_times = cf.time_steps\nfuture_times_to_plot = []\nhas_initial_condition = (0 in desired_times)\nfor t in desired_times:\n    if t > 0:\n        future_times_to_plot.append(t)\n\n# 3. Translate the FUTURE times to array indices\nindices_to_plot = []\nvalid_future_times = []\nfor t in future_times_to_plot:\n    if t <= cf.T_out:\n        indices_to_plot.append(t - 1)\n        valid_future_times.append(t)\n    else:\n        print(f\"Warning: Time t={t} is out of valid prediction range. Skipping.\")\nprint(f\"Plotting for future times: {valid_future_times} --> which correspond to array indices: {indices_to_plot}\")\n\n# 4. MOVE ALL DATA TO THE TARGET DEVICE BEFORE OPERATIONS\nt0_data_cpu = a_ind\nu_exact_cpu = u_exact\nu_pred_cpu = u_pred\nerror_cpu = error\n\nt0_data_gpu = t0_data_cpu.to(device)\nu_exact_gpu = u_exact_cpu.to(device)\nu_pred_gpu = u_pred_cpu.to(device)\nerror_gpu = error_cpu.to(device)\nindices_tensor_gpu = torch.tensor(indices_to_plot, device=device)\n\n# 5. PREPARE COMBINED TENSORS FOR PLOTTING on the GPU\nif has_initial_condition:\n    # --- ### FIXED DIMENSION HANDLING ### ---\n    # `a_ind` has shape (sx, sy, sz, 1) where the last dim is a channel.\n    # `u_exact_gpu` has shape (sx, sy, sz, T) where the last dim is time.\n    # They are both 4D, so we can concatenate them directly if the last dimension is treated as the time dimension.\n    # We don't need to do any reshaping. `t0_data_gpu` is already correct.\n    t0_for_concat = t0_data_gpu\n\n    # Select the future time slices from the GPU tensors\n    u_exact_selected = u_exact_gpu.index_select(-1, indices_tensor_gpu)\n    u_pred_selected = u_pred_gpu.index_select(-1, indices_tensor_gpu)\n    error_selected = error_gpu.index_select(-1, indices_tensor_gpu)\n\n    # Combine t=0 data with the selected future steps\n    u_exact_for_plot = torch.cat((t0_for_concat, u_exact_selected), dim=-1)\n    u_pred_for_plot = torch.cat((t0_for_concat, u_pred_selected), dim=-1)\n\n    # The error for t=0 is zero by definition\n    error_t0 = torch.zeros_like(t0_for_concat)\n    error_for_plot = torch.cat((error_t0, error_selected), dim=-1)\n\n    final_indices = list(range(len(desired_times)))\n    final_labels = desired_times\nelse:\n    u_exact_for_plot = u_exact_gpu\n    u_pred_for_plot = u_pred_gpu\n    error_for_plot = error_gpu\n    final_indices = indices_to_plot\n    final_labels = valid_future_times\n\nprint(f\"Final data prepared for plotting with shape: {u_exact_for_plot.shape}\")\nprint(f\"Final indices for plotting: {final_indices}\")\nprint(f\"Final labels for plotting: {final_labels}\")\n\n# Plot XY-plane for the \"Exact\" solution trajectory (includes t=0)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=u_exact_for_plot,\n                       field_name='Exact Solution',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[0],\n                       problem=problem,\n                       network_name=network_name)\n\n# Plot XY-plane for the \"Predicted\" solution trajectory (includes t=0 from input)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=u_pred_for_plot,\n                       field_name='Predicted Solution',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[1],\n                       problem=problem,\n                       network_name=network_name)\n\n# Plot XY-plane for the \"Error\" (error is 0 at t=0)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=error_for_plot,\n                       field_name='Error',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[2],\n                       problem=problem,\n                       network_name=network_name)\n\n# Calculate L2 norm on original full prediction\nl2_norm_error = torch.norm(u_pred - u_exact, p=2)\nl2_norm_exact = torch.norm(u_exact, p=2)\nepsilon = 1e-8\nif l2_norm_exact.item() > epsilon:\n    relative_l2_error = l2_norm_error / l2_norm_exact\nelse:\n    relative_l2_error = torch.tensor(0.0) if l2_norm_error.item() < epsilon else torch.tensor(float('inf'))\n\nprint(f\"L2 norm of error: {l2_norm_error.item()}\")\nprint(f\"L2 norm of exact solution: {l2_norm_exact.item()}\")\nprint(f\"Relative L2 norm error: {relative_l2_error.item()}\")\nrelative_l2_error_percentage = (relative_l2_error * 100)\nprint(f\"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%\")\n\n# Call the combined results plots with the prepared data\nplot_combined_results(\n    domain=cf.domain,\n    u_exact=u_exact_for_plot,\n    u_pred=u_pred_for_plot,\n    error=error_for_plot,\n    plot_ranges=plot_range,\n    problem=problem,\n    network_name=network_name,\n    plot_dir=plot_dir,\n    pde_weight=PDE_WEIGHT,\n    time_steps_indices=final_indices,\n    desired_times=final_labels\n)\n\nplot_combined_results_3d(\n    domain=cf.domain,\n    u_exact=u_exact_for_plot,\n    u_pred=u_pred_for_plot,\n    error=error_for_plot,\n    plot_ranges=plot_range,\n    problem=problem,\n    network_name=network_name,\n    plot_dir=plot_dir,\n    pde_weight=PDE_WEIGHT,\n    time_steps_indices=final_indices,\n    desired_times=final_labels\n)\n\n# =========================================================================================\n# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===\n# =========================================================================================\n\n################################################################\n# Save Results to MATLAB .mat file\n################################################################\nprint(\"\\n--- Saving Results to .mat File ---\")\nimport scipy.io\n\nmat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')\n\nif PINN_MODE:\n    try:\n        results_dict = {\n            'train_mse_log': train_mse_hybrid_log,\n            'train_hybrid_loss': np.array(train_l2_hybrid_log),\n            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),\n            'train_data_log': np.array(train_data_log),\n            'test_data_log': np.array(test_data_log),\n            'train_pde_scaled_log': np.array(train_pde_scaled_log),\n            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,\n            'config_pde_loss_scaler': pde_loss_scaler if PINN_MODE else 0.0,\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\nelse:\n    try:\n        results_dict = {\n            'train_mse_log': np.array(train_mse_log),\n            'train_l2_log': np.array(train_l2_log),\n            'test_l2_log': np.array(test_l2_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\n\nprint(\"\\n--- Script Finished ---\")
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/main.py b/main.py
++--- a/main.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/main.py	(date 1754055606774)
++@@ -4,108 +4,122 @@
++ import inspect
++ import numpy as np
++ import matplotlib
+++import h5py  # MODIFIED: Added h5py import
+++import scipy.io
++ 
++ matplotlib.use('TkAgg')
++ import matplotlib.pyplot as plt
++ import torch.nn.functional as F
++-from training import train_fno, train_fno_time, train_hybrid, compute_initial_loss_scaler
+++from training import train_fno, train_fno_time, train_hybrid, train_fno4d
++ from torch.utils.data import DataLoader, random_split
++-from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator
+++from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator, SobolevLoss
++ from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \
++     make_video, save_vtk, plot_xy_plane_subplots
++-import time  # Import the time module at the beginning of the script
+++import time
++ from torch_optimizer import Lamb
++ 
+++################################################################
+++# Problem Definition
+++################################################################
+++
++ ################################################################
++ # Problem Definition
++ ################################################################
++ # problem = 'AC2D'
++-# problem = 'AC3D'
+++problem = 'AC3D'
++ # problem = 'CH2DNL'
++ # problem = 'SH2D'
++-problem = 'SH3D'
+++#problem = 'SH3D'
++ # problem = 'PFC2D'
++-# problem = 'PFC3D'
+++#problem = 'PFC3D'
++ # problem = 'MBE2D'
++-# problem = 'MBE3D'
+++#problem = 'MBE3D'
++ # problem = 'CH2D'
++-# problem = 'CH3D'
+++#problem = 'CH3D'
++ 
++ # network_name = 'TNO2d'
++ # network_name = 'FNO2d'
++ #network_name = 'FNO3d'
+++#network_name = 'FNO4d'
++ network_name = 'TNO3d'
++ 
++-PINN_MODE =  True #False #  False #  False  # False #
+++PINN_MODE =  False # True #  True #  False #  True #   True #    True #
+++#  False #    True # False #  False  # False #
++ 
++ print(f"problem = {problem}")
++ print(f"network = {network_name}")
++ os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
++-cf = importlib.import_module(f"configs.config_{problem}_{network_name}")  # configuration file
++-# above line means: import configs.config_PFC3D_TNO3d as cf
++-network = getattr(importlib.import_module('networks'), network_name)  # from networks import TNO3d
+++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+++network = getattr(importlib.import_module('networks'), network_name)
++ torch.manual_seed(cf.torch_seed)
++ np.random.seed(cf.numpy_seed)
++-# device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')
++-device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
+++device = torch.device("cuda:2" if torch.cuda.is_available() else "cpu")
++ print("Device: ", device)
++-# --- Define Output Directory ---
++-
++ 
++ PDE_WEIGHT = cf.pde_weight
++-#PDE_LOSS_SCALER = cf.pde_loss_scaler
+++pde_loss_scaler = cf.pde_loss_scaler
++ 
++ if PINN_MODE:
++     run_descriptor = f"PINN_w{int(PDE_WEIGHT * 100)}"
++-    output_subdir = f"plots_Data_Physics_{network_name}"  # Specific PINN output
+++    output_subdir = f"plots_Data_Physics_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_Hybrid_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
++ else:
++     run_descriptor = "DataDriven"
++-    output_subdir = f"plots_{network_name}"  # Original data-driven output
+++    output_subdir = f"plots_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
++ 
++-# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'
++-# model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_SH3D_random_sphere_finial.pt'
++-model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d.pt'
++-model_dir = os.path.join(problem, 'models')  # models_smpooth
+++model_dir = os.path.join(problem, 'models')
++ model_name = f'{model_run_name}'
++ model_path = os.path.join(model_dir, model_name)
++-
++-plot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir
+++plot_dir = os.path.join(problem, output_subdir)
++ os.makedirs(model_dir, exist_ok=True)
++-os.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists
+++os.makedirs(plot_dir, exist_ok=True)
++ 
++ print(f"Model Run Name: {model_run_name}")
++ print(f"Model Path: {model_path}")
++ print(f"Plot Directory: {plot_dir}")
++ 
++-# width_q = 32
++ start_time = time.time()
++ 
++ ################################################################
++ # load data and data normalization
++ ################################################################
++-# model_dir = problem + '/models'
++-
++-print(f"model = {model_name}")
++-print(f"number of epoch = {cf.epochs}")
++-print(f"batch size = {cf.batch_size}")
++-print(f"nTrain = {cf.nTrain}")
++-print(f"nTest = {cf.nTest}")
++-print(f"learning_rate = {cf.learning_rate}")
++-print(f"n_layers = {cf.n_layers}")
++-print(f"width_q = {cf.width_q}")
++-print(f"width_h = {cf.width_h}")
++-
++-model_path = os.path.join(model_dir, model_name)
++-os.makedirs(model_dir, exist_ok=True)
++-# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf
++-dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++# MODIFIED: Added special handling for SH3D dataset loading
+++try:
+++    dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++    if problem == 'SH3D':
+++        print("SH3D dataset detected - applying special handling")
+++        # Verify dataset sizes
+++        sample = dataset[0][0]  # Get first sample
+++        print(f"SH3D sample shape: {sample.shape}, dtype: {sample.dtype}")
+++        print(f"SH3D stats - mean: {sample.mean():.4f}, std: {sample.std():.4f}")
+++except Exception as e:
+++    print(f"Error loading dataset: {e}")
+++    raise
++ 
++ train_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])
++-# to see train_dataset values: print("train_dataset subset:", [train_dataset[i] for i in range(len(train_dataset))])
++ normalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None
++ 
++-train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
++-test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++train_loader = DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
+++test_loader = DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++
+++
+++# ==================== CODE TO INSPECT BATCH SHAPE ====================
+++print("\n" + "="*50)
+++print("Inspecting DataLoader Batch Shapes")
+++print("="*50)
+++# Get one batch of data from the train_loader
+++try:
+++    x_batch, y_batch = next(iter(train_loader))
+++    # Print the shape of the batch
+++    # This will be (batch_size, S, S, S, T_in) for input
+++    # and (batch_size, S, S, S, T_out) for target
+++    print(f"Shape of an input batch from DataLoader: {x_batch.shape}")
+++    print(f"Shape of a target batch from DataLoader: {y_batch.shape}")
+++except StopIteration:
+++    print("Train loader is empty. Cannot retrieve a batch.")
+++print("="*50 + "\n")
+++# =======================================================================
++ 
++ ############AA####################################################
++ # training and evaluation
++@@ -122,6 +136,19 @@
++ elif network_name == 'TNO3d':
++     model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(
++         device)
+++elif network_name == 'FNO4d':
+++    model = network(
+++        modes1=cf.modes,
+++        modes2=cf.modes,
+++        modes3=cf.modes,
+++        modes4_internal =1, # cf.modes_t, # MUST BE 1
+++        width=cf.width,
+++        width_q=cf.width_q,
+++        T_in_channels=cf.T_in,
+++        n_layers=cf.n_layers
+++    ).to(device)
+++
+++
++ else:
++     raise Exception("network_name is not correct")
++ 
++@@ -142,7 +169,10 @@
++ # Define optimizer, scheduler, and loss function
++ optimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)
++ scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)
++-myloss = LpLoss(p=2, l1_weight=0.0, size_average=False)
+++myloss = LpLoss(p=2, l1_weight=0.1, size_average=False) # size_average=True # False
+++# NEW: Instantiate SobolevLoss instead of LpLoss
+++# You can tune grad_weight. A good starting point is 0.1 or 1.0.
+++#myloss = SobolevLoss(d=3, p=2, grad_weight=0.1)
++ 
++ # COMPUTE THE DYNAMIC SCALER
++ # Use the train_loader to get a representative batch
++@@ -159,19 +189,6 @@
++             'T_out': cf.T_out
++         }
++ 
++-        pde_loss_scaler = compute_initial_loss_scaler(
++-            model,
++-            train_loader,
++-            myloss,
++-            cf.normalized,
++-            normalizers,
++-            device,
++-            grid_info,
++-            cf.epsilon,
++-            problem
++-        )
++-
++-
++         if PDE_WEIGHT == 0.0:
++             print("Running PINN training loop with pde_weight=0 (Data-Driven only loss).")
++         else:
++@@ -203,6 +220,13 @@
++                 train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                                optimizer, scheduler, cf.normalized, normalizers, device))
++             train_mse_log = []
+++        elif network_name == 'FNO4d':
+++
+++            model, train_mse_log, train_l2_log, test_l2_log = (  # Add val logs
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++            # train_fno4d = train_fno
++         else:
++             model, train_mse_log, train_l2_log, test_l2_log = (
++                 train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++@@ -216,14 +240,129 @@
++         'test_l2_log': test_l2_log
++     }, model_path)
++ 
+++
+++'''
+++# Train the model
+++if cf.training:
+++    print("\n--- Starting Training ---")
+++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
+++        grid_info = {
+++            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
+++            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
+++            'dt_model': cf.dt_model,
+++            'T_out': cf.T_out
+++        }
+++
+++        # --- NEW: Define the two stages for the training curriculum ---
+++        epochs_stage1 = 10
+++        scaler_stage1 = 1e-4
+++
+++        # Calculate remaining epochs for stage 2
+++        epochs_stage2 = cf.epochs - epochs_stage1
+++        scaler_stage2 = 1e-6
+++
+++        # --- Stage 1 Training ---
+++        print("\n--- Starting Training Stage 1 ---")
+++        print(f"Epochs: {epochs_stage1}, PDE Scaler: {scaler_stage1:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++        # Note: The 'model' object is updated in-place by the function call
+++        model, train_mse_s1, train_l2_s1, test_data_s1, test_pde_s1, train_data_s1, train_pde_scl_s1, test_loss_s1 = (
+++            train_hybrid(model, myloss, epochs_stage1, cf.batch_size, train_loader, test_loader,
+++                         optimizer, scheduler, cf.normalized, normalizers, device,
+++                         PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                         pde_loss_scaler=scaler_stage1)
+++        )
+++
+++        # --- Stage 2 Training (if there are remaining epochs) ---
+++        if epochs_stage2 > 0:
+++            print("\n--- Starting Training Stage 2 ---")
+++            print(f"Epochs: {epochs_stage2}, PDE Scaler: {scaler_stage2:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++            model, train_mse_s2, train_l2_s2, test_data_s2, test_pde_s2, train_data_s2, train_pde_scl_s2, test_loss_s2 = (
+++                train_hybrid(model, myloss, epochs_stage2, cf.batch_size, train_loader, test_loader,
+++                             optimizer, scheduler, cf.normalized, normalizers, device,
+++                             PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                             pde_loss_scaler=scaler_stage2)
+++            )
+++
+++            # Combine the logs from both stages for plotting and saving
+++            train_mse_hybrid_log = train_mse_s1 + train_mse_s2
+++            train_l2_hybrid_log = train_l2_s1 + train_l2_s2
+++            test_data_log = test_data_s1 + test_data_s2
+++            test_pde_loss_scaled_log = test_pde_s1 + test_pde_s2
+++            train_data_log = train_data_s1 + train_data_s2
+++            train_pde_scaled_log = train_pde_scl_s1 + train_pde_scl_s2
+++            test_loss_hybrid_log = test_loss_s1 + test_loss_s2
+++        else:
+++            # If only stage 1 was run, the final logs are just the stage 1 logs
+++            train_mse_hybrid_log = train_mse_s1
+++            train_l2_hybrid_log = train_l2_s1
+++            test_data_log = test_data_s1
+++            test_pde_loss_scaled_log = test_pde_s1
+++            train_data_log = train_data_s1
+++            train_pde_scaled_log = train_pde_scl_s1
+++            test_loss_hybrid_log = test_loss_s1
+++
+++        print(f"\n--- Training Finished. Saving model and logs to {model_path} ---")
+++        # The torch.save call remains the same, as the log variables have been correctly prepared
+++        torch.save({
+++            'model': model,
+++            'train_mse_log': train_mse_hybrid_log,
+++            'train_l2_log': train_l2_hybrid_log,
+++            'test_l2_log': test_data_log, # 'test_l2_log' is used by evaluator, it should contain data loss
+++            'test_pde_scaled_log': test_pde_loss_scaled_log,
+++            'train_data_log': train_data_log,
+++            'train_pde_scaled_log': train_pde_scaled_log,
+++            'test_loss_hybrid_log': test_loss_hybrid_log
+++        }, model_path)
+++
+++    else:  # Original Data-Driven Mode (This part remains unchanged)
+++        if network_name == 'FNO2d' or network_name == 'FNO3d':
+++            model, train_l2_log, test_l2_log = (
+++                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                               optimizer, scheduler, cf.normalized, normalizers, device))
+++            train_mse_log = []
+++        else:
+++            model, train_mse_log, train_l2_log, test_l2_log = (
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++        print(f"Saving model and logs to {model_path}")
+++        torch.save({
+++            'model': model,
+++            'train_mse_log': train_mse_log,
+++            'train_l2_log': train_l2_log,
+++            'test_l2_log': test_l2_log
+++        }, model_path)
+++'''
+++
++ end_time = time.time()
++ Final_time = round(end_time - start_time, 2)
++ print(f"Total Execution Time: {Final_time} seconds")
++ 
+++# ==================== START: CAPTURE PREDICTION AND EXACT SOLUTION TIMES ====================
+++print("\n--- Evaluating Model and Measuring Prediction Time ---")
++ evaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,
++                            time_history=(network_name == 'FNO2d'))
++ 
+++# Measure the time it takes to get predictions for the entire test set
+++prediction_start_time = time.time()
++ results = evaluator.evaluate(loss_fn=myloss)
+++prediction_end_time = time.time()
+++
+++# Calculate the model's prediction time
+++model_prediction_time = prediction_end_time - prediction_start_time
+++print(f"Model prediction time for the test set: {model_prediction_time:.4f} seconds")
+++
+++# IMPORTANT: Placeholder for the exact solution time.
+++# This value MUST be updated manually with the time it took the numerical
+++# solver to generate the ground truth data for the test set.
+++# The value here is just an example.
+++exact_solution_time = 3600.0  # Placeholder in seconds (e.g., 1 hour)
+++print(f"Using placeholder for exact solution time: {exact_solution_time:.2f} seconds. PLEASE UPDATE THIS VALUE.")
+++# ===================== END: CAPTURE PREDICTION AND EXACT SOLUTION TIMES =====================
+++
+++
++ inp = results['input']
++ pred = results['prediction']
++ exact = results['exact']
++@@ -326,7 +465,89 @@
++ print(f"Final indices for plotting: {final_indices}")
++ print(f"Final labels for plotting: {final_labels}")
++ 
+++
+++# =========================================================================================
+++# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===
+++# =========================================================================================
+++
+++################################################################
+++# Save Results to MATLAB .mat file
+++################################################################
+++print("\n--- Saving Results to .mat File ---")
+++mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
+++
+++# MODIFIED: Enhanced saving logic with fallbacks
+++def save_results(mat_filename, results_dict):
+++    try:
+++        # First try standard save
+++        scipy.io.savemat(mat_filename, results_dict)
+++        print(f"Saved with standard format to {mat_filename}")
+++    except ValueError as e:
+++        if "Format should be '4' or '5'" in str(e):
+++            print("Large data detected, trying v7.3 format...")
+++            try:
+++                scipy.io.savemat(mat_filename, results_dict, format='v7.3')
+++                print(f"Saved with v7.3 format to {mat_filename}")
+++            except Exception as e:
+++                print(f"v7.3 failed: {e}")
+++                # Fallback to HDF5
+++                h5_filename = mat_filename.replace('.mat', '.h5')
+++                with h5py.File(h5_filename, 'w') as f:
+++                    for k, v in results_dict.items():
+++                        f.create_dataset(k, data=v, compression='gzip')
+++                print(f"Saved as HDF5 to {h5_filename}")
+++        else:
+++            raise
+++
+++if PINN_MODE:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_hybrid_log, dtype=np.float32),  # MODIFIED: Added dtype
+++        'train_hybrid_loss': np.array(train_l2_hybrid_log, dtype=np.float32),
+++        'test_loss_hybrid_log': np.array(test_loss_hybrid_log, dtype=np.float32),
+++        'train_data_log': np.array(train_data_log, dtype=np.float32),
+++        'test_data_log': np.array(test_data_log, dtype=np.float32),
+++        'train_pde_scaled_log': np.array(train_pde_scaled_log, dtype=np.float32),
+++        'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),  # MODIFIED: Added astype
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_pde_weight': np.float32(PDE_WEIGHT),
+++        'config_pde_loss_scaler': np.float32(pde_loss_scaler),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++        'model_prediction_time': np.float32(model_prediction_time),  # ADDED
+++        'exact_solution_time': np.float32(exact_solution_time),      # ADDED
+++    }
+++else:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_log, dtype=np.float32),
+++        'train_l2_log': np.array(train_l2_log, dtype=np.float32),
+++        'test_l2_log': np.array(test_l2_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++        'model_prediction_time': np.float32(model_prediction_time),  # ADDED
+++        'exact_solution_time': np.float32(exact_solution_time),      # ADDED
+++    }
+++
+++# MODIFIED: Use the new save function
+++save_results(mat_filename, results_dict)
+++
++ # Plot XY-plane for the "Exact" solution trajectory (includes t=0)
+++
+++'''
++ plot_xy_plane_subplots(domain=cf.domain,
++                        field=u_exact_for_plot,
++                        field_name='Exact Solution',
++@@ -355,6 +576,7 @@
++                        plot_range=plot_range[2],
++                        problem=problem,
++                        network_name=network_name)
+++'''
++ 
++ # Calculate L2 norm on original full prediction
++ l2_norm_error = torch.norm(u_pred - u_exact, p=2)
++@@ -400,65 +622,4 @@
++     desired_times=final_labels
++ )
++ 
++-# =========================================================================================
++-# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===
++-# =========================================================================================
++-
++-################################################################
++-# Save Results to MATLAB .mat file
++-################################################################
++-print("\n--- Saving Results to .mat File ---")
++-import scipy.io
++-
++-mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
++-
++-if PINN_MODE:
++-    try:
++-        results_dict = {
++-            'train_mse_log': train_mse_hybrid_log,
++-            'train_hybrid_loss': np.array(train_l2_hybrid_log),
++-            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),
++-            'train_data_log': np.array(train_data_log),
++-            'test_data_log': np.array(test_data_log),
++-            'train_pde_scaled_log': np.array(train_pde_scaled_log),
++-            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,
++-            'config_pde_loss_scaler': pde_loss_scaler if PINN_MODE else 0.0,
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-else:
++-    try:
++-        results_dict = {
++-            'train_mse_log': np.array(train_mse_log),
++-            'train_l2_log': np.array(train_l2_log),
++-            'test_l2_log': np.array(test_l2_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-
++ print("\n--- Script Finished ---")
++\ No newline at end of file
++Index: run_interface3.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport numpy as np\nimport importlib\nfrom utilities import ImportDataset\nimport matplotlib\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom skimage import measure\nfrom matplotlib.colors import LightSource\n\n# Load model\ndevice = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n\n#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6.pt'\n\nmodel_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'\n\n# Option 1 (Recommended secure approach)\ntry:\n    from networks import TNO3d  # Import your custom network class\n    torch.serialization.add_safe_globals([TNO3d])\n    checkpoint = torch.load(model_path, map_location=device, weights_only=True)\nexcept Exception as e:\n    print(f\"Secure loading failed: {e}\\nFalling back to weights_only=False\")\n    # Option 2 (Less secure fallback)\n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n\nmodel = checkpoint['model']\nmodel.eval()\n\n# Load dataset for normalization\nproblem = 'SH3D'\nnetwork_name = 'TNO3d'\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\")\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\n# Move normalizer parameters to device\ndataset.normalizer_x.mean = dataset.normalizer_x.mean.to(device)\ndataset.normalizer_x.std = dataset.normalizer_x.std.to(device)\ndataset.normalizer_y.mean = dataset.normalizer_y.mean.to(device)\ndataset.normalizer_y.std = dataset.normalizer_y.std.to(device)\n\n\n# Create spherical initial condition\ndef create_sharp_sphere_initial_condition(N=32, radius=2, L=10):\n    x = np.linspace(-L / 2, L / 2, N)\n    y = np.linspace(-L / 2, L / 2, N)\n    z = np.linspace(-L / 2, L / 2, N)\n    xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')\n\n    r = np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)\n    sphere = np.ones((N, N, N), dtype=np.float32)  # Use float32 for consistency\n\n    # Perfectly sharp transition (no smoothing)\n    outer_mask = r > radius\n    sphere[outer_mask] = -1.0\n\n    # Force exact values (no floating point artifacts)\n    sphere = np.where(r <= radius, 1.0, -1.0)\n\n    return sphere\n# Create initial condition with perfect sharp interface\nsphere_ic = create_sharp_sphere_initial_condition()\n\ninput_tensor = torch.from_numpy(sphere_ic).float().unsqueeze(0).unsqueeze(-1).to(device)\ninput_tensor = dataset.normalizer_x.encode(input_tensor)\n\n# Run prediction\nwith torch.no_grad():\n    prediction = model(input_tensor)  # Shape [1, 32, 32, 32, 10]\n    prediction = dataset.normalizer_y.decode(prediction)\n\n# Define your custom frames to display\nselected_frames = [0, 50, 90]  # Adjusted for T_out=10\nnum_frames = len(selected_frames)\n\n# Create figure with two subplots: 3D views and 1D profile\nfig = plt.figure(figsize=(20, 10))\ngrid = plt.GridSpec(2, num_frames, hspace=0.3, wspace=0.2)\n\n# 1. Plot 3D isosurfaces for selected frames\nfor i, t in enumerate(selected_frames):\n    ax = fig.add_subplot(grid[0, i], projection='3d')\n    frame_data = prediction[0, ..., t].cpu().numpy()\n\n    # Print data range for debugging\n    print(f\"Frame {t}: min={np.min(frame_data):.3f}, max={np.max(frame_data):.3f}\")\n\n    # Determine appropriate level\n    data_min, data_max = np.min(frame_data), np.max(frame_data)\n    if data_min > 0 or data_max < 0:\n        level = (data_max + data_min) / 2  # Midpoint if zero is outside range\n    else:\n        level = 0.0  # Default level\n\n    try:\n        # Extract smooth isosurface with adjusted level\n        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level)\n\n        # Apply lighting and coloring\n        ls = LightSource(azdeg=135, altdeg=45)\n        rgb = ls.shade_normals(verts[faces], fraction=0.8)\n\n        mesh = Poly3DCollection(verts[faces],\n                                facecolors=rgb,\n                                edgecolor='none',\n                                alpha=0.9)\n\n        ax.add_collection3d(mesh)\n        plot_success = True\n    except ValueError as e:\n        print(f\"Could not generate isosurface for frame {t}: {e}\")\n        plot_success = False\n        # Display empty plot with error message\n        ax.text(0.5, 0.5, 0.5, f\"No isosurface\\nat level={level:.2f}\",\n                ha='center', va='center', fontsize=10)\n\n    # Set viewing parameters\n    ax.set_xlim(0, frame_data.shape[0])\n    ax.set_ylim(0, frame_data.shape[1])\n    ax.set_zlim(0, frame_data.shape[2])\n    ax.set_title(f'Time = {t}\\nLevel = {level:.2f}', pad=10)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_zticks([])\n    if plot_success:\n        ax.view_init(elev=30, azim=45)\n\n# 2. Plot 1D profile through center for all time steps\nax_profile = fig.add_subplot(grid[1, :])\nL = 10  # Domain size\nx = np.linspace(-L / 2, L / 2, prediction.shape[1])\ncenter_idx = prediction.shape[1] // 2  # Middle of the domain\n\n# Plot profiles for the same custom frames in the profile plot\nfor t in selected_frames:\n    profile = prediction[0, :, center_idx, center_idx, t].cpu().numpy()\n    ax_profile.plot(x, profile, label=f't={t}', alpha=0.8, linewidth=1.5)\n\n# Format profile plot\nax_profile.set_xlabel('Position along x-axis', fontsize=12)\nax_profile.set_ylabel('Field value', fontsize=12)\nax_profile.set_title('1D Profile Evolution Through Domain Center', pad=15)\nax_profile.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nax_profile.grid(True, alpha=0.3)\nax_profile.set_ylim([-1.2, 1.5])  # Match MATLAB y-limits\n\nplt.tight_layout()\nplt.show()\n\n# After getting predictions in Python\nprediction_np = prediction.cpu().numpy()  # Convert to numpy array\n\n# Save to .mat file\nfrom scipy.io import savemat\nsavemat('SH3D_python_predictions.mat', {\n    'python_pred': prediction_np,\n    'selected_frames': np.array(selected_frames),\n    'x': x  # Spatial coordinates\n})
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/run_interface3.py b/run_interface3.py
++--- a/run_interface3.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/run_interface3.py	(date 1754322796725)
++@@ -3,125 +3,373 @@
++ import importlib
++ from utilities import ImportDataset
++ import matplotlib
+++
++ matplotlib.use('TkAgg')
++ import matplotlib.pyplot as plt
++ from mpl_toolkits.mplot3d import Axes3D
++ from mpl_toolkits.mplot3d.art3d import Poly3DCollection
++ from skimage import measure
++ from matplotlib.colors import LightSource
+++from scipy.io import savemat
++ 
+++# ============================================================================
+++# 1. CHOOSE INITIAL CONDITION
+++# ============================================================================
+++# Options: 'sphere', 'dumbbell', 'star', separation, torus, 'heart'
+++initial_condition_type = 'sphere'  # <-- CHANGE THIS VALUE TO RUN A DIFFERENT SIMULATION
+++print(f"Running simulation for Initial Condition: {initial_condition_type.upper()}")
+++
+++# ============================================================================
+++# 2. MODEL AND DATASET LOADING
+++# ============================================================================
++ # Load model
++ device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")
++ 
++-#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6.pt'
++-
+++# SH3D
++ model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++
+++# AC3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/AC3D/models/TNO3d_AC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt' # AC3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/AC3D/models/TNO3d_AC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt' # AC3D
+++# CH3D
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/CH3D/models/TNO3d_CH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/CH3D/models/TNO3d_CH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++
+++
+++# mixed MBE3d#
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++# model_path = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
++ 
++-# Option 1 (Recommended secure approach)
+++# No Mixed
+++# model_path ='/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_S32_T1to100_width12_modes14_q12_h6_grf3d_NoMixed.pt'
+++# model_path ='/scratch/noqu8762/phase_field_equations_4d/MBE3D/models/TNO3d_MBE3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d_NoMixed.pt'
+++
+++# PFC (we plotted this)
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/models/TNO3d_PFC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++#model_path = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/models/TNO3d_PFC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+++
+++
+++
++ try:
++-    from networks import TNO3d  # Import your custom network class
++-    torch.serialization.add_safe_globals([TNO3d])
+++    from networks import TNO3d  # Assuming networks.py and TNO3d are available
+++
+++    # Add builtins.set to safe globals for robust loading
+++    torch.serialization.add_safe_globals([set])
+++    torch.serialization.add_safe_globals([TNO3d])  # Add TNO3d if it's part of the global scope during saving
+++
++     checkpoint = torch.load(model_path, map_location=device, weights_only=True)
++ except Exception as e:
++     print(f"Secure loading failed: {e}\nFalling back to weights_only=False")
++-    # Option 2 (Less secure fallback)
+++    # It's good practice to ensure the safe globals are added even for fallback
+++    torch.serialization.add_safe_globals([set])
+++    torch.serialization.add_safe_globals([TNO3d])
++     checkpoint = torch.load(model_path, map_location=device, weights_only=False)
++ 
++ model = checkpoint['model']
++ model.eval()
++ 
++-# Load dataset for normalization
++-problem = 'SH3D'
+++# Load dataset for normalization AND EXTRACT PROBLEM NAME
+++key_directory = 'phase_field_equations_4d'
+++problem = ''
+++try:
+++    parts = model_path.split('/')
+++    index = parts.index(key_directory)
+++    problem = parts[index + 1]  # This gets the directory name (e.g., 'AC3D')
+++except (ValueError, IndexError):
+++    print(f"Could not automatically determine problem name. Set manually if needed.")
+++
+++print(f"Problem Name Determined: {problem}")
++ network_name = 'TNO3d'
++-cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")  # Assuming configs module is available
++ dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
++ 
++-# Move normalizer parameters to device
++ dataset.normalizer_x.mean = dataset.normalizer_x.mean.to(device)
++ dataset.normalizer_x.std = dataset.normalizer_x.std.to(device)
++ dataset.normalizer_y.mean = dataset.normalizer_y.mean.to(device)
++ dataset.normalizer_y.std = dataset.normalizer_y.std.to(device)
++ 
++ 
++-# Create spherical initial condition
++-def create_sharp_sphere_initial_condition(N=32, radius=2, L=10):
++-    x = np.linspace(-L / 2, L / 2, N)
++-    y = np.linspace(-L / 2, L / 2, N)
++-    z = np.linspace(-L / 2, L / 2, N)
++-    xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')
+++# ============================================================================
+++# 3. CREATE INITIAL CONDITION
+++# ============================================================================
+++def create_initial_condition(ic_type='sphere'):
+++    Nx, Ny, Nz = 0, 0, 0
+++    Lx, Ly, Lz = 0, 0, 0
+++    epsilon = 0
+++    Nt = 0
+++    selected_frames = []
+++    u = None
+++    dt = 0
+++
+++    if ic_type == 'sphere':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        # Lx = 10*np.pi; # PFC3D
+++        #Lx = 5 # AC3D
+++        Lx = 15  # SH3D
+++        Ly = Lx;
+++        Lz = Lx
+++        # epsilon = 0.5 # PFC3D
+++        epsilon = 0.15 # SH3d
+++        #epsilon = 0.1 # AC3d
+++        # dt = 0.0005
+++        dt = 0.05  # SH3D
+++        Nt = 100
+++        selected_frames = [0, 70, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        # radius = 6 # PFC3D
+++        #radius = 0.5 # AC3D
+++        radius = 2.0  # SH3D
+++        interface_width = np.sqrt(2) * epsilon
+++        u = np.tanh((radius - np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)) / interface_width)
+++
+++    elif ic_type == 'dumbbell':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        Lx = 40;
+++        Ly = 20;
+++        Lz = 20
+++        epsilon = 0.005
+++        dt = 0.01
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(0, Lx, Nx)
+++        y_grid = np.linspace(0, Ly, Ny)
+++        z_grid = np.linspace(0, Lz, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        R0 = 0.25
+++        interface_width = np.sqrt(2) * epsilon
+++
+++        r1 = np.sqrt((xx - (0.3 * Lx)) ** 2 + (yy - (0.5 * Ly)) ** 2 + (zz - (0.5 * Lz)) ** 2)
+++        r2 = np.sqrt((xx - (1.7 * Lx)) ** 2 + (yy - (0.5 * Ly)) ** 2 + (zz - (0.5 * Lz)) ** 2)
+++        u_spheres = np.tanh((R0 - r1) / interface_width) + np.tanh((R0 - r2) / interface_width) + 1
+++
+++        bar_mask = (xx > (0.4 * Lx)) & (xx < (1.6 * Lx)) & \
+++                   (yy > (0.4 * Ly)) & (yy < (0.6 * Ly)) & \
+++                   (zz > (0.4 * Lz)) & (zz < (0.6 * Lz))
+++        u = u_spheres
+++        u[bar_mask] = 1.0
+++        u = np.clip(u, -1.0, 1.0)
+++
+++    elif ic_type == 'star':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        #Lx = 5 # AC3D,
+++        Lx = 10 * np.pi  # --> PFC3D
+++        #Lx = 2  # CH3D
+++        Ly = Lx;
+++        Lz = Lx
+++        epsilon = 0.5  # PFC3D
+++        #epsilon = 0.05 # CH3d
+++        dt = 0.005
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++ 
++-    r = np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)
++-    sphere = np.ones((N, N, N), dtype=np.float32)  # Use float32 for consistency
+++        interface_width = np.sqrt(2.0) * epsilon
+++        theta = np.arctan2(zz, xx)
+++        R_theta = 5.0 + 1.0 * np.cos(6 * theta)  # PFC3D
+++        # R_theta = 0.7 + 0.2 * np.cos(6 * theta)  # AC3D
+++        #R_theta = 0.7 + 0.2 * np.cos(6 * theta)  # CH3D
+++        dist = np.sqrt(xx ** 2 + 2 * yy ** 2 + zz ** 2)
+++        u = np.tanh((R_theta - dist) / interface_width)
++ 
++-    # Perfectly sharp transition (no smoothing)
++-    outer_mask = r > radius
++-    sphere[outer_mask] = -1.0
+++    elif ic_type == 'torus':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        # Lx = 10*np.pi;
+++        Lx = 2 * np.pi  # MBE3D
+++        Ly = Lx;
+++        Lz = Lx
+++        # epsilon = 0.5
+++        epsilon = 0.1  # MBE3D
+++        # dt = 0.005
+++        dt = 0.001  # MBE3D
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
++ 
++-    # Force exact values (no floating point artifacts)
++-    sphere = np.where(r <= radius, 1.0, -1.0)
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
++ 
++-    return sphere
++-# Create initial condition with perfect sharp interface
++-sphere_ic = create_sharp_sphere_initial_condition()
+++        # R_major = 5.5
+++        # r_minor = 3.5
+++        R_major = 2.1  # MBE3D
+++        r_minor = 0.7  # MBE3D
++ 
++-input_tensor = torch.from_numpy(sphere_ic).float().unsqueeze(0).unsqueeze(-1).to(device)
+++        interface_width = np.sqrt(2) * epsilon
+++        torus_dist = np.sqrt((np.sqrt(xx ** 2 + yy ** 2) - R_major) ** 2 + zz ** 2)
+++        u = np.tanh((r_minor - torus_dist) / interface_width)
+++        # u = np.clip(u, -1.0, 1.0)
+++
+++    elif ic_type == 'separation':
+++        Nx = 32;
+++        Ny = 32;
+++        Nz = 32
+++        Lx = 2 * np.pi;
+++        Ly = 2 * np.pi;
+++        Lz = 2 * np.pi
+++        epsilon = 0.5
+++        dt = 0.0005
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        interface_width = np.sqrt(2) * epsilon
+++
+++        r1_dist = np.sqrt((xx + 1) ** 2 + yy ** 2 + zz ** 2)
+++        r2_dist = np.sqrt((xx - 1) ** 2 + yy ** 2 + zz ** 2)
+++
+++        u = np.tanh((1 - r1_dist) / interface_width) + np.tanh((1 - r2_dist) / interface_width)
+++        # u = np.clip(u, -1.0, 1.0)
+++
+++    elif ic_type == 'heart':
+++        Nx = 32
+++        Ny = 32
+++        Nz = 32
+++        Lx = 5.0
+++        Ly = Lx
+++        Lz = Lx
+++        epsilon = 0.15
+++        dt = 0.005  # Assuming a dt similar to other conditions
+++        Nt = 100
+++        selected_frames = [0, 50, 90]
+++
+++        x_grid = np.linspace(-Lx / 2, Lx / 2, Nx)
+++        y_grid = np.linspace(-Ly / 2, Ly / 2, Ny)
+++        z_grid = np.linspace(-Lz / 2, Lz / 2, Nz)
+++        xx, yy, zz = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
+++
+++        # Equation from image: phi(x,y,z,0) = tanh( ( (x^2 + 9/4*y^2 + z^2 - 1)^3 - x^2*z^3 - 9/80*y^2*z^3 ) / sqrt(2*epsilon) )
+++        denominator = np.sqrt(2 * epsilon)
+++        numerator = (xx ** 2 + (9 / 4) * yy ** 2 + zz ** 2 - 1) ** 3 - xx ** 2 * zz ** 3 - (9 / 80) * yy ** 2 * zz ** 3
+++        u = np.tanh(numerator / denominator)
+++
+++    else:
+++        raise ValueError(f"Unknown initial condition type: {ic_type}")
+++
+++    return u, (Lx, Ly, Lz), (Nx, Ny, Nz), Nt, dt, selected_frames
+++
+++
+++# Create the selected initial condition
+++initial_condition_field, domain_lengths, grid_sizes, Nt, dt, selected_frames = create_initial_condition(
+++    ic_type=initial_condition_type)
+++Lx, Ly, Lz = domain_lengths
+++Nx, Ny, Nz = grid_sizes
+++
+++# ============================================================================
+++# 4. PREDICTION AND VISUALIZATION
+++# ============================================================================
+++# Prepare tensor for the model
+++input_tensor = torch.from_numpy(initial_condition_field).float().unsqueeze(0).unsqueeze(-1).to(device)
++ input_tensor = dataset.normalizer_x.encode(input_tensor)
++ 
++ # Run prediction
++ with torch.no_grad():
++-    prediction = model(input_tensor)  # Shape [1, 32, 32, 32, 10]
+++    # Start timer
+++    start_time = torch.cuda.Event(enable_timing=True)
+++    end_time = torch.cuda.Event(enable_timing=True)
+++
+++    torch.cuda.synchronize()  # Wait for all operations to complete
+++    start_time.record()  # Start recording
+++
+++    prediction = model(input_tensor)
+++
+++    end_time.record()  # Stop recording
+++    torch.cuda.synchronize()  # Wait for all operations to complete
+++
+++    # ==================== MODIFICATION START ====================
+++    # Calculate elapsed time in milliseconds
+++    inference_time_ms = start_time.elapsed_time(end_time)
+++    # Convert milliseconds to seconds for saving
+++    inference_time = inference_time_ms / 1000.0
+++    # ===================== MODIFICATION END =====================
+++
++     prediction = dataset.normalizer_y.decode(prediction)
+++    # Clip the prediction to be within the physical bounds [-1, 1].
+++    #prediction = torch.clamp(prediction, min=-1.0, max=1.0) # SH3d
++ 
++-# Define your custom frames to display
++-selected_frames = [0, 50, 90]  # Adjusted for T_out=10
++-num_frames = len(selected_frames)
+++# ==================== MODIFICATION START ====================
+++# Updated print statement to show both units
+++print(f"Inference time: {inference_time_ms:.3f} milliseconds ({inference_time:.6f} seconds)")
+++# ===================== MODIFICATION END =====================
++ 
++-# Create figure with two subplots: 3D views and 1D profile
+++
+++# Create figure
++ fig = plt.figure(figsize=(20, 10))
++-grid = plt.GridSpec(2, num_frames, hspace=0.3, wspace=0.2)
+++grid = plt.GridSpec(2, len(selected_frames), hspace=0.3, wspace=0.2)
+++fig.suptitle(f"TNO Prediction for {initial_condition_type.upper()} Initial Condition ({problem})", fontsize=16)
++ 
++-# 1. Plot 3D isosurfaces for selected frames
+++# Define mesh coordinates for plotting
+++if initial_condition_type in ['sphere', 'star', 'torus', 'separation', 'heart']:
+++    x_coords = np.linspace(-Lx / 2, Lx / 2, Nx)
+++    x_lim_low, x_lim_high = -Lx / 2, Lx / 2
+++    y_lim_low, y_lim_high = -Ly / 2, Ly / 2
+++    z_lim_low, z_lim_high = -Lz / 2, Lz / 2
+++elif initial_condition_type == 'dumbbell':
+++    x_coords = np.linspace(0, Lx, Nx)
+++    x_lim_low, x_lim_high = 0, Lx
+++    y_lim_low, y_lim_high = 0, Ly
+++    z_lim_low, z_lim_high = 0, Lz
+++
+++# 1. Plot 3D isosurfaces
++ for i, t in enumerate(selected_frames):
++     ax = fig.add_subplot(grid[0, i], projection='3d')
+++
+++    # if t == 0:
+++    #    frame_data = initial_condition_field
+++    #    title_text = f'Initial Condition\nTime = {t}'
+++    # else:
+++    #    frame_data = prediction[0, ..., t].cpu().numpy()
+++    #    title_text = f'Prediction\nTime = {t}'
+++
++     frame_data = prediction[0, ..., t].cpu().numpy()
++-
++-    # Print data range for debugging
++-    print(f"Frame {t}: min={np.min(frame_data):.3f}, max={np.max(frame_data):.3f}")
+++    title_text = f'Prediction\nTime = {t}'
++ 
++-    # Determine appropriate level
++-    data_min, data_max = np.min(frame_data), np.max(frame_data)
++-    if data_min > 0 or data_max < 0:
++-        level = (data_max + data_min) / 2  # Midpoint if zero is outside range
++-    else:
++-        level = 0.0  # Default level
++-
+++    level = 0.0
++     try:
++-        # Extract smooth isosurface with adjusted level
++-        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level)
+++        dx, dy, dz = Lx / (Nx - 1), Ly / (Ny - 1), Lz / (Nz - 1)
+++        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level, spacing=(dx, dy, dz))
++ 
++-        # Apply lighting and coloring
+++        if initial_condition_type in ['sphere', 'star', 'torus', 'separation', 'heart']:
+++            verts[:, 0] -= Lx / 2
+++            verts[:, 1] -= Ly / 2
+++            verts[:, 2] -= Lz / 2
+++
++         ls = LightSource(azdeg=135, altdeg=45)
++-        rgb = ls.shade_normals(verts[faces], fraction=0.8)
++-
++-        mesh = Poly3DCollection(verts[faces],
++-                                facecolors=rgb,
++-                                edgecolor='none',
++-                                alpha=0.9)
++-
+++        mesh = Poly3DCollection(verts[faces], facecolors='gray', edgecolor='none', alpha=0.9)
++         ax.add_collection3d(mesh)
++         plot_success = True
++     except ValueError as e:
++         print(f"Could not generate isosurface for frame {t}: {e}")
+++        ax.text(0.5, 0.5, 0.5, f"No isosurface\nat level={level:.2f}", ha='center', va='center', transform=ax.transAxes)
++         plot_success = False
++-        # Display empty plot with error message
++-        ax.text(0.5, 0.5, 0.5, f"No isosurface\nat level={level:.2f}",
++-                ha='center', va='center', fontsize=10)
++ 
++-    # Set viewing parameters
++-    ax.set_xlim(0, frame_data.shape[0])
++-    ax.set_ylim(0, frame_data.shape[1])
++-    ax.set_zlim(0, frame_data.shape[2])
++-    ax.set_title(f'Time = {t}\nLevel = {level:.2f}', pad=10)
+++    ax.set_xlim(x_lim_low, x_lim_high)
+++    ax.set_ylim(y_lim_low, y_lim_high)
+++    ax.set_zlim(z_lim_low, z_lim_high)
+++    ax.set_title(f'{title_text}\nLevel = {level:.2f}', pad=10)
++     ax.grid(False)
++     ax.set_xticks([])
++     ax.set_yticks([])
++@@ -129,35 +377,76 @@
++     if plot_success:
++         ax.view_init(elev=30, azim=45)
++ 
++-# 2. Plot 1D profile through center for all time steps
+++# 2. Plot 1D profile
++ ax_profile = fig.add_subplot(grid[1, :])
++-L = 10  # Domain size
++-x = np.linspace(-L / 2, L / 2, prediction.shape[1])
++-center_idx = prediction.shape[1] // 2  # Middle of the domain
+++center_y_idx = Ny // 2
+++center_z_idx = Nz // 2
++ 
++-# Plot profiles for the same custom frames in the profile plot
++ for t in selected_frames:
++-    profile = prediction[0, :, center_idx, center_idx, t].cpu().numpy()
++-    ax_profile.plot(x, profile, label=f't={t}', alpha=0.8, linewidth=1.5)
+++    if t == 0:
+++        profile = initial_condition_field[:, center_y_idx, center_z_idx]
+++        label_text = f't={t} (IC)'
+++    else:
+++        profile = prediction[0, :, center_y_idx, center_z_idx, t].cpu().numpy()
+++        label_text = f't={t}'
+++    # profile = prediction[0, :, center_y_idx, center_z_idx, t].cpu().numpy()
+++    # label_text = f't={t}'
++ 
++-# Format profile plot
+++    ax_profile.plot(x_coords, profile, label=label_text, alpha=0.8, linewidth=1.5)
+++
++ ax_profile.set_xlabel('Position along x-axis', fontsize=12)
++ ax_profile.set_ylabel('Field value', fontsize=12)
++ ax_profile.set_title('1D Profile Evolution Through Domain Center', pad=15)
++ ax_profile.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
++ ax_profile.grid(True, alpha=0.3)
++-ax_profile.set_ylim([-1.2, 1.5])  # Match MATLAB y-limits
+++ax_profile.set_ylim([-1.5, 1.5])
++ 
++-plt.tight_layout()
+++plt.tight_layout(rect=[0, 0, 1, 0.96])
++ plt.show()
++ 
++-# After getting predictions in Python
++-prediction_np = prediction.cpu().numpy()  # Convert to numpy array
++ 
++-# Save to .mat file
++-from scipy.io import savemat
++-savemat('SH3D_python_predictions.mat', {
++-    'python_pred': prediction_np,
+++## This is saved the data of initial condition itself
+++# ============================================================================
+++# 5. SAVE RESULTS TO .MAT FILE
+++# ============================================================================
+++# Get the raw prediction tensor from the model as a NumPy array
+++prediction_np = prediction.cpu().numpy()
+++# Create a "hybrid" tensor for saving, ensuring the t=0 slice is the true IC
+++final_prediction_to_save = np.copy(prediction_np)
+++final_prediction_to_save[0, :, :, :, 0] = initial_condition_field
+++# Define the output filename using the 'problem' variable extracted earlier
+++# from the model_path. This makes the filename dynamic.
+++output_filename = f'{problem}_python_predictions_{initial_condition_type}.mat'
+++
+++# ==================== MODIFICATION START ====================
+++# Save the corrected data and the inference time to the .mat file
+++savemat(output_filename, {
+++    'python_pred': final_prediction_to_save,
++     'selected_frames': np.array(selected_frames),
++-    'x': x  # Spatial coordinates
++-})
++\ No newline at end of file
+++    'x': x_coords,
+++    'inference_time': inference_time  # Add the inference time (in seconds)
+++})
+++print(f"Corrected prediction (with true IC at t=0) and inference time saved to {output_filename}")
+++
+++# ===================== MODIFICATION END =====================
+++
+++'''
+++# ============================================================================
+++# 5. SAVE RESULTS TO .MAT FILE
+++# ============================================================================
+++# Get the raw prediction tensor from the model as a NumPy array
+++prediction_np = prediction.cpu().numpy()
+++# The array to save is now just the raw prediction
+++final_prediction_to_save = prediction_np
+++# The line that overwrites t=0 has been removed.
+++output_filename = f'{problem}_python_predictions_{initial_condition_type}.mat'
+++# Save the raw prediction data to the .mat file
+++savemat(output_filename, {
+++    'python_pred': final_prediction_to_save,
+++    'selected_frames': np.array(selected_frames),
+++    'x': x_coords,
+++    'inference_time': inference_time  # Add the inference time (in seconds)
+++})
+++print(f"Raw model prediction saved to {output_filename}")
+++
+++'''
++Index: configs/config_MBE3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\nimport numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 #1600 # 4000\nnTest = 300  # 400\nbatch_size = 50# 25 #100\nlearning_rate = 0.005\nweight_decay = 1e-4\nepochs = 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 12\nwidth = 12 #32\nwidth_q = width #32\nwidth_h = width // 2 # width # 32\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # True  # True\nload_model = False #True  # False  # False\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'\nmatlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 9  # 72\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_MBE3D_TNO3d.py b/configs/config_MBE3D_TNO3d.py
++--- a/configs/config_MBE3D_TNO3d.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/configs/config_MBE3D_TNO3d.py	(date 1754055606807)
++@@ -7,23 +7,23 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 1200 #1600 # 4000
+++nTrain = 1300 #1600 # 4000
++ nTest = 300  # 400
++-batch_size = 50# 25 #100
++-learning_rate = 0.005
+++batch_size = 20 # 50# 25 #100
+++learning_rate = 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 1000
+++epochs =  50 # 25# 50 # 20 # 50 # 1000
++ iterations = epochs * (nTrain // batch_size)
++-modes = 14 # 12
++-width = 12 #32
+++modes = 14 # 14 # 12
+++width = 12 # 12 #32
++ width_q = width #32
++ width_h = width // 2 # width # 32
++-n_layers = 4
+++n_layers = 2 # 4 # 3 # 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -32,14 +32,45 @@
++ 
++ # Database
++ parent_dir = './data/'
++-#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'
++-matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'
+++
+++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat' # I got the result based on this Dataset!! epochs = 50 !! n_layers = 2 pde_loss_scaler = 1e-4 # 1e-3
+++#matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat' # not valid
+++
++ # Plotting
++-index = 9  # 72
++-domain = [-np.pi, np.pi]
+++index = 62  # 72
+++#domain = [-np.pi, np.pi]
+++Lx = 2* np.pi  # 6 # 2* np.pi            # Domain size from MATLAB
+++domain = [-Lx/2, Lx/2]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.001 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.1 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4 # 1e-3
++\ No newline at end of file
++Index: training.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport torch.nn.functional as F\nfrom timeit import default_timer\nfrom tqdm import tqdm\n\ndef train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,\n              optimizer, scheduler, normalized, normalizer, device):\n    train_mse_log = []\n    train_l2_log = []\n    test_l2_log = []\n\n    if normalized:\n        # a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        # a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n        train_mse = 0\n        train_l2 = 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            #print(\"x shape\", x.shape)\n            out = model(x)\n            #print(f\"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}\")\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            train_mse += mse.item()\n            train_l2 += loss.item()\n\n        model.eval()\n        test_l2 = 0.0\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                #test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n\n        train_mse /= len(train_loader)\n        train_l2 /= (batch_size * len(train_loader))\n        test_l2 /= (batch_size * len(test_loader))\n\n        train_mse_log.append(train_mse)\n        train_l2_log.append(train_l2)\n        test_l2_log.append(test_l2)\n\n        # Update the learning rate based on the test_l2 metric\n        #scheduler.step(test_l2) ##\n\n\n        t2 = default_timer()\n        #print(ep, t2 - t1, train_mse, train_l2, test_l2)\n        if ep == 0:  # Print the header row once\n            print(\"No. Epoch   Time (s)       Train MSE      Train L2       Test L2\")\n\n        print(f\"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}\")\n\n    return model, train_mse_log, train_l2_log, test_l2_log\n\ndef train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,\n                   optimizer, scheduler, normalized, normalizer, device):\n    ntrain = len(train_loader) * train_loader.batch_size\n    ntest = len(test_loader) * test_loader.batch_size\n    train_mse_log = []\n    train_l2_log = []\n    test_l2_log = []\n    step = 1\n    if normalized:\n        a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n        train_l2_step = 0\n        train_l2_full = 0\n        for xx, yy in train_loader:\n            loss = 0\n            xx = xx.to(device)\n            yy = yy.to(device)\n            T = yy.shape[-1]\n            #print(f\" T : {T}\")\n            #print(f\"target shape: {yy.shape}\")\n            #print(f\"Input shape: {xx.shape}, y (target): {yy.shape}\")\n            for t in range(0, T, step):\n                y = yy[..., t:t + step]\n                im = model(xx)\n                #print(f\"Input shape: {xx.shape}, y (target): {y.shape}, prediction (model output): {im.shape}\")\n                #print(f\"target shape 2: {yy.shape}\")\n                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n\n                if t == 0:\n                    pred = im\n                else:\n                    pred = torch.cat((pred, im), -1)\n                xx = torch.cat((xx[..., step:], im), dim=-1)\n\n            train_l2_step += loss.item()\n            l2_full = myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1))\n            train_l2_full += l2_full.item()\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n        test_l2_step = 0\n        test_l2_full = 0\n        with torch.no_grad():\n            for xx, yy in test_loader:\n                loss = 0\n                xx = xx.to(device)\n                yy = yy.to(device)\n\n                for t in range(0, T, step):\n                    y = yy[..., t:t + step]\n                    im = model(xx)\n                    loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n\n                    if t == 0:\n                        pred = im\n                    else:\n                        pred = torch.cat((pred, im), -1)\n\n                    xx = torch.cat((xx[..., step:], im), dim=-1)\n\n                test_l2_step += loss.item()\n                test_l2_full += myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1)).item()\n\n        t2 = default_timer()\n        train_mse = train_l2_step / ntrain / (T / step)\n        train_l2 = train_l2_full / ntrain\n        test_l2 = test_l2_full / ntest\n\n        # Log the loss values\n        train_l2_log.append(train_l2_step / ntrain / (T / step))\n        test_l2_log.append(test_l2_step / ntest / (T / step))\n\n        if ep == 0:  # Print the header row once\n            print(\"No. Epoch   Time (s)       Train MSE      Train L2       Test L2\")\n\n        print(f\"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}\")\n\n    return model, train_l2_log, test_l2_log\n\n\n\n########################\n########################\n\ndef calculate_pde_residual(u_phys, grid_info, epsilon, problem, device):\n    \"\"\"\n    Calculates the residual for a specified 3D PDE on PHYSICAL data.\n    u_phys shape: (batch, Nx, Ny, Nz, T_out) - Denormalized data\n    grid_info: Dictionary containing Nx, Ny, Nz, Lx, Ly, Lz, dt_model, T_out\n    pde_params: Dictionary containing PDE-specific parameters\n    problem_name: String identifier for the PDE (e.g., 'SH3D', 'AC3D', 'CH3D', 'MBE3D', 'PFC3D')\n    device: PyTorch device\n    \"\"\"\n    batch_size, Nx, Ny, Nz, T_out = u_phys.shape\n    Lx, Ly, Lz = grid_info['Lx'], grid_info['Ly'], grid_info['Lz']\n    dt_model = grid_info['dt_model']\n\n    if T_out <= 1:\n        print(f\"Warning: T_out ({T_out}) <= 1 for problem {problem}. PDE loss requires T_out > 1. Returning zero loss.\")\n        return torch.zeros(1, device=device, requires_grad=True)\n\n    # --- Calculate Time Derivative (u/t) ---\n    du_dt = torch.zeros_like(u_phys)\n    du_dt[..., 0] = (u_phys[..., 1] - u_phys[..., 0]) / dt_model\n    du_dt[..., -1] = (u_phys[..., -1] - u_phys[..., -2]) / dt_model\n    if T_out > 2:\n       du_dt[..., 1:-1] = (u_phys[..., 2:] - u_phys[..., :-2]) / (2 * dt_model)\n\n    # --- Common Spectral Derivative Setup ---\n    _kx = torch.fft.fftfreq(Nx, d=Lx/Nx) * 2 * torch.pi\n    _ky = torch.fft.fftfreq(Ny, d=Ly/Ny) * 2 * torch.pi\n    _kz = torch.fft.fftfreq(Nz, d=Lz/Nz) * 2 * torch.pi\n\n    ikx_m, iky_m, ikz_m = torch.meshgrid(1j * _kx, 1j * _ky, 1j * _kz, indexing='ij')\n    ikx_m = ikx_m.to(device)\n    iky_m = iky_m.to(device)\n    ikz_m = ikz_m.to(device)\n\n    k2x_m, k2y_m, k2z_m = torch.meshgrid(_kx**2, _ky**2, _kz**2, indexing='ij')\n    # k2_m is kx^2 + ky^2 + kz^2. In Fourier space, laplacian is -k2_m\n    k2_m = (k2x_m + k2y_m + k2z_m).to(device)\n\n    u_hat = torch.fft.fftn(u_phys, dim=[1, 2, 3])\n\n    pde_residual = None\n\n    if problem == 'SH3D':\n        epsilon_sh = epsilon # pde_params.get('epsilon_sh')\n        if epsilon_sh is None: raise ValueError(\"Parameter 'epsilon_sh' not provided for SH3D.\")\n        k4_m = k2_m**2\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n        rhs_sh3d = -(u_phys**3) - (1 - epsilon_sh) * u_phys - biharm_u - 2 * lap_u\n        pde_residual = du_dt - rhs_sh3d\n\n    elif problem == 'AC3D':\n        Cahn_ac = epsilon # pde_params.get('Cahn_ac')\n        if Cahn_ac is None: raise ValueError(\"Parameter 'Cahn_ac' not provided for AC3D.\")\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        f_prime_u = u_phys**3 - u_phys\n        rhs_ac3d = Cahn_ac * lap_u - f_prime_u\n        pde_residual = du_dt - rhs_ac3d\n\n    elif problem == 'CH3D':\n        Cahn_ch = epsilon #  pde_params.get('Cahn_ch')\n        if Cahn_ch is None: raise ValueError(\"Parameter 'Cahn_ch' not provided for CH3D.\")\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        #mu_terms = (u_phys**3 - 3 * u_phys) - Cahn_ch * lap_u\n        mu_terms = (u_phys ** 3 -  u_phys) - Cahn_ch * lap_u\n        mu_terms_hat = torch.fft.fftn(mu_terms, dim=[1, 2, 3])\n        lap_mu_terms_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * mu_terms_hat\n        lap_mu_terms = torch.fft.ifftn(lap_mu_terms_hat, dim=[1, 2, 3]).real\n        rhs_ch3d = lap_mu_terms\n        pde_residual = du_dt - rhs_ch3d\n\n    elif problem == 'MBE3D':\n        epsilon_mbe = epsilon #  pde_params.get('epsilon_mbe')\n        if epsilon_mbe is None: raise ValueError(\"Parameter 'epsilon_mbe' not provided for MBE3D.\")\n        du_dx_hat = ikx_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dy_hat = iky_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dz_hat = ikz_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dx = torch.fft.ifftn(du_dx_hat, dim=[1, 2, 3]).real\n        du_dy = torch.fft.ifftn(du_dy_hat, dim=[1, 2, 3]).real\n        du_dz = torch.fft.ifftn(du_dz_hat, dim=[1, 2, 3]).real\n        grad_u_sq = du_dx**2 + du_dy**2 + du_dz**2\n        f1 = grad_u_sq * du_dx\n        f2 = grad_u_sq * du_dy\n        f3 = grad_u_sq * du_dz\n        f1_hat = torch.fft.fftn(f1, dim=[1, 2, 3])\n        f2_hat = torch.fft.fftn(f2, dim=[1, 2, 3])\n        f3_hat = torch.fft.fftn(f3, dim=[1, 2, 3])\n        div_term_hat = (ikx_m.unsqueeze(0).unsqueeze(-1) * f1_hat +\n                        iky_m.unsqueeze(0).unsqueeze(-1) * f2_hat +\n                        ikz_m.unsqueeze(0).unsqueeze(-1) * f3_hat)\n        div_term = torch.fft.ifftn(div_term_hat, dim=[1, 2, 3]).real\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        k4_m = k2_m**2\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term\n        pde_residual = du_dt - rhs_mbe3d\n\n    elif problem == 'PFC3D':\n        epsilon_pfc = epsilon # pde_params.get('epsilon_pfc') # Parameter 'r' in PFC, often -(epsilon)\n        if epsilon_pfc is None: raise ValueError(\"Parameter 'epsilon_pfc' not provided for PFC3D.\")\n\n        # Calculate necessary derivatives\n        # -u  (term1_spatial_operator * u)\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n\n        # u   (term2_spatial_operator * u)\n        k4_m = k2_m**2\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n\n        # -u  (term3_spatial_operator * u)\n        k6_m = k2_m**3 # Be careful with sign if k2_m is just kx^2+ky^2+kz^2\n                      # Since k^6 in Fourier space corresponds to (-^2)^3 = -^6 if direct multiplication\n                      # Or (i k)^6 = -k^6.\n                      # The MATLAB denominator (1/dt + (1-eps)k^2 + k^6) implies the k^6 term is positive.\n                      # So in real space, this corresponds to -u (because -(-)^3 u = u is not what we want)\n                      # A positive k^6 in Fourier space means we multiply by k^6, which is (-(laplacian_operator))^3,\n                      # this will become -laplacian_operator^3 which is -.\n                      # The MATLAB form `(pp2+qq2+rr2).^3` is `(k^2)^3 = k^6`.\n                      # So this term becomes `k^6 * u_hat` -> `u` (with a negative sign from implicit to explicit)\n        # Or, if (pp2+qq2+rr2) is k^2, then (pp2+qq2+rr2)^3 is k^6.\n        # The term in the denominator is `+ k^6`, so when moved to RHS it's `-k^6 u_hat`.\n        # `-k^6 u_hat` corresponds to `u` in real space.\n        triharm_u_hat = -k6_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        triharm_u = torch.fft.ifftn(triharm_u_hat, dim=[1, 2, 3]).real\n\n\n        # (u)\n        u_cubed = u_phys**3\n        u_cubed_hat = torch.fft.fftn(u_cubed, dim=[1, 2, 3])\n        lap_u_cubed_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_cubed_hat\n        lap_u_cubed = torch.fft.ifftn(lap_u_cubed_hat, dim=[1, 2, 3]).real\n\n        # PDE: u/t + (1-)u + 2u + u + (u) = 0\n        # RHS = - ( (1-_pfc)u + 2u + u + (u) )\n        # Let's use the parameter `epsilon` from PFC MATLAB as `r` (undercooling param)\n        # A common PFC form is du/dt = nabla^2 * ( (r)u + u^3 - (1+nabla^2)^2 u )\n        # du/dt = nabla^2 * ( ru + u^3 - (1 + 2 nabla^2 + nabla^4)u )\n        # du/dt = r nabla^2 u + nabla^2(u^3) - nabla^2 u - 2 nabla^4 u - nabla^6 u\n        # du/dt = (r-1) nabla^2 u - 2 nabla^4 u - nabla^6 u + nabla^2(u^3)\n        # Here 'r' from literature is often called 'epsilon' in PFC code.\n        # Let's match the form derived from MATLAB:\n        # u/t = -(1-)u - 2u - u - (u)\n        # Residual: du_dt - [-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed]\n\n        term1_spatial = (1 - epsilon_pfc) * lap_u # (1-eps)(-nabla^2 u) -> (eps-1)nabla^2 u\n        term2_spatial = 2 * biharm_u             # 2 nabla^4 u\n        term3_spatial = triharm_u                # nabla^6 u\n        term4_nonlinear = lap_u_cubed            # nabla^2 (u^3)\n\n        # According to the derived form: u/t = -(1-)u - 2u - u - (u)\n        # residual = du_dt - (-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed)\n        rhs_pfc3d = -(1 - epsilon_pfc) * lap_u - 2 * biharm_u - triharm_u - lap_u_cubed\n        pde_residual = du_dt - rhs_pfc3d\n\n    else:\n        raise ValueError(f\"Unknown problem_name: {problem}. PDE residual not defined.\")\n\n    if pde_residual is not None:\n        loss_pde = F.mse_loss(pde_residual, torch.zeros_like(pde_residual))\n    else:\n        loss_pde = torch.zeros(1, device=device, requires_grad=True)\n\n    return loss_pde\n\n\ndef train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,\n                    optimizer, scheduler, normalized, normalizer, device, pde_weight, grid_info, epsilon, problem, pde_loss_scaler=1.0, can_compute_pde = True):\n    train_mse_hybrid_log = []\n    train_l2_hybrid_log = []\n\n    test_mse_hybrid_log = []\n    test_loss_hybrid_log = []\n\n\n    train_data_log = []\n    test_data_log = []\n\n    train_pde_scaled_log = []\n    train_pde_raw_log = []\n\n    test_pde_loss_scaled_log = []\n    test_pde_loss_raw_log = []\n\n\n    if normalized:\n        # a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        # a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n\n        train_mse_hybrid = 0\n        train_l2_hybrid = 0\n\n        train_data = 0.0\n        train_pde_scaled = 0.0\n        train_pde_raw = 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            # print(\"x shape\", x.shape)\n            out = model(x)\n            # print(f\"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}\")\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n\n            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n            loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n            # --- PDE Loss Calculation (on physical scale) ---\n            if can_compute_pde:\n                # loss_pde_raw = calculate_pde_residual_sh3d(pred_phys, grid_info, epsilon, device)\n                #loss_pde_raw = calculate_pde_residual_sh3d(out, grid_info, epsilon, device)\n                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                loss_pde_scaled = loss_pde_raw * pde_loss_scaler  # Apply scaling\n\n            loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled\n            mse_hybrid = (1.0 - pde_weight) * mse_data + pde_weight * loss_pde_scaled\n\n\n            loss_hybrid.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # Hybrid\n            train_mse_hybrid += mse_hybrid.item()\n            train_l2_hybrid += loss_hybrid.item()\n            ##\n            train_data += loss_data.item()\n            train_pde_scaled += loss_pde_scaled.item()\n            train_pde_raw += loss_pde_raw.item()\n\n\n        model.eval()\n        test_data= 0.0 # data\n        test_mse_data = 0.0\n        test_pde_loss_scaled = 0.0\n        test_pde_loss_raw = 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                # test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n                test_mse_data += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n                test_data += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n\n                # PDE Loss\n                if can_compute_pde:\n                    #loss_pde_test_raw = calculate_pde_residual_sh3d(out, grid_info, epsilon, device)\n                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n\n                test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()\n                test_pde_loss_raw += loss_pde_test_raw.item()\n\n            test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled\n            test_mse_hybrid = (1.0 - pde_weight) * test_mse_data + pde_weight * test_pde_loss_scaled\n\n        # Train Hybrid\n        train_mse_hybrid /= len(train_loader)\n        train_l2_hybrid /= (batch_size * len(train_loader))\n\n        # Test Hybrid\n        test_mse_hybrid /= len(test_loader)\n        test_loss_hybrid /= (batch_size * len(test_loader))\n\n        # train data\n        train_data /= (batch_size * len(train_loader))\n        # test data\n        test_data /= (batch_size * len(test_loader))\n        # train pde\n        train_pde_scaled /= (batch_size * len(train_loader))\n        train_pde_raw /= (batch_size * len(train_loader))\n        # test pde\n        test_pde_loss_scaled /= (batch_size * len(test_loader))\n        test_pde_loss_raw /= (batch_size * len(test_loader))\n\n\n\n\n        # train Hybrid\n        train_mse_hybrid_log.append(train_mse_hybrid)\n        train_l2_hybrid_log.append(train_l2_hybrid)\n\n        # Test Hybrid\n        test_mse_hybrid_log.append(test_mse_hybrid)\n        test_loss_hybrid_log.append(test_loss_hybrid)\n\n        # train data\n        train_data_log.append(train_data)\n        # test data\n        test_data_log.append(test_data)\n        # train pde\n        train_pde_scaled_log.append(train_pde_scaled)\n        train_pde_raw_log.append(train_pde_raw)\n        # test pde\n        test_pde_loss_scaled_log.append(test_pde_loss_scaled)\n        test_pde_loss_raw_log.append(test_pde_loss_raw)\n\n        # Update the learning rate based on the test_l2 metric\n        # scheduler.step(test_l2) ##\n\n        t2 = default_timer()\n\n        if ep == 0:\n            # Update header to reflect spectral raw PDE loss\n            print(\"No. Epoch | Time (s)   | Train MSE Hyb  | Train L2 Hyb  | test L2 Hyb | Test L2 data        | test_pde scl.   | test_pde_raw \")\n            print(\"---------------------------------------------------------------------------------------------\")\n        # Update print statement\n        print(f\"{ep:<9}  {t2 - t1:<10.4f}   {train_mse_hybrid:<10.6e}     {train_l2_hybrid:<10.6e} {test_loss_hybrid:<10.6e}  {test_data:<24.6e} {test_pde_loss_scaled:<24.6e} {test_pde_loss_raw:<24.6e} \")\n\n    return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log\n\n\ndef compute_initial_loss_scaler(model, loader, myloss, normalized, normalizer, device, grid_info, epsilon, problem):\n    \"\"\"\n    Computes the scaling factor to balance data and PDE losses.\n    \"\"\"\n    model.eval()\n\n    # Get one batch from the loader\n    x, y = next(iter(loader))\n    x, y = x.to(device), y.to(device)\n\n    with torch.no_grad():\n        out = model(x)\n        if normalized:\n            y_normalizer = normalizer[1].to(device)\n            out = y_normalizer.decode(out)\n            y = y_normalizer.decode(y)\n\n        # Calculate initial data loss\n        initial_loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n        # Calculate initial raw PDE loss\n        initial_loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n\n        # Handle case where PDE loss is zero to avoid division by zero\n        if initial_loss_pde_raw.item() < 1e-12:\n            scaler = 1.0\n            print(\"Warning: Initial PDE loss is near zero. Setting scaler to 1.0.\")\n        else:\n            # The scaler is the ratio of the two losses\n            scaler = initial_loss_data.item() / initial_loss_pde_raw.item()\n            print(f\"Computed initial loss scaler: {scaler:.4f}\")\n            print(f\"  - Initial Data Loss: {initial_loss_data.item():.6f}\")\n            print(f\"  - Initial PDE Loss (raw): {initial_loss_pde_raw.item():.6f}\")\n\n    model.train()  # Set model back to training mode\n    return scaler\n\n\n''''\ndef train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,\n                 optimizer, scheduler, normalized, normalizer, device, pde_weight,\n                 grid_info, epsilon, problem, pde_loss_scaler='auto', can_compute_pde=True):\n    # --- Logging Lists ---\n    train_mse_hybrid_log, train_l2_hybrid_log = [], []\n    test_mse_hybrid_log, test_loss_hybrid_log = [], []\n    train_data_log, test_data_log = [], []\n    train_pde_scaled_log, train_pde_raw_log = [], []\n    test_pde_loss_scaled_log, test_pde_loss_raw_log = [], []\n\n    if normalized:\n        y_normalizer = normalizer[1].to(device)\n    else:\n        y_normalizer = None\n\n    # ====================================================================================\n    # Automatic PDE Loss Scaler Calculation\n    # ====================================================================================\n    if pde_loss_scaler == 'auto' and can_compute_pde and pde_weight > 0:\n        print(\"--- Calibrating PDE loss scaler automatically ---\")\n        model.eval()\n        total_data_loss_for_scaling = 0.0\n        total_pde_loss_for_scaling = 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n                out = model(x)\n\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                # Calculate data loss for this batch\n                data_loss_batch = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n                total_data_loss_for_scaling += data_loss_batch.item()\n\n                # Calculate raw PDE loss for this batch\n                pde_loss_batch_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                total_pde_loss_for_scaling += pde_loss_batch_raw.item()\n\n        # Calculate the average losses\n        avg_data_loss = total_data_loss_for_scaling / len(test_loader)\n        avg_pde_loss = total_pde_loss_for_scaling / len(test_loader)\n\n        # Compute the scaler\n        if avg_pde_loss > 1e-8:  # Avoid division by zero\n            pde_loss_scaler = avg_data_loss / avg_pde_loss\n        else:\n            pde_loss_scaler = 1.0  # Default to 1 if PDE loss is negligible\n\n        print(f\"Initial Avg Data Loss: {avg_data_loss:.6e}\")\n        print(f\"Initial Avg Raw PDE Loss: {avg_pde_loss:.6e}\")\n        print(f\"Calculated pde_loss_scaler: {pde_loss_scaler:.6f}\")\n        print(\"---------------------------------------------\")\n\n    elif not can_compute_pde or pde_weight == 0:\n        pde_loss_scaler = 0.0  # No scaling needed if PDE is not used\n    elif isinstance(pde_loss_scaler, str):  # Handle cases like 'auto' when PDE is off\n        pde_loss_scaler = 1.0\n\n    # --- Main Training Loop ---\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n\n        # Initialize epoch-level accumulators\n        train_mse_hybrid, train_l2_hybrid = 0.0, 0.0\n        train_data, train_pde_scaled, train_pde_raw = 0.0, 0.0, 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            optimizer.zero_grad()\n\n            out = model(x)\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n\n            # --- Loss Calculation ---\n            loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n\n            loss_pde_scaled = torch.tensor(0.0, device=device)\n            loss_pde_raw = torch.tensor(0.0, device=device)\n\n            if can_compute_pde and pde_weight > 0:\n                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                loss_pde_scaled = loss_pde_raw * pde_loss_scaler\n\n            # Combine losses\n            loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled\n            mse_hybrid = (1.0 - pde_weight) * mse_data + pde_weight * loss_pde_scaled\n\n            loss_hybrid.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # --- Accumulate Metrics ---\n            train_mse_hybrid += mse_hybrid.item()\n            train_l2_hybrid += loss_hybrid.item()\n            train_data += loss_data.item()\n            train_pde_scaled += loss_pde_scaled.item()\n            train_pde_raw += loss_pde_raw.item()\n\n        # --- Evaluation ---\n        model.eval()\n        test_data, test_mse_data = 0.0, 0.0\n        test_pde_loss_scaled, test_pde_loss_raw = 0.0, 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                test_data += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n                test_mse_data += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean').item()\n\n                if can_compute_pde and pde_weight > 0:\n                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                    test_pde_loss_raw += loss_pde_test_raw.item()\n                    test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()\n\n        # --- Normalize and Log Metrics ---\n        # Note: We divide by len(loader) because item() gives the mean loss for the batch.\n        # This computes the average of the batch means.\n\n        # Averages for training set\n        train_mse_hybrid /= len(train_loader)\n        train_l2_hybrid /= len(train_loader)\n        train_data /= len(train_loader)\n        train_pde_scaled /= len(train_loader)\n        train_pde_raw /= len(train_loader)\n\n        # Averages for test set\n        test_mse_data /= len(test_loader)\n        test_data /= len(test_loader)\n        test_pde_loss_scaled /= len(test_loader)\n        test_pde_loss_raw /= len(test_loader)\n\n        # Calculate final hybrid test losses from averages\n        test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled\n        test_mse_hybrid = (1.0 - pde_weight) * test_mse_data + pde_weight * test_pde_loss_scaled\n\n        # Append to logs\n        train_mse_hybrid_log.append(train_mse_hybrid)\n        train_l2_hybrid_log.append(train_l2_hybrid)\n        test_mse_hybrid_log.append(test_mse_hybrid)\n        test_loss_hybrid_log.append(test_loss_hybrid)\n        train_data_log.append(train_data)\n        test_data_log.append(test_data)\n        train_pde_scaled_log.append(train_pde_scaled)\n        train_pde_raw_log.append(train_pde_raw)\n        test_pde_loss_scaled_log.append(test_pde_loss_scaled)\n        test_pde_loss_raw_log.append(test_pde_loss_raw)\n\n        t2 = default_timer()\n\n        if ep == 0:\n            print(\"--- Starting Training ---\")\n            print(f\"PDE Loss Scaler is set to: {pde_loss_scaler:.6f}\")\n            print(\n                \"No. Epoch | Time (s)   | Train MSE Hyb  | Train L2 Hyb   | Test L2 Hyb    | Test L2 data   | Test PDE Scl.  | Test PDE Raw\")\n            print(\n                \"-------------------------------------------------------------------------------------------------------------------------\")\n\n        # CORRECTED PRINT STATEMENT:\n        print(\n            f\"{ep:<9} | {t2 - t1:<10.4f} | {train_mse_hybrid:<14.6e} | {train_l2_hybrid:<14.6e} | {test_loss_hybrid:<14.6e} | {test_data:<14.6e} | {test_pde_loss_scaled:<14.6e} | {test_pde_loss_raw:<14.6e}\")\n\n    return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log\n'''
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/training.py b/training.py
++--- a/training.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/training.py	(date 1754055606834)
++@@ -1,8 +1,10 @@
++ import torch
++ import torch.nn.functional as F
++ from timeit import default_timer
+++import numpy as np
++ from tqdm import tqdm
++ 
+++'''
++ def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
++               optimizer, scheduler, normalized, normalizer, device):
++     train_mse_log = []
++@@ -65,7 +67,6 @@
++         # Update the learning rate based on the test_l2 metric
++         #scheduler.step(test_l2) ##
++ 
++-
++         t2 = default_timer()
++         #print(ep, t2 - t1, train_mse, train_l2, test_l2)
++         if ep == 0:  # Print the header row once
++@@ -75,6 +76,347 @@
++ 
++     return model, train_mse_log, train_l2_log, test_l2_log
++ 
+++'''
+++
+++
+++# Make sure SobolevLoss is imported or defined before this function is called
+++# so that isinstance() can work correctly.
+++# from your_utilities import SobolevLoss
+++
+++def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
+++              optimizer, scheduler, normalized, normalizer, device):
+++    # This is a placeholder for the real import.
+++    # In your actual code, you must import SobolevLoss from utilities.py
+++    from utilities import SobolevLoss
+++
+++    train_mse_log = []
+++    train_l2_log = []
+++    test_l2_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++            # --- THIS IS THE FIX ---
+++            # If the loss is SobolevLoss, pass the original multi-dimensional tensors.
+++            # Otherwise, for losses like LpLoss, pass the flattened tensors.
+++            if isinstance(myloss, SobolevLoss):
+++                loss = myloss(out, y)  # Pass the un-flattened tensor
+++            else:
+++                loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))  # The original behavior
+++            # --- END OF FIX ---
+++
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++            train_mse += mse.item()
+++            train_l2 += loss.item()
+++
+++        model.eval()
+++        test_l2 = 0.0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                # --- APPLY THE SAME FIX HERE ---
+++                if isinstance(myloss, SobolevLoss):
+++                    test_l2 += myloss(out, y).item()
+++                else:
+++                    test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()
+++                # --- END OF FIX ---
+++
+++        train_mse /= len(train_loader)
+++        train_l2 /= (batch_size * len(train_loader))
+++        test_l2 /= (batch_size * len(test_loader))
+++
+++        train_mse_log.append(train_mse)
+++        train_l2_log.append(train_l2)
+++        test_l2_log.append(test_l2)
+++
+++        t2 = default_timer()
+++        if ep == 0:
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log
+++''''
+++def train_fno4d(model, myloss, epochs, batch_size, train_loader, test_loader,
+++              optimizer, scheduler, normalized, normalizer, device):
+++    train_mse_log = []
+++    train_l2_log = []
+++    #val_mse_log = []  # New
+++    #val_l2_log = []  # New
+++    test_l2_log = []
+++    test_mse_log = []
+++
+++    # --- Early Stopping Parameters (Optional) ---
+++    #best_val_loss = float('inf')
+++    #patience_counter = 0
+++    #patience_epochs = 5 # 10  # Example: stop if no improvement for 10 epochs
+++    #best_model_state = None
+++    # ---
+++
+++    if normalized:
+++        # a_normalizer = normalizer[0].to(device)
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        # a_normalizer = None
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            #print("x shape", x.shape)
+++            out = model(x)
+++            print(f"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}")
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                #print("out shape1:", out.shape)
+++                y = y_normalizer.decode(y)
+++            print("out shape2 :", out.shape)
+++            print("y shape:", y.shape)
+++
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
+++
+++            loss.backward()
+++            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Adjust max_norm if needed
+++            optimizer.step()
+++            scheduler.step()
+++            train_mse += mse.item()
+++            train_l2 += loss.item()
+++
+++        # Test
+++
+++        model.eval()
+++        test_l2 = 0.0
+++        test_mse = 0.0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                #test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()
+++                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()
+++                test_mse += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++
+++        test_l2 /= (batch_size * len(test_loader))
+++        test_mse /= (batch_size * len(test_loader))
+++
+++        test_l2_log.append(test_l2)
+++        test_mse_log.append(test_mse)
+++        # Update the learning rate based on the test_l2 metric
+++        #scheduler.step(test_l2) ##
+++
+++
+++        t2 = default_timer()
+++        #print(ep, t2 - t1, train_mse, train_l2, test_l2)
+++
+++
+++        if ep == 0:
+++            # Update header to reflect spectral raw PDE loss
+++            print("No. Epoch | Time (s)   | Train MSE     | Test mse     | Train L2      |  Test L2 ")
+++            print("---------------------------------------------------------------------------------------")
+++        # Update print statement
+++        print(f"{ep:<9} | {t2 - t1:<10.4f} | {train_mse:<10.6e} | {test_mse:<10.6e} | {train_l2:<10.6e} | {test_l2:<24.6e} ")
+++
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log, test_mse_log
+++'''
+++
+++
+++def train_fno4d(model, myloss, epochs, batch_size, train_loader, test_loader,
+++                optimizer, scheduler, normalized, normalizer, device):
+++    """Training function for FNO4d model."""
+++    ntrain = len(train_loader) * train_loader.batch_size
+++    ntest = len(test_loader) * test_loader.batch_size
+++
+++    train_mse_log = []
+++    train_l2_log = []
+++    test_l2_log = []
+++    test_mse_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
+++
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++
+++            train_mse += mse.item()
+++            train_l2 += loss.item() / batch_size  # Normalize by batch size
+++
+++        model.eval()
+++        test_l2 = 0
+++        test_mse = 0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                test_mse += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean').item()
+++                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item() / batch_size  # Normalize here too
+++
+++        # Average over number of batches
+++        train_mse /= len(train_loader)
+++        train_l2 /= len(train_loader)
+++        test_mse /= len(test_loader)
+++        test_l2 /= len(test_loader)
+++
+++        train_mse_log.append(train_mse)
+++        train_l2_log.append(train_l2)
+++        test_l2_log.append(test_l2)
+++        test_mse_log.append(test_mse)
+++
+++        t2 = default_timer()
+++
+++        if ep == 0:
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test MSE       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_mse:<13.10f} {test_l2:<13.10f}")
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log
+++
+++
+++
+++import torch
+++import torch.nn.functional as F
+++from timeit import default_timer
+++
+++'''
+++def train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,
+++              optimizer, scheduler, normalized, normalizer, device):
+++    train_mse_log = []
+++    train_l2_log = []
+++    test_l2_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_mse = 0
+++        train_l2 = 0
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            # This MSE is kept for logging the data-only error
+++            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++            # --- MINIMAL CHANGE HERE ---
+++            # The loss function now receives the UN-FLATTENED tensors
+++            # so it can compute spatial gradients for the Sobolev loss.
+++            loss = myloss(out, y)
+++
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++            train_mse += mse.item()
+++            train_l2 += loss.item()
+++
+++        model.eval()
+++        test_l2 = 0.0
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
+++
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
+++
+++                # --- MINIMAL CHANGE HERE ---
+++                # Also pass the un-flattened tensors during evaluation.
+++                test_l2 += myloss(out, y).item()
+++
+++        train_mse /= len(train_loader)
+++        train_l2 /= (batch_size * len(train_loader))  # Kept original scaling
+++        test_l2 /= (batch_size * len(test_loader))  # Kept original scaling
+++
+++        train_mse_log.append(train_mse)
+++        train_l2_log.append(train_l2)
+++        test_l2_log.append(test_l2)
+++
+++        t2 = default_timer()
+++        if ep == 0:  # Print the header row once
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
+++
+++    return model, train_mse_log, train_l2_log, test_l2_log
+++'''
+++
+++
++ def train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,
++                    optimizer, scheduler, normalized, normalizer, device):
++     ntrain = len(train_loader) * train_loader.batch_size
++@@ -164,7 +506,110 @@
++ 
++     return model, train_l2_log, test_l2_log
++ 
+++'''
+++def train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,
+++                   optimizer, scheduler, normalized, normalizer, device):
+++    ntrain = len(train_loader) * train_loader.batch_size
+++    ntest = len(test_loader) * test_loader.batch_size
+++    train_l2_log = []
+++    test_l2_log = []
+++    step = 1
+++
+++    # Normalizer setup is unchanged
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++        train_l2_step = 0
+++        train_l2_full = 0
+++        for xx, yy in train_loader:
+++            loss = 0
+++            xx = xx.to(device)
+++            yy = yy.to(device)
+++            T = yy.shape[-1]
+++
+++            # The auto-regressive loop for one-step-ahead prediction
+++            for t in range(0, T, step):
+++                y = yy[..., t:t + step]
+++                im = model(xx)
+++
+++                # --- MINIMAL CHANGE #1 ---
+++                # Pass the un-flattened tensors (im, y) to myloss.
+++                # Both have shape (batch, s, s, s, 1) here.
+++                loss += myloss(im, y)
+++
+++                if t == 0:
+++                    pred = im
+++                else:
+++                    pred = torch.cat((pred, im), -1)
+++
+++                # Update input for next time step
+++                xx = torch.cat((xx[..., step:], im), dim=-1)
+++
+++            train_l2_step += loss.item()
+++
+++            # --- MINIMAL CHANGE #2 ---
+++            # Also pass the un-flattened full tensors (pred, yy) to myloss.
+++            # Both have shape (batch, s, s, s, T_out) here.
+++            l2_full = myloss(pred, yy)
+++            train_l2_full += l2_full.item()
+++
+++            optimizer.zero_grad()
+++            loss.backward()
+++            optimizer.step()
+++            scheduler.step()
+++
+++        # Evaluation loop
+++        test_l2_step = 0
+++        test_l2_full = 0
+++        with torch.no_grad():
+++            for xx, yy in test_loader:
+++                loss = 0
+++                xx = xx.to(device)
+++                yy = yy.to(device)
+++                T = yy.shape[-1]  # T is defined inside the loop for safety
+++
+++                for t in range(0, T, step):
+++                    y = yy[..., t:t + step]
+++                    im = model(xx)
+++
+++                    # --- MINIMAL CHANGE #3 ---
+++                    loss += myloss(im, y)
+++
+++                    if t == 0:
+++                        pred = im
+++                    else:
+++                        pred = torch.cat((pred, im), -1)
+++
+++                    xx = torch.cat((xx[..., step:], im), dim=-1)
+++
+++                test_l2_step += loss.item()
+++
+++                # --- MINIMAL CHANGE #4 ---
+++                test_l2_full += myloss(pred, yy).item()
++ 
+++        t2 = default_timer()
+++        # The meaning of these metrics is slightly different now, but the calculation is kept
+++        train_mse = train_l2_step / ntrain / (T / step)
+++        train_l2 = train_l2_full / ntrain
+++        test_l2 = test_l2_full / ntest
+++
+++        # Log the loss values
+++        train_l2_log.append(train_l2_step / ntrain / (T / step))
+++        test_l2_log.append(test_l2_step / ntest / (T / step))
+++
+++        if ep == 0:  # Print the header row once
+++            print("No. Epoch   Time (s)       Train MSE      Train L2       Test L2")
+++
+++        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}")
+++
+++    # Returning the logs for the one-step-ahead loss
+++    return model, train_l2_log, test_l2_log
+++'''
++ 
++ ########################
++ ########################
++@@ -227,12 +672,15 @@
++         if Cahn_ac is None: raise ValueError("Parameter 'Cahn_ac' not provided for AC3D.")
++         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
++-        f_prime_u = u_phys**3 - u_phys
++-        rhs_ac3d = Cahn_ac * lap_u - f_prime_u
+++        #f_prime_u = u_phys**3 - u_phys
+++        #rhs_ac3d = Cahn_ac * lap_u - f_prime_u ##
+++        f_prime_u = (1/Cahn_ac) * (u_phys ** 3 - u_phys)
+++        rhs_ac3d = lap_u - f_prime_u  ##
+++
++         pde_residual = du_dt - rhs_ac3d
++ 
++     elif problem == 'CH3D':
++-        Cahn_ch = epsilon #  pde_params.get('Cahn_ch')
+++        Cahn_ch = epsilon**2 #  pde_params.get('Cahn_ch')
++         if Cahn_ch is None: raise ValueError("Parameter 'Cahn_ch' not provided for CH3D.")
++         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
++@@ -269,66 +717,39 @@
++         k4_m = k2_m**2
++         biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real
++-        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term
+++        #rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term
+++        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u + div_term
++         pde_residual = du_dt - rhs_mbe3d
++ 
++     elif problem == 'PFC3D':
++-        epsilon_pfc = epsilon # pde_params.get('epsilon_pfc') # Parameter 'r' in PFC, often -(epsilon)
+++        epsilon_pfc = epsilon
++         if epsilon_pfc is None: raise ValueError("Parameter 'epsilon_pfc' not provided for PFC3D.")
++-
++-        # Calculate necessary derivatives
++-        # -u  (term1_spatial_operator * u)
+++        # Calculate necessary spatial derivatives using Fourier transforms
+++        # u (Laplacian)
++         lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real
++ 
++-        # u   (term2_spatial_operator * u)
++-        k4_m = k2_m**2
+++        # u (Biharmonic)
+++        k4_m = k2_m ** 2
++         biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real
++ 
++-        # -u  (term3_spatial_operator * u)
++-        k6_m = k2_m**3 # Be careful with sign if k2_m is just kx^2+ky^2+kz^2
++-                      # Since k^6 in Fourier space corresponds to (-^2)^3 = -^6 if direct multiplication
++-                      # Or (i k)^6 = -k^6.
++-                      # The MATLAB denominator (1/dt + (1-eps)k^2 + k^6) implies the k^6 term is positive.
++-                      # So in real space, this corresponds to -u (because -(-)^3 u = u is not what we want)
++-                      # A positive k^6 in Fourier space means we multiply by k^6, which is (-(laplacian_operator))^3,
++-                      # this will become -laplacian_operator^3 which is -.
++-                      # The MATLAB form `(pp2+qq2+rr2).^3` is `(k^2)^3 = k^6`.
++-                      # So this term becomes `k^6 * u_hat` -> `u` (with a negative sign from implicit to explicit)
++-        # Or, if (pp2+qq2+rr2) is k^2, then (pp2+qq2+rr2)^3 is k^6.
++-        # The term in the denominator is `+ k^6`, so when moved to RHS it's `-k^6 u_hat`.
++-        # `-k^6 u_hat` corresponds to `u` in real space.
+++        # u (Triharmonic)
+++        k6_m = k2_m ** 3
+++        # In Fourier space, multiplying by -k^6 corresponds to the  operator
++         triharm_u_hat = -k6_m.unsqueeze(0).unsqueeze(-1) * u_hat
++         triharm_u = torch.fft.ifftn(triharm_u_hat, dim=[1, 2, 3]).real
++ 
++-
++         # (u)
++-        u_cubed = u_phys**3
+++        u_cubed = u_phys ** 3
++         u_cubed_hat = torch.fft.fftn(u_cubed, dim=[1, 2, 3])
++         lap_u_cubed_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_cubed_hat
++         lap_u_cubed = torch.fft.ifftn(lap_u_cubed_hat, dim=[1, 2, 3]).real
++ 
++-        # PDE: u/t + (1-)u + 2u + u + (u) = 0
++-        # RHS = - ( (1-_pfc)u + 2u + u + (u) )
++-        # Let's use the parameter `epsilon` from PFC MATLAB as `r` (undercooling param)
++-        # A common PFC form is du/dt = nabla^2 * ( (r)u + u^3 - (1+nabla^2)^2 u )
++-        # du/dt = nabla^2 * ( ru + u^3 - (1 + 2 nabla^2 + nabla^4)u )
++-        # du/dt = r nabla^2 u + nabla^2(u^3) - nabla^2 u - 2 nabla^4 u - nabla^6 u
++-        # du/dt = (r-1) nabla^2 u - 2 nabla^4 u - nabla^6 u + nabla^2(u^3)
++-        # Here 'r' from literature is often called 'epsilon' in PFC code.
++-        # Let's match the form derived from MATLAB:
++-        # u/t = -(1-)u - 2u - u - (u)
++-        # Residual: du_dt - [-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed]
++-
++-        term1_spatial = (1 - epsilon_pfc) * lap_u # (1-eps)(-nabla^2 u) -> (eps-1)nabla^2 u
++-        term2_spatial = 2 * biharm_u             # 2 nabla^4 u
++-        term3_spatial = triharm_u                # nabla^6 u
++-        term4_nonlinear = lap_u_cubed            # nabla^2 (u^3)
++-
++-        # According to the derived form: u/t = -(1-)u - 2u - u - (u)
++-        # residual = du_dt - (-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed)
++-        rhs_pfc3d = -(1 - epsilon_pfc) * lap_u - 2 * biharm_u - triharm_u - lap_u_cubed
+++        # Construct the Right-Hand Side (RHS) of the PDE to match the MATLAB code
+++        # PDE: u/t = (1-)u + 2u + u + (u)
+++        rhs_pfc3d = (1 - epsilon_pfc) * lap_u + 2 * biharm_u + triharm_u + lap_u_cubed
+++        # The residual is the difference between the time derivative and the RHS
++         pde_residual = du_dt - rhs_pfc3d
++ 
++     else:
++@@ -503,42 +924,117 @@
++     return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log
++ 
++ 
++-def compute_initial_loss_scaler(model, loader, myloss, normalized, normalizer, device, grid_info, epsilon, problem):
++-    """
++-    Computes the scaling factor to balance data and PDE losses.
++-    """
++-    model.eval()
+++'''
+++
+++def train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,
+++                 optimizer, scheduler, normalized, normalizer, device, pde_weight, grid_info, epsilon, problem,
+++                 pde_loss_scaler=1.0, can_compute_pde=True):
+++    train_mse_hybrid_log = []
+++    train_l2_hybrid_log = []
+++    test_loss_hybrid_log = []
+++    train_data_log = []
+++    test_data_log = []
+++    train_pde_scaled_log = []
+++    test_pde_loss_scaled_log = []
+++
+++    if normalized:
+++        y_normalizer = normalizer[1].to(device)
+++    else:
+++        y_normalizer = None
+++
+++    for ep in range(epochs):
+++        model.train()
+++        t1 = default_timer()
+++
+++        train_mse_hybrid = 0
+++        train_l2_hybrid = 0
+++        train_data = 0.0
+++        train_pde_scaled = 0.0
+++
+++        for x, y in train_loader:
+++            x, y = x.to(device), y.to(device)
+++
+++            optimizer.zero_grad()
+++            out = model(x)
+++            if normalized:
+++                out = y_normalizer.decode(out)
+++                y = y_normalizer.decode(y)
+++
+++            # --- MINIMAL CHANGE #1 ---
+++            # Pass the UN-FLATTENED tensors to myloss.
+++            loss_data = myloss(out, y)
+++
+++            # Kept for logging purposes
+++            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+++
+++            if can_compute_pde and pde_weight > 0:
+++                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
+++                loss_pde_scaled = loss_pde_raw * pde_loss_scaler
+++                loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled
+++            else:
+++                loss_pde_scaled = torch.tensor(0.0)  # For logging
+++                loss_hybrid = loss_data
+++
+++            loss_hybrid.backward()
+++            optimizer.step()
+++            scheduler.step()
+++
+++            train_l2_hybrid += loss_hybrid.item()
+++            train_data += loss_data.item()
+++            train_pde_scaled += loss_pde_scaled.item()
+++
+++        model.eval()
+++        test_data = 0.0
+++        test_pde_loss_scaled = 0.0
++ 
++-    # Get one batch from the loader
++-    x, y = next(iter(loader))
++-    x, y = x.to(device), y.to(device)
+++        with torch.no_grad():
+++            for x, y in test_loader:
+++                x, y = x.to(device), y.to(device)
++ 
++-    with torch.no_grad():
++-        out = model(x)
++-        if normalized:
++-            y_normalizer = normalizer[1].to(device)
++-            out = y_normalizer.decode(out)
++-            y = y_normalizer.decode(y)
+++                out = model(x)
+++                if normalized:
+++                    out = y_normalizer.decode(out)
+++                    y = y_normalizer.decode(y)
++ 
++-        # Calculate initial data loss
++-        initial_loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
+++                # --- MINIMAL CHANGE #2 ---
+++                # Pass the UN-FLATTENED tensors here as well.
+++                test_data += myloss(out, y).item()
+++
+++                if can_compute_pde and pde_weight > 0:
+++                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
+++                    test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()
+++
+++        # Normalize losses
+++        train_l2_hybrid /= len(train_loader)
+++        train_data /= len(train_loader)
+++        train_pde_scaled /= len(train_loader)
+++
+++        test_data /= len(test_loader)
+++        test_pde_loss_scaled /= len(test_loader)
++ 
++-        # Calculate initial raw PDE loss
++-        initial_loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
+++        test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled
++ 
++-        # Handle case where PDE loss is zero to avoid division by zero
++-        if initial_loss_pde_raw.item() < 1e-12:
++-            scaler = 1.0
++-            print("Warning: Initial PDE loss is near zero. Setting scaler to 1.0.")
++-        else:
++-            # The scaler is the ratio of the two losses
++-            scaler = initial_loss_data.item() / initial_loss_pde_raw.item()
++-            print(f"Computed initial loss scaler: {scaler:.4f}")
++-            print(f"  - Initial Data Loss: {initial_loss_data.item():.6f}")
++-            print(f"  - Initial PDE Loss (raw): {initial_loss_pde_raw.item():.6f}")
+++        # Append logs
+++        train_l2_hybrid_log.append(train_l2_hybrid)
+++        test_loss_hybrid_log.append(test_loss_hybrid)
+++        train_data_log.append(train_data)
+++        test_data_log.append(test_data)
+++        train_pde_scaled_log.append(train_pde_scaled)
+++        test_pde_loss_scaled_log.append(test_pde_loss_scaled)
++ 
++-    model.train()  # Set model back to training mode
++-    return scaler
+++        t2 = default_timer()
+++
+++        if ep == 0:
+++            print("No. Epoch | Time (s)   | Train L2 Hyb  | Test L2 Hyb   | Test L2 data  | Test PDE Scaled")
+++            print("---------------------------------------------------------------------------------------")
+++
+++        print(
+++            f"{ep:<9} | {t2 - t1:<10.4f} | {train_l2_hybrid:<13.6e} | {test_loss_hybrid:<13.6e} | {test_data:<13.6e} | {test_pde_loss_scaled:<13.6e}")
+++
+++    # Simplified return statement
+++    return model, train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log
+++'''''
+++
++ 
++ 
++ ''''
++Index: main1.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import os\nimport importlib\nimport torch\nimport inspect\nimport numpy as np\nimport matplotlib\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom training import train_fno, train_fno_time, train_hybrid\nfrom torch.utils.data import DataLoader, random_split\nfrom utilities import ImportDataset, count_params, LpLoss, ModelEvaluator\nfrom post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, make_video, save_vtk, plot_xy_plane_subplots\nimport time  # Import the time module at the beginning of the script\nfrom torch_optimizer import Lamb\nimport scipy.io\n\n################################################################\n# Problem Definition\n################################################################\n# problem = 'AC2D'\n#problem = 'AC3D'\n# problem = 'CH2DNL'\n# problem = 'SH2D'\nproblem = 'SH3D'\n# problem = 'PFC2D'\n#problem = 'PFC3D'\n#problem = 'MBE2D'\n#problem = 'MBE3D'\n# problem = 'CH2D'\n#problem = 'CH3D'\n\n#network_name = 'TNO2d'\n# network_name = 'FNO2d'\n#network_name = 'FNO3d'\nnetwork_name = 'TNO3d'\n\nPINN_MODE = False # True # False #\n\nprint(f\"problem = {problem}\")\nprint(f\"network = {network_name}\")\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\") # configuration file\n# above line means: import configs.config_PFC3D_TNO3d as cf\nnetwork = getattr(importlib.import_module('networks'), network_name) # from networks import TNO3d\ntorch.manual_seed(cf.torch_seed)\nnp.random.seed(cf.numpy_seed)\n#device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')\ndevice = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)\n# --- Define Output Directory ---\n\n\nPDE_WEIGHT = cf.pde_weight\nPDE_LOSS_SCALER = cf.pde_loss_scaler\n\nif PINN_MODE:\n    run_descriptor = f\"PINN_w{int(PDE_WEIGHT * 100)}\"\n    output_subdir = f\"plots_Data_Physics_{network_name}\"  # Specific PINN output\nelse:\n    run_descriptor = \"DataDriven\"\n    output_subdir = f\"plots_{network_name}\"  # Original data-driven output\n\n#model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'\nmodel_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}.pt'\nmodel_dir = os.path.join(problem, 'models') # models_smpooth\nmodel_name = f'{model_run_name}'\nmodel_path = os.path.join(model_dir, model_name)\n\nplot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir\nos.makedirs(model_dir, exist_ok=True)\nos.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists\n\nprint(f\"Model Run Name: {model_run_name}\")\nprint(f\"Model Path: {model_path}\")\nprint(f\"Plot Directory: {plot_dir}\")\n\n# width_q = 32\nstart_time = time.time()\n\n################################################################\n# load data and data normalization\n################################################################\n#model_dir = problem + '/models'\n\nprint(f\"model = {model_name}\")\nprint(f\"number of epoch = {cf.epochs}\")\nprint(f\"batch size = {cf.batch_size}\")\nprint(f\"nTrain = {cf.nTrain}\")\nprint(f\"nTest = {cf.nTest}\")\nprint(f\"learning_rate = {cf.learning_rate}\")\nprint(f\"n_layers = {cf.n_layers}\")\nprint(f\"width_q = {cf.width_q}\")\nprint(f\"width_h = {cf.width_h}\")\n\nmodel_path = os.path.join(model_dir, model_name)\nos.makedirs(model_dir, exist_ok=True)\n# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\ntrain_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])\n# to see train_dataset values: print(\"train_dataset subset:\", [train_dataset[i] for i in range(len(train_dataset))])\nnormalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)\n\n################################################################\n# training and evaluation\n################################################################\nsig = inspect.signature(network.__init__)\nrequired_args = [param.name for param in sig.parameters.values()\n                 if param.default == inspect.Parameter.empty and param.name != \"self\"]\nif network_name == 'FNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'FNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelse:\n    raise Exception(\"network_name is not correct\")\n\nprint(count_params(model))      # Print model parameters\ntrain_mse_log, train_l2_log, test_l2_log = [], [], []       # Initialize logs\n\n# Load the entire model and logs\nif os.path.exists(model_path) and cf.load_model:\n    print(f\"Loading pre-trained model from {model_path}\")\n    checkpoint = torch.load(model_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict']) # Use this line if you only save state_dict\n    #model = checkpoint['model'] # Use this line if you save the entire model object\n    train_mse_log = checkpoint.get('train_mse_log', [])\n    train_l2_log = checkpoint.get('train_l2_log', [])\n    test_l2_log = checkpoint.get('test_l2_log', [])\nelse:\n    print(\"No pre-trained model loaded. Initializing a new model.\")\n\n# Define optimizer, scheduler, and loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)\nmyloss = LpLoss(size_average=False)\n\n###\n\n# Train the model\nif cf.training:\n    print(\"\\n--- Starting Training ---\")\n    if PINN_MODE:\n        grid_info = {\n            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,\n            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,\n            'dt_model': cf.dt_model,\n            'T_out': cf.T_out\n        }\n\n        if PDE_WEIGHT == 0.0:\n            print(\"Running PINN training loop with pde_weight=0 (Data-Driven only loss).\")\n        else:\n            print(\n                f\"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {PDE_LOSS_SCALER:.2e}\")\n\n        model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (\n            train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                         optimizer, scheduler, cf.normalized, normalizers, device,\n                         PDE_WEIGHT, grid_info, cf.epsilon, problem,\n                         pde_loss_scaler=PDE_LOSS_SCALER)\n        )\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'train_mse_log': train_mse_hybrid_log,\n            'train_l2_log': train_l2_hybrid_log,\n            'test_l2_log': test_data_log,\n            'test_pde_scaled_log': test_pde_loss_scaled_log,\n            'train_data_log': train_data_log,\n            'train_pde_scaled_log': train_pde_scaled_log,\n            'test_loss_hybrid_log': test_loss_hybrid_log\n        }, model_path)\n\n    else:\n        if network_name in ['FNO2d', 'FNO3d']:\n            model, train_l2_log, test_l2_log = (\n                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                               optimizer, scheduler, cf.normalized, normalizers, device))\n            train_mse_log = []\n        else:\n            model, train_mse_log, train_l2_log, test_l2_log = (\n               train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                           optimizer, scheduler, cf.normalized, normalizers, device))\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'train_mse_log': train_mse_log,\n            'train_l2_log': train_l2_log,\n            'test_l2_log': test_l2_log\n        }, model_path)\n\n\nend_time = time.time()\nFinal_time = round(end_time - start_time, 2)\nprint(f\"Total Execution Time: {Final_time} seconds\")\n\nevaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,\n                           time_history=(network_name in ['FNO2d', 'FNO3d']))\n\nresults = evaluator.evaluate(loss_fn=myloss)\ninp = results['input']\npred = results['prediction']\nexact = results['exact']\ntest_l2_avg = results[\"average\"]\n\nif PINN_MODE:\n    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log]\n    labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\nelse:\n    losses = [train_l2_log, test_l2_log]\n    labels = ['Train L2', 'Test L2']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\n\n\n################################################################\n# post-processing\n################################################################\na_ind = inp[cf.index]\nu_pred = pred[cf.index]\nu_exact = exact[cf.index]\nerror = u_pred - u_exact\n\nplot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]\nprint(f\"Field shape: {u_exact.shape}\")\n\nselected_time_steps = [0, 2, 4, 6, 8, 9]\n\n# Plot exact solution\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=u_exact,\n                      field_name='Exact Solution',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[0],\n                      problem=problem,\n                      network_name=network_name)\n\n# Plot predicted solution\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=u_pred,\n                      field_name='Predicted Solution',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[1],\n                      problem=problem,\n                      network_name=network_name)\n\n# Plot error\nplot_xy_plane_subplots(domain=cf.domain,\n                      field=error,\n                      field_name='Error',\n                      time_steps=selected_time_steps,\n                      plot_range=plot_range[2],\n                      problem=problem,\n                      network_name=network_name)\n\n\n# ==============================================================================\n# NEW SECTION: PREDICT AND VISUALIZE A SINGLE TRAJECTORY EVOLUTION\n# ==============================================================================\nprint(\"\\n--- Generating Visualization for a Single Predicted Trajectory ---\")\n\n# Ensure dt_simulation is defined in the config file.\nif not hasattr(cf, 'dt_simulation'):\n    raise AttributeError(\"Configuration file is missing 'dt_simulation'. Please add it (e.g., dt_simulation = 0.00002).\")\n\npredicted_trajectory = u_pred # Shape: (s, s, s, T_out)\n\n# 1. Choose 4 suitable time frames for visualization from the predicted steps.\nnum_time_frames_to_plot = 4\ntotal_predicted_steps = predicted_trajectory.shape[-1]  # This is T_out\n\nif total_predicted_steps < 1:\n    print(\"No time steps to plot in the predicted trajectory.\")\nelse:\n    # Select 4 evenly spaced indices from the available time steps.\n    time_indices_to_plot = np.linspace(0, total_predicted_steps - 1, num_time_frames_to_plot, dtype=int).tolist()\n\n    print(f\"Selected time indices for plotting: {time_indices_to_plot}\")\n\n    # 2. Create the subplot (1 row, 4 columns) and save it.\n    fig, axes = plt.subplots(1, num_time_frames_to_plot, figsize=(5 * num_time_frames_to_plot, 5), squeeze=False)\n    axes = axes.flatten()\n\n    vmin = predicted_trajectory.cpu().numpy().min()\n    vmax = predicted_trajectory.cpu().numpy().max()\n    s = cf.s\n    slice_index = s // 2  # Middle slice in the Z-direction\n\n    for i, t_idx in enumerate(time_indices_to_plot):\n        # 3. Calculate the correct physical time for the label.\n        # The prediction starts after T_in steps.\n        physical_time = (cf.T_in + t_idx) * cf.dt_simulation\n\n        slice_2d = predicted_trajectory[:, :, slice_index, t_idx].cpu().numpy()\n\n        ax = axes[i]\n        im = ax.imshow(slice_2d, cmap='viridis', vmin=vmin, vmax=vmax,\n                       extent=[0, cf.Lx, 0, cf.Ly], origin='lower', interpolation='bicubic')\n        ax.set_title(f'Predicted t={physical_time:.2e}') # Use scientific notation for time\n        ax.set_xlabel('x')\n        if i == 0:\n            ax.set_ylabel('y')\n\n    fig.colorbar(im, ax=axes.tolist(), orientation='vertical', pad=0.02)\n    z_coord = cf.Lx / s * (slice_index - s / 2)\n    fig.suptitle(f'Predicted Evolution (Z-slice at z={z_coord:.2f})', fontsize=16)\n    fig.tight_layout(rect=[0, 0, 1, 0.95])\n\n    subplot_filename = os.path.join(plot_dir, f'{model_run_name}_single_trajectory_subplot.png')\n    plt.savefig(subplot_filename, dpi=300, bbox_inches='tight')\n    print(f\"Trajectory subplot saved to {subplot_filename}\")\n    plt.close(fig)\n\n# END OF NEW SECTION\n# ==============================================================================\n\n# The p=2 explicitly specifies the L2 norm.\nl2_norm_error = torch.norm(u_pred - u_exact, p=2)\n\n# Calculate the L2 norm of the exact solution\nl2_norm_exact = torch.norm(u_exact, p=2)\n\n# Calculate the relative L2 norm error\nepsilon = 1e-8\nif l2_norm_exact.item() > epsilon:\n    relative_l2_error = l2_norm_error / l2_norm_exact\nelse:\n    if l2_norm_error.item() < epsilon:\n        relative_l2_error = torch.tensor(0.0, device=u_pred.device, dtype=u_pred.dtype)\n    else:\n        print(f\"Warning: L2 norm of exact solution is {l2_norm_exact.item()}, which is close to zero. L2 norm of error is {l2_norm_error.item()}.\")\n        relative_l2_error = torch.tensor(float('inf'), device=u_pred.device, dtype=u_pred.dtype)\n\nprint(f\"L2 norm of error: {l2_norm_error.item()}\")\nprint(f\"L2 norm of exact solution: {l2_norm_exact.item()}\")\nprint(f\"Relative L2 norm error: {relative_l2_error.item()}\")\nrelative_l2_error_percentage = (relative_l2_error * 100)\nprint(f\"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%\")\n\n###\nplot_combined_results(\n    domain=cf.domain,\n    u_exact=u_exact,\n    u_pred=u_pred,\n    error=error,\n    plot_ranges=[\n        [-1.2, 1.2],\n        [-1.2, 1.2],\n        [-1.2, 1.2]\n    ],\n    problem=problem,\n    network_name=network_name,\n    plot_dir = plot_dir,\n    pde_weight = PDE_WEIGHT\n)\n\nplot_combined_results_3d(\n    domain=cf.domain,\n    u_exact=u_exact,\n    u_pred=u_pred,\n    error=error,\n    plot_ranges=[\n        [-1.2, 1.2],\n        [-1.2, 1.2],\n        [-1.2, 1.2]\n    ],\n    problem=problem,\n    network_name=network_name,\n    plot_dir = plot_dir,\n    pde_weight = PDE_WEIGHT\n)\n\n################################################################\n# Save Results to MATLAB .mat file\n################################################################\nprint(\"\\n--- Saving Results to .mat File ---\")\n\nmat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')\n\nif PINN_MODE:\n    try:\n        results_dict = {\n            'train_mse_log': train_mse_hybrid_log,\n            'train_hybrid_loss': np.array(train_l2_hybrid_log),\n            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),\n            'train_data_log': np.array(train_data_log),\n            'test_data_log': np.array(test_data_log),\n            'train_pde_scaled_log': np.array(train_pde_scaled_log),\n            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,\n            'config_pde_loss_scaler': PDE_LOSS_SCALER if PINN_MODE else 0.0,\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\nelse:\n    try:\n        results_dict = {\n            'train_mse_log': np.array(train_mse_log),\n            'train_l2_log': np.array(train_l2_log),\n            'test_l2_log': np.array(test_l2_log),\n            'test_input': inp.cpu().numpy(),\n            'test_prediction': pred.cpu().numpy(),\n            'test_exact': exact.cpu().numpy(),\n            'config_epochs': cf.epochs,\n            'config_lr': cf.learning_rate,\n            'config_T_in': cf.T_in,\n            'config_T_out': cf.T_out,\n            'config_s': cf.s,\n            'config_Lx': cf.Lx,\n            'final_exec_time_s': Final_time,\n        }\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Results saved successfully to: {mat_filename}\")\n    except Exception as e:\n        print(f\"Error saving results to .mat file: {e}\")\n\nprint(\"\\n--- Script Finished ---\")
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/main1.py b/main1.py
++--- a/main1.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/main1.py	(date 1754055606856)
++@@ -1,111 +1,128 @@
+++
++ import os
++ import importlib
++ import torch
++ import inspect
++ import numpy as np
++ import matplotlib
+++import h5py  # MODIFIED: Added h5py import
+++import scipy.io
+++
++ matplotlib.use('TkAgg')
++ import matplotlib.pyplot as plt
++ import torch.nn.functional as F
++-from training import train_fno, train_fno_time, train_hybrid
+++from training import train_fno, train_fno_time, train_hybrid, train_fno4d
++ from torch.utils.data import DataLoader, random_split
++-from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator
++-from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, make_video, save_vtk, plot_xy_plane_subplots
++-import time  # Import the time module at the beginning of the script
+++from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator, SobolevLoss
+++from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \
+++    make_video, save_vtk, plot_xy_plane_subplots
+++import time
++ from torch_optimizer import Lamb
++-import scipy.io
+++
+++################################################################
+++# Problem Definition
+++################################################################
++ 
++ ################################################################
++ # Problem Definition
++ ################################################################
++ # problem = 'AC2D'
++-#problem = 'AC3D'
+++problem = 'AC3D'
++ # problem = 'CH2DNL'
++ # problem = 'SH2D'
++-problem = 'SH3D'
+++#problem = 'SH3D'
++ # problem = 'PFC2D'
++ #problem = 'PFC3D'
++-#problem = 'MBE2D'
+++# problem = 'MBE2D'
++ #problem = 'MBE3D'
++ # problem = 'CH2D'
++ #problem = 'CH3D'
++ 
++-#network_name = 'TNO2d'
+++# network_name = 'TNO2d'
++ # network_name = 'FNO2d'
++ #network_name = 'FNO3d'
+++#network_name = 'FNO4d'
++ network_name = 'TNO3d'
++ 
++-PINN_MODE = False # True # False #
+++PINN_MODE =  False # True #  True #  False #  True #   True #    True #
+++#  False #    True # False #  False  # False #
++ 
++ print(f"problem = {problem}")
++ print(f"network = {network_name}")
++ os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
++-cf = importlib.import_module(f"configs.config_{problem}_{network_name}") # configuration file
++-# above line means: import configs.config_PFC3D_TNO3d as cf
++-network = getattr(importlib.import_module('networks'), network_name) # from networks import TNO3d
+++cf = importlib.import_module(f"configs.config_{problem}_{network_name}")
+++network = getattr(importlib.import_module('networks'), network_name)
++ torch.manual_seed(cf.torch_seed)
++ np.random.seed(cf.numpy_seed)
++-#device = torch.device(cf.gpu_number if torch.cuda.is_available() else 'cpu')
++-device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")
+++device = torch.device("cuda:2" if torch.cuda.is_available() else "cpu")
++ print("Device: ", device)
++-# --- Define Output Directory ---
++-
++ 
++ PDE_WEIGHT = cf.pde_weight
++-PDE_LOSS_SCALER = cf.pde_loss_scaler
+++pde_loss_scaler = cf.pde_loss_scaler
++ 
++ if PINN_MODE:
++     run_descriptor = f"PINN_w{int(PDE_WEIGHT * 100)}"
++-    output_subdir = f"plots_Data_Physics_{network_name}"  # Specific PINN output
+++    output_subdir = f"plots_Data_Physics_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_Hybrid_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
++ else:
++     run_descriptor = "DataDriven"
++-    output_subdir = f"plots_{network_name}"  # Original data-driven output
+++    output_subdir = f"plots_{network_name}"
+++    model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d_NoMixed.pt'
++ 
++-#model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_w{cf.width}_m{cf.modes}_q{cf.width_q}_h{cf.width_h}_{run_descriptor}'
++-model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}.pt'
++-model_dir = os.path.join(problem, 'models') # models_smpooth
+++model_dir = os.path.join(problem, 'models')
++ model_name = f'{model_run_name}'
++ model_path = os.path.join(model_dir, model_name)
++-
++-plot_dir = os.path.join(problem, output_subdir)  # Use specific plot dir
+++plot_dir = os.path.join(problem, output_subdir)
++ os.makedirs(model_dir, exist_ok=True)
++-os.makedirs(plot_dir, exist_ok=True)  # Make sure plot directory exists
+++os.makedirs(plot_dir, exist_ok=True)
++ 
++ print(f"Model Run Name: {model_run_name}")
++ print(f"Model Path: {model_path}")
++ print(f"Plot Directory: {plot_dir}")
++ 
++-# width_q = 32
++ start_time = time.time()
++ 
++ ################################################################
++ # load data and data normalization
++ ################################################################
++-#model_dir = problem + '/models'
++-
++-print(f"model = {model_name}")
++-print(f"number of epoch = {cf.epochs}")
++-print(f"batch size = {cf.batch_size}")
++-print(f"nTrain = {cf.nTrain}")
++-print(f"nTest = {cf.nTest}")
++-print(f"learning_rate = {cf.learning_rate}")
++-print(f"n_layers = {cf.n_layers}")
++-print(f"width_q = {cf.width_q}")
++-print(f"width_h = {cf.width_h}")
++-
++-model_path = os.path.join(model_dir, model_name)
++-os.makedirs(model_dir, exist_ok=True)
++-# dataset creates an instance of the ImportDataset class, initializing it with parameters from cf
++-dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++# MODIFIED: Added special handling for SH3D dataset loading
+++try:
+++    dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)
+++    if problem == 'SH3D':
+++        print("SH3D dataset detected - applying special handling")
+++        # Verify dataset sizes
+++        sample = dataset[0][0]  # Get first sample
+++        print(f"SH3D sample shape: {sample.shape}, dtype: {sample.dtype}")
+++        print(f"SH3D stats - mean: {sample.mean():.4f}, std: {sample.std():.4f}")
+++except Exception as e:
+++    print(f"Error loading dataset: {e}")
+++    raise
++ 
++ train_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])
++-# to see train_dataset values: print("train_dataset subset:", [train_dataset[i] for i in range(len(train_dataset))])
++ normalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None
++ 
++-train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
++-test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++train_loader = DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)
+++test_loader = DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)
+++
++ 
++-################################################################
+++# ==================== CODE TO INSPECT BATCH SHAPE ====================
+++print("\n" + "="*50)
+++print("Inspecting DataLoader Batch Shapes")
+++print("="*50)
+++# Get one batch of data from the train_loader
+++try:
+++    x_batch, y_batch = next(iter(train_loader))
+++    # Print the shape of the batch
+++    # This will be (batch_size, S, S, S, T_in) for input
+++    # and (batch_size, S, S, S, T_out) for target
+++    print(f"Shape of an input batch from DataLoader: {x_batch.shape}")
+++    print(f"Shape of a target batch from DataLoader: {y_batch.shape}")
+++except StopIteration:
+++    print("Train loader is empty. Cannot retrieve a batch.")
+++print("="*50 + "\n")
+++# =======================================================================
+++
+++############AA####################################################
++ # training and evaluation
++ ################################################################
++ sig = inspect.signature(network.__init__)
++@@ -118,19 +135,32 @@
++ elif network_name == 'FNO3d':
++     model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)
++ elif network_name == 'TNO3d':
++-    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)
+++    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(
+++        device)
+++elif network_name == 'FNO4d':
+++    model = network(
+++        modes1=cf.modes,
+++        modes2=cf.modes,
+++        modes3=cf.modes,
+++        modes4_internal =1, # cf.modes_t, # MUST BE 1
+++        width=cf.width,
+++        width_q=cf.width_q,
+++        T_in_channels=cf.T_in,
+++        n_layers=cf.n_layers
+++    ).to(device)
+++
+++
++ else:
++     raise Exception("network_name is not correct")
++ 
++-print(count_params(model))      # Print model parameters
++-train_mse_log, train_l2_log, test_l2_log = [], [], []       # Initialize logs
+++print(count_params(model))  # Print model parameters
+++train_mse_log, train_l2_log, test_l2_log = [], [], []  # Initialize logs
++ 
++ # Load the entire model and logs
++ if os.path.exists(model_path) and cf.load_model:
++     print(f"Loading pre-trained model from {model_path}")
++     checkpoint = torch.load(model_path, map_location=device)
++-    model.load_state_dict(checkpoint['model_state_dict']) # Use this line if you only save state_dict
++-    #model = checkpoint['model'] # Use this line if you save the entire model object
+++    model = checkpoint['model']
++     train_mse_log = checkpoint.get('train_mse_log', [])
++     train_l2_log = checkpoint.get('train_l2_log', [])
++     test_l2_log = checkpoint.get('test_l2_log', [])
++@@ -140,14 +170,19 @@
++ # Define optimizer, scheduler, and loss function
++ optimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)
++ scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)
++-myloss = LpLoss(size_average=False)
+++myloss = LpLoss(p=2, l1_weight=0.1, size_average=False) # size_average=True # False
+++# NEW: Instantiate SobolevLoss instead of LpLoss
+++# You can tune grad_weight. A good starting point is 0.1 or 1.0.
+++#myloss = SobolevLoss(d=3, p=2, grad_weight=0.1)
++ 
++-###
+++# COMPUTE THE DYNAMIC SCALER
+++# Use the train_loader to get a representative batch
+++
++ 
++ # Train the model
++ if cf.training:
++     print("\n--- Starting Training ---")
++-    if PINN_MODE:
+++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
++         grid_info = {
++             'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
++             'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
++@@ -159,18 +194,18 @@
++             print("Running PINN training loop with pde_weight=0 (Data-Driven only loss).")
++         else:
++             print(
++-                f"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {PDE_LOSS_SCALER:.2e}")
+++                f"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {pde_loss_scaler:.2e}")
++ 
++         model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (
++             train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                          optimizer, scheduler, cf.normalized, normalizers, device,
++                          PDE_WEIGHT, grid_info, cf.epsilon, problem,
++-                         pde_loss_scaler=PDE_LOSS_SCALER)
+++                         pde_loss_scaler=pde_loss_scaler)
++         )
++ 
++         print(f"Saving model and logs to {model_path}")
++         torch.save({
++-            'model_state_dict': model.state_dict(),
+++            'model': model,
++             'train_mse_log': train_mse_hybrid_log,
++             'train_l2_log': train_l2_hybrid_log,
++             'test_l2_log': test_data_log,
++@@ -180,32 +215,134 @@
++             'test_loss_hybrid_log': test_loss_hybrid_log
++         }, model_path)
++ 
++-    else:
++-        if network_name in ['FNO2d', 'FNO3d']:
+++    else:  # Original Data-Driven Mode
+++        if network_name == 'FNO2d' or network_name == 'FNO3d':
+++            model, train_l2_log, test_l2_log = (
+++                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                               optimizer, scheduler, cf.normalized, normalizers, device))
+++            train_mse_log = []
+++        elif network_name == 'FNO4d':
+++
+++            model, train_mse_log, train_l2_log, test_l2_log = (  # Add val logs
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++            # train_fno4d = train_fno
+++        else:
+++            model, train_mse_log, train_l2_log, test_l2_log = (
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
+++
+++    print(f"Saving model and logs to {model_path}")
+++    torch.save({
+++        'model': model,
+++        'train_mse_log': train_mse_log,
+++        'train_l2_log': train_l2_log,
+++        'test_l2_log': test_l2_log
+++    }, model_path)
+++
+++
+++'''
+++# Train the model
+++if cf.training:
+++    print("\n--- Starting Training ---")
+++    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)
+++        grid_info = {
+++            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,
+++            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,
+++            'dt_model': cf.dt_model,
+++            'T_out': cf.T_out
+++        }
+++
+++        # --- NEW: Define the two stages for the training curriculum ---
+++        epochs_stage1 = 10
+++        scaler_stage1 = 1e-4
+++
+++        # Calculate remaining epochs for stage 2
+++        epochs_stage2 = cf.epochs - epochs_stage1
+++        scaler_stage2 = 1e-6
+++
+++        # --- Stage 1 Training ---
+++        print("\n--- Starting Training Stage 1 ---")
+++        print(f"Epochs: {epochs_stage1}, PDE Scaler: {scaler_stage1:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++        # Note: The 'model' object is updated in-place by the function call
+++        model, train_mse_s1, train_l2_s1, test_data_s1, test_pde_s1, train_data_s1, train_pde_scl_s1, test_loss_s1 = (
+++            train_hybrid(model, myloss, epochs_stage1, cf.batch_size, train_loader, test_loader,
+++                         optimizer, scheduler, cf.normalized, normalizers, device,
+++                         PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                         pde_loss_scaler=scaler_stage1)
+++        )
+++
+++        # --- Stage 2 Training (if there are remaining epochs) ---
+++        if epochs_stage2 > 0:
+++            print("\n--- Starting Training Stage 2 ---")
+++            print(f"Epochs: {epochs_stage2}, PDE Scaler: {scaler_stage2:.2e}, PDE Weight: {PDE_WEIGHT:.2f}")
+++
+++            model, train_mse_s2, train_l2_s2, test_data_s2, test_pde_s2, train_data_s2, train_pde_scl_s2, test_loss_s2 = (
+++                train_hybrid(model, myloss, epochs_stage2, cf.batch_size, train_loader, test_loader,
+++                             optimizer, scheduler, cf.normalized, normalizers, device,
+++                             PDE_WEIGHT, grid_info, cf.epsilon, problem,
+++                             pde_loss_scaler=scaler_stage2)
+++            )
+++
+++            # Combine the logs from both stages for plotting and saving
+++            train_mse_hybrid_log = train_mse_s1 + train_mse_s2
+++            train_l2_hybrid_log = train_l2_s1 + train_l2_s2
+++            test_data_log = test_data_s1 + test_data_s2
+++            test_pde_loss_scaled_log = test_pde_s1 + test_pde_s2
+++            train_data_log = train_data_s1 + train_data_s2
+++            train_pde_scaled_log = train_pde_scl_s1 + train_pde_scl_s2
+++            test_loss_hybrid_log = test_loss_s1 + test_loss_s2
+++        else:
+++            # If only stage 1 was run, the final logs are just the stage 1 logs
+++            train_mse_hybrid_log = train_mse_s1
+++            train_l2_hybrid_log = train_l2_s1
+++            test_data_log = test_data_s1
+++            test_pde_loss_scaled_log = test_pde_s1
+++            train_data_log = train_data_s1
+++            train_pde_scaled_log = train_pde_scl_s1
+++            test_loss_hybrid_log = test_loss_s1
+++
+++        print(f"\n--- Training Finished. Saving model and logs to {model_path} ---")
+++        # The torch.save call remains the same, as the log variables have been correctly prepared
+++        torch.save({
+++            'model': model,
+++            'train_mse_log': train_mse_hybrid_log,
+++            'train_l2_log': train_l2_hybrid_log,
+++            'test_l2_log': test_data_log, # 'test_l2_log' is used by evaluator, it should contain data loss
+++            'test_pde_scaled_log': test_pde_loss_scaled_log,
+++            'train_data_log': train_data_log,
+++            'train_pde_scaled_log': train_pde_scaled_log,
+++            'test_loss_hybrid_log': test_loss_hybrid_log
+++        }, model_path)
+++
+++    else:  # Original Data-Driven Mode (This part remains unchanged)
+++        if network_name == 'FNO2d' or network_name == 'FNO3d':
++             model, train_l2_log, test_l2_log = (
++                 train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++                                optimizer, scheduler, cf.normalized, normalizers, device))
++             train_mse_log = []
++         else:
++             model, train_mse_log, train_l2_log, test_l2_log = (
++-               train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
++-                           optimizer, scheduler, cf.normalized, normalizers, device))
+++                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+++                          optimizer, scheduler, cf.normalized, normalizers, device))
++ 
++         print(f"Saving model and logs to {model_path}")
++         torch.save({
++-            'model_state_dict': model.state_dict(),
+++            'model': model,
++             'train_mse_log': train_mse_log,
++             'train_l2_log': train_l2_log,
++             'test_l2_log': test_l2_log
++         }, model_path)
++-
+++'''
++ 
++ end_time = time.time()
++ Final_time = round(end_time - start_time, 2)
++ print(f"Total Execution Time: {Final_time} seconds")
++ 
++ evaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,
++-                           time_history=(network_name in ['FNO2d', 'FNO3d']))
+++                           time_history=(network_name == 'FNO2d'))
++ 
++ results = evaluator.evaluate(loss_fn=myloss)
++ inp = results['input']
++@@ -214,7 +351,8 @@
++ test_l2_avg = results["average"]
++ 
++ if PINN_MODE:
++-    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log]
+++    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log,
+++              train_pde_scaled_log]
++     labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']
++     plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)
++ else:
++@@ -222,7 +360,6 @@
++     labels = ['Train L2', 'Test L2']
++     plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)
++ 
++-
++ ################################################################
++ # post-processing
++ ################################################################
++@@ -231,115 +368,202 @@
++ u_exact = exact[cf.index]
++ error = u_pred - u_exact
++ 
+++print(f"DEBUG: Shape of u_exact passed to plotting function: {u_exact.shape}")
+++print(f"DEBUG: Shape of u_pred passed to plotting function: {u_pred.shape}")
+++
++ plot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]
++-print(f"Field shape: {u_exact.shape}")
+++
+++# =========================================================================================
+++# ===                START OF MODIFIED PLOTTING PREPARATION BLOCK                      ===
+++# =========================================================================================
+++
+++# 1. Get the initial condition (t=0) data for the chosen sample index
+++a_ind = inp[cf.index]
+++print(f"Shape of initial condition (t=0) data 'a_ind': {a_ind.shape}")
+++
+++# 2. Separate desired times into t=0 vs. future predictions
+++desired_times = cf.time_steps
+++future_times_to_plot = []
+++has_initial_condition = (0 in desired_times)
+++for t in desired_times:
+++    if t > 0:
+++        future_times_to_plot.append(t)
+++
+++# 3. Translate the FUTURE times to array indices
+++indices_to_plot = []
+++valid_future_times = []
+++for t in future_times_to_plot:
+++    if t <= cf.T_out:
+++        indices_to_plot.append(t - 1)
+++        valid_future_times.append(t)
+++    else:
+++        print(f"Warning: Time t={t} is out of valid prediction range. Skipping.")
+++print(f"Plotting for future times: {valid_future_times} --> which correspond to array indices: {indices_to_plot}")
+++
+++# 4. MOVE ALL DATA TO THE TARGET DEVICE BEFORE OPERATIONS
+++t0_data_cpu = a_ind
+++u_exact_cpu = u_exact
+++u_pred_cpu = u_pred
+++error_cpu = error
+++
+++t0_data_gpu = t0_data_cpu.to(device)
+++u_exact_gpu = u_exact_cpu.to(device)
+++u_pred_gpu = u_pred_cpu.to(device)
+++error_gpu = error_cpu.to(device)
+++indices_tensor_gpu = torch.tensor(indices_to_plot, device=device)
+++
+++# 5. PREPARE COMBINED TENSORS FOR PLOTTING on the GPU
+++if has_initial_condition:
+++    # --- ### FIXED DIMENSION HANDLING ### ---
+++    # `a_ind` has shape (sx, sy, sz, 1) where the last dim is a channel.
+++    # `u_exact_gpu` has shape (sx, sy, sz, T) where the last dim is time.
+++    # They are both 4D, so we can concatenate them directly if the last dimension is treated as the time dimension.
+++    # We don't need to do any reshaping. `t0_data_gpu` is already correct.
+++    t0_for_concat = t0_data_gpu
+++
+++    # Select the future time slices from the GPU tensors
+++    u_exact_selected = u_exact_gpu.index_select(-1, indices_tensor_gpu)
+++    u_pred_selected = u_pred_gpu.index_select(-1, indices_tensor_gpu)
+++    error_selected = error_gpu.index_select(-1, indices_tensor_gpu)
+++
+++    # Combine t=0 data with the selected future steps
+++    u_exact_for_plot = torch.cat((t0_for_concat, u_exact_selected), dim=-1)
+++    u_pred_for_plot = torch.cat((t0_for_concat, u_pred_selected), dim=-1)
+++
+++    # The error for t=0 is zero by definition
+++    error_t0 = torch.zeros_like(t0_for_concat)
+++    error_for_plot = torch.cat((error_t0, error_selected), dim=-1)
++ 
++-selected_time_steps = [0, 2, 4, 6, 8, 9]
+++    final_indices = list(range(len(desired_times)))
+++    final_labels = desired_times
+++else:
+++    u_exact_for_plot = u_exact_gpu
+++    u_pred_for_plot = u_pred_gpu
+++    error_for_plot = error_gpu
+++    final_indices = indices_to_plot
+++    final_labels = valid_future_times
++ 
++-# Plot exact solution
+++print(f"Final data prepared for plotting with shape: {u_exact_for_plot.shape}")
+++print(f"Final indices for plotting: {final_indices}")
+++print(f"Final labels for plotting: {final_labels}")
+++
+++
+++# =========================================================================================
+++# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===
+++# =========================================================================================
+++
+++################################################################
+++# Save Results to MATLAB .mat file
+++################################################################
+++print("\n--- Saving Results to .mat File ---")
+++mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
+++
+++# MODIFIED: Enhanced saving logic with fallbacks
+++def save_results(mat_filename, results_dict):
+++    try:
+++        # First try standard save
+++        scipy.io.savemat(mat_filename, results_dict)
+++        print(f"Saved with standard format to {mat_filename}")
+++    except ValueError as e:
+++        if "Format should be '4' or '5'" in str(e):
+++            print("Large data detected, trying v7.3 format...")
+++            try:
+++                scipy.io.savemat(mat_filename, results_dict, format='v7.3')
+++                print(f"Saved with v7.3 format to {mat_filename}")
+++            except Exception as e:
+++                print(f"v7.3 failed: {e}")
+++                # Fallback to HDF5
+++                h5_filename = mat_filename.replace('.mat', '.h5')
+++                with h5py.File(h5_filename, 'w') as f:
+++                    for k, v in results_dict.items():
+++                        f.create_dataset(k, data=v, compression='gzip')
+++                print(f"Saved as HDF5 to {h5_filename}")
+++        else:
+++            raise
+++
+++if PINN_MODE:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_hybrid_log, dtype=np.float32),  # MODIFIED: Added dtype
+++        'train_hybrid_loss': np.array(train_l2_hybrid_log, dtype=np.float32),
+++        'test_loss_hybrid_log': np.array(test_loss_hybrid_log, dtype=np.float32),
+++        'train_data_log': np.array(train_data_log, dtype=np.float32),
+++        'test_data_log': np.array(test_data_log, dtype=np.float32),
+++        'train_pde_scaled_log': np.array(train_pde_scaled_log, dtype=np.float32),
+++        'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),  # MODIFIED: Added astype
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_pde_weight': np.float32(PDE_WEIGHT),
+++        'config_pde_loss_scaler': np.float32(pde_loss_scaler),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++    }
+++else:
+++    results_dict = {
+++        'train_mse_log': np.array(train_mse_log, dtype=np.float32),
+++        'train_l2_log': np.array(train_l2_log, dtype=np.float32),
+++        'test_l2_log': np.array(test_l2_log, dtype=np.float32),
+++        'test_input': inp.cpu().numpy().astype(np.float32),
+++        'test_prediction': pred.cpu().numpy().astype(np.float32),
+++        'test_exact': exact.cpu().numpy().astype(np.float32),
+++        'config_epochs': np.int32(cf.epochs),
+++        'config_lr': np.float32(cf.learning_rate),
+++        'config_T_in': np.int32(cf.T_in),
+++        'config_T_out': np.int32(cf.T_out),
+++        'config_s': np.int32(cf.s),
+++        'config_Lx': np.float32(cf.Lx),
+++        'final_exec_time_s': np.float32(Final_time),
+++    }
+++
+++# MODIFIED: Use the new save function
+++save_results(mat_filename, results_dict)
+++
+++# Plot XY-plane for the "Exact" solution trajectory (includes t=0)
+++
+++'''
++ plot_xy_plane_subplots(domain=cf.domain,
++-                      field=u_exact,
++-                      field_name='Exact Solution',
++-                      time_steps=selected_time_steps,
++-                      plot_range=plot_range[0],
++-                      problem=problem,
++-                      network_name=network_name)
+++                       field=u_exact_for_plot,
+++                       field_name='Exact Solution',
+++                       time_steps=final_indices,
+++                       desired_times=final_labels,
+++                       plot_range=plot_range[0],
+++                       problem=problem,
+++                       network_name=network_name)
++ 
++-# Plot predicted solution
+++# Plot XY-plane for the "Predicted" solution trajectory (includes t=0 from input)
++ plot_xy_plane_subplots(domain=cf.domain,
++-                      field=u_pred,
++-                      field_name='Predicted Solution',
++-                      time_steps=selected_time_steps,
++-                      plot_range=plot_range[1],
++-                      problem=problem,
++-                      network_name=network_name)
+++                       field=u_pred_for_plot,
+++                       field_name='Predicted Solution',
+++                       time_steps=final_indices,
+++                       desired_times=final_labels,
+++                       plot_range=plot_range[1],
+++                       problem=problem,
+++                       network_name=network_name)
++ 
++-# Plot error
+++# Plot XY-plane for the "Error" (error is 0 at t=0)
++ plot_xy_plane_subplots(domain=cf.domain,
++-                      field=error,
++-                      field_name='Error',
++-                      time_steps=selected_time_steps,
++-                      plot_range=plot_range[2],
++-                      problem=problem,
++-                      network_name=network_name)
++-
++-
++-# ==============================================================================
++-# NEW SECTION: PREDICT AND VISUALIZE A SINGLE TRAJECTORY EVOLUTION
++-# ==============================================================================
++-print("\n--- Generating Visualization for a Single Predicted Trajectory ---")
++-
++-# Ensure dt_simulation is defined in the config file.
++-if not hasattr(cf, 'dt_simulation'):
++-    raise AttributeError("Configuration file is missing 'dt_simulation'. Please add it (e.g., dt_simulation = 0.00002).")
++-
++-predicted_trajectory = u_pred # Shape: (s, s, s, T_out)
++-
++-# 1. Choose 4 suitable time frames for visualization from the predicted steps.
++-num_time_frames_to_plot = 4
++-total_predicted_steps = predicted_trajectory.shape[-1]  # This is T_out
++-
++-if total_predicted_steps < 1:
++-    print("No time steps to plot in the predicted trajectory.")
++-else:
++-    # Select 4 evenly spaced indices from the available time steps.
++-    time_indices_to_plot = np.linspace(0, total_predicted_steps - 1, num_time_frames_to_plot, dtype=int).tolist()
++-
++-    print(f"Selected time indices for plotting: {time_indices_to_plot}")
+++                       field=error_for_plot,
+++                       field_name='Error',
+++                       time_steps=final_indices,
+++                       desired_times=final_labels,
+++                       plot_range=plot_range[2],
+++                       problem=problem,
+++                       network_name=network_name)
+++'''
++ 
++-    # 2. Create the subplot (1 row, 4 columns) and save it.
++-    fig, axes = plt.subplots(1, num_time_frames_to_plot, figsize=(5 * num_time_frames_to_plot, 5), squeeze=False)
++-    axes = axes.flatten()
++-
++-    vmin = predicted_trajectory.cpu().numpy().min()
++-    vmax = predicted_trajectory.cpu().numpy().max()
++-    s = cf.s
++-    slice_index = s // 2  # Middle slice in the Z-direction
++-
++-    for i, t_idx in enumerate(time_indices_to_plot):
++-        # 3. Calculate the correct physical time for the label.
++-        # The prediction starts after T_in steps.
++-        physical_time = (cf.T_in + t_idx) * cf.dt_simulation
++-
++-        slice_2d = predicted_trajectory[:, :, slice_index, t_idx].cpu().numpy()
++-
++-        ax = axes[i]
++-        im = ax.imshow(slice_2d, cmap='viridis', vmin=vmin, vmax=vmax,
++-                       extent=[0, cf.Lx, 0, cf.Ly], origin='lower', interpolation='bicubic')
++-        ax.set_title(f'Predicted t={physical_time:.2e}') # Use scientific notation for time
++-        ax.set_xlabel('x')
++-        if i == 0:
++-            ax.set_ylabel('y')
++-
++-    fig.colorbar(im, ax=axes.tolist(), orientation='vertical', pad=0.02)
++-    z_coord = cf.Lx / s * (slice_index - s / 2)
++-    fig.suptitle(f'Predicted Evolution (Z-slice at z={z_coord:.2f})', fontsize=16)
++-    fig.tight_layout(rect=[0, 0, 1, 0.95])
++-
++-    subplot_filename = os.path.join(plot_dir, f'{model_run_name}_single_trajectory_subplot.png')
++-    plt.savefig(subplot_filename, dpi=300, bbox_inches='tight')
++-    print(f"Trajectory subplot saved to {subplot_filename}")
++-    plt.close(fig)
++-
++-# END OF NEW SECTION
++-# ==============================================================================
++-
++-# The p=2 explicitly specifies the L2 norm.
+++# Calculate L2 norm on original full prediction
++ l2_norm_error = torch.norm(u_pred - u_exact, p=2)
++-
++-# Calculate the L2 norm of the exact solution
++ l2_norm_exact = torch.norm(u_exact, p=2)
++-
++-# Calculate the relative L2 norm error
++ epsilon = 1e-8
++ if l2_norm_exact.item() > epsilon:
++     relative_l2_error = l2_norm_error / l2_norm_exact
++ else:
++-    if l2_norm_error.item() < epsilon:
++-        relative_l2_error = torch.tensor(0.0, device=u_pred.device, dtype=u_pred.dtype)
++-    else:
++-        print(f"Warning: L2 norm of exact solution is {l2_norm_exact.item()}, which is close to zero. L2 norm of error is {l2_norm_error.item()}.")
++-        relative_l2_error = torch.tensor(float('inf'), device=u_pred.device, dtype=u_pred.dtype)
+++    relative_l2_error = torch.tensor(0.0) if l2_norm_error.item() < epsilon else torch.tensor(float('inf'))
++ 
++ print(f"L2 norm of error: {l2_norm_error.item()}")
++ print(f"L2 norm of exact solution: {l2_norm_exact.item()}")
++@@ -347,93 +571,33 @@
++ relative_l2_error_percentage = (relative_l2_error * 100)
++ print(f"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%")
++ 
++-###
+++# Call the combined results plots with the prepared data
++ plot_combined_results(
++     domain=cf.domain,
++-    u_exact=u_exact,
++-    u_pred=u_pred,
++-    error=error,
++-    plot_ranges=[
++-        [-1.2, 1.2],
++-        [-1.2, 1.2],
++-        [-1.2, 1.2]
++-    ],
+++    u_exact=u_exact_for_plot,
+++    u_pred=u_pred_for_plot,
+++    error=error_for_plot,
+++    plot_ranges=plot_range,
++     problem=problem,
++     network_name=network_name,
++-    plot_dir = plot_dir,
++-    pde_weight = PDE_WEIGHT
+++    plot_dir=plot_dir,
+++    pde_weight=PDE_WEIGHT,
+++    time_steps_indices=final_indices,
+++    desired_times=final_labels
++ )
++ 
++ plot_combined_results_3d(
++     domain=cf.domain,
++-    u_exact=u_exact,
++-    u_pred=u_pred,
++-    error=error,
++-    plot_ranges=[
++-        [-1.2, 1.2],
++-        [-1.2, 1.2],
++-        [-1.2, 1.2]
++-    ],
+++    u_exact=u_exact_for_plot,
+++    u_pred=u_pred_for_plot,
+++    error=error_for_plot,
+++    plot_ranges=plot_range,
++     problem=problem,
++     network_name=network_name,
++-    plot_dir = plot_dir,
++-    pde_weight = PDE_WEIGHT
+++    plot_dir=plot_dir,
+++    pde_weight=PDE_WEIGHT,
+++    time_steps_indices=final_indices,
+++    desired_times=final_labels
++ )
++ 
++-################################################################
++-# Save Results to MATLAB .mat file
++-################################################################
++-print("\n--- Saving Results to .mat File ---")
++-
++-mat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')
++-
++-if PINN_MODE:
++-    try:
++-        results_dict = {
++-            'train_mse_log': train_mse_hybrid_log,
++-            'train_hybrid_loss': np.array(train_l2_hybrid_log),
++-            'test_loss_hybrid_log': np.array(test_loss_hybrid_log),
++-            'train_data_log': np.array(train_data_log),
++-            'test_data_log': np.array(test_data_log),
++-            'train_pde_scaled_log': np.array(train_pde_scaled_log),
++-            'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_pde_weight': PDE_WEIGHT if PINN_MODE else 0.0,
++-            'config_pde_loss_scaler': PDE_LOSS_SCALER if PINN_MODE else 0.0,
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-else:
++-    try:
++-        results_dict = {
++-            'train_mse_log': np.array(train_mse_log),
++-            'train_l2_log': np.array(train_l2_log),
++-            'test_l2_log': np.array(test_l2_log),
++-            'test_input': inp.cpu().numpy(),
++-            'test_prediction': pred.cpu().numpy(),
++-            'test_exact': exact.cpu().numpy(),
++-            'config_epochs': cf.epochs,
++-            'config_lr': cf.learning_rate,
++-            'config_T_in': cf.T_in,
++-            'config_T_out': cf.T_out,
++-            'config_s': cf.s,
++-            'config_Lx': cf.Lx,
++-            'final_exec_time_s': Final_time,
++-        }
++-        scipy.io.savemat(mat_filename, results_dict)
++-        print(f"Results saved successfully to: {mat_filename}")
++-    except Exception as e:
++-        print(f"Error saving results to .mat file: {e}")
++-
++ print("\n--- Script Finished ---")
++\ No newline at end of file
++Index: networks.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef get_grid_2d(shape, device):\n    batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n    gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n    gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n    return torch.cat((gridx, gridy), dim=-1).to(device)\n\n\ndef get_grid_3d(shape, device):\n    batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n    gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n    gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n    gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n    return torch.cat((gridx, gridy, gridz), dim=-1).to(device)\n\n\n# Complex multiplication\ndef compl_mul2d(inp, weights):\n    # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n    return torch.einsum(\"bixy,ioxy->boxy\", inp, weights)\n\n\ndef compl_mul3d(inp, weights):\n    # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n    return torch.einsum(\"bixyz,ioxyz->boxyz\", inp, weights)\n\n\nclass SpectralConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, modes1, modes2):\n        super(SpectralConv2d, self).__init__()\n\n        \"\"\"\n        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n        \"\"\"\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n        self.modes2 = modes2\n\n        self.scale = (1 / (in_channels * out_channels))\n        self.weights1 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n        self.weights2 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n\n    def forward(self, x):\n        batchsize = x.shape[0]\n        # Compute Fourier coefficients --  1. Compute Fourier Transform\n        # Now, instead of working with raw pixel/grid values, we work with frequency components\\\n        # Suppose the input x has shape (batch, in_channels, H, W)\n        # x_ft has shape: batchin_channelsH(W/2+1)\n        x_ft = torch.fft.rfft2(x) # 2D Fast Fourier Transform (FFT) --> v0 = F(v0)\n\n        # Multiply relevant Fourier modes -- 2. Apply Spectral Convolution\n        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat,\n                             device=x.device)\n        # v1(k1,k2)= W(k1,k2).v0(k1,k2) --> W(k1,k2) are learnable parameters that control how much each frequency mode contributes\n        out_ft[:, :, :self.modes1, :self.modes2] = \\\n            compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n            compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n\n        # Return to physical space\n        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1))) # Apply Inverse Fourier Transform (iFFT) --> v1(x,y) = F^(-1)[v1(k1,k2)]\n        return x\n\n\nclass SpectralConv3d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n        super(SpectralConv3d, self).__init__()\n\n        \"\"\"\n        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n        \"\"\"\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n        self.modes2 = modes2\n        self.modes3 = modes3\n\n        self.scale = (1 / (in_channels * out_channels))\n        self.weights1 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights2 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights3 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights4 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n\n    def forward(self, x):\n        batchsize = x.shape[0]\n        # Compute Fourier coefficients up to factor of e^(- something constant)\n        x_ft = torch.fft.rfftn(x, dim=[-3, -2, -1])\n\n        # Multiply relevant Fourier modes\n        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1) // 2 + 1,\n                             dtype=torch.cfloat, device=x.device)\n        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n\n        # Return to physical space\n        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n        return x\n\n\nclass MLP2d(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels, T=1, num_layers=2):\n        \"\"\"\n        Initialize the MLP2d class.\n        Parameters:\n        - in_channels: Number of input channels.\n        - out_channels: Number of output channels.\n        - mid_channels: Number of intermediate channels.\n        - T: Number of blocks (default=1).\n        - num_layers: Number of layers in each block (default=2).\n        \"\"\"\n        super(MLP2d, self).__init__()\n\n        self.num_layers = num_layers\n        self.layers = nn.ModuleList()\n\n        for _ in range(T):\n            self.layers.append(nn.Conv2d(in_channels, mid_channels, 1))\n            for _ in range(self.num_layers - 2):\n                self.layers.append(nn.Conv2d(mid_channels, mid_channels, 1))\n            self.layers.append(nn.Conv2d(mid_channels, out_channels, 1))\n\n    def forward(self, x, t=0):\n        start = t * self.num_layers\n        end = start + self.num_layers\n        for i in range(start, end - 1):\n            x = F.gelu(self.layers[i](x))\n        x = self.layers[end - 1](x)\n        return x\n\n\nclass MLP3d(MLP2d):\n    def __init__(self, in_channels, out_channels, mid_channels, T=1, num_layers=2):\n        super(MLP3d, self).__init__(in_channels, out_channels, mid_channels, T, num_layers)\n\n        self.layers = nn.ModuleList()\n        for _ in range(T):\n            self.layers.append(nn.Conv3d(in_channels, mid_channels, 1))\n            # After (3x3x3 kernel)\n            #self.layers.append(nn.Conv3d(in_channels, mid_channels, 3, padding=1))  ## Changed from 1*1*1 to 3*3*3\n            for _ in range(self.num_layers - 2):\n                self.layers.append(nn.Conv3d(mid_channels, mid_channels, 1))\n                #self.layers.append(nn.Conv3d(mid_channels, mid_channels, 3, padding=1))  ## Changed from 1 to 3\n            self.layers.append(nn.Conv3d(mid_channels, out_channels, 1))\n            #self.layers.append(nn.Conv3d(mid_channels, out_channels, 3, padding=1))  ## Changed from 1 to 3\n\n\nclass FNO2d(nn.Module):\n    def __init__(self, modes1, modes2, width, width_q, T_in, T_out, n_layers):\n        super(FNO2d, self).__init__()\n\n        \"\"\"\n        The overall network. It contains 4 layers of the Fourier layer.\n        1. Lift the input to the desire channel dimension by self.fc0 .\n        2. 4 layers of the integral operators u' = (W + K)(u).\n            W defined by self.w; K defined by self.conv .\n        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n\n        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n        input shape: (batchsize, x=64, y=64, c=12)\n        output: the solution of the next timestep\n        output shape: (batchsize, x=64, y=64, c=1)\n        \"\"\"\n\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.width = width\n        self.width_q = width_q\n        self.T_in = T_in\n        self.T_out = T_out\n        self.padding = 8  # pad the domain if input is non-periodic\n        self.n_layers = n_layers\n\n        self.p = nn.Linear(T_in + 2, self.width)  # We start with an input x == u(x,y) of shape (batch,x,y,c), We lift it to a higher-dimensional space using a linear layer\n        # v0(x,y) = p(x=u)\n        self.convs = nn.ModuleList(\n            [SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(n_layers)]) # 2D Fast Fourier Transform (FFT) --> v0 = F(v0)\n        self.mlps = nn.ModuleList([MLP2d(self.width, self.width, self.width) for _ in range(n_layers)])\n        self.ws = nn.ModuleList([nn.Conv2d(self.width, self.width, 1) for _ in range(n_layers)]) # Pointwise convolution layers\n        self.norm = nn.InstanceNorm2d(self.width)\n        self.q = MLP2d(self.width, 1, self.width_q)  # output channel is 1: u(x, y)\n\n    def forward(self, x):\n        grid = get_grid_2d(x.shape, x.device)\n        x = torch.cat((x, grid), dim=-1)\n        x = self.p(x)\n        x = x.permute(0, 3, 1, 2)\n        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            '''\n            x1 = self.mlps[i](x1): Local Mixing Using MLP: Since the Fourier convolution captures global dependencies,\n             we still need local interactions --> v_i+1 = sigma(W.vi  +  b), \n             which W and b are learnable parameters, and  is the activation function.\n            '''\n            x2 = self.ws[i](x)\n            '''\n             x2 = self.ws[i](x): applies a pointwise convolution (11 convolution) to the input tensor x.\n                self.ws is a list (nn.ModuleList) of 11 convolutional layers.\n                Each self.ws[i] is a 2D convolution layer (nn.Conv2d) with a kernel size of 1x1.\n                The purpose of these layers is to perform a linear transformation of the feature maps \n                without mixing spatial locations.\n\n            '''\n            x = x1 + x2 #  Merge Global and Local Representations\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n        x = self.q(x)\n        '''\n         Output Projection back to the desired shape using another MLP\n        v_out = Q.v_final(x,y)\n        Q is a learnable projection.\n\n        '''\n        x = x.permute(0, 2, 3, 1)\n        #The final shape of x is (batch,x,y,1), which represents the predicted function value at each spatial location.\n        return x\n\n\nclass TNO2d(FNO2d):\n    def __init__(self, modes1, modes2, width, width_q, width_h, T_in, T_out, n_layers, n_layers_q=2, n_layers_h=4):\n        super(TNO2d, self).__init__(modes1, modes2, width, width_q, T_in, T_out, n_layers)\n        '''\n         TNO2d extends FNO2d. It introduces temporal modeling by adding two MLP layers:\n        self.q  projects the Fourier features to output over time.\n        self.h  handles temporal dependencies between consecutive time steps.\n        New parameters added:\n        width_h  controls temporal memory features.\n        n_layers_q  depth of self.q (output MLP).\n        n_layers_h  depth of self.h (temporal evolution MLP).\n        '''\n        self.width_h = width_h\n        #self.q = MLP2d(self.width, 1, self.width, T_out) # for AC\n        #self.q2 = MLP2d(1, 1, self.width // 4, T_out - 1)\n        #self.q = MLP2d(self.width, 1, 2 * self.width, T_out)  # for CH\n        #self.q2 = MLP2d(1, 1, self.width, T_out - 1)\n        self.q = MLP2d(self.width, 1, self.width_q, T_out, n_layers_q)  # for CHNL\n        self.h = MLP2d(1, 1, self.width_h, T_out - 1, n_layers_h)\n\n    def forward(self, x):\n        grid = get_grid_2d(x.shape, x.device)\n        x = torch.cat((x, grid), dim=-1) # a(x) or= x : Input function (e.g., initial condition for a PDE)\n        x = self.p(x) # \tLifts input to a high-dimensional space\n        x = x.permute(0, 3, 1, 2)\n        # x = F.pad(x, [0, self.padding, 0, self.padding])\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x # x=GELU(FourierConv(x)+MLP(x)+PointwiseConv(x)\n\n        # x = x[..., :-self.padding, :-self.padding]\n        '''\n         Temporal Evolution Loop\n        Initial time step prediction:\n        Uses self.q(x) to generate the first time step.\n        Stores result in X[..., 0]\n        '''\n        X = torch.zeros(*grid.shape[:-1], self.T_out, device=x.device)\n        xt = self.q(x)\n        X[..., 0] = xt.permute(0, 2, 3, 1).squeeze(-1)\n\n        for t in range(1, self.T_out):\n            x1 = self.q(x, t) # Predicts the next step using Fourier features.  # Q_n(W_L+ K_L )...P(a(x)), Projects final Fourier features to outpu\n            x2 = self.h(xt, t - 1) # Uses previous output (xt) to refine the next state. # H_nG_ (x,t_(n-1) )(a(x)), Models dependency on past states\n            xt = x1 + x2 #  Solution at time t_n : x_t = G_ (x,t_n )(a(x))\n            X[..., t] = xt.permute(0, 2, 3, 1).squeeze(-1)\n            '''\n             Uses previous output (xt) to refine the next state.\n            Combines both predictions --> x_t=MLP_q(x)+MLP_h[(x t1)]\n            Stores result in X[..., t]\n            '''\n        return X\n\n\nclass FNO3d(nn.Module):\n    def __init__(self, modes1, modes2, modes3, width, width_q, T_in, T_out, n_layers, n_layers_q=2, n_layers_h=2):\n        super(FNO3d, self).__init__()\n\n        \"\"\"\n        The FNO3d class is a deep learning model designed for solving spatiotemporal problems. \n        The overall network. It contains 4 layers of the Fourier layer.\n        1. Lift the input to the desire channel dimension by self.fc0 .\n        2. 4 layers of the integral operators u' = (W + K)(u).\n            W defined by self.w; K defined by self.conv .\n        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n\n        input: the solution of the first 10 time_steps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n        input shape: (batchsize, x=64, y=64, t=40, c=13)\n        output: the solution of the next 40 time_steps\n        output shape: (batchsize, x=64, y=64, t=40, c=1)\n        \"\"\"\n\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.modes3 = modes3\n        self.width = width\n        self.width_q = width_q\n        self.T_in = T_in\n        self.T_out = T_out\n        self.padding = 6  # pad the domain if input is non-periodic\n        self.n_layers = n_layers\n\n        self.p = nn.Linear(self.T_in + 3, self.width)  # Lifting Layer: input channel is 12: the solution of the first 10 time_steps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n\n        self.convs = nn.ModuleList(\n            [SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3) for _ in range(n_layers)])\n        self.mlps = nn.ModuleList([MLP3d(self.width, self.width, self.width) for _ in range(n_layers)])\n        self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 1) for _ in range(n_layers)])\n        #self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 3, padding=1) for _ in range(n_layers)])  ## kernel changed\n        #self.q = MLP3d(self.width, 1, self.width)  # output channel is 1: u(x, y)\n        self.q = MLP3d(self.width, 1, self.width_q)  # output channel is 1: u(x, y)\n\n    def forward(self, x):\n        #x = x.unsqueeze(3).repeat([1, 1, 1, self.T_out, 1])\n        grid = get_grid_3d(x.shape, x.device)\n        #print(' x shape:', x.shape)\n        x = torch.cat((x, grid), dim=-1)\n        #print(' x shape after cat:', x.shape)\n        x = self.p(x)\n        x = x.permute(0, 4, 1, 2, 3)\n        #x = F.pad(x, [0, self.padding])  # pad the domain if input is non-periodic\n        #print(' x shape after permute:', x.shape)\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        #x = x[..., :-self.padding]\n        x = self.q(x)\n        #x = x.permute(0, 2, 3, 4, 1)[..., 0]  # pad the domain if input is non-periodic\n        x = x.permute(0, 2, 3, 4, 1)\n        #print('FNO3d return x shape:', x.shape)\n        return x\n\n\nclass TNO3d(FNO3d):\n    def __init__(self, modes1, modes2, modes3, width, width_q, width_h, T_in, T_out, n_layers):\n        super(TNO3d, self).__init__(modes1, modes2, modes3, width, width_q, T_in, T_out, n_layers)\n        \"\"\"\n        The super() function calls the parent class (FNO3d) constructor to initialize \n        the parameters that are inherited from the parent class.\n        input: the initial condition and locations (a(x, y, z), x, y, z)\n        input shape: (batchsize, x=s, y=s, z=s, c=4)\n        output: the solution \n        output shape: (batchsize, x=s, y=s, z=s, t=T)\n        \"\"\"\n        self.width_h = width_h\n\n        #self.q = MLP3d(self.width, 1, self.width, T_out)\n        #self.q2 = MLP3d(1, 1, self.width // 4, T_out - 1)\n        self.q = MLP3d(self.width, 1, self.width_q, T_out)\n        self.h = MLP3d(1, 1, self.width_h, T_out - 1)\n\n    def forward(self, x):\n        grid = get_grid_3d(x.shape, x.device)\n        #print('x shape: ',x.shape)\n        #print('grid shape: ', grid.shape)\n        x = torch.cat((x, grid), dim=-1)\n        x = self.p(x)\n        x = x.permute(0, 4, 1, 2, 3)\n        # x = F.pad(x, [0, self.padding, 0, self.padding])\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        # x = x[..., :-self.padding, :-self.padding]\n        X = torch.zeros(*grid.shape[:-1], self.T_out, device=x.device)\n        xt = self.q(x)\n        X[..., 0] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)\n        for t in range(1, self.T_out):\n            x1 = self.q(x, t)\n            x2 = self.h(xt, t - 1)\n            xt = x1 + x2\n            X[..., t] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)\n\n        #print('shape X for model TNO: ', X.shape)\n        return X\n\n\ndef compute_spatial_derivatives(field, coordinates):\n    \"\"\"\n    Computes first and second spatial derivatives of a field with respect to coordinates\n\n    Args:\n        field: Tensor of shape [batch, x, y, z]\n        coordinates: Tensor of shape [batch, x, y, z, 3] (must require grad)\n\n    Returns:\n        laplacian: Tensor of shape [batch, x, y, z] containing \n    \"\"\"\n    # Ensure we can compute gradients\n    field = field.clone().requires_grad_(True)\n    coordinates = coordinates.clone().requires_grad_(True)\n\n    # Compute first derivatives\n    grad_outputs = torch.ones_like(field)\n    grad_x, grad_y, grad_z = torch.autograd.grad(\n        outputs=field,\n        inputs=coordinates,\n        grad_outputs=grad_outputs,\n        create_graph=True,\n        retain_graph=True,\n        allow_unused=False\n    )[0].unbind(dim=-1)\n\n    # Compute second derivatives\n    laplacian = 0.0\n    for grad in [grad_x, grad_y, grad_z]:\n        grad_outputs = torch.ones_like(grad)\n        d2phi = torch.autograd.grad(\n            outputs=grad,\n            inputs=coordinates,\n            grad_outputs=grad_outputs,\n            create_graph=True,\n            retain_graph=True,\n            allow_unused=False\n        )[0].unbind(dim=-1)[0]  # Take derivative along same axis\n        laplacian += d2phi\n\n    return laplacian\ndef compute_allen_cahn_loss(predictions, coordinates, epsilon=0.05, delta_t=0.01):\n    \"\"\"\n    Robust physics loss calculation for Allen-Cahn equation\n\n    Args:\n        predictions: Model outputs [batch, x, y, z, time]\n        coordinates: Spatial coordinates [batch, x, y, z, 3]\n        epsilon: Interface width parameter\n        delta_t: Time step size\n\n    Returns:\n        pde_loss: PDE residual loss\n        bc_loss: Boundary condition loss\n    \"\"\"\n    batch_size = predictions.shape[0]\n    pde_loss = 0.0\n    bc_loss = 0.0\n\n    # Compute for each time step\n    for t in range(predictions.shape[-1]):\n        phi_t = predictions[..., t]\n\n        # Compute Laplacian\n        laplacian = compute_spatial_derivatives(phi_t, coordinates)\n\n        # Compute time derivative (finite difference)\n        if t == 0:\n            dt = (predictions[..., t + 1] - predictions[..., t]) / delta_t\n        elif t == predictions.shape[-1] - 1:\n            dt = (predictions[..., t] - predictions[..., t - 1]) / delta_t\n        else:\n            dt = (predictions[..., t + 1] - predictions[..., t - 1]) / (2 * delta_t)\n\n        # Allen-Cahn residual\n        residual = dt - (laplacian - (1 / epsilon ** 2) * (phi_t ** 3 - phi_t))\n        pde_loss += torch.mean(residual ** 2)\n\n        # Periodic boundary conditions\n        bc_loss += torch.mean((phi_t[..., 0, :, :] - phi_t[..., -1, :, :]) ** 2)\n        bc_loss += torch.mean((phi_t[..., :, 0, :] - phi_t[..., :, -1, :]) ** 2)\n        bc_loss += torch.mean((phi_t[..., :, :, 0] - phi_t[..., :, :, -1]) ** 2)\n\n    return pde_loss / predictions.shape[-1], bc_loss / (3 * predictions.shape[-1])
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/networks.py b/networks.py
++--- a/networks.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/networks.py	(date 1754055606877)
++@@ -410,8 +410,9 @@
++         xt = self.q(x)
++         X[..., 0] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)
++         for t in range(1, self.T_out):
++-            x1 = self.q(x, t)
++-            x2 = self.h(xt, t - 1)
+++            #  two special MLPs (self.q and self.h) to generate the forecast step-by-step.
+++            x1 = self.q(x, t) # A new prediction based on the original initial state.
+++            x2 = self.h(xt, t - 1) #  A "correction" or "update" based on the prediction from the previous step (Time=1).
++             xt = x1 + x2
++             X[..., t] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)
++ 
++@@ -419,87 +420,150 @@
++         return X
++ 
++ 
++-def compute_spatial_derivatives(field, coordinates):
++-    """
++-    Computes first and second spatial derivatives of a field with respect to coordinates
+++###############
+++###############
+++
+++
+++# Add to networks.py
+++''''
+++def get_grid_4d(shape, device):
+++    batchsize, size_x, size_y, size_z, size_t = shape[0], shape[1], shape[2], shape[3], shape[4]
+++    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
+++    gridx = gridx.reshape(1, size_x, 1, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, size_t, 1])
+++    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
+++    gridy = gridy.reshape(1, 1, size_y, 1, 1, 1).repeat([batchsize, size_x, 1, size_z, size_t, 1])
+++    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
+++    gridz = gridz.reshape(1, 1, 1, size_z, 1, 1).repeat([batchsize, size_x, size_y, 1, size_t, 1])
+++    gridt = torch.tensor(np.linspace(0, 1, size_t), dtype=torch.float)
+++    gridt = gridt.reshape(1, 1, 1, 1, size_t, 1).repeat([batchsize, size_x, size_y, size_z, 1, 1])
+++    return torch.cat((gridx, gridy, gridz, gridt), dim=-1).to(device)
+++'''
+++
+++def get_grid_4d(shape, device):
+++    batchsize, size_x, size_y, size_z, _ = shape  # Note: last dim is channels, not time
+++    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
+++    gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])
+++    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
+++    gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])
+++    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
+++    gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])
+++    return torch.cat((gridx, gridy, gridz), dim=-1).to(device)  # Returns (batch, x, y, z, 3)
+++
+++
+++def compl_mul4d(inp, weights):
+++    # (batch, in_channel, x,y,z,t), (in_channel, out_channel, x,y,z,t) -> (batch, out_channel, x,y,z,t)
+++    return torch.einsum("bixyzt,ioxyzt->boxyzt", inp, weights)
+++
+++
+++class SpectralConv4d(nn.Module):
+++    def __init__(self, in_channels, out_channels, modes1, modes2, modes3, modes4):
+++        super(SpectralConv4d, self).__init__()
++ 
++-    Args:
++-        field: Tensor of shape [batch, x, y, z]
++-        coordinates: Tensor of shape [batch, x, y, z, 3] (must require grad)
+++        self.in_channels = in_channels
+++        self.out_channels = out_channels
+++        self.modes1 = modes1  # Number of Fourier modes to multiply
+++        self.modes2 = modes2
+++        self.modes3 = modes3
+++        self.modes4 = modes4
++ 
++-    Returns:
++-        laplacian: Tensor of shape [batch, x, y, z] containing 
++-    """
++-    # Ensure we can compute gradients
++-    field = field.clone().requires_grad_(True)
++-    coordinates = coordinates.clone().requires_grad_(True)
+++        self.scale = (1 / (in_channels * out_channels))
+++        # We'll use 8 weights for 4D (similar to how 3D uses 4 weights)
+++        self.weights1 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights2 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights3 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights4 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights5 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights6 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights7 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
+++        self.weights8 = nn.Parameter(
+++            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, self.modes4,
+++                                    dtype=torch.cfloat))
++ 
++-    # Compute first derivatives
++-    grad_outputs = torch.ones_like(field)
++-    grad_x, grad_y, grad_z = torch.autograd.grad(
++-        outputs=field,
++-        inputs=coordinates,
++-        grad_outputs=grad_outputs,
++-        create_graph=True,
++-        retain_graph=True,
++-        allow_unused=False
++-    )[0].unbind(dim=-1)
+++    def forward(self, x):
+++        batchsize = x.shape[0]
+++        # Compute Fourier coefficients
+++        x_ft = torch.fft.rfftn(x, dim=[-4, -3, -2, -1])  # FFT over spatial and time dimensions
++ 
++-    # Compute second derivatives
++-    laplacian = 0.0
++-    for grad in [grad_x, grad_y, grad_z]:
++-        grad_outputs = torch.ones_like(grad)
++-        d2phi = torch.autograd.grad(
++-            outputs=grad,
++-            inputs=coordinates,
++-            grad_outputs=grad_outputs,
++-            create_graph=True,
++-            retain_graph=True,
++-            allow_unused=False
++-        )[0].unbind(dim=-1)[0]  # Take derivative along same axis
++-        laplacian += d2phi
+++        # Multiply relevant Fourier modes
+++        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-4), x.size(-3), x.size(-2), x.size(-1) // 2 + 1,
+++                             dtype=torch.cfloat, device=x.device)
++ 
++-    return laplacian
++-def compute_allen_cahn_loss(predictions, coordinates, epsilon=0.05, delta_t=0.01):
++-    """
++-    Robust physics loss calculation for Allen-Cahn equation
+++        # Handle all combinations of modes
+++        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3, :self.modes4], self.weights1)
+++        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3, :self.modes4], self.weights2)
+++        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3, :self.modes4], self.weights3)
+++        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3, :self.modes4], self.weights4)
+++        out_ft[:, :, :self.modes1, :self.modes2, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, :self.modes2, -self.modes3:, :self.modes4], self.weights5)
+++        out_ft[:, :, -self.modes1:, :self.modes2, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, :self.modes2, -self.modes3:, :self.modes4], self.weights6)
+++        out_ft[:, :, :self.modes1, -self.modes2:, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, :self.modes1, -self.modes2:, -self.modes3:, :self.modes4], self.weights7)
+++        out_ft[:, :, -self.modes1:, -self.modes2:, -self.modes3:, :self.modes4] = \
+++            compl_mul4d(x_ft[:, :, -self.modes1:, -self.modes2:, -self.modes3:, :self.modes4], self.weights8)
++ 
++-    Args:
++-        predictions: Model outputs [batch, x, y, z, time]
++-        coordinates: Spatial coordinates [batch, x, y, z, 3]
++-        epsilon: Interface width parameter
++-        delta_t: Time step size
+++        # Return to physical space
+++        x = torch.fft.irfftn(out_ft, s=(x.size(-4), x.size(-3), x.size(-2), x.size(-1)))
+++        return x
++ 
++-    Returns:
++-        pde_loss: PDE residual loss
++-        bc_loss: Boundary condition loss
++-    """
++-    batch_size = predictions.shape[0]
++-    pde_loss = 0.0
++-    bc_loss = 0.0
++ 
++-    # Compute for each time step
++-    for t in range(predictions.shape[-1]):
++-        phi_t = predictions[..., t]
+++class FNO4d(nn.Module):
+++    def __init__(self, modes1, modes2, modes3, modes4_internal, width, width_q, T_in_channels, n_layers):
+++        super(FNO4d, self).__init__()
++ 
++-        # Compute Laplacian
++-        laplacian = compute_spatial_derivatives(phi_t, coordinates)
+++        self.modes1 = modes1
+++        self.modes2 = modes2
+++        self.modes3 = modes3
+++        self.modes4 = modes4_internal
+++        self.width = width
+++        self.width_q = width_q
+++        self.T_in = T_in_channels
+++        self.n_layers = n_layers
+++        self.padding = 6
++ 
++-        # Compute time derivative (finite difference)
++-        if t == 0:
++-            dt = (predictions[..., t + 1] - predictions[..., t]) / delta_t
++-        elif t == predictions.shape[-1] - 1:
++-            dt = (predictions[..., t] - predictions[..., t - 1]) / delta_t
++-        else:
++-            dt = (predictions[..., t + 1] - predictions[..., t - 1]) / (2 * delta_t)
+++        # Input is (x,y,z) + time channels (t_in_channels) + 3 spatial coordinates
+++        self.p = nn.Linear(self.T_in + 3, self.width)  # +3 for (x,y,z) coordinates
++ 
++-        # Allen-Cahn residual
++-        residual = dt - (laplacian - (1 / epsilon ** 2) * (phi_t ** 3 - phi_t))
++-        pde_loss += torch.mean(residual ** 2)
+++        self.convs = nn.ModuleList([
+++            SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)
+++            for _ in range(n_layers)
+++        ])
+++        self.mlps = nn.ModuleList([MLP3d(self.width, self.width, self.width) for _ in range(n_layers)])
+++        self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 1) for _ in range(n_layers)])
+++        self.q = MLP3d(self.width, 1, self.width_q)  # Output channel is 1
++ 
++-        # Periodic boundary conditions
++-        bc_loss += torch.mean((phi_t[..., 0, :, :] - phi_t[..., -1, :, :]) ** 2)
++-        bc_loss += torch.mean((phi_t[..., :, 0, :] - phi_t[..., :, -1, :]) ** 2)
++-        bc_loss += torch.mean((phi_t[..., :, :, 0] - phi_t[..., :, :, -1]) ** 2)
+++    def forward(self, x):
+++        # Input shape: (batch, x, y, z, t_in_channels)
+++        grid = get_grid_4d(x.shape, x.device)
+++        x = torch.cat((x, grid), dim=-1)  # This is the key step where "time" is handled.  Now both are 5D: (batch, x, y, z, t_in_channels + 3)
+++        x = self.p(x)  # Lift to higher dimension
+++        x = x.permute(0, 4, 1, 2, 3)  # (batch, channels, x, y, z)
++ 
++-    return pde_loss / predictions.shape[-1], bc_loss / (3 * predictions.shape[-1])
++\ No newline at end of file
+++        for i in range(self.n_layers):
+++            x1 = self.convs[i](x)
+++            x1 = self.mlps[i](x1)
+++            x2 = self.ws[i](x)
+++            x = x1 + x2
+++            x = F.gelu(x) if i < self.n_layers - 1 else x
+++
+++        x = self.q(x)
+++        x = x.permute(0, 2, 3, 4, 1)  # (batch, x, y, z, 1)
+++        return x
++\ No newline at end of file
++Index: MatlabCode/Out_Distribution/SH3D_Spherical_Comparison.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/Out_Distribution/SH3D_Spherical_Comparison.m b/MatlabCode/Out_Distribution/SH3D_Spherical_Comparison.m
++new file mode 100644
++--- /dev/null	(date 1754317238473)
+++++ b/MatlabCode/Out_Distribution/SH3D_Spherical_Comparison.m	(date 1754317238473)
++@@ -0,0 +1,222 @@
+++clc; 
+++clear; 
+++close all; 
+++fclose('all');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 1: LOAD PYTHON (TNO) MODEL RESULTS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Loading Python (TNO) model predictions...');
+++
+++% --- MODIFIED SECTION ---
+++% Define the path and load the Python data file
+++python_data_file = '/scratch/noqu8762/phase_field_equations_4d/SH3D_python_predictions_sphere.mat';
+++try
+++    python_data = load(python_data_file);
+++    
+++    % Extract inference time from the loaded data, with a fallback default
+++    if isfield(python_data, 'inference_time')
+++        python_inference_time = python_data.inference_time;
+++    else
+++        disp('Warning: "inference_time" not found in .mat file. Using a default value.');
+++        python_inference_time = 0.045; % (seconds) - fallback value
+++    end
+++    
+++catch ME
+++    error('Could not load Python prediction file: %s. Error: %s', python_data_file, ME.message);
+++end
+++% --- END OF MODIFIED SECTION ---
+++
+++python_pred = squeeze(python_data.python_pred); % Remove batch dimension
+++selected_frames = python_data.selected_frames;
+++num_selected = length(selected_frames);
+++
+++% Spatial Parameters (must be consistent across both models)
+++Nx = 32; Lx = 15;
+++Ny = Nx; Ly = Lx;
+++Nz = Nx; Lz = Lx;
+++x = linspace(-Lx/2, Lx/2, Nx);
+++y = linspace(-Ly/2, Ly/2, Ny);
+++z = linspace(-Lz/2, Lz/2, Nz);
+++[xx, yy, zz] = ndgrid(x, y, z);
+++
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 2: RUN MATLAB (DNS) EXACT SOLUTION
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Starting MATLAB (DNS) simulation...');
+++tic; % Start the timer for the MATLAB simulation
+++
+++% --- PDE Parameters ---
+++epsilon = 0.15;
+++dt = 0.05;
+++Nt = 100;
+++num_saved_steps = 101;
+++ns = Nt/(num_saved_steps-1);
+++
+++% --- Create SMOOTH Spherical Initial Condition using tanh ---
+++% This is the key correction. Instead of a sharp step function, we
+++% create a smooth transition from +1 to -1.
+++radius = 2;
+++transition_width = 0.5; % Controls the smoothness of the boundary
+++r = sqrt(xx.^2 + yy.^2 + zz.^2);
+++u = tanh((radius - r) / transition_width);
+++
+++% --- Pre-calculate spectral terms (they don't change in the loop) ---
+++kx = 2*pi/Lx * [0:Nx/2, -Nx/2+1:-1];
+++ky = 2*pi/Ly * [0:Ny/2, -Ny/2+1:-1];
+++kz = 2*pi/Lz * [0:Nz/2, -Nz/2+1:-1];
+++[kxx,kyy,kzz] = ndgrid(kx.^2, ky.^2, kz.^2);
+++
+++% --- Initialize Storage for DNS results ---
+++all_iterations_dns = zeros(num_saved_steps, Nx, Ny, Nz, 'single');
+++
+++% --- Main Simulation Loop (Corrected Logic) ---
+++% First, store the true initial condition (t=0)
+++all_iterations_dns(1, :, :, :) = u;
+++
+++% Now, loop through time to compute and store subsequent frames
+++for iter = 1:Nt
+++    % Advance the solution by one time step
+++    u = real(u);
+++    s_hat = fftn(u/dt) - fftn(u.^3) + 2*(kxx + kyy + kzz).*fftn(u);
+++    v_hat = s_hat ./ (1.0/dt + (1-epsilon) + (kxx + kyy + kzz).^2);
+++    u = ifftn(v_hat);
+++
+++    % --- ADDED LINE: Cap values of u greater than +1 to be +1 ---
+++    %u(u > 1) = 1;
+++
+++    % Store the result in the correct slot. The array index is iter+1.
+++    all_iterations_dns(iter + 1, :, :, :) = u;
+++end
+++
+++
+++matlab_simulation_time = toc; % Stop the timer
+++disp(['MATLAB (DNS) simulation complete. Elapsed time: ', num2str(matlab_simulation_time), ' s']);
+++
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 3: COMBINED VISUALIZATION (MODIFIED TO MATCH CODE 1 STYLE)
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Generating comparison plots...');
+++fig_width = 450 * num_selected;
+++fig_height = 900; 
+++fig = figure('Position', [100 100 fig_width fig_height]);
+++
+++sgtitle(sprintf('SH3D MHNO (Sphere)\nPrediction Time: %.2f s  vs.  Ground Truth Time: %.2f s', ...
+++                python_inference_time, matlab_simulation_time), ...
+++                'FontSize', 20, 'FontWeight', 'bold');
+++
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    
+++    % --- Plot Python TNO results (TOP ROW) ---
+++    ax1 = subplot(3, num_selected, i); 
+++    frame_idx_py = frame_to_plot + 1; % Python index is direct
+++    u_python = python_pred(:,:,:,frame_idx_py);
+++    [f, v] = isosurface(xx, yy, zz, u_python, 0);
+++    if ~isempty(v)
+++        patch(ax1, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax1, 'gouraud'); light(ax1, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax1, 'dull'); colormap(ax1, jet); view(45, 30); axis(ax1, 'tight', 'equal');
+++        title(ax1, sprintf('Prediction\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax1, sprintf('Prediction\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax1, 'tight', 'equal');
+++    end
+++    set(ax1, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax1, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax1, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax1, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++
+++    % --- Plot MATLAB DNS results (MIDDLE ROW) ---
+++    ax2 = subplot(3, num_selected, num_selected + i);
+++    % ** ADAPTATION: Convert frame number to the saved index for the DNS array **
+++    frame_idx_dns = min(max(round(frame_to_plot / ns + 1), 1), num_saved_steps);
+++    u_matlab = squeeze(all_iterations_dns(frame_idx_dns,:,:,:));
+++    [f, v] = isosurface(xx, yy, zz, u_matlab, 0);
+++    if ~isempty(v)
+++        patch(ax2, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax2, 'gouraud'); light(ax2, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax2, 'dull'); colormap(ax2, jet); view(45, 30); axis(ax2, 'tight', 'equal');
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax2, 'tight', 'equal');
+++    end
+++    set(ax2, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax2, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax2, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax2, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++end
+++
+++% === PROFESSIONAL 1D PROFILE PLOT WS ORGANIZED LEGEND (FROM CODE 1) ===
+++
+++% Get the centerline indices
+++center_idx = round(Ny/2);
+++
+++% Define position for the combined 1D plot
+++ax_profile_pos = [0.1, 0.08, 0.85, 0.22]; 
+++ax_profile = axes('Position', ax_profile_pos);
+++
+++hold(ax_profile, 'on');
+++grid(ax_profile, 'on');
+++box(ax_profile, 'on'); 
+++
+++% Define line styles and colors
+++line_styles = {'-', '--'}; % Solid for Ground Truth, Dashed for Prediction
+++line_width = 2.5;
+++colors = get(ax_profile, 'ColorOrder');
+++
+++% Loop through selected time steps to plot the ACTUAL data
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++
+++    % Plot Ground Truth (DNS) Profile
+++    % ** ADAPTATION: Use correct DNS frame index and 'x' variable **
+++    frame_idx_dns = min(max(round(frame_to_plot / ns + 1), 1), num_saved_steps);
+++    profile_dns = squeeze(all_iterations_dns(frame_idx_dns, :, center_idx, center_idx));
+++    plot(ax_profile, x, profile_dns, ...
+++        'LineStyle', line_styles{1}, 'Color', current_color, 'LineWidth', line_width);
+++        
+++    % Plot Prediction (SANO) Profile
+++    % ** ADAPTATION: Use correct Python frame index and 'x' variable **
+++    frame_idx_py = frame_to_plot + 1;
+++    profile_py = squeeze(python_pred(:, center_idx, center_idx, frame_idx_py));
+++    plot(ax_profile, x, profile_py, ...
+++        'LineStyle', line_styles{2}, 'Color', current_color, 'LineWidth', line_width);
+++end
+++
+++% --- Create Proxy Artists for a Clean, Organized Legend ---
+++h_proxy = gobjects(2 + num_selected, 1); % Pre-allocate graphics object array
+++h_proxy(1) = plot(NaN, NaN, 'LineStyle', line_styles{1}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Ground Truth');
+++h_proxy(2) = plot(NaN, NaN, 'LineStyle', line_styles{2}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Prediction');
+++for i = 1:num_selected
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++    h_proxy(2+i) = plot(NaN, NaN, 'LineStyle', '-', 'Color', current_color, 'LineWidth', line_width, 'DisplayName', sprintf('t = %d', selected_frames(i)));
+++end
+++hold(ax_profile, 'off');
+++
+++% --- Professional Formatting for the 1D Plot ---
+++title(ax_profile, '1D Centerline Profile Comparison', 'FontSize', 18, 'FontWeight', 'bold');
+++xlabel(ax_profile, 'Position along x-axis', 'FontSize', 16, 'FontWeight', 'bold');
+++ylabel(ax_profile, 'Field Value u', 'FontSize', 16, 'FontWeight', 'bold');
+++ylim(ax_profile, [-1.1, 1.5]); % Adjusted Y-Limit to better fit the data
+++xlim(ax_profile, [x(1), x(end)]);
+++set(ax_profile, 'FontSize', 16, 'FontWeight', 'bold', 'LineWidth', 1.5);
+++lgd = legend(h_proxy, 'Location', 'northeast', 'NumColumns', 1);
+++set(lgd, 'FontSize', 14, 'FontWeight', 'bold', 'Box', 'on');
+++
+++disp('Comparison visualization complete.');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 4: SAVE THE FIGURE
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Saving the figure...');
+++% ** ADAPTATION: Using the original filename from Code 2 **
+++filename = 'SH3D_Comparison_Plot_Modified.png'; 
+++print(fig, filename, '-dpng', '-r300');
+++disp(['Figure saved as ', filename]);
++\ No newline at end of file
++Index: MatlabCode/Out_Distribution/AC3D_Spherical_Comparison.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/Out_Distribution/AC3D_Spherical_Comparison.m b/MatlabCode/Out_Distribution/AC3D_Spherical_Comparison.m
++new file mode 100644
++--- /dev/null	(date 1754317804344)
+++++ b/MatlabCode/Out_Distribution/AC3D_Spherical_Comparison.m	(date 1754317804344)
++@@ -0,0 +1,276 @@
+++clc;
+++clear;
+++close all;
+++fclose('all');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 1: CHOOSE IC & SETUP PARAMETERS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++
+++% --- CHOOSE THE INITIAL CONDITION ---
+++initial_condition_type = 'sphere'; % Options: 'sphere', 'dumbbell', 'star', 'heart'
+++
+++fprintf('Setting up comparison for Initial Condition: %s\n', upper(initial_condition_type));
+++
+++% --- Declare variables ---
+++python_data_file = '';
+++Nx=0; Ny=0; Nz=0; Lx=0; Ly=0; Lz=0;
+++epsilon = 0; Nt = 0; selected_frames = [];
+++u = [];
+++
+++% --- Setup based on selected initial condition ---
+++switch initial_condition_type
+++    case 'sphere'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/AC3D_python_predictions_sphere.mat';
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 5;  Ly = 5;  Lz = 5;
+++        epsilon = 0.15;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        radius = 0.5;
+++        interface_width = sqrt(2) * epsilon;
+++        u = tanh((radius - sqrt(xx.^2 + yy.^2 + zz.^2)) / interface_width);
+++
+++    case 'dumbbell'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/AC3D_python_predictions_dumbbell.mat';
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 2.0; Ly = 1.0; Lz = 1.0;
+++        epsilon = 0.05;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        x_grid = linspace(0, Lx, Nx);
+++        y_grid = linspace(0, Ly, Ny);
+++        z_grid = linspace(0, Lz, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        R0 = 0.25;
+++        interface_width = sqrt(2) * epsilon;
+++        r1 = sqrt((xx - 0.3).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        r2 = sqrt((xx - 1.7).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        u_spheres = tanh((R0 - r1) / interface_width) + tanh((R0 - r2) / interface_width) + 1;
+++        bar_mask = (xx > 0.4 & xx < 1.6 & yy > 0.4 & yy < 0.6 & zz > 0.4 & zz < 0.6);
+++        u = u_spheres;
+++        u(bar_mask) = 1.0;
+++        u = max(-1.0, min(1.0, u));
+++
+++    case 'star'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/AC3D_python_predictions_star.mat';
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 5.0; Ly = 5.0; Lz = 5.0;
+++        epsilon = 0.05;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        interface_width = sqrt(2.0) * epsilon;
+++        theta = atan2(zz, xx);
+++        R_theta = 0.7 + 0.2 * cos(6 * theta);
+++        dist = sqrt(xx.^2 + 2*yy.^2 + zz.^2);
+++        u = tanh((R_theta - dist) / interface_width);
+++
+++    case 'heart'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/AC3D_python_predictions_heart.mat';
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 3.0; Ly = 3.0; Lz = 3.0;
+++        epsilon = 0.05;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        % Equation from image: phi(x,y,z,0) = tanh( ( (x^2 + 9/4*y^2 + z^2 - 1)^3 - x^2*z^3 - 9/80*y^2*z^3 ) / sqrt(2*epsilon) )
+++        interface_term = sqrt(2*epsilon);
+++        numerator = (xx.^2 + (9/4)*yy.^2 + zz.^2 - 1).^3 - xx.^2.*zz.^3 - (9/80)*yy.^2.*zz.^3;
+++        u = tanh(numerator ./ interface_term);
+++
+++    otherwise
+++        error("Unknown initial_condition_type. Choose 'sphere', 'dumbbell', 'star', or 'heart'.");
+++end
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 2: LOAD PYTHON MODEL RESULTS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp(['Loading Python predictions from: ', python_data_file]);
+++try
+++    python_data = load(python_data_file);
+++    python_pred = squeeze(python_data.python_pred);
+++    [py_Nx, py_Ny, py_Nz, ~] = size(python_pred);
+++    if py_Nx ~= Nx || py_Ny ~= Ny || py_Nz ~= Nz
+++        error('Dimension Mismatch! Loaded Python data is [%d x %d x %d] but MATLAB grid is [%d x %d x %d].', ...
+++              py_Nx, py_Ny, py_Nz, Nx, Ny, Nz);
+++    end
+++    num_selected = length(selected_frames);
+++    if isfield(python_data, 'inference_time')
+++        python_inference_time = python_data.inference_time;
+++    else
+++        python_inference_time = 0.045;
+++    end
+++catch ME
+++    error('Could not load Python prediction file: %s. Error: %s', python_data_file, ME.message);
+++end
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 3: RUN MATLAB (DNS) EXACT SOLUTION FOR AC3D
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Starting MATLAB (DNS) simulation for AC3D...');
+++tic;
+++epsilon1 = 0.1;
+++Cahn = epsilon1^2;
+++dt = 0.0005;
+++
+++kx = 2*pi/Lx * [0:Nx/2, -Nx/2+1:-1];
+++ky = 2*pi/Ly * [0:Ny/2, -Ny/2+1:-1];
+++kz = 2*pi/Lz * [0:Nz/2, -Nz/2+1:-1];
+++[kxx, kyy, kzz] = ndgrid(kx.^2, ky.^2, kz.^2);
+++K2_laplace = kxx + kyy + kzz;
+++
+++all_iterations_dns = zeros(Nt + 1, Nx, Ny, Nz, 'single');
+++all_iterations_dns(1, :, :, :) = u;
+++
+++for iter = 1:Nt
+++    u = real(u);
+++    nonlinear_term_hat = fftn(u.^3 - u);
+++    u_hat = fftn(u);
+++    v_hat = (u_hat - (dt/Cahn) * nonlinear_term_hat) ./ (1 + dt * K2_laplace);
+++    u = real(ifftn(v_hat));
+++    all_iterations_dns(iter + 1, :, :, :) = u;
+++end
+++
+++matlab_simulation_time = toc;
+++disp(['MATLAB (DNS) simulation complete. Elapsed time: ', num2str(matlab_simulation_time), ' s']);
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 4: COMBINED VISUALIZATION (MODIFIED VERSION)
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Generating comparison plots...');
+++fig_width = 450 * num_selected;
+++fig_height = 900; 
+++fig = figure('Position', [100 100 fig_width fig_height]);
+++
+++sgtitle(sprintf('AC3D MHNO (%s)\nPrediction Time: %.2f s  vs.  Ground Truth Time: %.2f s', ...
+++                upper(initial_condition_type), python_inference_time, matlab_simulation_time), ...
+++                'FontSize', 20, 'FontWeight', 'bold');
+++
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    frame_idx = frame_to_plot + 1;
+++    
+++    % Python prediction isosurfaces (Top Row)
+++    ax1 = subplot(3, num_selected, i); 
+++    u_python = python_pred(:,:,:,frame_idx);
+++    [f, v] = isosurface(xx, yy, zz, u_python, 0);
+++    if ~isempty(v)
+++        patch(ax1, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax1, 'gouraud'); light(ax1, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax1, 'dull'); colormap(ax1, jet); view(45, 30); axis(ax1, 'tight', 'equal');
+++        title(ax1, sprintf('Prediction\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax1, sprintf('Prediction\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax1, 'tight', 'equal');
+++    end
+++    set(ax1, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax1, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax1, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax1, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++
+++    % MATLAB DNS isosurfaces (Middle Row)
+++    ax2 = subplot(3, num_selected, num_selected + i);
+++    u_matlab = squeeze(all_iterations_dns(frame_idx,:,:,:));
+++    [f, v] = isosurface(xx, yy, zz, u_matlab, 0);
+++    if ~isempty(v)
+++        patch(ax2, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax2, 'gouraud'); light(ax2, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax2, 'dull'); colormap(ax2, jet); view(45, 30); axis(ax2, 'tight', 'equal');
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax2, 'tight', 'equal');
+++    end
+++    set(ax2, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax2, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax2, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax2, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++end
+++
+++% === NEW PROFESSIONAL 1D PROFILE PLOT WITH ORGANIZED LEGEND (MODIFIED SECTION) ===
+++
+++% Get the centerline indices
+++center_y_idx = round(Ny/2); 
+++center_z_idx = round(Nz/2);
+++
+++% Define position for the combined 1D plot
+++ax_profile_pos = [0.1, 0.08, 0.85, 0.22]; 
+++ax_profile = axes('Position', ax_profile_pos);
+++
+++hold(ax_profile, 'on');
+++grid(ax_profile, 'on');
+++box(ax_profile, 'on'); 
+++
+++% Define line styles and colors
+++line_styles = {'-', '--'}; % Solid for Ground Truth, Dashed for Prediction
+++line_width = 2.5;
+++colors = get(ax_profile, 'ColorOrder');
+++
+++% Loop through selected time steps to plot the ACTUAL data
+++% NOTE: We remove the 'DisplayName' from here, as the legend will be custom-built.
+++for i = 1:num_selected
+++    frame_idx = selected_frames(i) + 1;
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++
+++    % Plot Ground Truth (DNS) Profile
+++    profile_dns = squeeze(all_iterations_dns(frame_idx, :, center_y_idx, center_z_idx));
+++    plot(ax_profile, x_grid, profile_dns, ...
+++        'LineStyle', line_styles{1}, 'Color', current_color, 'LineWidth', line_width);
+++        
+++    % Plot Prediction (SANO) Profile
+++    profile_py = squeeze(python_pred(:, center_y_idx, center_z_idx, frame_idx));
+++    plot(ax_profile, x_grid, profile_py, ...
+++        'LineStyle', line_styles{2}, 'Color', current_color, 'LineWidth', line_width);
+++end
+++
+++% --- Create Proxy Artists for a Clean, Organized Legend ---
+++% We create invisible plots that have the desired properties for our legend entries.
+++h_proxy = gobjects(2 + num_selected, 1); % Pre-allocate graphics object array
+++
+++% Proxy for Line Styles
+++h_proxy(1) = plot(NaN, NaN, 'LineStyle', line_styles{1}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Ground Truth');
+++h_proxy(2) = plot(NaN, NaN, 'LineStyle', line_styles{2}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Prediction');
+++
+++% Proxies for Time (Colors)
+++for i = 1:num_selected
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++    h_proxy(2+i) = plot(NaN, NaN, 'LineStyle', '-', 'Color', current_color, 'LineWidth', line_width, 'DisplayName', sprintf('t = %d', selected_frames(i)));
+++end
+++
+++hold(ax_profile, 'off');
+++
+++% --- Professional Formatting for the 1D Plot ---
+++title(ax_profile, '1D Centerline Profile Comparison', 'FontSize', 18, 'FontWeight', 'bold');
+++xlabel(ax_profile, 'Position along x-axis', 'FontSize', 16, 'FontWeight', 'bold');
+++ylabel(ax_profile, 'Field Value u', 'FontSize', 16, 'FontWeight', 'bold');
+++ylim(ax_profile, [-1.1, 1.1]);
+++xlim(ax_profile, [x_grid(1), x_grid(end)]);
+++set(ax_profile, 'FontSize', 16, 'FontWeight', 'bold', 'LineWidth', 1.5);
+++
+++% Generate the legend using ONLY the proxy artists
+++lgd = legend(h_proxy, 'Location', 'northeast', 'NumColumns', 1); % Single column is cleaner
+++set(lgd, 'FontSize', 14, 'FontWeight', 'bold', 'Box', 'on');
+++
+++disp('Comparison visualization complete.');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 5: SAVE THE FIGURE
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Saving the figure...');
+++filename = ['AC3D_Comparison_' initial_condition_type '.png'];
+++print(fig, filename, '-dpng', '-r300');
+++disp(['Figure saved as ', filename]);
++\ No newline at end of file
++Index: MatlabCode/Out_Distribution/CH3D_Star_Comparison.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/Out_Distribution/CH3D_Star_Comparison.m b/MatlabCode/Out_Distribution/CH3D_Star_Comparison.m
++new file mode 100644
++--- /dev/null	(date 1754318915982)
+++++ b/MatlabCode/Out_Distribution/CH3D_Star_Comparison.m	(date 1754318915982)
++@@ -0,0 +1,302 @@
+++clc;
+++clear;
+++close all;
+++fclose('all');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 1: CHOOSE IC & SETUP PARAMETERS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++
+++% --- CHOOSE THE INITIAL CONDITION ---
+++initial_condition_type = 'star';  % dumbbell, star, sphere, we validated for star for CH3D
+++
+++fprintf('Setting up comparison for CH3D Initial Condition: %s\n', upper(initial_condition_type));
+++
+++% --- Declare variables that will be set in the switch block ---
+++python_data_file = '';
+++Nx=0; Ny=0; Nz=0; Lx=0; Ly=0; Lz=0;
+++epsilon = 0; Nt = 0; selected_frames = [];
+++u = []; % The initial condition for the DNS
+++
+++% --- Setup based on selected initial condition ---
+++switch initial_condition_type
+++
+++    case 'heart'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/CH3D_python_predictions_heart.mat';
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 5.0; Ly = Lx; Lz = Lx;
+++        epsilon = 0.15;
+++        Nt = 100;
+++        selected_frames = [0, 50, 90];
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        % Equation from image: phi(x,y,z,0) = tanh( ( (x^2 + 9/4*y^2 + z^2 - 1)^3 - x^2*z^3 - 9/80*y^2*z^3 ) / sqrt(2*epsilon) )
+++        interface_term = sqrt(2*epsilon);
+++        numerator = (xx.^2 + (9/4)*yy.^2 + zz.^2 - 1).^3 - xx.^2.*zz.^3 - (9/80)*yy.^2.*zz.^3;
+++        u = tanh(numerator ./ interface_term);
+++
+++    case 'sphere'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/CH3D_python_predictions_sphere.mat'; % <-- UPDATE THIS PATH
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 2;  Ly = 2;  Lz = 2;
+++        epsilon = 0.05;
+++        selected_frames = [0, 50, 90];
+++        
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++
+++        radius = 0.5;
+++        interface_width = sqrt(2) * epsilon;
+++        u = tanh((radius - sqrt(xx.^2 + yy.^2 + zz.^2)) / interface_width);
+++
+++    case 'dumbbell'
+++        python_data_file = '/scratch/noqu8762/phase_field_equations_4d/CH3D_python_predictions_dumbbell.mat';
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        Lx = 2.5; Ly = 1.0; Lz = 1.0;
+++        epsilon = 0.05;
+++        selected_frames = [0, 50, 90];
+++
+++        x_grid = linspace(0, Lx, Nx);
+++        y_grid = linspace(0, Ly, Ny);
+++        z_grid = linspace(0, Lz, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        
+++        R0 = 0.25;
+++        interface_width = sqrt(2) * epsilon;
+++        r1 = sqrt((xx - 0.3).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        r2 = sqrt((xx - 1.7).^2 + (yy - 0.5).^2 + (zz - 0.5).^2);
+++        u_spheres = tanh((R0 - r1) / interface_width) + tanh((R0 - r2) / interface_width) + 1;
+++        bar_mask = (xx > 0.4 & xx < 1.6 & yy > 0.4 & yy < 0.6 & zz > 0.4 & zz < 0.6);
+++        u = u_spheres;
+++        u(bar_mask) = 1.0;
+++        u = max(-1.0, min(1.0, u));
+++
+++    case 'star'
+++        python_data_file = '//scratch/noqu8762/phase_field_equations_4d/CH3D_python_predictions_star.mat';
+++        
+++        Nx = 32; Ny = 32; Nz = 32;
+++        % Corrected Lx, Ly, Lz to match the plot's x-axis from -1 to 1
+++        Lx = 2.0; 
+++        Ly = Lx ; Lz = Lx ; 
+++        epsilon = 0.05;
+++        Cahn = epsilon^2;
+++        selected_frames = [0, 50, 90];
+++        
+++        x_grid = linspace(-Lx/2, Lx/2, Nx);
+++        y_grid = linspace(-Ly/2, Ly/2, Ny);
+++        z_grid = linspace(-Lz/2, Lz/2, Nz);
+++        [xx, yy, zz] = ndgrid(x_grid, y_grid, z_grid);
+++        
+++        interface_width = sqrt(2.0) * epsilon;
+++        theta = atan2(zz, xx);
+++        R_theta = 0.7 + 0.2 * cos(6 * theta);
+++        dist = sqrt(xx.^2 + 2*yy.^2 + zz.^2);
+++        u = tanh((R_theta - dist) / interface_width);
+++        
+++    otherwise
+++        error("Unknown initial_condition_type. Choose 'sphere', 'dumbbell', or 'star'.");
+++end
+++
+++% Set total simulation time based on the last frame needed
+++Nt = max(selected_frames);
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 2: LOAD PYTHON MODEL RESULTS
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp(['Loading Python predictions from: ', python_data_file]);
+++try
+++    python_data = load(python_data_file);
+++    python_pred = squeeze(python_data.python_pred);
+++    
+++    [py_Nx, py_Ny, py_Nz, ~] = size(python_pred);
+++    if py_Nx ~= Nx || py_Ny ~= Ny || py_Nz ~= Nz
+++        error('Dimension Mismatch! Loaded Python data is [%d x %d x %d] but MATLAB grid is [%d x %d x %d].', ...
+++              py_Nx, py_Ny, py_Nz, Nx, Ny, Nz);
+++    end
+++    
+++    % % ******** TEMPORARILY DISABLE THE FIX TO SEE RAW DATA ********
+++    % disp('Synchronizing t=0 frame between prediction and ground truth.');
+++    % python_pred(:,:,:,1) = u;
+++    % % ***************************************************************
+++    
+++    num_selected = length(selected_frames);
+++    
+++    if isfield(python_data, 'inference_time')
+++        python_inference_time = python_data.inference_time;
+++    else
+++        python_inference_time = 0.050; 
+++    end
+++    
+++catch ME
+++    error('Could not load Python prediction file: %s. Error: %s', python_data_file, ME.message);
+++end
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 3: RUN MATLAB (DNS) EXACT SOLUTION FOR CH3D
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Starting MATLAB (DNS) simulation for CH3D...');
+++tic; 
+++
+++% --- PDE and Solver Parameters ---
+++
+++dt = 0.0005; % Using the smaller dt from the original code 2
+++
+++% --- Fourier Constants ---
+++kx = 2*pi/Lx * [0:Nx/2, -Nx/2+1:-1];
+++ky = 2*pi/Ly * [0:Ny/2, -Ny/2+1:-1];
+++kz = 2*pi/Lz * [0:Nz/2, -Nz/2+1:-1];
+++[kxx,kyy,kzz] = ndgrid(kx.^2, ky.^2, kz.^2);
+++K2_laplace = kxx + kyy + kzz;
+++
+++% --- Simulation Loop ---
+++all_iterations_dns = zeros(Nt + 1, Nx, Ny, Nz, 'single');
+++all_iterations_dns(1, :, :, :) = u;
+++u_dns = u; % Use a separate variable for the simulation
+++
+++for iter = 1:Nt
+++    u_dns = real(u_dns);
+++    nonlinear_term_hat = fftn(u_dns.^3 - 3*u_dns);
+++    s_hat = fftn(u_dns) - dt * K2_laplace .* nonlinear_term_hat;
+++    v_hat = s_hat ./ (1.0 + dt * (2.0 * K2_laplace + Cahn * K2_laplace.^2));
+++    u_dns = real(ifftn(v_hat));
+++    all_iterations_dns(iter + 1, :, :, :) = u_dns;
+++end
+++
+++matlab_simulation_time = toc;
+++disp(['MATLAB (DNS) simulation complete. Elapsed time: ', num2str(matlab_simulation_time), ' s']);
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 4: COMBINED VISUALIZATION (MODIFIED VERSION)
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Generating comparison plots...');
+++fig_width = 450 * num_selected;
+++fig_height = 900; 
+++fig = figure('Position', [100 100 fig_width fig_height]);
+++
+++sgtitle(sprintf('CH3D: MHNO Method (%s)\nPrediction Time: %.2f s  vs.  Ground Truth Time: %.2f s', ...
+++                upper(initial_condition_type), python_inference_time, matlab_simulation_time), ...
+++                'FontSize', 20, 'FontWeight', 'bold');
+++
+++for i = 1:num_selected
+++    frame_to_plot = selected_frames(i);
+++    frame_idx = frame_to_plot + 1;
+++    
+++    % Python prediction isosurfaces (Top Row)
+++    ax1 = subplot(3, num_selected, i); 
+++    u_python = python_pred(:,:,:,frame_idx);
+++    [f, v] = isosurface(xx, yy, zz, u_python, 0);
+++    if ~isempty(v)
+++        patch(ax1, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax1, 'gouraud'); light(ax1, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax1, 'dull'); colormap(ax1, jet); view(45, 30); axis(ax1, 'tight', 'equal');
+++        title(ax1, sprintf('Prediction\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax1, sprintf('Prediction\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax1, 'tight', 'equal');
+++    end
+++    set(ax1, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax1, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax1, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax1, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++
+++    % MATLAB DNS isosurfaces (Middle Row)
+++    ax2 = subplot(3, num_selected, num_selected + i);
+++    u_matlab = squeeze(all_iterations_dns(frame_idx,:,:,:));
+++    [f, v] = isosurface(xx, yy, zz, u_matlab, 0);
+++    if ~isempty(v)
+++        patch(ax2, 'Faces', f, 'Vertices', v, 'FaceColor', 'interp', 'EdgeColor', 'none', ...
+++              'FaceVertexCData', v(:,3), 'FaceAlpha', 0.8);
+++        lighting(ax2, 'gouraud'); light(ax2, 'Position', [1 1 1], 'Style', 'infinite');
+++        material(ax2, 'dull'); colormap(ax2, jet); view(45, 30); axis(ax2, 'tight', 'equal');
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++    else
+++        title(ax2, sprintf('Ground Truth\nTime Step: %d (Vanished)', frame_to_plot), 'FontSize', 18, 'FontWeight', 'bold');
+++        view(45, 30); axis(ax2, 'tight', 'equal');
+++    end
+++    set(ax2, 'FontSize', 16, 'FontWeight', 'bold');
+++    xlabel(ax2, 'X', 'FontSize', 16, 'FontWeight', 'bold');
+++    ylabel(ax2, 'Y', 'FontSize', 16, 'FontWeight', 'bold');
+++    zlabel(ax2, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++end
+++
+++% === NEW PROFESSIONAL 1D PROFILE PLOT WITH ORGANIZED LEGEND (MODIFIED SECTION) ===
+++
+++% Get the centerline indices
+++center_y_idx = round(Ny/2); 
+++center_z_idx = round(Nz/2);
+++
+++% Define position for the combined 1D plot
+++ax_profile_pos = [0.1, 0.08, 0.85, 0.22]; 
+++ax_profile = axes('Position', ax_profile_pos);
+++
+++hold(ax_profile, 'on');
+++grid(ax_profile, 'on');
+++box(ax_profile, 'on'); 
+++
+++% Define line styles and colors
+++line_styles = {'-', '--'}; % Solid for Ground Truth, Dashed for Prediction
+++line_width = 2.5;
+++colors = get(ax_profile, 'ColorOrder');
+++
+++% Loop through selected time steps to plot the ACTUAL data
+++% NOTE: We remove the 'DisplayName' from here, as the legend will be custom-built.
+++for i = 1:num_selected
+++    frame_idx = selected_frames(i) + 1;
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++
+++    % Plot Ground Truth (DNS) Profile
+++    profile_dns = squeeze(all_iterations_dns(frame_idx, :, center_y_idx, center_z_idx));
+++    plot(ax_profile, x_grid, profile_dns, ...
+++        'LineStyle', line_styles{1}, 'Color', current_color, 'LineWidth', line_width);
+++        
+++    % Plot Prediction (SANO) Profile
+++    profile_py = squeeze(python_pred(:, center_y_idx, center_z_idx, frame_idx));
+++    plot(ax_profile, x_grid, profile_py, ...
+++        'LineStyle', line_styles{2}, 'Color', current_color, 'LineWidth', line_width);
+++end
+++
+++% --- Create Proxy Artists for a Clean, Organized Legend ---
+++% We create invisible plots that have the desired properties for our legend entries.
+++h_proxy = gobjects(2 + num_selected, 1); % Pre-allocate graphics object array
+++
+++% Proxy for Line Styles
+++h_proxy(1) = plot(NaN, NaN, 'LineStyle', line_styles{1}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Ground Truth');
+++h_proxy(2) = plot(NaN, NaN, 'LineStyle', line_styles{2}, 'Color', 'k', 'LineWidth', line_width, 'DisplayName', 'Prediction');
+++
+++% Proxies for Time (Colors)
+++for i = 1:num_selected
+++    current_color = colors(mod(i-1, size(colors, 1)) + 1, :);
+++    h_proxy(2+i) = plot(NaN, NaN, 'LineStyle', '-', 'Color', current_color, 'LineWidth', line_width, 'DisplayName', sprintf('t = %d', selected_frames(i)));
+++end
+++
+++hold(ax_profile, 'off');
+++
+++% --- Professional Formatting for the 1D Plot ---
+++title(ax_profile, '1D Centerline Profile Comparison', 'FontSize', 18, 'FontWeight', 'bold');
+++xlabel(ax_profile, 'Position along x-axis', 'FontSize', 16, 'FontWeight', 'bold');
+++ylabel(ax_profile, 'Field Value u', 'FontSize', 16, 'FontWeight', 'bold');
+++ylim(ax_profile, [-1.1, 1.1]);
+++xlim(ax_profile, [x_grid(1), x_grid(end)]);
+++set(ax_profile, 'FontSize', 16, 'FontWeight', 'bold', 'LineWidth', 1.5);
+++
+++% Generate the legend using ONLY the proxy artists
+++lgd = legend(h_proxy, 'Location', 'northeast', 'NumColumns', 1); % Single column is cleaner
+++set(lgd, 'FontSize', 14, 'FontWeight', 'bold', 'Box', 'on');
+++
+++disp('Comparison visualization complete.');
+++
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++%% PART 5: SAVE THE FIGURE
+++%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
+++disp('Saving the figure...');
+++filename = ['CH3D_Comparison_' initial_condition_type '.png'];
+++print(fig, filename, '-dpng', '-r300');
+++disp(['Figure saved as ', filename]);
++\ No newline at end of file
++Index: MatlabCode/In_Distribution/3D_phase_evolution4GRF.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/In_Distribution/3D_phase_evolution4GRF.m b/MatlabCode/In_Distribution/3D_phase_evolution4GRF.m
++new file mode 100644
++--- /dev/null	(date 1754320570648)
+++++ b/MatlabCode/In_Distribution/3D_phase_evolution4GRF.m	(date 1754320570648)
++@@ -0,0 +1,324 @@
+++clc;
+++clear;
+++close all;
+++
+++%% ======================= Configuration =======================
+++% --- File Path ---
+++
+++% You can switch between these paths. The titles will update automatically.
+++
+++% SH3D
+++
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat';
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat';
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_FNO3d/FNO3d_SH3D_S32_T1to91_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_FNO4d/FNO4d_SH3D_S32_T1to91_width12_modes14_q12_h6_grf3d_NoMixed.pt_results.mat'
+++
+++
+++%AC3D
+++
+++mat_filepath = '//scratch/noqu8762/phase_field_equations_4d/AC3D/plots_TNO3d/TNO3d_AC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/AC3D/plots_FNO3d/FNO3d_AC3D_S32_T1to91_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/AC3D/plots_Data_Physics_TNO3d/TNO3d_AC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++
+++% AC3D Mixed
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/AC3D/plots_TNO3d/TNO3d_AC3D_S32_T1to100_width12_modes14_q12_h6_grf3d_Mixed.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/AC3D/plots_Data_Physics_TNO3d/TNO3d_AC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d_Mixed.pt_results.mat'
+++
+++% AC3d FNO4d
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/AC3D/plots_FNO4d/FNO4d_AC3D_S32_T1to91_width12_modes14_q12_h6_grf3d_NoMixed.pt_results.mat'
+++
+++% CH3D
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/CH3D/plots_TNO3d/TNO3d_CH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath ='/scratch/noqu8762/phase_field_equations_4d/CH3D/plots_Data_Physics_TNO3d/TNO3d_CH3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/CH3D/plots_FNO3d/FNO3d_CH3D_S32_T1to91_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/CH3D/plots_FNO4d/FNO4d_CH3D_S32_T1to91_width12_modes14_q12_h6_grf3d_NoMixed.pt_results.mat'
+++
+++% MBE3D
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/plots_TNO3d/TNO3d_MBE3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/plots_Data_Physics_TNO3d/TNO3d_MBE3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat';
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/plots_FNO3d/FNO3d_MBE3D_S32_T1to91_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++
+++% MBE3D with FNO4d
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/MBE3D/plots_FNO4d/FNO4d_MBE3D_S32_T1to91_width12_modes14_q12_h6_grf3d_NoMixed.pt_results.mat'
+++
+++% PFC
+++mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_TNO3d/TNO3d_PFC3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_Data_Physics_TNO3d/TNO3d_PFC3D_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_FNO3d/FNO3d_PFC3D_S32_T1to91_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_Data_Physics_TNO3d/TNO3d_PFC3D_Mixed_Hybrid_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++%mat_filepath ='/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_TNO3d/TNO3d_PFC3D_Mixed_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.mat'
+++ 
+++%mat_filepath = '/scratch/noqu8762/phase_field_equations_4d/PFC3D/plots_FNO4d/FNO4d_PFC3D_S32_T1to91_width12_modes14_q12_h6_grf3d_NoMixed.pt_results.mat'
+++
+++
+++% --- Visualization Parameters ---
+++time_steps_to_plot = [0, 50, 90];
+++sample_index_to_plot = 2; % set 2 for MBE model
+++iso_value = 0;
+++error_display_threshold_ratio = 0.20;
+++
+++%% ======================= Automatic Title Generation =======================
+++path_parts = strsplit(mat_filepath, '/');
+++problem_name = 'UnknownProblem'; 
+++base_dir_idx = find(strcmp(path_parts, 'phase_field_equations_4d'));
+++if ~isempty(base_dir_idx) && base_dir_idx < length(path_parts)
+++    problem_name = path_parts{base_dir_idx + 1};
+++end
+++model_name = 'UnknownModel';
+++if ~isempty(base_dir_idx) && (base_dir_idx + 1) < length(path_parts)
+++    plot_dir_name = path_parts{base_dir_idx + 2};
+++    switch plot_dir_name
+++        case 'plots_Data_Physics_TNO3d'
+++            model_name = 'Hybrid';
+++        case 'plots_TNO3d'
+++            model_name = 'MHNO';
+++        case 'plots_FNO3d'
+++            model_name = 'FNO\_3d';
+++        case 'plots_FNO4d'
+++            model_name = 'FNO\_4d';
+++            
+++    end
+++end
+++main_plot_title = sprintf('3D Phase Evolution of %s Based on %s Model', problem_name, model_name);
+++loss_plot_title = sprintf('Loss Progression for %s - %s Model', problem_name, model_name);
+++fprintf('Generated Plot Title: "%s"\n', main_plot_title);
+++
+++%% ======================= Load and Prepare Data =======================
+++fprintf('Loading data from: %s\n', mat_filepath);
+++if ~exist(mat_filepath, 'file')
+++    error('File not found! Please check the mat_filepath variable.');
+++end
+++results = load(mat_filepath);
+++disp('Data loaded successfully.');
+++
+++u_input_all = double(results.test_input);
+++u_exact_all = double(results.test_exact);
+++u_pred_all  = double(results.test_prediction);
+++u_error_all = u_pred_all - u_exact_all;
+++
+++% First, squeeze to extract the single sample we want to plot
+++u_input = squeeze(u_input_all(sample_index_to_plot, :, :, :, :));
+++u_exact = squeeze(u_exact_all(sample_index_to_plot, :, :, :, :));
+++u_pred = squeeze(u_pred_all(sample_index_to_plot, :, :, :, :));
+++u_error = squeeze(u_error_all(sample_index_to_plot, :, :, :, :));
+++
+++% Second, permute the dimensions of the extracted sample from (x,y,z,t) 
+++% to (y,x,z,t) to match the 'meshgrid' convention required by plotting functions.
+++u_input = permute(u_input, [2 1 3 4]);
+++u_exact = permute(u_exact, [2 1 3 4]);
+++u_pred  = permute(u_pred,  [2 1 3 4]);
+++u_error = permute(u_error, [2 1 3 4]);
+++Lx = double(results.config_Lx);
+++%Lx = 2*pi %double(results.config_Lx);
+++Ly = Lx;
+++Lz = Lx;
+++
+++% Get the new size after permutation (Note: Ny is now the first dimension)
+++[Ny, Nx, Nz, ~] = size(u_exact);
+++x = linspace(-Lx/2, Lx/2, Nx);
+++y = linspace(-Ly/2, Ly/2, Ny);
+++z = linspace(-Lz/2, Lz/2, Nz);
+++
+++% Use 'meshgrid' to create the grid, which is expected by functions like 'slice'.
+++[xx, yy, zz] = meshgrid(x, y, z);
+++
+++
+++%% ======================= Plot 1: Loss Curves (Generalized) =======================
+++fig1 = figure('Name', 'Loss vs. Epoch', 'NumberTitle', 'off', 'Position', [100, 400, 800, 600]);
+++if isfield(results, 'test_loss_hybrid_log')
+++    hybrid_loss = double(results.test_loss_hybrid_log);
+++    data_loss = double(results.test_data_log);
+++    epochs = 1:length(hybrid_loss);
+++    semilogy(epochs, hybrid_loss, 'b-', 'LineWidth', 2.5, 'DisplayName', 'Test Hybrid Loss');
+++    hold on;
+++    semilogy(epochs, data_loss, 'r--', 'LineWidth', 2.5, 'DisplayName', 'Test Data-Only Loss');
+++    hold off;
+++    legend('show', 'Location', 'northeast');
+++else
+++    test_loss = double(results.test_l2_log);
+++    epochs = 1:length(test_loss);
+++    semilogy(epochs, test_loss, 'g-', 'LineWidth', 2.5, 'DisplayName', 'Test L2 Loss');
+++    legend('show', 'Location', 'northeast');
+++end
+++grid on; box on;
+++xlabel('Epoch', 'FontWeight', 'bold');
+++ylabel('L2 Relative Loss', 'FontWeight', 'bold');
+++title(loss_plot_title, 'FontSize', 14);
+++set(gca, 'FontSize', 12, 'LineWidth', 1);
+++
+++%% ======================= Plot 2: 3D Subplots (FINAL - CORRECTED SPACING) =======================
+++num_times = length(time_steps_to_plot);
+++fig2 = figure('Name', '3D Field Comparison', 'NumberTitle', 'off', 'Position', [200, 100, 950, 800]); 
+++set(fig2, 'Color', [0.94 0.94 0.94]);
+++
+++tl = tiledlayout(3, num_times, 'TileSpacing', 'compact', 'Padding', 'normal');
+++title(tl, {main_plot_title; ''}, 'FontSize', 22, 'FontWeight', 'bold');
+++custom_error_map = [linspace(1,0,256)', linspace(1,1,256)', linspace(0.2,0,256)']; % Yellow->Green
+++
+++for i = 1:num_times
+++    t_step = time_steps_to_plot(i);
+++    
+++    if t_step == 0
+++        exact_slice = u_input;
+++        pred_slice  = u_input;
+++        title_time_str = 't = 0 (Input)';
+++        error_title_str = 't = 0';
+++    else
+++        exact_slice = u_exact(:, :, :, t_step);
+++        pred_slice  = u_pred(:, :, :, t_step);
+++        error_slice = u_error(:, :, :, t_step);
+++        title_time_str = sprintf('%d\\Deltat', t_step);
+++        norm_of_error = norm(error_slice(:));
+++        norm_of_exact = norm(exact_slice(:));
+++        relative_l2_error = (norm_of_exact > 1e-9) * (norm_of_error / norm_of_exact);
+++        error_title_str = sprintf('Rel. L2: %.2f', relative_l2_error);
+++    end
+++    
+++    % --- Exact Row ---
+++    ax1 = nexttile(i);
+++    plot_isosurface_with_fallback(ax1, xx, yy, zz, exact_slice, iso_value, [0.85, 0.25, 0.25]);
+++    title(ax1, title_time_str, 'FontSize', 20, 'FontWeight', 'bold'); 
+++    if i == 1 % for PFC only we set  ax1, -0.9, 0.5, , and the rest should be ax1, -0.7, 0.5, 
+++        text(ax1, -0.9, 0.5, 'Exact', 'FontSize', 22, 'FontWeight', 'bold', 'HorizontalAlignment', 'center', 'Rotation', 90, 'Units', 'normalized');
+++    end
+++
+++    % --- Predicted Row ---
+++    ax2 = nexttile(i + num_times);
+++    plot_isosurface_with_fallback(ax2, xx, yy, zz, pred_slice, iso_value, [0.25, 0.5, 0.85]);
+++    title(ax2, title_time_str, 'FontSize', 20, 'FontWeight', 'bold');
+++    if i == 1
+++        text(ax2, -0.9, 0.5, 'Predicted', 'FontSize', 22, 'FontWeight', 'bold', 'HorizontalAlignment', 'center', 'Rotation', 90, 'Units', 'normalized');
+++    end
+++
+++    % --- Error Row ---
+++    ax3 = nexttile(i + 2*num_times);
+++    if t_step == 0
+++        [x_grid, y_grid, z_grid] = meshgrid(linspace(min(x), max(x), 5), linspace(min(y), max(y), 5), linspace(min(z), max(z), 5));
+++        scatter3(ax3, x_grid(:), y_grid(:), z_grid(:), 40, [1 1 0.2], 'filled');
+++        colorbar(ax3, 'off');
+++    else
+++        abs_error = abs(u_error(:,:,:,t_step));
+++        max_abs_error = max(abs_error(:));
+++        error_threshold = error_display_threshold_ratio * max_abs_error;
+++        idx_to_plot = find(abs_error >= error_threshold);
+++        if isempty(idx_to_plot) || max_abs_error < 1e-9
+++            text(ax3, 0.5, 0.5, 'No significant error', 'HorizontalAlignment', 'center', 'FontSize', 14, 'Units', 'normalized', 'FontWeight', 'bold');
+++            axis(ax3, 'off');
+++        else
+++            x_err = xx(idx_to_plot); y_err = yy(idx_to_plot); z_err = zz(idx_to_plot);
+++            c_data = abs_error(idx_to_plot);
+++            scatter3(ax3, x_err, y_err, z_err, 40, c_data, 'filled');
+++            caxis(ax3, [error_threshold, max_abs_error]);
+++        end
+++    end
+++    
+++    title(ax3, error_title_str, 'FontSize', 16, 'FontWeight', 'bold'); 
+++    colormap(ax3, custom_error_map); 
+++    cb = colorbar(ax3); 
+++    ylabel(cb, 'Relative Error', 'FontSize', 14, 'FontWeight', 'bold'); 
+++    cb.FontSize = 14;
+++    cb.FontWeight = 'bold';
+++    
+++    plot_isosurface_with_fallback(ax3, [],[],[],[],[],[]); % Just use it to set axis properties
+++    if i == 1
+++        text(ax3, -0.9, 0.5, 'Error', 'FontSize', 20, 'FontWeight', 'bold', 'HorizontalAlignment', 'center', 'Rotation', 90, 'Units', 'normalized');
+++    end
+++end
+++
+++%% ======================= Save Plots to File =======================
+++fprintf('\nSaving generated plots...\n');
+++output_dir = 'saved_plots';
+++if ~exist(output_dir, 'dir'), mkdir(output_dir); end
+++loss_plot_filename = sprintf('%s_%s_loss_curve.png', problem_name, model_name);
+++field_plot_filename = sprintf('%s_%s_field_comparison_FINAL.png', problem_name, model_name);
+++
+++try
+++    exportgraphics(fig1, fullfile(output_dir, loss_plot_filename), 'Resolution', 300);
+++    fprintf('Saved loss plot to: %s\n', fullfile(output_dir, loss_plot_filename));
+++catch ME
+++    fprintf('Error saving loss plot: %s\n', ME.message);
+++end
+++
+++try
+++    exportgraphics(fig2, fullfile(output_dir, field_plot_filename), 'Resolution', 600);
+++    fprintf('Saved high-quality field plot to: %s\n', fullfile(output_dir, field_plot_filename));
+++catch ME
+++    fprintf('Error saving field plot with exportgraphics: %s\n', ME.message);
+++end
+++
+++disp('Visualization script finished.');
+++
+++%% ======================= MODIFIED Local Helper Function =======================
+++function plot_isosurface_with_fallback(ax, xx, yy, zz, data, iso_value, color)
+++    % This helper function plots a 3D surface. It first tries the specified
+++    % iso_value. If no surface is found, it automatically tries to plot the
+++    % "peaks" and "valleys" of the data to show its 3D structure.
+++
+++    if ~isempty(data)
+++        % --- Primary Plotting Attempt ---
+++        % Try to find the surface at the requested iso_value (usually 0).
+++        [faces, vertices] = isosurface(xx, yy, zz, data, iso_value);
+++
+++        if ~isempty(faces)
+++            % SUCCESS: The u=0 surface exists. Plot it.
+++            p = patch(ax, 'Faces', faces, 'Vertices', vertices);
+++            set(p, 'FaceColor', color, 'EdgeColor', 'none', 'FaceAlpha', 0.8);
+++            lighting(ax, 'gouraud'); material(ax, 'dull');
+++            camlight(ax);
+++        else
+++            % --- Fallback Plotting Logic ---
+++            % The u=0 surface does not exist. Let's visualize the data's
+++            % actual structure by plotting its peaks and valleys.
+++
+++            % Define new isosurface values based on the data's range.
+++            max_val = max(data(:));
+++            min_val = min(data(:));
+++            
+++            % Set thresholds to avoid plotting noise near zero.
+++            positive_iso = 0.3 * max_val;
+++            negative_iso = 0.3 * min_val;
+++            
+++            % Find the "peak" and "valley" surfaces.
+++            [faces_pos, vertices_pos] = isosurface(xx, yy, zz, data, positive_iso);
+++            [faces_neg, vertices_neg] = isosurface(xx, yy, zz, data, negative_iso);
+++
+++            if isempty(faces_pos) && isempty(faces_neg)
+++                % Fallback also failed (data is too flat). Show the old slice plot.
+++                slice(ax, xx, yy, zz, data, [], [], 0);
+++                shading(ax, 'interp'); caxis(ax, [-1.2, 1.2]); colorbar(ax);
+++                text(ax, 0.05, 0.95, 'No clear structure found.', 'Color', 'k', 'BackgroundColor', 'w', 'Margin', 2, 'VerticalAlignment', 'top', 'FontSize', 9, 'Units', 'normalized');
+++            else
+++                % SUCCESS: We found some structure. Plot it.
+++                hold(ax, 'on');
+++                % Plot positive surface (peaks)
+++                if ~isempty(faces_pos)
+++                    p_pos = patch(ax, 'Faces', faces_pos, 'Vertices', vertices_pos);
+++                    set(p_pos, 'FaceColor', color, 'EdgeColor', 'none', 'FaceAlpha', 0.8);
+++                end
+++                % Plot negative surface (valleys) using a slightly different shade for contrast
+++                if ~isempty(faces_neg)
+++                    p_neg = patch(ax, 'Faces', faces_neg, 'Vertices', vertices_neg);
+++                    % Use a complementary or darker/lighter color for the second surface
+++                    comp_color = color * 0.6; % A simple way to make it darker
+++                    set(p_neg, 'FaceColor', comp_color, 'EdgeColor', 'none', 'FaceAlpha', 0.8);
+++                end
+++                hold(ax, 'off');
+++                lighting(ax, 'gouraud'); material(ax, 'dull');
+++                camlight(ax);
+++            end
+++        end
+++    end
+++    
+++    % --- Universal Axis Formatting ---
+++    daspect(ax, [1 1 1]); view(ax, 45, 30);
+++    grid(ax, 'on'); box(ax, 'on'); axis(ax, 'tight');
+++    xlabel(ax, 'X', 'FontSize', 16, 'FontWeight', 'bold'); 
+++    ylabel(ax, 'Y', 'FontSize', 16, 'FontWeight', 'bold'); 
+++    zlabel(ax, 'Z', 'FontSize', 16, 'FontWeight', 'bold');
+++    ax.FontSize = 14;
+++    ax.FontWeight = 'bold';
+++end
++Index: PFC3D/.idea/PFC3D.iml
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/PFC3D/.idea/PFC3D.iml b/PFC3D/.idea/PFC3D.iml
++new file mode 100644
++--- /dev/null	(date 1754055607115)
+++++ b/PFC3D/.idea/PFC3D.iml	(date 1754055607115)
++@@ -0,0 +1,8 @@
+++<?xml version="1.0" encoding="UTF-8"?>
+++<module type="PYTHON_MODULE" version="4">
+++  <component name="NewModuleRootManager">
+++    <content url="file://$MODULE_DIR$" />
+++    <orderEntry type="inheritedJdk" />
+++    <orderEntry type="sourceFolder" forTests="false" />
+++  </component>
+++</module>
++\ No newline at end of file
++Index: configs/config_CH3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:3'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500\nnTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500\nbatch_size = 2 # 20 # 50 # 3 # 20 # 50 # 5 # 50\nlearning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-3 # 1e-4\nepochs = 100 # 500 # 1000 # 25 # 100 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 10 #12 # 14 # 16 # 10 # 16\nwidth = 12 # 8 #12 #14 # 12 # 16 # 32\nwidth_q = width # 2 * width #\nwidth_h = width//2 # width//4 # width #\nn_layers = 4 # 4 # 5 # 5 # 8\n\n# Discretization\n\ns = 64 # 32 # 64 #32 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False # True # False  # True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n\n#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'\n\n# Plotting\nindex = 62  # 24 # 62\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_CH3D_FNO3d.py b/configs/config_CH3D_FNO3d.py
++--- a/configs/config_CH3D_FNO3d.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/configs/config_CH3D_FNO3d.py	(date 1754055607070)
++@@ -6,24 +6,24 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+++nTrain = 1300 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
++ nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
++-batch_size = 2 # 20 # 50 # 3 # 20 # 50 # 5 # 50
+++batch_size = 10 # 20 # 20 # 50 # 3 # 20 # 50 # 5 # 50
++ learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
++ weight_decay = 1e-4 # 1e-3 # 1e-4
++-epochs = 100 # 500 # 1000 # 25 # 100 # 1000
+++epochs = 50 # 100 # 500 # 1000 # 25 # 100 # 1000
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 # 10 #12 # 14 # 16 # 10 # 16
++ width = 12 # 8 #12 #14 # 12 # 16 # 32
++ width_q = width # 2 * width #
++ width_h = width//2 # width//4 # width #
++-n_layers = 4 # 4 # 5 # 5 # 8
+++n_layers = 3 # 2 # 4 # 5 # 5 # 8
++ 
++ # Discretization
++ 
++-s = 64 # 32 # 64 #32 # 64
+++s = 32 # 64 # 32 # 64 #32 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -34,15 +34,44 @@
++ parent_dir = './data/'
++ 
++ #matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
++-
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++ # Plotting
++ index = 62  # 24 # 62
++-domain = [-np.pi, np.pi]
+++#domain = [-np.pi, np.pi]
+++Lx = 2 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.05  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: configs/config_SH3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:2'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 # 5250 # 7500\nnTest = 300 # 2250 #500\nbatch_size = 10 # 50 # 50\nlearning_rate = 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-4\nepochs = 30 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 16\nwidth =  12 #32\nwidth_q =   width # width # 2 * width #\nwidth_h = width//2  # width//4 # width #\nn_layers = 2 # 8\n\n# Discretization\ns = 32 # 32 # 64\nT_in = 1\nT_out = 91 # 100 # 100\n\n# Training Setting\nnormalized = True # False #True\ntraining = True # False  # True\nload_model = False # False #True\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results\n\n# Plotting\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\nLx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\nLy =Lx\nLz= Lx\n\nindex = 62  # 24 # 62\n#domain = [-np.pi, np.pi]  ######\ndomain = [-Lx/2, Lx/2]\n\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 50, 90]\n\n\n### Hybrid method\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\n#Lx = np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\n# domain = [-Lx/2, Lx/2] # Assuming centered domain\n\n# Time Discretization (from MATLAB)\ndt_sim = 0.0000002 # Simulation time step\nNt = 100 # Total simulation steps\nnum_saved_steps = 101 # Number of saved steps (includes t=0)\nns = Nt / (num_saved_steps - 1) # Interval between saved steps\ndt_model = ns * dt_sim # Effective time step between model outputs\n\n# PDE Parameters\nepsilon = 0.15\n#pde_weight = 0.3 # Example: 30% physics loss\npde_weight = 0.0 # Example: 70% physics loss\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\npde_loss_scaler = 1e-11\n###########################\n# ... rest of config ...
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_SH3D_FNO3d.py b/configs/config_SH3D_FNO3d.py
++--- a/configs/config_SH3D_FNO3d.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/configs/config_SH3D_FNO3d.py	(date 1754055607087)
++@@ -33,12 +33,12 @@
++ parent_dir = './data/'
++ #matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'
++ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
++-
+++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
++ # Plotting
++ 
++ # In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
++-Lx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++Lx = 15 # 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
++ Ly =Lx
++ Lz= Lx
++ 
++@@ -62,7 +62,7 @@
++ # domain = [-Lx/2, Lx/2] # Assuming centered domain
++ 
++ # Time Discretization (from MATLAB)
++-dt_sim = 0.0000002 # Simulation time step
+++dt_sim = 0.0002 # Simulation time step
++ Nt = 100 # Total simulation steps
++ num_saved_steps = 101 # Number of saved steps (includes t=0)
++ ns = Nt / (num_saved_steps - 1) # Interval between saved steps
++@@ -75,6 +75,6 @@
++ # Learning Rate Scheduler Parameters (for StepLR)
++ scheduler_step = 20  # Decay learning rate every 20 epochs
++ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++-pde_loss_scaler = 1e-11
+++pde_loss_scaler = 1e-0
++ ###########################
++ # ... rest of config ...
++\ No newline at end of file
++Index: configs/config_CH3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500\nnTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500\nbatch_size = 20 # 50 # 3 # 20 # 50 # 5 # 50\nlearning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-3 # 1e-4\nepochs = 100 # 500 # 1000 # 25 # 100 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 10 #12 # 14 # 16 # 10 # 16\nwidth = 12 # 8 #12 #14 # 12 # 16 # 32\nwidth_q = width # 2 * width #\nwidth_h = width//2 # width//4 # width #\nn_layers = 4 # 4 # 5 # 5 # 8\n\n# Discretization\n\ns = 64 # 64 #32 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False # True # False  # True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'\n\n\n# Plotting\nindex = 62  # 24 # 62\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_CH3D_TNO3d.py b/configs/config_CH3D_TNO3d.py
++--- a/configs/config_CH3D_TNO3d.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/configs/config_CH3D_TNO3d.py	(date 1754055607106)
++@@ -6,24 +6,24 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
++-nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
++-batch_size = 20 # 50 # 3 # 20 # 50 # 5 # 50
+++nTrain = 1200 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+++nTest =  300 # 300 # 100 # 2000 # 4000 #300 # 300 #500
+++batch_size = 20 # 15 # 50 # 3 # 20 # 50 # 5 # 50
++ learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
++ weight_decay = 1e-4 # 1e-3 # 1e-4
++-epochs = 100 # 500 # 1000 # 25 # 100 # 1000
+++epochs = 50 # 50 # 50 # 100 # 500 # 1000 # 25 # 100 # 1000
++ iterations = epochs * (nTrain // batch_size)
++-modes = 14 # 10 #12 # 14 # 16 # 10 # 16
++-width = 12 # 8 #12 #14 # 12 # 16 # 32
+++modes = 14 # 14 # 12 # 14 # 10 #12 # 14 # 16 # 10 # 16
+++width = 12 # 12 # 8 #12 #14 # 12 # 16 # 32
++ width_q = width # 2 * width #
++ width_h = width//2 # width//4 # width #
++-n_layers = 4 # 4 # 5 # 5 # 8
+++n_layers = 3 # 4 # 5 # 5 # 8
++ 
++ # Discretization
++ 
++-s = 64 # 64 #32 # 64
+++s = 32 # 64 # 64 #32 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -33,16 +33,46 @@
++ # Database
++ parent_dir = './data/'
++ #matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
++-
++-
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_32.mat'
+++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
++ # Plotting
++ index = 62  # 24 # 62
++-domain = [-np.pi, np.pi]
+++Lx = 2 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
+++#domain = [-np.pi, np.pi]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.05 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: utilities.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import torch\nimport numpy as np\nimport scipy.io\nimport h5py\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport os\n\nimport operator\nfrom functools import reduce\nfrom functools import partial\n\n#################################################\n#\n# Utilities\n#\n#################################################\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# reading data\nclass MatReader(object):\n    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n        super(MatReader, self).__init__()\n\n        self.to_torch = to_torch\n        self.to_cuda = to_cuda\n        self.to_float = to_float\n\n        self.file_path = file_path\n\n        self.data = None\n        self.old_mat = None\n        self._load_file()\n\n    def _load_file(self):\n        try:\n            self.data = scipy.io.loadmat(self.file_path)\n            self.old_mat = True\n        except:\n            self.data = h5py.File(self.file_path)\n            self.old_mat = False\n\n    def load_file(self, file_path):\n        self.file_path = file_path\n        self._load_file()\n\n    def read_field(self, field):\n        print(f\"Available keys in self.data: {list(self.data.keys())}\")\n        x = self.data[field]\n\n        if not self.old_mat:\n            x = x[()]\n            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n\n        if self.to_float:\n            x = x.astype(np.float32)\n\n        if self.to_torch:\n            x = torch.from_numpy(x)\n\n            if self.to_cuda:\n                x = x.cuda()\n\n        return x\n\n    def set_cuda(self, to_cuda):\n        self.to_cuda = to_cuda\n\n    def set_torch(self, to_torch):\n        self.to_torch = to_torch\n\n    def set_float(self, to_float):\n        self.to_float = to_float\n\n\n# normalization, pointwise gaussian\nclass UnitGaussianNormalizer(object):\n    def __init__(self, x, eps=0.00001, time_last=True):\n        super(UnitGaussianNormalizer, self).__init__()\n\n        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T in 1D\n        # x could be in shape of ntrain*w*l or ntrain*T*w*l or ntrain*w*l*T in 2D\n        self.mean = torch.mean(x, 0)\n        self.std = torch.std(x, 0)\n        self.eps = eps\n        self.time_last = time_last  # if the time dimension is the last dim\n\n    def encode(self, x):\n        x = (x - self.mean) / (self.std + self.eps)\n        return x\n\n    def decode(self, x, sample_idx=None):\n        # sample_idx is the spatial sampling mask\n        #print('x shape in decode: ', x.shape)\n        global std, mean\n        if sample_idx is None:\n            std = self.std + self.eps  # n\n            mean = self.mean\n            #print(\"x shape:\", x.shape)\n            #print(\"std shape:\", std.shape)\n            #print(\"mean shape:\", mean.shape)\n        else:\n            if self.mean.ndim == sample_idx.ndim or self.time_last:\n                std = self.std[sample_idx] + self.eps  # batch*n\n                mean = self.mean[sample_idx]\n            if self.mean.ndim > sample_idx.ndim and not self.time_last:\n                std = self.std[..., sample_idx] + self.eps  # T*batch*n\n                mean = self.mean[..., sample_idx]\n        # x is in shape of batch*(spatial discretization size) or T*batch*(spatial discretization size)\n\n        x = (x * std) + mean\n        return x\n\n    def to(self, device):\n        if torch.is_tensor(self.mean):\n            self.mean = self.mean.to(device)\n            self.std = self.std.to(device)\n        else:\n            self.mean = torch.from_numpy(self.mean).to(device)\n            self.std = torch.from_numpy(self.std).to(device)\n        return self\n\n    def cuda(self):\n        self.mean = self.mean.cuda()\n        self.std = self.std.cuda()\n\n    def cpu(self):\n        self.mean = self.mean.cpu()\n        self.std = self.std.cpu()\n\n\n# normalization, Gaussian\nclass GaussianNormalizer(object):\n    def __init__(self, x, eps=0.00001):\n        super(GaussianNormalizer, self).__init__()\n\n        self.mean = torch.mean(x)\n        self.std = torch.std(x)\n        self.eps = eps\n\n    def encode(self, x):\n        x = (x - self.mean) / (self.std + self.eps)\n        return x\n\n    def decode(self, x, sample_idx=None):\n        x = (x * (self.std + self.eps)) + self.mean\n        return x\n\n    def cuda(self):\n        self.mean = self.mean.cuda()\n        self.std = self.std.cuda()\n\n    def cpu(self):\n        self.mean = self.mean.cpu()\n        self.std = self.std.cpu()\n\n\n# normalization, scaling by range\nclass RangeNormalizer(object):\n    def __init__(self, x, low=0.0, high=1.0):\n        super(RangeNormalizer, self).__init__()\n        mymin = torch.min(x, 0)[0].view(-1)\n        mymax = torch.max(x, 0)[0].view(-1)\n\n        self.a = (high - low) / (mymax - mymin)\n        self.b = -self.a * mymax + high\n\n    def encode(self, x):\n        s = x.size()\n        x = x.view(s[0], -1)\n        x = self.a * x + self.b\n        x = x.view(s)\n        return x\n\n    def decode(self, x):\n        s = x.size()\n        x = x.view(s[0], -1)\n        x = (x - self.b) / self.a\n        x = x.view(s)\n        return x\n\n\n# loss function with rel/abs Lp loss\nclass LpLoss(object):\n    #def __init__(self, d=2, p=2, size_average=True, reduction=True):\n    #    super(LpLoss, self).__init__()\n    def __init__(self, d=2, p=2, l1_weight=0.0, size_average=True, reduction=True):\n        super(LpLoss, self).__init__()\n        assert d > 0 and p > 0\n\n\n        # Dimension and Lp-norm type are postive\n        assert d > 0 and p > 0\n\n        self.d = d\n        self.p = p\n        self.l1_weight = l1_weight  # Weight for the L1 compon\n        self.reduction = reduction\n        self.size_average = size_average\n\n    def abs(self, x, y):\n        num_examples = x.size()[0] # number of rows\n\n        # Assume uniform mesh\n        h = 1.0 / (x.size()[1] - 1.0)\n\n        all_norms = (h ** (self.d / self.p)) * torch.norm(x.view(num_examples, -1) - y.view(num_examples, -1), self.p,\n                                                          1)\n\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(all_norms)\n            else:\n                return torch.sum(all_norms)\n\n        return all_norms\n\n    def rel(self, x, y):\n        num_examples = x.size()[0]\n\n        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(diff_norms / y_norms)\n            else:\n                return torch.sum(diff_norms / y_norms)\n\n        return diff_norms / y_norms\n\n    #def __call__(self, x, y):\n    #    return self.rel(x, y)\n    # --- UPDATE THE __call__ METHOD ---\n    def __call__(self, x, y):\n        # Calculate the primary loss (e.g., L2)\n        primary_loss = self.rel(x, y)\n\n        # If an L1 weight is specified, calculate and add the L1 loss\n        if self.l1_weight > 0:\n            # Temporarily set p=1 to calculate L1 loss\n            original_p = self.p\n            self.p = 1\n            l1_loss = self.rel(x, y)\n            self.p = original_p  # Restore original p\n\n            # Return the weighted combination\n            return (1.0 - self.l1_weight) * primary_loss + self.l1_weight * l1_loss\n        else:\n            # If no L1 weight, return the primary loss as before\n            return primary_loss\n\n\n# Sobolev norm (HS norm)\n# where we also compare the numerical derivatives between the output and target\nclass HsLoss(object):\n    def __init__(self, d=2, p=2, k=1, a=None, group=False, size_average=True, reduction=True):\n        super(HsLoss, self).__init__()\n\n        # Dimension and Lp-norm type are postive\n        assert d > 0 and p > 0\n\n        self.d = d\n        self.p = p\n        self.k = k\n        self.balanced = group\n        self.reduction = reduction\n        self.size_average = size_average\n\n        if a == None:\n            a = [1, ] * k\n        self.a = a\n\n    def rel(self, x, y):\n        num_examples = x.size()[0]\n        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n        if self.reduction:\n            if self.size_average:\n                return torch.mean(diff_norms / y_norms)\n            else:\n                return torch.sum(diff_norms / y_norms)\n        return diff_norms / y_norms\n\n    def __call__(self, x, y, a=None):\n        nx = x.size()[1]\n        ny = x.size()[2]\n        k = self.k\n        balanced = self.balanced\n        a = self.a\n        x = x.view(x.shape[0], nx, ny, -1)\n        y = y.view(y.shape[0], nx, ny, -1)\n\n        k_x = torch.cat((torch.arange(start=0, end=nx // 2, step=1), torch.arange(start=-nx // 2, end=0, step=1)),\n                        0).reshape(nx, 1).repeat(1, ny)\n        k_y = torch.cat((torch.arange(start=0, end=ny // 2, step=1), torch.arange(start=-ny // 2, end=0, step=1)),\n                        0).reshape(1, ny).repeat(nx, 1)\n        k_x = torch.abs(k_x).reshape(1, nx, ny, 1).to(x.device)\n        k_y = torch.abs(k_y).reshape(1, nx, ny, 1).to(x.device)\n\n        x = torch.fft.fftn(x, dim=[1, 2])\n        y = torch.fft.fftn(y, dim=[1, 2])\n\n        if balanced == False:\n            weight = 1\n            if k >= 1:\n                weight += a[0] ** 2 * (k_x ** 2 + k_y ** 2)\n            if k >= 2:\n                weight += a[1] ** 2 * (k_x ** 4 + 2 * k_x ** 2 * k_y ** 2 + k_y ** 4)\n            weight = torch.sqrt(weight)\n            loss = self.rel(x * weight, y * weight)\n        else:\n            loss = self.rel(x, y)\n            if k >= 1:\n                weight = a[0] * torch.sqrt(k_x ** 2 + k_y ** 2)\n                loss += self.rel(x * weight, y * weight)\n            if k >= 2:\n                weight = a[1] * torch.sqrt(k_x ** 4 + 2 * k_x ** 2 * k_y ** 2 + k_y ** 4)\n                loss += self.rel(x * weight, y * weight)\n            loss = loss / (k + 1)\n\n        return loss\n\n\n# A simple feedforward neural network\nclass DenseNet(torch.nn.Module):\n    def __init__(self, layers, nonlinearity, out_nonlinearity=None, normalize=False):\n        super(DenseNet, self).__init__()\n\n        self.n_layers = len(layers) - 1\n\n        assert self.n_layers >= 1\n\n        self.layers = nn.ModuleList()\n\n        for j in range(self.n_layers):\n            self.layers.append(nn.Linear(layers[j], layers[j + 1]))\n\n            if j != self.n_layers - 1:\n                if normalize:\n                    self.layers.append(nn.BatchNorm1d(layers[j + 1]))\n\n                self.layers.append(nonlinearity())\n\n        if out_nonlinearity is not None:\n            self.layers.append(out_nonlinearity())\n\n    def forward(self, x):\n        for _, l in enumerate(self.layers):\n            x = l(x)\n\n        return x\n\n\n# print the number of parameters\ndef count_params(model):\n    c = 0\n    for p in list(model.parameters()):\n        c += reduce(operator.mul, list(p.size() + (2,) if p.is_complex() else p.size()))\n    return c\n\n\nclass ImportDataset(Dataset):\n    def __init__(self, parent_dir, matlab_dataset, normalized, T_in, T_out):\n        self.y = None # Stores target\n        self.x = None # Stores input\n        '''\n        The values for x and y are not yet available but will be assigned later (inside the set_data() method).\n        '''\n        self.T_in = T_in\n        self.T_out = T_out\n        self.normalized = normalized\n        self.normalizer_x = None\n        self.normalizer_y = None\n\n        matlab_dataset = parent_dir + matlab_dataset\n        python_dataset = matlab_dataset.replace('.mat', '.pt')\n        #python_dataset = matlab_dataset.replace('.npz', '.pt')\n        os.makedirs(parent_dir, exist_ok=True)\n\n        if os.path.exists(python_dataset):\n            print(\"Found saved dataset at\", python_dataset)\n            self.data = torch.load(python_dataset)['data']\n        else:\n            reader = MatReader(matlab_dataset)\n            self.data = reader.read_field('phi')\n            torch.save({'data': self.data}, python_dataset)\n        self.set_data()\n\n    def set_data(self):\n        permute_order = list(range(self.data.ndim))\n        permute_order.append(permute_order.pop(1))  # Move the second dimension to the end\n        self.x = self.data[:, 0:self.T_in, *[slice(None)] * (self.data.ndim - 3)].permute(*permute_order)\n        self.y = self.data[:, self.T_in:self.T_in + self.T_out, *[slice(None)] * (\n                self.data.ndim - 3)].permute(*permute_order)\n       # print(self.x.shape)\n       # print(self.y.shape)\n        if self.normalized:\n            self.make_normal()\n\n    def make_normal(self):\n        self.normalizer_x = UnitGaussianNormalizer(self.x)\n        self.normalizer_y = UnitGaussianNormalizer(self.y)\n        self.x = self.normalizer_x.encode(self.x)\n        self.y = self.normalizer_y.encode(self.y)\n\n    def __len__(self):\n        return self.x.shape[0]\n\n    def __getitem__(self, idx):\n        return self.x[idx], self.y[idx]\n\n\nclass ModelEvaluator:\n    def __init__(self, model, test_dataset, s, T_in, T_out, device, normalized=False, normalizers=None,\n                 time_history=False):\n        self.model = model\n        self.test_dataset = test_dataset\n        self.s = s\n        self.T_in = T_in\n        self.T_out = T_out\n        self.device = device\n        self.normalized = normalized\n        self.time_history = time_history\n        self.normalizer_x = normalizers[0].to(self.device)\n        self.normalizer_y = normalizers[1].to(self.device)\n        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n        spatial_dims = [s] * (len(test_dataset[0][0].shape) - 1)\n        self.inp = torch.zeros((len(test_dataset), *spatial_dims, T_in))\n        self.exact = torch.zeros((len(test_dataset), *spatial_dims, T_out))\n        self.pred = torch.zeros((len(test_dataset), *spatial_dims, T_out))\n        self.test_l2_set = []\n\n    def evaluate(self, loss_fn):\n        if self.time_history:\n            index = 0\n            step = 1\n            with torch.no_grad():\n                for xx, yy in self.test_loader:\n                    self.inp[index] = xx.squeeze(0)\n                    xx, yy = xx.to(self.device), yy.to(self.device)\n\n                    for t in range(0, self.T_out, step):\n                        y = yy[..., t:t + step]\n                        im = self.model(xx)\n                        # loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n                        if t == 0:\n                            pred = im\n                        else:\n                            pred = torch.cat((pred, im), -1)\n                        xx = torch.cat((xx[..., step:], im), dim=-1)\n\n                    self.exact[index] = yy.squeeze(0)\n                    self.pred[index] = pred.squeeze(0)\n                    test_l2 = loss_fn(pred.view(1, -1), yy.view(1, -1)).item()\n                    self.test_l2_set.append(test_l2)\n                    #print(index, test_l2)\n                    index += 1\n\n        else:\n            index = 0\n            with torch.no_grad():\n                for x, y in self.test_loader:\n                    x, y = x.to(self.device), y.to(self.device)\n                    out = self.model(x)\n                    if self.normalized:\n                        out = self.normalizer_y.decode(out)\n                        y = self.normalizer_y.decode(y)\n                        x = self.normalizer_x.decode(x)\n                    self.inp[index] = x.squeeze(0)\n                    self.exact[index] = y.squeeze(0)\n                    self.pred[index] = out.squeeze(0)\n                    test_l2 = loss_fn(out.view(1, -1), y.view(1, -1)).item()\n                    self.test_l2_set.append(test_l2)\n                    #print(index, test_l2)\n                    index += 1\n\n        return self._compute_statistics()\n\n    def _compute_statistics(self):\n        self.test_l2_set = torch.tensor(self.test_l2_set)\n        test_l2_avg = torch.mean(self.test_l2_set)\n        test_l2_std = torch.std(self.test_l2_set)\n        test_l2_min, min_idx = torch.min(self.test_l2_set), torch.argmin(self.test_l2_set)\n        test_l2_max, max_idx = torch.max(self.test_l2_set), torch.argmax(self.test_l2_set)\n        test_l2_mode, mode_count = torch.mode(self.test_l2_set)\n        mode_indices = torch.nonzero(self.test_l2_set == test_l2_mode).squeeze().tolist()\n\n        print(\"The average testing error is\", test_l2_avg.item())\n        print(\"Std. deviation of testing error is\", test_l2_std.item())\n        print(\"Min testing error is\", test_l2_min.item(), \"at index\", min_idx.item())\n        print(\"Max testing error is\", test_l2_max.item(), \"at index\", max_idx.item())\n        print(\"Mode of testing errors is\", test_l2_mode.item(), \"appearing\", mode_count.item(), \"times at indices\",\n              mode_indices)\n\n        return {\n            \"input\": self.inp,\n            \"exact\": self.exact,\n            \"prediction\": self.pred,\n            \"average\": test_l2_avg.item(),\n            \"std_dev\": test_l2_std.item(),\n            \"min\": {\"value\": test_l2_min.item(), \"index\": min_idx.item()},\n            \"max\": {\"value\": test_l2_max.item(), \"index\": max_idx.item()},\n            \"mode\": {\"value\": test_l2_mode.item(), \"count\": mode_count.item(), \"indices\": mode_indices}\n        }\n
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/utilities.py b/utilities.py
++--- a/utilities.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/utilities.py	(date 1754055607135)
++@@ -252,6 +252,81 @@
++             return primary_loss
++ 
++ 
+++# Add this code to your utilities.py file
+++
+++import torch
+++import torch.nn.functional as F
+++
+++
+++# --- NEW SOBOLEV LOSS CLASS ---
+++class SobolevLoss(object):
+++    def __init__(self, d=3, p=2, grad_weight=0.1, size_average=False, reduction=True):
+++        super(SobolevLoss, self).__init__()
+++        # Ensure dimension and p-norm are valid
+++        assert d > 0 and p > 0
+++
+++        self.d = d
+++        self.p = p
+++        self.reduction = reduction
+++        self.size_average = size_average
+++        self.grad_weight = grad_weight  # Weight for the gradient loss component
+++
+++    def _compute_gradients(self, x):
+++        """
+++        Computes spatial gradients using a 3D Sobel filter.
+++        Assumes input x has shape (batch, sx, sy, sz, t)
+++        """
+++        # We need to operate on each time step independently
+++        # and on data with shape (B, C, D, H, W) for conv3d
+++
+++        # Permute to (batch, t, sx, sy, sz)
+++        x_permuted = x.permute(0, 4, 1, 2, 3)
+++        batch_size, T, sx, sy, sz = x_permuted.shape
+++
+++        # Reshape to treat time steps as part of the batch for convolution
+++        x_reshaped = x_permuted.reshape(batch_size * T, 1, sx, sy, sz)
+++
+++        # 3D Sobel filters
+++        sobel_x = torch.tensor([[[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]],
+++                                 [[-2, 0, 2], [-4, 0, 4], [-2, 0, 2]],
+++                                 [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]]],
+++                               dtype=torch.float32, device=x.device).unsqueeze(0)
+++        sobel_y = sobel_x.permute(0, 1, 3, 2, 4)
+++        sobel_z = sobel_x.permute(0, 1, 4, 3, 2)
+++
+++        grad_x = F.conv3d(x_reshaped, sobel_x, padding='same')
+++        grad_y = F.conv3d(x_reshaped, sobel_y, padding='same')
+++        grad_z = F.conv3d(x_reshaped, sobel_z, padding='same')
+++
+++        # Reshape back to (batch, t, sx, sy, sz, 3_grads)
+++        grads = torch.stack([grad_x, grad_y, grad_z], dim=-1)
+++        return grads.reshape(batch_size, T, sx, sy, sz, 3)
+++
+++    def __call__(self, x, y):
+++        """
+++        x: prediction, y: ground truth
+++        Assumes x and y have shape (batch, sx, sy, sz, T)
+++        """
+++        num_examples = x.size(0)
+++
+++        # 1. Standard L2 Data Loss (relative)
+++        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)
+++        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)
+++        data_loss = torch.mean(diff_norms / y_norms)
+++
+++        # 2. Gradient Loss
+++        if self.grad_weight > 0:
+++            pred_grads = self._compute_gradients(x)
+++            true_grads = self._compute_gradients(y)
+++            grad_loss = F.mse_loss(pred_grads, true_grads)
+++
+++            # Combine losses
+++            total_loss = data_loss + self.grad_weight * grad_loss
+++        else:
+++            total_loss = data_loss
+++
+++        return total_loss
+++
++ # Sobolev norm (HS norm)
++ # where we also compare the numerical derivatives between the output and target
++ class HsLoss(object):
++@@ -371,7 +446,7 @@
++         self.T_in = T_in
++         self.T_out = T_out
++         self.normalized = normalized
++-        self.normalizer_x = None
+++        self.normalizer_x =  None
++         self.normalizer_y = None
++ 
++         matlab_dataset = parent_dir + matlab_dataset
++@@ -432,6 +507,7 @@
++         self.pred = torch.zeros((len(test_dataset), *spatial_dims, T_out))
++         self.test_l2_set = []
++ 
+++    '''''
++     def evaluate(self, loss_fn):
++         if self.time_history:
++             index = 0
++@@ -477,7 +553,58 @@
++                     index += 1
++ 
++         return self._compute_statistics()
++-
+++    '''
+++
+++    # Replace the evaluate method in your ModelEvaluator class with this one.
+++
+++    def evaluate(self, loss_fn):
+++        if self.time_history:
+++            index = 0
+++            step = 1
+++            with torch.no_grad():
+++                for xx, yy in self.test_loader:
+++                    self.inp[index] = xx.squeeze(0)
+++                    xx, yy = xx.to(self.device), yy.to(self.device)
+++
+++                    for t in range(0, self.T_out, step):
+++                        y = yy[..., t:t + step]
+++                        im = self.model(xx)
+++                        if t == 0:
+++                            pred = im
+++                        else:
+++                            pred = torch.cat((pred, im), -1)
+++                        xx = torch.cat((xx[..., step:], im), dim=-1)
+++
+++                    self.exact[index] = yy.squeeze(0)
+++                    self.pred[index] = pred.squeeze(0)
+++
+++                    # --- CORRECTED LINE ---
+++                    # Pass the un-flattened tensors directly to the loss function
+++                    test_l2 = loss_fn(pred, yy).item()
+++                    self.test_l2_set.append(test_l2)
+++                    index += 1
+++
+++        else:
+++            index = 0
+++            with torch.no_grad():
+++                for x, y in self.test_loader:
+++                    x, y = x.to(self.device), y.to(self.device)
+++                    out = self.model(x)
+++                    if self.normalized:
+++                        out = self.normalizer_y.decode(out)
+++                        y = self.normalizer_y.decode(y)
+++                        x = self.normalizer_x.decode(x)
+++                    self.inp[index] = x.squeeze(0)
+++                    self.exact[index] = y.squeeze(0)
+++                    self.pred[index] = out.squeeze(0)
+++
+++                    # --- CORRECTED LINE ---
+++                    # Pass the un-flattened tensors directly to the loss function
+++                    test_l2 = loss_fn(out, y).item()
+++                    self.test_l2_set.append(test_l2)
+++                    index += 1
+++
+++        return self._compute_statistics()
++     def _compute_statistics(self):
++         self.test_l2_set = torch.tensor(self.test_l2_set)
++         test_l2_avg = torch.mean(self.test_l2_set)
++Index: configs/config_MBE3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_MBE3D_FNO4d.py b/configs/config_MBE3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1754055883519)
+++++ b/configs/config_MBE3D_FNO4d.py	(date 1754055883519)
++@@ -0,0 +1,75 @@
+++
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda:1'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1200 #1600 # 4000
+++nTest = 300  # 400
+++batch_size = 50 # 10 # 20 # 50# 25 #100
+++learning_rate = 0.001
+++weight_decay = 1e-4
+++epochs = 30 # 50 # 1000
+++iterations = epochs * (nTrain // batch_size)
+++modes = 14 # 12
+++width = 12 #32
+++width_q = width #32
+++width_h = width // 2 # width # 32
+++n_layers = 2 # 4
+++
+++# Discretization
+++s = 32
+++T_in = 1
+++T_out = 91 #20 #91 # 20 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True  # True  # True
+++load_model = False #True  # False  # False
+++
+++# Database
+++parent_dir = './data/'
+++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat'
+++
+++# Plotting
+++# Plotting
+++index = 62  # 72
+++#domain = [-np.pi, np.pi]
+++Lx = 2* np.pi  #10 # np.pi            # Domain size from MATLAB
+++domain = [-Lx/2, Lx/2]
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 59, 79]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_SH3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_SH3D_FNO4d.py b/configs/config_SH3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1754055606933)
+++++ b/configs/config_SH3D_FNO4d.py	(date 1754055606933)
++@@ -0,0 +1,80 @@
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda:2'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1200 # 5250 # 7500
+++nTest = 300 # 2250 #500
+++batch_size = 20 # 10 # 50 # 50
+++learning_rate = 0.001 # 0.005 # 0.001
+++weight_decay = 1e-4 # 1e-4
+++epochs = 30 # 1000
+++iterations = epochs * (nTrain // batch_size)
+++modes =  14 # 16
+++width =  12 #32
+++width_q =   width # width # 2 * width #
+++width_h = width//2  # width//4 # width #
+++n_layers = 2 # 8
+++
+++# Discretization
+++s = 32 # 32 # 64
+++T_in = 1
+++T_out = 91 # 100 # 100
+++
+++# Training Setting
+++normalized = True # False #True
+++training = True # False  # True
+++load_model = False # False #True
+++
+++# Database
+++parent_dir = './data/'
+++#matlab_dataset = 'SH3D_600_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
+++# Plotting
+++
+++# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
+++Lx = 15 # 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++Ly =Lx
+++Lz= Lx
+++
+++index = 62  # 24 # 62
+++#domain = [-np.pi, np.pi]  ######
+++domain = [-Lx/2, Lx/2]
+++
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++### Hybrid method
+++
+++# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
+++#Lx = np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++# domain = [-Lx/2, Lx/2] # Assuming centered domain
+++
+++# Time Discretization (from MATLAB)
+++dt_sim = 0.0002 # Simulation time step
+++Nt = 100 # Total simulation steps
+++num_saved_steps = 101 # Number of saved steps (includes t=0)
+++ns = Nt / (num_saved_steps - 1) # Interval between saved steps
+++dt_model = ns * dt_sim # Effective time step between model outputs
+++
+++# PDE Parameters
+++epsilon = 0.15
+++#pde_weight = 0.3 # Example: 30% physics loss
+++pde_weight = 0.0 # Example: 70% physics loss
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++pde_loss_scaler = 1e-0
+++###########################
+++# ... rest of config ...
++\ No newline at end of file
++Index: configs/config_SH3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:2'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 # 5250 # 7500\nnTest = 300 # 2250 #500\nbatch_size = 20 # 50\nlearning_rate = 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-4\nepochs = 30 # 50 # 50 # 50 # 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 16 # 16\nwidth =  12 # 12 #32\nwidth_q =   width # width # 2 * width #\nwidth_h = width//2  # width//4 # width #\nn_layers = 2 # 8\n\n# Discretization\n#s = 32 # 32 # 64\n#T_in = 1\n#T_out = 20 # 100\n# Discretization\ns = 32 # 80         # CRITICAL: Must match Nx, Ny, Nz from MATLAB (which is 80)\nT_in = 1       # CRITICAL: Use the first time step (t=0) as input\nT_out = 100 # 91 # 100 # 20     # CRITICAL: Predict the next 10 time steps. Total steps used = 1+10=11, which matches the data.\n\n# Training Setting\nnormalized = True # False\ntraining = True # False  #   True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_3232.mat' # correct\n#matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results\n# Plotting\n\n# In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)\nLx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)\nLy =Lx\nLz= Lx\n\n\nindex = 62  # 24 # 62\n#domain = [-np.pi, np.pi] ######\ndomain = [-Lx/2, Lx/2]\n\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\n#time_steps = [0, 9, 19]\ntime_steps = [0, 50, 90]\n####\n### Hybrid method\n\n\n#domain = [-Lx/2, Lx/2] # Assuming centered domain\n\n# Time Discretization (from MATLAB)\ndt_sim = 0.05 # Simulation time step\ndt_simulation = 0.05\nNt = 100 # Total simulation steps\nnum_saved_steps = 101 # Number of saved steps (includes t=0)\nns = Nt / (num_saved_steps - 1) # Interval between saved steps\ndt_model = ns * dt_sim # Effective time step between model outputs\n\n# PDE Parameters\nepsilon = 0.15\n#pde_weight = 0.3 # Example: 30% physics loss\npde_weight = 0.4 # Example: 70% physics loss\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\npde_loss_scaler = 1e1\n###########################\n# ... rest of config ...
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_SH3D_TNO3d.py b/configs/config_SH3D_TNO3d.py
++--- a/configs/config_SH3D_TNO3d.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/configs/config_SH3D_TNO3d.py	(date 1754055606955)
++@@ -6,18 +6,18 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 1200 # 5250 # 7500
++-nTest = 300 # 2250 #500
+++nTrain = 1200 # 1600 # 5250 # 7500
+++nTest = 300 # 400 # 2250 #500
++ batch_size = 20 # 50
++ learning_rate = 0.001 # 0.005 # 0.001
++ weight_decay = 1e-4 # 1e-4
++-epochs = 30 # 50 # 50 # 50 # 50 # 1000
+++epochs = 30 # 50 # 50 # 50 # 50 # 50 # 1000
++ iterations = epochs * (nTrain // batch_size)
++ modes =  14 # 16 # 16
++ width =  12 # 12 #32
++-width_q =   width # width # 2 * width #
+++width_q = width # width # 2 * width #
++ width_h = width//2  # width//4 # width #
++-n_layers = 2 # 8
+++n_layers = 2 # 4 # 8
++ 
++ # Discretization
++ #s = 32 # 32 # 64
++@@ -38,11 +38,13 @@
++ 
++ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_3232.mat' # correct
++ #matlab_dataset = 'SH3D_1500_Nt_101_Nx_32.mat'
++-matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++#matlab_dataset = 'SH3D_grf3d_1500_Nt_101_Nx_32.mat' # Correct code # TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results
+++
+++matlab_dataset = 'SH3D_grf3d_ff_2000_Nt_101_Nx_32.mat' # last correct dataset. used 2000 samples
++ # Plotting
++ 
++ # In configs/config_SH3D_TNO3d.py (Add these or ensure they exist)
++-Lx = 10 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
+++Lx = 15 # 10 # 15 # np.pi # 1.0 # Domain size (assuming Lx=Ly=Lz based on MATLAB)
++ Ly =Lx
++ Lz= Lx
++ 
++@@ -76,11 +78,11 @@
++ # PDE Parameters
++ epsilon = 0.15
++ #pde_weight = 0.3 # Example: 30% physics loss
++-pde_weight = 0.4 # Example: 70% physics loss
+++pde_weight = 0.5 # 0.2 # Example: 70% physics loss
++ 
++ # Learning Rate Scheduler Parameters (for StepLR)
++ scheduler_step = 20  # Decay learning rate every 20 epochs
++ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++-pde_loss_scaler = 1e1
+++pde_loss_scaler = 1e0
++ ###########################
++ # ... rest of config ...
++\ No newline at end of file
++Index: configs/config_CH3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_CH3D_FNO4d.py b/configs/config_CH3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1754055606895)
+++++ b/configs/config_CH3D_FNO4d.py	(date 1754055606895)
++@@ -0,0 +1,77 @@
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda:3'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1300 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+++nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
+++batch_size = 20 # 10 # 20 # 20 # 50 # 3 # 20 # 50 # 5 # 50
+++learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
+++weight_decay = 1e-4 # 1e-3 # 1e-4
+++epochs = 50 # 100 # 500 # 1000 # 25 # 100 # 1000
+++iterations = epochs * (nTrain // batch_size)
+++modes = 14 # 10 #12 # 14 # 16 # 10 # 16
+++width = 12 # 8 #12 #14 # 12 # 16 # 32
+++width_q = width # 2 * width #
+++width_h = width//2 # width//4 # width #
+++n_layers = 3 # 2 # 4 # 5 # 5 # 8
+++
+++# Discretization
+++
+++s = 32 # 64 # 32 # 64 #32 # 64
+++T_in = 1
+++T_out = 91 # 20 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True # False # True # False  # True
+++load_model = False # True # False # False #True
+++
+++# Database
+++parent_dir = './data/'
+++
+++#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
+++# Plotting
+++index = 62  # 24 # 62
+++#domain = [-np.pi, np.pi]
+++Lx = 2 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.05  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: configs/config_AC3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_AC3D_FNO4d.py b/configs/config_AC3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1754055606981)
+++++ b/configs/config_AC3D_FNO4d.py	(date 1754055606981)
++@@ -0,0 +1,76 @@
+++import numpy as np
+++
+++# General Setting
+++gpu_number = 'cuda'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1000 # 900 # 1000
+++nTest = 300 # 100 # 100
+++batch_size = 20 # 10 # 50 # 20 #5 # 25
+++learning_rate = 0.001
+++weight_decay = 1e-4
+++epochs = 20 # 50 # 100 # 900  # 100
+++iterations = epochs * (nTrain // batch_size)
+++modes =  14 # 8 # last time modes =  8
+++width =  12 # 32 # last time width =  32
+++width_q = width
+++width_h = width // 2 # width // 4 # last time
+++n_layers = 2 # 4
+++
+++# Discretization
+++s = 32
+++T_in = 1
+++T_out = 91 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True # False  # False
+++load_model = False # True  # True
+++
+++# Database
+++parent_dir = './data/'
+++# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'AC3D_32_1000.mat'
+++#matlab_dataset = 'AC3D_32_1300.mat'
+++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
+++# Plotting
+++index = 9 # 12
+++#domain = [-np.pi, np.pi]
+++Lx = 5 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
+++
+++# time_steps = [29, 69]
+++#time_steps = [39, 49, 59, 69, 79, 89, 99]
+++# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++#############
+++#Lx = np.pi            # Domain size from MATLAB
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.0001     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-5
++\ No newline at end of file
++Index: configs/config_AC3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1000 # 900 # 1000\nnTest = 300 # 100 # 100\nbatch_size = 50 # 20 #5 # 25\nlearning_rate = 0.001\nweight_decay = 1e-4\nepochs = 50 # 100 # 900  # 100\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 8 # last time modes =  8\nwidth =  12 # 32 # last time width =  32\nwidth_q = width\nwidth_h = width // 2 # width // 4 # last time\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # False\nload_model = False # True  # True\n\n# Database\nparent_dir = './data/'\n# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'\n#matlab_dataset = 'AC3D_32_1000.mat'\nmatlab_dataset = 'AC3D_32_1300.mat'\n# Plotting\nindex = 9 # 12\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 69]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]\n\n#############\nLx = np.pi            # Domain size from MATLAB\n# Time Discretization Parameters (from AC3D MATLAB)\ndt_sim = 0.0001     # Time step in the MATLAB simulation\nNt_sim = 50        # Total number of simulation steps in MATLAB\nnum_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)\n# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps\n# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output\n# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.\ndt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in\n# PDE Parameters for Allen-Cahn (AC3D)\n# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.\n# The PDE implemented in calculate_pde_residual was:\n# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)\nepsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter\n# PINN Specific Settings (if PINN_MODE is True in main.py)\npde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.\n# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\n\npde_loss_scaler = 1e-5
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_AC3D_FNO3d.py b/configs/config_AC3D_FNO3d.py
++--- a/configs/config_AC3D_FNO3d.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/configs/config_AC3D_FNO3d.py	(date 1754055607011)
++@@ -8,21 +8,21 @@
++ # Network Parameters
++ nTrain = 1000 # 900 # 1000
++ nTest = 300 # 100 # 100
++-batch_size = 50 # 20 #5 # 25
+++batch_size = 10 # 50 # 20 #5 # 25
++ learning_rate = 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 100 # 900  # 100
+++epochs = 20 # 50 # 100 # 900  # 100
++ iterations = epochs * (nTrain // batch_size)
++ modes =  14 # 8 # last time modes =  8
++ width =  12 # 32 # last time width =  32
++ width_q = width
++ width_h = width // 2 # width // 4 # last time
++-n_layers = 4
+++n_layers = 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -33,19 +33,25 @@
++ parent_dir = './data/'
++ # matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
++ #matlab_dataset = 'AC3D_32_1000.mat'
++-matlab_dataset = 'AC3D_32_1300.mat'
+++#matlab_dataset = 'AC3D_32_1300.mat'
+++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
++ # Plotting
++ index = 9 # 12
++-domain = [-np.pi, np.pi]
+++#domain = [-np.pi, np.pi]
+++Lx = 5 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
+++
++ # time_steps = [29, 69]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ # time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
+++time_steps = [0, 50, 90]
++ 
++ #############
++-Lx = np.pi            # Domain size from MATLAB
+++#Lx = np.pi            # Domain size from MATLAB
++ # Time Discretization Parameters (from AC3D MATLAB)
++ dt_sim = 0.0001     # Time step in the MATLAB simulation
++ Nt_sim = 50        # Total number of simulation steps in MATLAB
++Index: configs/config_MBE3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\nimport numpy as np\n\n# General Setting\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200 #1600 # 4000\nnTest = 300  # 400\nbatch_size = 50# 25 #100\nlearning_rate = 0.005\nweight_decay = 1e-4\nepochs = 50 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 12\nwidth = 12 #32\nwidth_q = width #32\nwidth_h = width // 2 # width # 32\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # True  # True\nload_model = False #True  # False  # False\n\n# Database\nparent_dir = './data/'\n#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'\nmatlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 9  # 72\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_MBE3D_FNO3d.py b/configs/config_MBE3D_FNO3d.py
++--- a/configs/config_MBE3D_FNO3d.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/configs/config_MBE3D_FNO3d.py	(date 1754055606967)
++@@ -9,21 +9,21 @@
++ # Network Parameters
++ nTrain = 1200 #1600 # 4000
++ nTest = 300  # 400
++-batch_size = 50# 25 #100
++-learning_rate = 0.005
+++batch_size = 10 # 20 # 50# 25 #100
+++learning_rate = 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 1000
+++epochs = 50 # 50 # 1000
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 # 12
++ width = 12 #32
++ width_q = width #32
++ width_h = width // 2 # width # 32
++-n_layers = 4
+++n_layers = 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -32,14 +32,44 @@
++ 
++ # Database
++ parent_dir = './data/'
++-#matlab_dataset = 'MBE3D_2000_Nt_101_Nx_32.mat'
++-matlab_dataset = 'MBE3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'MBE3D_Augmented_2000_Nt_101_Nx_32.mat'
+++
+++# Plotting
++ # Plotting
++-index = 9  # 72
++-domain = [-np.pi, np.pi]
+++index = 62  # 72
+++#domain = [-np.pi, np.pi]
+++Lx = 10 # np.pi            # Domain size from MATLAB
+++domain = [-Lx/2, Lx/2]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon = 0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_PFC3D_FNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>\"\"\"\nDevice:  cuda:0\nmodel = TNO2d_PFC2D_S64_T1to100_width32_modes12_q32_h16.pt\nnumber of epoch = 1000\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n2539703\n\nThe average testing error is 0.027059923857450485\nStd. deviation of testing error is 0.01980009116232395\n----------------------------------------------\nmodel = TNO2d_PFC2D_S64_T1to50_width16_modes12_q32_h16.pt\nnumber of epoch = 200\nbatch size = 100\nnTrain = 4000\nnTest = 400\nlearning_rate = 0.005\nn_layers = 4\nwidth_q = 32\nwidth_h = 16\n651059\n\nThe average testing error is 0.005057875066995621\nStd. deviation of testing error is 0.0021678071934729815\n----------------------------------------------\n\n\n\"\"\"\n\nimport numpy as np\n\n# General SettingnTrain = 1200 # 5250 # 7500\n\ngpu_number = 'cuda:1'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1200\nnTest = 300\nbatch_size = 50 # 100\nlearning_rate = 0.005\nweight_decay = 1e-4 # 1e-4\nepochs = 50\niterations = epochs * (nTrain // batch_size)\nmodes = 14 #12\nwidth = 12 # 16 # 32\nwidth_q = width # 32\nwidth_h = width//2 # 16\nn_layers = 4\n\n'''\ntau = 315;\nalpha = 115; \n'''\n\n# Discretization\ns = 32 # 64 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False  # True\nload_model = False # True # False # True  # False\n\n# Database\nparent_dir = './data/'\nmatlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'\n# Plotting\nindex = 200  # 110  # 200\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n# time_steps = [0, 2, 4, 6, 8, 9]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_PFC3D_FNO3d.py b/configs/config_PFC3D_FNO3d.py
++--- a/configs/config_PFC3D_FNO3d.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/configs/config_PFC3D_FNO3d.py	(date 1754055607031)
++@@ -43,16 +43,16 @@
++ # Network Parameters
++ nTrain = 1200
++ nTest = 300
++-batch_size = 50 # 100
++-learning_rate = 0.005
+++batch_size = 15 # 100
+++learning_rate = 0.001
++ weight_decay = 1e-4 # 1e-4
++-epochs = 50
+++epochs = 30 # 50
++ iterations = epochs * (nTrain // batch_size)
++ modes = 14 #12
++ width = 12 # 16 # 32
++ width_q = width # 32
++ width_h = width//2 # 16
++-n_layers = 4
+++n_layers = 2 # 4
++ 
++ '''
++ tau = 315;
++@@ -62,7 +62,7 @@
++ # Discretization
++ s = 32 # 64 # 64
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 91 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -71,14 +71,45 @@
++ 
++ # Database
++ parent_dir = './data/'
++-matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
++ # Plotting
++-index = 200  # 110  # 200
++-domain = [-np.pi, np.pi]
+++
+++# Plotting
+++index = 69  # 110  # 200
+++Lx = 10*np.pi
+++domain = [-5*np.pi, 5*np.pi]
++ # time_steps = [29, 35, 39, 45, 49]
++ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
++ #time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ # time_steps = [0, 2, 4, 6, 8, 9]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
++\ No newline at end of file
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.05 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_PFC3D_FNO4d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_PFC3D_FNO4d.py b/configs/config_PFC3D_FNO4d.py
++new file mode 100644
++--- /dev/null	(date 1754055607047)
+++++ b/configs/config_PFC3D_FNO4d.py	(date 1754055607047)
++@@ -0,0 +1,81 @@
+++import numpy as np
+++
+++# General SettingnTrain = 1200 # 5250 # 7500
+++
+++gpu_number = 'cuda:1'  # 'cuda:1'
+++torch_seed = 0
+++numpy_seed = 0
+++
+++# Network Parameters
+++nTrain = 1200
+++nTest = 300
+++batch_size = 20 # 15 # 100
+++learning_rate = 0.001
+++weight_decay = 1e-4 # 1e-4
+++epochs = 30 # 50
+++iterations = epochs * (nTrain // batch_size)
+++modes = 14 #12
+++width = 12 # 16 # 32
+++width_q = width # 32
+++width_h = width//2 # 16
+++n_layers = 2 # 4
+++
+++'''
+++tau = 315;
+++alpha = 115; 
+++'''
+++
+++# Discretization
+++s = 32 # 64 # 64
+++T_in = 1
+++T_out = 91 # 20 # 100
+++
+++# Training Setting
+++normalized = True
+++training = True # False  # True
+++load_model = False # True # False # True  # False
+++
+++# Database
+++parent_dir = './data/'
+++#matlab_dataset = 'PFC3D_1500_Nt_101_Nx_32.mat'
+++matlab_dataset = 'PFC3D_Augmented_1500_Nt_101_Nx_32.mat'
+++# Plotting
+++
+++# Plotting
+++index = 69  # 110  # 200
+++Lx = 10*np.pi
+++domain = [-5*np.pi, 5*np.pi]
+++# time_steps = [29, 35, 39, 45, 49]
+++# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+++#time_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+++#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+++# time_steps = [0, 2, 4, 6, 8, 9]
+++#time_steps = [39, 59, 79]
+++time_steps = [0, 50, 90]
+++
+++
+++
+++#############
+++
+++# Time Discretization Parameters (from AC3D MATLAB)
+++dt_sim = 0.05 # 0.1     # Time step in the MATLAB simulation
+++Nt_sim = 50        # Total number of simulation steps in MATLAB
+++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
+++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
+++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
+++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
+++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
+++# PDE Parameters for Allen-Cahn (AC3D)
+++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
+++# The PDE implemented in calculate_pde_residual was:
+++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
+++epsilon =  0.5 #0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
+++# PINN Specific Settings (if PINN_MODE is True in main.py)
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
+++
+++# Learning Rate Scheduler Parameters (for StepLR)
+++scheduler_step = 20  # Decay learning rate every 20 epochs
+++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
+++
+++pde_loss_scaler = 1e-6
++\ No newline at end of file
++Index: configs/config_AC3D_TNO3d.py
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 1000 # 900 # 1000\nnTest = 300 # 100 # 100\nbatch_size = 10 # 50 # 20 #5 # 25\nlearning_rate = 0.001\nweight_decay = 1e-4\nepochs = 50 # 100 # 900  # 100\niterations = epochs * (nTrain // batch_size)\nmodes =  14 # 8 # last time modes =  8\nwidth =  12 # 32 # last time width =  32\nwidth_q = width\nwidth_h = width // 2 # width // 4 # last time\nn_layers = 4\n\n# Discretization\ns = 32\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True  # False #  False\nload_model = False # True  #  True  # True\n\n# Database\nparent_dir = './data/'\n# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'\n#matlab_dataset = 'AC3D_32_1000.mat'\nmatlab_dataset = 'AC3D_32_1300.mat'\n# Plotting\nindex = 9 # 12\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 69]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n# time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]\n\n\n#############\nLx = np.pi            # Domain size from MATLAB\n# Time Discretization Parameters (from AC3D MATLAB)\ndt_sim = 0.0001     # Time step in the MATLAB simulation\nNt_sim = 50        # Total number of simulation steps in MATLAB\nnum_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)\n# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps\n# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output\n# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.\ndt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in\n# PDE Parameters for Allen-Cahn (AC3D)\n# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.\n# The PDE implemented in calculate_pde_residual was:\n# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)\nepsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter\n# PINN Specific Settings (if PINN_MODE is True in main.py)\npde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.\n# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference\n\n# Learning Rate Scheduler Parameters (for StepLR)\nscheduler_step = 20  # Decay learning rate every 20 epochs\nscheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time\n\npde_loss_scaler = 1e-3
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/configs/config_AC3D_TNO3d.py b/configs/config_AC3D_TNO3d.py
++--- a/configs/config_AC3D_TNO3d.py	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/configs/config_AC3D_TNO3d.py	(date 1754055607059)
++@@ -6,23 +6,23 @@
++ numpy_seed = 0
++ 
++ # Network Parameters
++-nTrain = 1000 # 900 # 1000
+++nTrain = 1200 # 900 # 1000
++ nTest = 300 # 100 # 100
++-batch_size = 10 # 50 # 20 #5 # 25
++-learning_rate = 0.001
+++batch_size = 20 # 20 # 50 # 20 #5 # 25
+++learning_rate = 0.001 # 0.001
++ weight_decay = 1e-4
++-epochs = 50 # 100 # 900  # 100
+++epochs = 20 # 50 #  # 100 # 900  # 100
++ iterations = epochs * (nTrain // batch_size)
++ modes =  14 # 8 # last time modes =  8
++-width =  12 # 32 # last time width =  32
+++width =  12 # 12 # 32 # last time width =  32
++ width_q = width
++ width_h = width // 2 # width // 4 # last time
++-n_layers = 4
+++n_layers = 2 # 2 # 4
++ 
++ # Discretization
++ s = 32
++ T_in = 1
++-T_out = 20 # 100
+++T_out = 100 # 20 # 100
++ 
++ # Training Setting
++ normalized = True
++@@ -31,24 +31,26 @@
++ 
++ # Database
++ parent_dir = './data/'
++-# matlab_dataset = 'AC3D_1200_Nt_101_Nx_32.mat'
++-#matlab_dataset = 'AC3D_32_1000.mat'
++-matlab_dataset = 'AC3D_32_1300.mat'
+++matlab_dataset = 'AC3D_32_1500_grf3d.mat'
+++#matlab_dataset ='AC3D_32_1500_Augmented.mat' # mixed --> 75% GRF and 25% sphere...
++ # Plotting
++ index = 9 # 12
++-domain = [-np.pi, np.pi]
+++Lx = 5 # np.pi            # Domain size from MATLAB
+++#domain = [-np.pi, np.pi]
+++domain = [-Lx/2, Lx/2]
+++
++ # time_steps = [29, 69]
++ #time_steps = [39, 49, 59, 69, 79, 89, 99]
++ # time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
++ #               54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
++ #time_steps = [39, 59, 79]
++-time_steps = [0, 9, 19]
+++time_steps = [1, 50, 90]
++ 
++ 
++ #############
++-Lx = np.pi            # Domain size from MATLAB
+++
++ # Time Discretization Parameters (from AC3D MATLAB)
++-dt_sim = 0.0001     # Time step in the MATLAB simulation
+++dt_sim = 0.0005     # Time step in the MATLAB simulation
++ Nt_sim = 50        # Total number of simulation steps in MATLAB
++ num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++ # ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++@@ -61,11 +63,11 @@
++ # du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++ epsilon = 0.1  # The epsilon from your AC3D MATLAB script, PDE parameter
++ # PINN Specific Settings (if PINN_MODE is True in main.py)
++-pde_weight = 0.5   # Example: 50% physics loss, 70% data loss. Adjust as needed.
+++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++ # PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++ 
++ # Learning Rate Scheduler Parameters (for StepLR)
++ scheduler_step = 20  # Decay learning rate every 20 epochs
++ scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++ 
++-pde_loss_scaler = 1e-3
++\ No newline at end of file
+++pde_loss_scaler = 1e-4
++\ No newline at end of file
++Index: .idea/workspace.xml
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"TNO3d vs FNO3d\">\n      <change afterPath=\"$PROJECT_DIR$/run_inference.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/vcs.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/vcs.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/main.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/main.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/networks.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/networks.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/post_processing.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/post_processing.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/training.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/training.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/utilities.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/utilities.py\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <excluded-from-favorite>\n      <branch-storage>\n        <map>\n          <entry type=\"LOCAL\">\n            <value>\n              <list>\n                <branch-info repo=\"$PROJECT_DIR$\" source=\"master\" />\n              </list>\n            </value>\n          </entry>\n        </map>\n      </branch-storage>\n    </excluded-from-favorite>\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\n      <map>\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\n      </map>\n    </option>\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n    <option name=\"ROOT_SYNC\" value=\"DONT_SYNC\" />\n  </component>\n  <component name=\"GitHubPullRequestSearchHistory\">{\n  &quot;lastFilter&quot;: {\n    &quot;state&quot;: &quot;OPEN&quot;,\n    &quot;assignee&quot;: &quot;MBamdad&quot;\n  }\n}</component>\n  <component name=\"GithubPullRequestsUISettings\">{\n  &quot;selectedUrlAndAccountId&quot;: {\n    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,\n    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;\n  }\n}</component>\n  <component name=\"ProjectColorInfo\">{\n  &quot;associatedIndex&quot;: 1\n}</component>\n  <component name=\"ProjectId\" id=\"2p11NySvsgjZ8eu9d53SI84567l\" />\n  <component name=\"ProjectReloadState\">\n    <option name=\"STATE\" value=\"1\" />\n  </component>\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">{\n  &quot;keyToString&quot;: {\n    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.main.executor&quot;: &quot;Run&quot;,\n    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.networks.executor&quot;: &quot;Run&quot;,\n    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,\n    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,\n    &quot;Python.test1.executor&quot;: &quot;Run&quot;,\n    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,\n    &quot;git-widget-placeholder&quot;: &quot;main&quot;,\n    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,\n    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,\n    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,\n    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,\n    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,\n    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,\n    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,\n    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;\n  },\n  &quot;keyToStringList&quot;: {\n    &quot;ChangesTree.GroupingKeys&quot;: [\n      &quot;directory&quot;\n    ]\n  }\n}</component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$/configs\" />\n      <recent name=\"$PROJECT_DIR$/AC2Dtest/models\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code/AC2D\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code\" />\n    </key>\n    <key name=\"MoveFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.AC3D_TNO3d\">\n    <configuration name=\"AC3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_TNO3d_hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"MBE3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d_Hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <list>\n      <item itemvalue=\"Python.AC3D_TNO3d\" />\n      <item itemvalue=\"Python.AC3d_FNO3d\" />\n      <item itemvalue=\"Python.AC3d_TNO3d_hybrid\" />\n      <item itemvalue=\"Python.CH3D_TNO3d\" />\n      <item itemvalue=\"Python.MBE3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_FNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d_Hybrid\" />\n    </list>\n  </component>\n  <component name=\"SharedIndexes\">\n    <attachedChunks>\n      <set>\n        <option value=\"bundled-js-predefined-1d06a55b98c1-0b3e54e931b4-JavaScript-PY-241.18034.82\" />\n        <option value=\"bundled-python-sdk-975db3bf15a3-2767605e8bc2-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-241.18034.82\" />\n      </set>\n    </attachedChunks>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"\" />\n      <created>1731918731711</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1731918731711</updated>\n      <workItem from=\"1731918732726\" duration=\"17070000\" />\n      <workItem from=\"1732010735784\" duration=\"777000\" />\n      <workItem from=\"1732011520582\" duration=\"8000\" />\n      <workItem from=\"1732011538945\" duration=\"13153000\" />\n      <workItem from=\"1732106481018\" duration=\"3721000\" />\n      <workItem from=\"1732480846034\" duration=\"2889000\" />\n      <workItem from=\"1732483872465\" duration=\"14926000\" />\n      <workItem from=\"1732567216112\" duration=\"964000\" />\n      <workItem from=\"1732765090621\" duration=\"5000\" />\n      <workItem from=\"1732765102609\" duration=\"12000\" />\n      <workItem from=\"1732765345288\" duration=\"10000\" />\n      <workItem from=\"1732903897716\" duration=\"3074000\" />\n      <workItem from=\"1732911303920\" duration=\"27201000\" />\n      <workItem from=\"1732999179592\" duration=\"8241000\" />\n      <workItem from=\"1733039613684\" duration=\"6792000\" />\n      <workItem from=\"1733095843263\" duration=\"10000\" />\n      <workItem from=\"1733140600841\" duration=\"6993000\" />\n      <workItem from=\"1733150993229\" duration=\"184000\" />\n      <workItem from=\"1733151279786\" duration=\"6000\" />\n      <workItem from=\"1733151296310\" duration=\"16875000\" />\n      <workItem from=\"1733233230739\" duration=\"5172000\" />\n      <workItem from=\"1733246997923\" duration=\"15986000\" />\n      <workItem from=\"1733349590652\" duration=\"1949000\" />\n      <workItem from=\"1733352121741\" duration=\"6332000\" />\n      <workItem from=\"1733405466233\" duration=\"12731000\" />\n      <workItem from=\"1733557048829\" duration=\"5541000\" />\n      <workItem from=\"1733583489891\" duration=\"16419000\" />\n      <workItem from=\"1733859258781\" duration=\"7356000\" />\n      <workItem from=\"1733995059967\" duration=\"7899000\" />\n      <workItem from=\"1734011167665\" duration=\"991000\" />\n      <workItem from=\"1734029966470\" duration=\"25769000\" />\n      <workItem from=\"1734205412700\" duration=\"7689000\" />\n      <workItem from=\"1734644992163\" duration=\"5017000\" />\n      <workItem from=\"1734788130789\" duration=\"2312000\" />\n      <workItem from=\"1734863751114\" duration=\"9000\" />\n      <workItem from=\"1734863775073\" duration=\"9221000\" />\n      <workItem from=\"1734880034791\" duration=\"57000\" />\n      <workItem from=\"1734880213539\" duration=\"15000\" />\n      <workItem from=\"1734880329890\" duration=\"30000\" />\n      <workItem from=\"1734880369064\" duration=\"31312000\" />\n      <workItem from=\"1734983129135\" duration=\"55000\" />\n      <workItem from=\"1735034212628\" duration=\"2274000\" />\n      <workItem from=\"1735049036048\" duration=\"5309000\" />\n      <workItem from=\"1735126261413\" duration=\"75000\" />\n      <workItem from=\"1735356723104\" duration=\"1208000\" />\n      <workItem from=\"1735422837186\" duration=\"1387000\" />\n      <workItem from=\"1735719009558\" duration=\"561000\" />\n      <workItem from=\"1736101930735\" duration=\"570000\" />\n      <workItem from=\"1736102511675\" duration=\"4000\" />\n      <workItem from=\"1736161159525\" duration=\"7670000\" />\n      <workItem from=\"1736237907904\" duration=\"111000\" />\n      <workItem from=\"1736519480236\" duration=\"1867000\" />\n      <workItem from=\"1737577034938\" duration=\"3945000\" />\n      <workItem from=\"1737590448155\" duration=\"6145000\" />\n      <workItem from=\"1738310597042\" duration=\"2502000\" />\n      <workItem from=\"1738316162773\" duration=\"726000\" />\n      <workItem from=\"1738326887364\" duration=\"4500000\" />\n      <workItem from=\"1738586797583\" duration=\"600000\" />\n      <workItem from=\"1738663690532\" duration=\"4505000\" />\n      <workItem from=\"1738668267214\" duration=\"5368000\" />\n      <workItem from=\"1738685509837\" duration=\"74000\" />\n      <workItem from=\"1738703726377\" duration=\"1677000\" />\n      <workItem from=\"1738774383038\" duration=\"2249000\" />\n      <workItem from=\"1738787637783\" duration=\"7013000\" />\n      <workItem from=\"1738962434877\" duration=\"1153000\" />\n      <workItem from=\"1738967049524\" duration=\"782000\" />\n      <workItem from=\"1739275350614\" duration=\"312000\" />\n      <workItem from=\"1739464522072\" duration=\"12498000\" />\n      <workItem from=\"1739572784568\" duration=\"1228000\" />\n      <workItem from=\"1739626528163\" duration=\"5778000\" />\n      <workItem from=\"1739689815626\" duration=\"10399000\" />\n      <workItem from=\"1739812786805\" duration=\"48519000\" />\n      <workItem from=\"1740212626723\" duration=\"1263000\" />\n      <workItem from=\"1740213932190\" duration=\"644000\" />\n      <workItem from=\"1741475492994\" duration=\"40894000\" />\n      <workItem from=\"1741690305204\" duration=\"339000\" />\n      <workItem from=\"1741705983516\" duration=\"604000\" />\n      <workItem from=\"1741713165753\" duration=\"1198000\" />\n      <workItem from=\"1741861318912\" duration=\"2286000\" />\n      <workItem from=\"1742201562752\" duration=\"618000\" />\n      <workItem from=\"1742209067924\" duration=\"383000\" />\n      <workItem from=\"1742226300133\" duration=\"2432000\" />\n      <workItem from=\"1743071528350\" duration=\"9513000\" />\n      <workItem from=\"1743490058046\" duration=\"9000\" />\n      <workItem from=\"1743587112942\" duration=\"1188000\" />\n      <workItem from=\"1748900986740\" duration=\"1771000\" />\n      <workItem from=\"1748931928220\" duration=\"446000\" />\n      <workItem from=\"1748932436127\" duration=\"20890000\" />\n      <workItem from=\"1748970706276\" duration=\"3719000\" />\n      <workItem from=\"1748988822181\" duration=\"59000\" />\n      <workItem from=\"1749200290051\" duration=\"680000\" />\n      <workItem from=\"1749203502833\" duration=\"1349000\" />\n      <workItem from=\"1749213099437\" duration=\"3082000\" />\n      <workItem from=\"1750057109660\" duration=\"10453000\" />\n      <workItem from=\"1750070416210\" duration=\"46415000\" />\n    </task>\n    <task id=\"LOCAL-00001\" summary=\"Initial Commit\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732484343908</created>\n      <option name=\"number\" value=\"00001\" />\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732484343908</updated>\n    </task>\n    <task id=\"LOCAL-00002\" summary=\"added TransformerFNO\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732497990642</created>\n      <option name=\"number\" value=\"00002\" />\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732497990642</updated>\n    </task>\n    <task id=\"LOCAL-00003\" summary=\"added the connection between time steps - the model development is finished\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732910153380</created>\n      <option name=\"number\" value=\"00003\" />\n      <option name=\"presentableId\" value=\"LOCAL-00003\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732910153380</updated>\n    </task>\n    <task id=\"LOCAL-00004\" summary=\"Finished Allen-Cahn Problem\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733176021525</created>\n      <option name=\"number\" value=\"00004\" />\n      <option name=\"presentableId\" value=\"LOCAL-00004\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733176021525</updated>\n    </task>\n    <task id=\"LOCAL-00005\" summary=\"Added Allen-Cahn 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733583274023</created>\n      <option name=\"number\" value=\"00005\" />\n      <option name=\"presentableId\" value=\"LOCAL-00005\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733583274023</updated>\n    </task>\n    <task id=\"LOCAL-00006\" summary=\"added save_vtk\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733995237535</created>\n      <option name=\"number\" value=\"00006\" />\n      <option name=\"presentableId\" value=\"LOCAL-00006\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733995237535</updated>\n    </task>\n    <task id=\"LOCAL-00007\" summary=\"added MATLAB codes for creating database\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1734788540933</created>\n      <option name=\"number\" value=\"00007\" />\n      <option name=\"presentableId\" value=\"LOCAL-00007\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1734788540933</updated>\n    </task>\n    <task id=\"LOCAL-00008\" summary=\"added CH2DNL\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735126332032</created>\n      <option name=\"number\" value=\"00008\" />\n      <option name=\"presentableId\" value=\"LOCAL-00008\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735126332032</updated>\n    </task>\n    <task id=\"LOCAL-00009\" summary=\"added SH2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735719422931</created>\n      <option name=\"number\" value=\"00009\" />\n      <option name=\"presentableId\" value=\"LOCAL-00009\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735719422931</updated>\n    </task>\n    <task id=\"LOCAL-00010\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1736237977029</created>\n      <option name=\"number\" value=\"00010\" />\n      <option name=\"presentableId\" value=\"LOCAL-00010\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1736237977029</updated>\n    </task>\n    <task id=\"LOCAL-00011\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738788849261</created>\n      <option name=\"number\" value=\"00011\" />\n      <option name=\"presentableId\" value=\"LOCAL-00011\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738788849261</updated>\n    </task>\n    <task id=\"LOCAL-00012\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738789326593</created>\n      <option name=\"number\" value=\"00012\" />\n      <option name=\"presentableId\" value=\"LOCAL-00012\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738789326593</updated>\n    </task>\n    <task id=\"LOCAL-00013\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738796104012</created>\n      <option name=\"number\" value=\"00013\" />\n      <option name=\"presentableId\" value=\"LOCAL-00013\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738796104012</updated>\n    </task>\n    <task id=\"LOCAL-00014\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962464719</created>\n      <option name=\"number\" value=\"00014\" />\n      <option name=\"presentableId\" value=\"LOCAL-00014\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962464719</updated>\n    </task>\n    <task id=\"LOCAL-00015\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962748829</created>\n      <option name=\"number\" value=\"00015\" />\n      <option name=\"presentableId\" value=\"LOCAL-00015\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962748829</updated>\n    </task>\n    <task id=\"LOCAL-00016\" summary=\"Turn Nx to 64\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738967163754</created>\n      <option name=\"number\" value=\"00016\" />\n      <option name=\"presentableId\" value=\"LOCAL-00016\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738967163754</updated>\n    </task>\n    <task id=\"LOCAL-00017\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275401458</created>\n      <option name=\"number\" value=\"00017\" />\n      <option name=\"presentableId\" value=\"LOCAL-00017\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275401458</updated>\n    </task>\n    <task id=\"LOCAL-00018\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275433418</created>\n      <option name=\"number\" value=\"00018\" />\n      <option name=\"presentableId\" value=\"LOCAL-00018\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275433418</updated>\n    </task>\n    <task id=\"LOCAL-00019\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690373369</created>\n      <option name=\"number\" value=\"00019\" />\n      <option name=\"presentableId\" value=\"LOCAL-00019\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690373369</updated>\n    </task>\n    <task id=\"LOCAL-00020\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690420059</created>\n      <option name=\"number\" value=\"00020\" />\n      <option name=\"presentableId\" value=\"LOCAL-00020\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690420059</updated>\n    </task>\n    <task id=\"LOCAL-00021\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1743587271259</created>\n      <option name=\"number\" value=\"00021\" />\n      <option name=\"presentableId\" value=\"LOCAL-00021\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1743587271259</updated>\n    </task>\n    <option name=\"localTasksCounter\" value=\"22\" />\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"Vcs.Log.Tabs.Properties\">\n    <option name=\"RECENT_FILTERS\">\n      <map>\n        <entry key=\"Branch\">\n          <value>\n            <list>\n              <RecentGroup>\n                <option name=\"FILTER_VALUES\">\n                  <option value=\"main\" />\n                </option>\n              </RecentGroup>\n            </list>\n          </value>\n        </entry>\n      </map>\n    </option>\n    <option name=\"TAB_STATES\">\n      <map>\n        <entry key=\"MAIN\">\n          <value>\n            <State>\n              <option name=\"FILTERS\">\n                <map>\n                  <entry key=\"branch\">\n                    <value>\n                      <list>\n                        <option value=\"main\" />\n                      </list>\n                    </value>\n                  </entry>\n                </map>\n              </option>\n            </State>\n          </value>\n        </entry>\n      </map>\n    </option>\n  </component>\n  <component name=\"VcsManagerConfiguration\">\n    <MESSAGE value=\"Initial Commit\" />\n    <MESSAGE value=\"added TransformerFNO\" />\n    <MESSAGE value=\"added the connection between time steps - the model development is finished\" />\n    <MESSAGE value=\"refactored\" />\n    <MESSAGE value=\"Finished Allen-Cahn Problem\" />\n    <MESSAGE value=\"Added Allen-Cahn 3D\" />\n    <MESSAGE value=\"added save_vtk\" />\n    <MESSAGE value=\"added MATLAB codes for creating database\" />\n    <MESSAGE value=\"seperated the number of layers in fourier part and convolutional part\" />\n    <MESSAGE value=\"added CH2DNL\" />\n    <MESSAGE value=\"added SH2D\" />\n    <MESSAGE value=\"added PFC2D\" />\n    <MESSAGE value=\"Turn Nx to 64\" />\n    <MESSAGE value=\"update to 3D\" />\n    <MESSAGE value=\"TNO3d vs FNO3d\" />\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"TNO3d vs FNO3d\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>142</line>\n          <option name=\"timeStamp\" value=\"17\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>163</line>\n          <option name=\"timeStamp\" value=\"18\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>134</line>\n          <option name=\"timeStamp\" value=\"19\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>327</line>\n          <option name=\"timeStamp\" value=\"20\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>243</line>\n          <option name=\"timeStamp\" value=\"21\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_2.py</url>\n          <line>333</line>\n          <option name=\"timeStamp\" value=\"27\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>\n          <line>371</line>\n          <option name=\"timeStamp\" value=\"44\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>\n          <line>338</line>\n          <option name=\"timeStamp\" value=\"54\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>53</line>\n          <option name=\"timeStamp\" value=\"128\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>30</line>\n          <option name=\"timeStamp\" value=\"129\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>25</line>\n          <option name=\"timeStamp\" value=\"133\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>18</line>\n          <option name=\"timeStamp\" value=\"135\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>\n          <line>44</line>\n          <option name=\"timeStamp\" value=\"138\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test2.py</url>\n          <line>16</line>\n          <option name=\"timeStamp\" value=\"144\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/utilities.py</url>\n          <line>98</line>\n          <option name=\"timeStamp\" value=\"170\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/main.py</url>\n          <line>157</line>\n          <option name=\"timeStamp\" value=\"177\" />\n        </line-breakpoint>\n      </breakpoints>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n  </component>\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test3.coverage\" NAME=\"Test3 Coverage Results\" MODIFIED=\"1739273938386\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage\" NAME=\"config_AC2D_FNO3d Coverage Results\" MODIFIED=\"1733233385695\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1743065376798\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_2.coverage\" NAME=\"AC2D_Net2D_2 Coverage Results\" MODIFIED=\"1732904114403\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$test2.coverage\" NAME=\"test2 Coverage Results\" MODIFIED=\"1742889074336\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1741561715014\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage\" NAME=\"config_SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254757455\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$backend_interagg.coverage\" NAME=\"backend_interagg Coverage Results\" MODIFIED=\"1737630366471\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript3.coverage\" NAME=\"RunScript3 Coverage Results\" MODIFIED=\"1736368081257\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_2.coverage\" NAME=\"AC2D_2 Coverage Results\" MODIFIED=\"1732483323689\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1733086051390\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main_TF.coverage\" NAME=\"main_TF Coverage Results\" MODIFIED=\"1738704014479\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1741538869064\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$THFNO.coverage\" NAME=\"THFNO Coverage Results\" MODIFIED=\"1732911474644\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/networks\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1740088478224\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$PFC3D.coverage\" NAME=\"PFC3D Coverage Results\" MODIFIED=\"1740083613128\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1741603428589\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$run_inference.coverage\" NAME=\"run_inference Coverage Results\" MODIFIED=\"1750323709039\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1738663765959\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$post_processing.coverage\" NAME=\"post_processing Coverage Results\" MODIFIED=\"1733557098801\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage\" NAME=\"config_CH2D_TNO2d Coverage Results\" MODIFIED=\"1734086207850\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1748933697533\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1750255151255\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript2.coverage\" NAME=\"RunScript2 Coverage Results\" MODIFIED=\"1736369209710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1742215946758\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_3.coverage\" NAME=\"AC2D_Net2D_3 Coverage Results\" MODIFIED=\"1732974697103\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_FNO3d.coverage\" NAME=\"AC3d_FNO3d Coverage Results\" MODIFIED=\"1749017845623\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D.coverage\" NAME=\"AC2D Coverage Results\" MODIFIED=\"1733088640665\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/Archive_Code\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D.coverage\" NAME=\"AC2D_Net2D Coverage Results\" MODIFIED=\"1732567473230\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1740054182408\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage\" NAME=\"MBE3D_TNO3d Coverage Results\" MODIFIED=\"1741562061391\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_AC3D_TNO3d.coverage\" NAME=\"config_AC3D_TNO3d Coverage Results\" MODIFIED=\"1737644605063\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D.coverage\" NAME=\"MBE3D Coverage Results\" MODIFIED=\"1739283566145\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1741605347375\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1743071672425\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1736268192289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage\" NAME=\"PFC3D_TNO3d Coverage Results\" MODIFIED=\"1741564210973\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage\" NAME=\"config_CH2DNL_TNO2d Coverage Results\" MODIFIED=\"1735052490996\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$MBE2D.coverage\" NAME=\"MBE2D Coverage Results\" MODIFIED=\"1732278526731\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1739914172084\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test_Run.coverage\" NAME=\"Test_Run Coverage Results\" MODIFIED=\"1738945320139\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1741561294310\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741861381348\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1743081225414\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage\" NAME=\"PFV3D_FNO3d Coverage Results\" MODIFIED=\"1741564487710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript1.coverage\" NAME=\"RunScript1 Coverage Results\" MODIFIED=\"1736368790622\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$SH2D.coverage\" NAME=\"SH2D Coverage Results\" MODIFIED=\"1732347080402\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$PFC2D.coverage\" NAME=\"PFC2D Coverage Results\" MODIFIED=\"1732278679485\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$CH2D.coverage\" NAME=\"CH2D Coverage Results\" MODIFIED=\"1732347055915\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_FNO3d.coverage\" NAME=\"AC3D_FNO3d Coverage Results\" MODIFIED=\"1741561435127\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D.coverage\" NAME=\"SH3D Coverage Results\" MODIFIED=\"1739044808411\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test.coverage\" NAME=\"Test Coverage Results\" MODIFIED=\"1739459206236\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741547133078\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage\" NAME=\"config_AC2D_FNO2d Coverage Results\" MODIFIED=\"1733393903488\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$AC3D.coverage\" NAME=\"AC3D Coverage Results\" MODIFIED=\"1740041515520\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_CH3D_TNO3d.coverage\" NAME=\"config_CH3D_TNO3d Coverage Results\" MODIFIED=\"1738089807566\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test2.coverage\" NAME=\"Test2 Coverage Results\" MODIFIED=\"1739283715182\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_FNO3d.coverage\" NAME=\"CH3D_FNO3d Coverage Results\" MODIFIED=\"1741628529142\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage\" NAME=\"AC3d_TNO3d_hybrid Coverage Results\" MODIFIED=\"1748989478372\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1737899062785\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D.coverage\" NAME=\"config_AC2D Coverage Results\" MODIFIED=\"1733087276180\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_1.coverage\" NAME=\"AC2D_Net2D_1 Coverage Results\" MODIFIED=\"1732535211383\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1736520700819\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$fourier_3d.coverage\" NAME=\"fourier_3d Coverage Results\" MODIFIED=\"1732221600628\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1750254767095\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage\" NAME=\"SH3D_TNO3d_Hybrid Coverage Results\" MODIFIED=\"1749216389646\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1748990262244\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$test1.coverage\" NAME=\"test1 Coverage Results\" MODIFIED=\"1733413325318\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_2.coverage\" NAME=\"CH3D_2 Coverage Results\" MODIFIED=\"1739918355289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254975290\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage\" NAME=\"config_MBE2D_TNO2d Coverage Results\" MODIFIED=\"1736261397712\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n  </component>\n</project>
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/.idea/workspace.xml b/.idea/workspace.xml
++--- a/.idea/workspace.xml	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/.idea/workspace.xml	(date 1754475619682)
++@@ -4,29 +4,87 @@
++     <option name="autoReloadType" value="SELECTIVE" />
++   </component>
++   <component name="ChangeListManager">
++-    <list default="true" id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="TNO3d vs FNO3d">
++-      <change afterPath="$PROJECT_DIR$/run_inference.py" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/.idea/vcs.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />
+++    <list default="true" id="4e84c369-97f3-4301-a9fc-5fc5327e1a8a" name="Changes" comment="3d_phase_evolution">
+++      <change afterPath="$PROJECT_DIR$/MBE3D/plots_Data_Physics_TNO3d/MBE3D_Hybrid.jpg" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/MatlabCode/In_Distribution/3D_phase_evolution4GRF.m" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/MatlabCode/Out_Distribution/AC3D_Spherical_Comparison.m" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/MatlabCode/Out_Distribution/CH3D_Star_Comparison.m" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/MatlabCode/Out_Distribution/SH3D_Spherical_Comparison.m" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/PFC3D.iml" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_CH3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_MBE3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_PFC3D_FNO4d.py" afterDir="false" />
+++      <change afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO4d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png" beforeDir="false" />
++-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_FNO3d/combined_results.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MBE3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/AC2D.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/AC2D_4circle.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/AC2D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/AC3D.m" beforeDir="false" afterPath="$PROJECT_DIR$/MatlabCode/AC3D.m" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/AC3D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/AC3D_rand_new.asv" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/AC3D_rand_new.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH2D.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH2DNL.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH2DNL_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH2D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D.m" beforeDir="false" afterPath="$PROJECT_DIR$/MatlabCode/CH3D.m" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_random_new.asv" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_random_new.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/CH3D_test.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/GRF.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/GRF3D.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/GRFtest.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/MBE2D.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/MBE2D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/MBE3D_rand.asv" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/MBE3D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/PFC2D.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/PFC2D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/PFC3D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH2D.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH2D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH3D.m" beforeDir="false" afterPath="$PROJECT_DIR$/MatlabCode/SH3D.m" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/SH3D_rand.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/MatlabCode/middle.m" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d/PFC3D_Hybrid_loss_curve_mixed.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_field_comparison_FINAL.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/PFC3D_FNO_loss_curve.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_FNO3d/combined_results.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_field_comparison_mixed.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/PFC3D_SANO_loss_curve_mixed.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/PFC3D/plots_TNO3d/combined_results.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" beforeDir="false" afterPath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/SH3D_Hybrid_field_comparison.png" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_Data_Physics_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" beforeDir="false" afterPath="$PROJECT_DIR$/SH3D/plots_FNO3d/SH3D_FNO_field_comparison.png" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/CH3D_Comparison_star_SANO.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_Comparison_Plot_Modified.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_SANO_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
+++      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_CH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_CH3D_FNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_CH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_CH3D_TNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_MBE3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_MBE3D_FNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_MBE3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_MBE3D_TNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_PFC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_PFC3D_FNO3d.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/main.py" beforeDir="false" afterPath="$PROJECT_DIR$/main.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/main1.py" beforeDir="false" afterPath="$PROJECT_DIR$/main1.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/networks.py" beforeDir="false" afterPath="$PROJECT_DIR$/networks.py" afterDir="false" />
++-      <change beforePath="$PROJECT_DIR$/post_processing.py" beforeDir="false" afterPath="$PROJECT_DIR$/post_processing.py" afterDir="false" />
+++      <change beforePath="$PROJECT_DIR$/run_interface3.py" beforeDir="false" afterPath="$PROJECT_DIR$/run_interface3.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/training.py" beforeDir="false" afterPath="$PROJECT_DIR$/training.py" afterDir="false" />
++       <change beforePath="$PROJECT_DIR$/utilities.py" beforeDir="false" afterPath="$PROJECT_DIR$/utilities.py" afterDir="false" />
++     </list>
++@@ -43,163 +101,49 @@
++     </option>
++   </component>
++   <component name="Git.Settings">
++-    <excluded-from-favorite>
++-      <branch-storage>
++-        <map>
++-          <entry type="LOCAL">
++-            <value>
++-              <list>
++-                <branch-info repo="$PROJECT_DIR$" source="master" />
++-              </list>
++-            </value>
++-          </entry>
++-        </map>
++-      </branch-storage>
++-    </excluded-from-favorite>
++-    <option name="RECENT_BRANCH_BY_REPOSITORY">
++-      <map>
++-        <entry key="$PROJECT_DIR$" value="main" />
++-      </map>
++-    </option>
++     <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
++-    <option name="ROOT_SYNC" value="DONT_SYNC" />
++   </component>
++-  <component name="GitHubPullRequestSearchHistory">{
++-  &quot;lastFilter&quot;: {
++-    &quot;state&quot;: &quot;OPEN&quot;,
++-    &quot;assignee&quot;: &quot;MBamdad&quot;
++-  }
++-}</component>
++-  <component name="GithubPullRequestsUISettings">{
++-  &quot;selectedUrlAndAccountId&quot;: {
++-    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,
++-    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;
++-  }
++-}</component>
++   <component name="ProjectColorInfo">{
+++  &quot;customColor&quot;: &quot;&quot;,
++   &quot;associatedIndex&quot;: 1
++ }</component>
++-  <component name="ProjectId" id="2p11NySvsgjZ8eu9d53SI84567l" />
++-  <component name="ProjectReloadState">
++-    <option name="STATE" value="1" />
++-  </component>
+++  <component name="ProjectId" id="30Ji1A2o7U8uDkwC8cwxQfRFc4k" />
++   <component name="ProjectViewState">
++     <option name="hideEmptyMiddlePackages" value="true" />
++     <option name="showLibraryContents" value="true" />
++   </component>
++   <component name="PropertiesComponent">{
++   &quot;keyToString&quot;: {
++-    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.Test.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.CH3D_FNO4d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.PFC3D_FNO4d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.SH3D_FNO4d.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.SH3D_Hybrid.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.SH3D_TNO3D.executor&quot;: &quot;Run&quot;,
++     &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,
++     &quot;Python.main.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,
++-    &quot;Python.networks.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,
++-    &quot;Python.test1.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.main1.executor&quot;: &quot;Run&quot;,
+++    &quot;Python.run_interface3.executor&quot;: &quot;Run&quot;,
++     &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
++     &quot;git-widget-placeholder&quot;: &quot;main&quot;,
++-    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,
+++    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/SH3D/plots_FNO4d&quot;,
++     &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
++-    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,
++     &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
++     &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,
++     &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,
++-    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,
++     &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;
++-  },
++-  &quot;keyToStringList&quot;: {
++-    &quot;ChangesTree.GroupingKeys&quot;: [
++-      &quot;directory&quot;
++-    ]
++   }
++ }</component>
++   <component name="RecentsManager">
++     <key name="CopyFile.RECENT_KEYS">
++-      <recent name="$PROJECT_DIR$/data" />
++-      <recent name="$PROJECT_DIR$/configs" />
++-      <recent name="$PROJECT_DIR$/AC2Dtest/models" />
++-      <recent name="$PROJECT_DIR$/Archive_Code/AC2D" />
++-      <recent name="$PROJECT_DIR$/Archive_Code" />
++-    </key>
++-    <key name="MoveFile.RECENT_KEYS">
++-      <recent name="$PROJECT_DIR$/data" />
++-      <recent name="$PROJECT_DIR$" />
+++      <recent name="$PROJECT_DIR$/SH3D/plots_FNO4d" />
+++      <recent name="$PROJECT_DIR$/MatlabCode" />
+++      <recent name="$PROJECT_DIR$/MatlabCode/Out_Distribution" />
+++      <recent name="$PROJECT_DIR$/MatlabCode/In_Distribution" />
+++      <recent name="$PROJECT_DIR$/SH3D/plots_TNO3d" />
++     </key>
++   </component>
++-  <component name="RunManager" selected="Python.AC3D_TNO3d">
++-    <configuration name="AC3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="AC3d_FNO3d" type="PythonConfigurationType" factoryName="Python">
+++  <component name="RunManager" selected="Python.CH3D_FNO4d">
+++    <configuration name="CH3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
++       <module name="PhaseFieldNet" />
++       <option name="ENV_FILES" value="" />
++       <option name="INTERPRETER_OPTIONS" value="" />
++@@ -223,7 +167,7 @@
++       <option name="INPUT_FILE" value="" />
++       <method v="2" />
++     </configuration>
++-    <configuration name="AC3d_TNO3d_hybrid" type="PythonConfigurationType" factoryName="Python">
+++    <configuration name="PFC3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
++       <module name="PhaseFieldNet" />
++       <option name="ENV_FILES" value="" />
++       <option name="INTERPRETER_OPTIONS" value="" />
++@@ -247,127 +191,7 @@
++       <option name="INPUT_FILE" value="" />
++       <method v="2" />
++     </configuration>
++-    <configuration name="CH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="CH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="MBE3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="SH3D_FNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="SH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
++-      <module name="PhaseFieldNet" />
++-      <option name="ENV_FILES" value="" />
++-      <option name="INTERPRETER_OPTIONS" value="" />
++-      <option name="PARENT_ENVS" value="true" />
++-      <envs>
++-        <env name="PYTHONUNBUFFERED" value="1" />
++-      </envs>
++-      <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
++-      <option name="WORKING_DIRECTORY" value="" />
++-      <option name="IS_MODULE_SDK" value="false" />
++-      <option name="ADD_CONTENT_ROOTS" value="true" />
++-      <option name="ADD_SOURCE_ROOTS" value="true" />
++-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
++-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
++-      <option name="PARAMETERS" value="" />
++-      <option name="SHOW_COMMAND_LINE" value="false" />
++-      <option name="EMULATE_TERMINAL" value="false" />
++-      <option name="MODULE_MODE" value="false" />
++-      <option name="REDIRECT_INPUT" value="false" />
++-      <option name="INPUT_FILE" value="" />
++-      <method v="2" />
++-    </configuration>
++-    <configuration name="SH3D_TNO3d_Hybrid" type="PythonConfigurationType" factoryName="Python">
+++    <configuration name="SH3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
++       <module name="PhaseFieldNet" />
++       <option name="ENV_FILES" value="" />
++       <option name="INTERPRETER_OPTIONS" value="" />
++@@ -376,7 +200,7 @@
++         <env name="PYTHONUNBUFFERED" value="1" />
++       </envs>
++       <option name="SDK_HOME" value="" />
++-      <option name="SDK_NAME" value="torch_env (2)" />
+++      <option name="SDK_NAME" value="torch_env" />
++       <option name="WORKING_DIRECTORY" value="" />
++       <option name="IS_MODULE_SDK" value="false" />
++       <option name="ADD_CONTENT_ROOTS" value="true" />
++@@ -392,14 +216,9 @@
++       <method v="2" />
++     </configuration>
++     <list>
++-      <item itemvalue="Python.AC3D_TNO3d" />
++-      <item itemvalue="Python.AC3d_FNO3d" />
++-      <item itemvalue="Python.AC3d_TNO3d_hybrid" />
++-      <item itemvalue="Python.CH3D_TNO3d" />
++-      <item itemvalue="Python.MBE3D_TNO3d" />
++-      <item itemvalue="Python.SH3D_FNO3d" />
++-      <item itemvalue="Python.SH3D_TNO3d" />
++-      <item itemvalue="Python.SH3D_TNO3d_Hybrid" />
+++      <item itemvalue="Python.CH3D_FNO4d" />
+++      <item itemvalue="Python.PFC3D_FNO4d" />
+++      <item itemvalue="Python.SH3D_FNO4d" />
++     </list>
++   </component>
++   <component name="SharedIndexes">
++@@ -413,501 +232,312 @@
++   <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
++   <component name="TaskManager">
++     <task active="true" id="Default" summary="Default task">
++-      <changelist id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="" />
++-      <created>1731918731711</created>
+++      <changelist id="4e84c369-97f3-4301-a9fc-5fc5327e1a8a" name="Changes" comment="3d_phase_evolution" />
+++      <created>1753351859462</created>
++       <option name="number" value="Default" />
++       <option name="presentableId" value="Default" />
++-      <updated>1731918731711</updated>
++-      <workItem from="1731918732726" duration="17070000" />
++-      <workItem from="1732010735784" duration="777000" />
++-      <workItem from="1732011520582" duration="8000" />
++-      <workItem from="1732011538945" duration="13153000" />
++-      <workItem from="1732106481018" duration="3721000" />
++-      <workItem from="1732480846034" duration="2889000" />
++-      <workItem from="1732483872465" duration="14926000" />
++-      <workItem from="1732567216112" duration="964000" />
++-      <workItem from="1732765090621" duration="5000" />
++-      <workItem from="1732765102609" duration="12000" />
++-      <workItem from="1732765345288" duration="10000" />
++-      <workItem from="1732903897716" duration="3074000" />
++-      <workItem from="1732911303920" duration="27201000" />
++-      <workItem from="1732999179592" duration="8241000" />
++-      <workItem from="1733039613684" duration="6792000" />
++-      <workItem from="1733095843263" duration="10000" />
++-      <workItem from="1733140600841" duration="6993000" />
++-      <workItem from="1733150993229" duration="184000" />
++-      <workItem from="1733151279786" duration="6000" />
++-      <workItem from="1733151296310" duration="16875000" />
++-      <workItem from="1733233230739" duration="5172000" />
++-      <workItem from="1733246997923" duration="15986000" />
++-      <workItem from="1733349590652" duration="1949000" />
++-      <workItem from="1733352121741" duration="6332000" />
++-      <workItem from="1733405466233" duration="12731000" />
++-      <workItem from="1733557048829" duration="5541000" />
++-      <workItem from="1733583489891" duration="16419000" />
++-      <workItem from="1733859258781" duration="7356000" />
++-      <workItem from="1733995059967" duration="7899000" />
++-      <workItem from="1734011167665" duration="991000" />
++-      <workItem from="1734029966470" duration="25769000" />
++-      <workItem from="1734205412700" duration="7689000" />
++-      <workItem from="1734644992163" duration="5017000" />
++-      <workItem from="1734788130789" duration="2312000" />
++-      <workItem from="1734863751114" duration="9000" />
++-      <workItem from="1734863775073" duration="9221000" />
++-      <workItem from="1734880034791" duration="57000" />
++-      <workItem from="1734880213539" duration="15000" />
++-      <workItem from="1734880329890" duration="30000" />
++-      <workItem from="1734880369064" duration="31312000" />
++-      <workItem from="1734983129135" duration="55000" />
++-      <workItem from="1735034212628" duration="2274000" />
++-      <workItem from="1735049036048" duration="5309000" />
++-      <workItem from="1735126261413" duration="75000" />
++-      <workItem from="1735356723104" duration="1208000" />
++-      <workItem from="1735422837186" duration="1387000" />
++-      <workItem from="1735719009558" duration="561000" />
++-      <workItem from="1736101930735" duration="570000" />
++-      <workItem from="1736102511675" duration="4000" />
++-      <workItem from="1736161159525" duration="7670000" />
++-      <workItem from="1736237907904" duration="111000" />
++-      <workItem from="1736519480236" duration="1867000" />
++-      <workItem from="1737577034938" duration="3945000" />
++-      <workItem from="1737590448155" duration="6145000" />
++-      <workItem from="1738310597042" duration="2502000" />
++-      <workItem from="1738316162773" duration="726000" />
++-      <workItem from="1738326887364" duration="4500000" />
++-      <workItem from="1738586797583" duration="600000" />
++-      <workItem from="1738663690532" duration="4505000" />
++-      <workItem from="1738668267214" duration="5368000" />
++-      <workItem from="1738685509837" duration="74000" />
++-      <workItem from="1738703726377" duration="1677000" />
++-      <workItem from="1738774383038" duration="2249000" />
++-      <workItem from="1738787637783" duration="7013000" />
++-      <workItem from="1738962434877" duration="1153000" />
++-      <workItem from="1738967049524" duration="782000" />
++-      <workItem from="1739275350614" duration="312000" />
++-      <workItem from="1739464522072" duration="12498000" />
++-      <workItem from="1739572784568" duration="1228000" />
++-      <workItem from="1739626528163" duration="5778000" />
++-      <workItem from="1739689815626" duration="10399000" />
++-      <workItem from="1739812786805" duration="48519000" />
++-      <workItem from="1740212626723" duration="1263000" />
++-      <workItem from="1740213932190" duration="644000" />
++-      <workItem from="1741475492994" duration="40894000" />
++-      <workItem from="1741690305204" duration="339000" />
++-      <workItem from="1741705983516" duration="604000" />
++-      <workItem from="1741713165753" duration="1198000" />
++-      <workItem from="1741861318912" duration="2286000" />
++-      <workItem from="1742201562752" duration="618000" />
++-      <workItem from="1742209067924" duration="383000" />
++-      <workItem from="1742226300133" duration="2432000" />
++-      <workItem from="1743071528350" duration="9513000" />
++-      <workItem from="1743490058046" duration="9000" />
++-      <workItem from="1743587112942" duration="1188000" />
++-      <workItem from="1748900986740" duration="1771000" />
++-      <workItem from="1748931928220" duration="446000" />
++-      <workItem from="1748932436127" duration="20890000" />
++-      <workItem from="1748970706276" duration="3719000" />
++-      <workItem from="1748988822181" duration="59000" />
++-      <workItem from="1749200290051" duration="680000" />
++-      <workItem from="1749203502833" duration="1349000" />
++-      <workItem from="1749213099437" duration="3082000" />
++-      <workItem from="1750057109660" duration="10453000" />
++-      <workItem from="1750070416210" duration="46415000" />
+++      <updated>1753351859462</updated>
+++      <workItem from="1753351861131" duration="6344000" />
+++      <workItem from="1753438320712" duration="13353000" />
+++      <workItem from="1753603965993" duration="23907000" />
+++      <workItem from="1753709105378" duration="8957000" />
+++      <workItem from="1753783502864" duration="521000" />
+++      <workItem from="1753784038079" duration="2184000" />
+++      <workItem from="1753792651870" duration="5722000" />
+++      <workItem from="1753867421329" duration="923000" />
+++      <workItem from="1753871809956" duration="11925000" />
+++      <workItem from="1754025478167" duration="1649000" />
+++      <workItem from="1754054724448" duration="1159000" />
+++      <workItem from="1754317580682" duration="1098000" />
+++      <workItem from="1754384107227" duration="613000" />
++     </task>
++-    <task id="LOCAL-00001" summary="Initial Commit">
+++    <task id="LOCAL-00001" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1732484343908</created>
+++      <created>1753438388631</created>
++       <option name="number" value="00001" />
++       <option name="presentableId" value="LOCAL-00001" />
++       <option name="project" value="LOCAL" />
++-      <updated>1732484343908</updated>
+++      <updated>1753438388631</updated>
++     </task>
++-    <task id="LOCAL-00002" summary="added TransformerFNO">
+++    <task id="LOCAL-00002" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1732497990642</created>
+++      <created>1753444583988</created>
++       <option name="number" value="00002" />
++       <option name="presentableId" value="LOCAL-00002" />
++       <option name="project" value="LOCAL" />
++-      <updated>1732497990642</updated>
+++      <updated>1753444583988</updated>
++     </task>
++-    <task id="LOCAL-00003" summary="added the connection between time steps - the model development is finished">
+++    <task id="LOCAL-00003" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1732910153380</created>
+++      <created>1753529013551</created>
++       <option name="number" value="00003" />
++       <option name="presentableId" value="LOCAL-00003" />
++       <option name="project" value="LOCAL" />
++-      <updated>1732910153380</updated>
+++      <updated>1753529013551</updated>
++     </task>
++-    <task id="LOCAL-00004" summary="Finished Allen-Cahn Problem">
+++    <task id="LOCAL-00004" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1733176021525</created>
+++      <created>1753539586020</created>
++       <option name="number" value="00004" />
++       <option name="presentableId" value="LOCAL-00004" />
++       <option name="project" value="LOCAL" />
++-      <updated>1733176021525</updated>
+++      <updated>1753539586020</updated>
++     </task>
++-    <task id="LOCAL-00005" summary="Added Allen-Cahn 3D">
+++    <task id="LOCAL-00005" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1733583274023</created>
+++      <created>1753640098974</created>
++       <option name="number" value="00005" />
++       <option name="presentableId" value="LOCAL-00005" />
++       <option name="project" value="LOCAL" />
++-      <updated>1733583274023</updated>
+++      <updated>1753640098974</updated>
++     </task>
++-    <task id="LOCAL-00006" summary="added save_vtk">
+++    <task id="LOCAL-00006" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1733995237535</created>
+++      <created>1753713910794</created>
++       <option name="number" value="00006" />
++       <option name="presentableId" value="LOCAL-00006" />
++       <option name="project" value="LOCAL" />
++-      <updated>1733995237535</updated>
+++      <updated>1753713910794</updated>
++     </task>
++-    <task id="LOCAL-00007" summary="added MATLAB codes for creating database">
+++    <task id="LOCAL-00007" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1734788540933</created>
+++      <created>1753722333819</created>
++       <option name="number" value="00007" />
++       <option name="presentableId" value="LOCAL-00007" />
++       <option name="project" value="LOCAL" />
++-      <updated>1734788540933</updated>
+++      <updated>1753722333819</updated>
++     </task>
++-    <task id="LOCAL-00008" summary="added CH2DNL">
+++    <task id="LOCAL-00008" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1735126332032</created>
+++      <created>1753789147535</created>
++       <option name="number" value="00008" />
++       <option name="presentableId" value="LOCAL-00008" />
++       <option name="project" value="LOCAL" />
++-      <updated>1735126332032</updated>
+++      <updated>1753789147535</updated>
++     </task>
++-    <task id="LOCAL-00009" summary="added SH2D">
+++    <task id="LOCAL-00009" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1735719422931</created>
+++      <created>1753867478797</created>
++       <option name="number" value="00009" />
++       <option name="presentableId" value="LOCAL-00009" />
++       <option name="project" value="LOCAL" />
++-      <updated>1735719422931</updated>
+++      <updated>1753867478797</updated>
++     </task>
++-    <task id="LOCAL-00010" summary="added PFC2D">
+++    <task id="LOCAL-00010" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1736237977029</created>
+++      <created>1753872227989</created>
++       <option name="number" value="00010" />
++       <option name="presentableId" value="LOCAL-00010" />
++       <option name="project" value="LOCAL" />
++-      <updated>1736237977029</updated>
+++      <updated>1753872227989</updated>
++     </task>
++-    <task id="LOCAL-00011" summary="added PFC2D">
+++    <task id="LOCAL-00011" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738788849261</created>
+++      <created>1753974441825</created>
++       <option name="number" value="00011" />
++       <option name="presentableId" value="LOCAL-00011" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738788849261</updated>
+++      <updated>1753974441825</updated>
++     </task>
++-    <task id="LOCAL-00012" summary="added PFC2D">
+++    <task id="LOCAL-00012" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738789326593</created>
+++      <created>1753976447489</created>
++       <option name="number" value="00012" />
++       <option name="presentableId" value="LOCAL-00012" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738789326593</updated>
+++      <updated>1753976447489</updated>
++     </task>
++-    <task id="LOCAL-00013" summary="added PFC2D">
+++    <task id="LOCAL-00013" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738796104012</created>
+++      <created>1753976663822</created>
++       <option name="number" value="00013" />
++       <option name="presentableId" value="LOCAL-00013" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738796104012</updated>
+++      <updated>1753976663822</updated>
++     </task>
++-    <task id="LOCAL-00014" summary="added PFC2D">
+++    <task id="LOCAL-00014" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738962464719</created>
+++      <created>1753984140485</created>
++       <option name="number" value="00014" />
++       <option name="presentableId" value="LOCAL-00014" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738962464719</updated>
+++      <updated>1753984140485</updated>
++     </task>
++-    <task id="LOCAL-00015" summary="added PFC2D">
+++    <task id="LOCAL-00015" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738962748829</created>
+++      <created>1754027236458</created>
++       <option name="number" value="00015" />
++       <option name="presentableId" value="LOCAL-00015" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738962748829</updated>
+++      <updated>1754027236458</updated>
++     </task>
++-    <task id="LOCAL-00016" summary="Turn Nx to 64">
+++    <task id="LOCAL-00016" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1738967163754</created>
+++      <created>1754056009830</created>
++       <option name="number" value="00016" />
++       <option name="presentableId" value="LOCAL-00016" />
++       <option name="project" value="LOCAL" />
++-      <updated>1738967163754</updated>
+++      <updated>1754056009830</updated>
++     </task>
++-    <task id="LOCAL-00017" summary="update to 3D">
+++    <task id="LOCAL-00017" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1739275401458</created>
+++      <created>1754317665438</created>
++       <option name="number" value="00017" />
++       <option name="presentableId" value="LOCAL-00017" />
++       <option name="project" value="LOCAL" />
++-      <updated>1739275401458</updated>
+++      <updated>1754317665438</updated>
++     </task>
++-    <task id="LOCAL-00018" summary="update to 3D">
+++    <task id="LOCAL-00018" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1739275433418</created>
+++      <created>1754320089838</created>
++       <option name="number" value="00018" />
++       <option name="presentableId" value="LOCAL-00018" />
++       <option name="project" value="LOCAL" />
++-      <updated>1739275433418</updated>
+++      <updated>1754320089838</updated>
++     </task>
++-    <task id="LOCAL-00019" summary="TNO3d vs FNO3d">
+++    <task id="LOCAL-00019" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1741690373369</created>
+++      <created>1754320859423</created>
++       <option name="number" value="00019" />
++       <option name="presentableId" value="LOCAL-00019" />
++       <option name="project" value="LOCAL" />
++-      <updated>1741690373369</updated>
+++      <updated>1754320859423</updated>
++     </task>
++-    <task id="LOCAL-00020" summary="TNO3d vs FNO3d">
+++    <task id="LOCAL-00020" summary="3d_phase_evolution">
++       <option name="closed" value="true" />
++-      <created>1741690420059</created>
+++      <created>1754323071886</created>
++       <option name="number" value="00020" />
++       <option name="presentableId" value="LOCAL-00020" />
++       <option name="project" value="LOCAL" />
++-      <updated>1741690420059</updated>
+++      <updated>1754323071886</updated>
++     </task>
++-    <task id="LOCAL-00021" summary="TNO3d vs FNO3d">
++-      <option name="closed" value="true" />
++-      <created>1743587271259</created>
++-      <option name="number" value="00021" />
++-      <option name="presentableId" value="LOCAL-00021" />
++-      <option name="project" value="LOCAL" />
++-      <updated>1743587271259</updated>
++-    </task>
++-    <option name="localTasksCounter" value="22" />
+++    <option name="localTasksCounter" value="21" />
++     <servers />
++   </component>
++   <component name="TypeScriptGeneratedFilesManager">
++     <option name="version" value="3" />
++   </component>
++-  <component name="Vcs.Log.Tabs.Properties">
++-    <option name="RECENT_FILTERS">
++-      <map>
++-        <entry key="Branch">
++-          <value>
++-            <list>
++-              <RecentGroup>
++-                <option name="FILTER_VALUES">
++-                  <option value="main" />
++-                </option>
++-              </RecentGroup>
++-            </list>
++-          </value>
++-        </entry>
++-      </map>
++-    </option>
++-    <option name="TAB_STATES">
++-      <map>
++-        <entry key="MAIN">
++-          <value>
++-            <State>
++-              <option name="FILTERS">
++-                <map>
++-                  <entry key="branch">
++-                    <value>
++-                      <list>
++-                        <option value="main" />
++-                      </list>
++-                    </value>
++-                  </entry>
++-                </map>
++-              </option>
++-            </State>
++-          </value>
++-        </entry>
++-      </map>
++-    </option>
++-  </component>
++   <component name="VcsManagerConfiguration">
++-    <MESSAGE value="Initial Commit" />
++-    <MESSAGE value="added TransformerFNO" />
++-    <MESSAGE value="added the connection between time steps - the model development is finished" />
++-    <MESSAGE value="refactored" />
++-    <MESSAGE value="Finished Allen-Cahn Problem" />
++-    <MESSAGE value="Added Allen-Cahn 3D" />
++-    <MESSAGE value="added save_vtk" />
++-    <MESSAGE value="added MATLAB codes for creating database" />
++-    <MESSAGE value="seperated the number of layers in fourier part and convolutional part" />
++-    <MESSAGE value="added CH2DNL" />
++-    <MESSAGE value="added SH2D" />
++-    <MESSAGE value="added PFC2D" />
++-    <MESSAGE value="Turn Nx to 64" />
++-    <MESSAGE value="update to 3D" />
++-    <MESSAGE value="TNO3d vs FNO3d" />
++-    <option name="LAST_COMMIT_MESSAGE" value="TNO3d vs FNO3d" />
+++    <MESSAGE value="3d_phase_evolution" />
+++    <option name="LAST_COMMIT_MESSAGE" value="3d_phase_evolution" />
++   </component>
++   <component name="XDebuggerManager">
++     <breakpoint-manager>
++       <breakpoints>
++         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>142</line>
++-          <option name="timeStamp" value="17" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>163</line>
++-          <option name="timeStamp" value="18" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>134</line>
++-          <option name="timeStamp" value="19" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>327</line>
++-          <option name="timeStamp" value="20" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/SH2D.py</url>
++-          <line>243</line>
++-          <option name="timeStamp" value="21" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/AC2D_2.py</url>
++-          <line>333</line>
++-          <option name="timeStamp" value="27" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>
++-          <line>371</line>
++-          <option name="timeStamp" value="44" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>
++-          <line>338</line>
++-          <option name="timeStamp" value="54" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>53</line>
++-          <option name="timeStamp" value="128" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>30</line>
++-          <option name="timeStamp" value="129" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>25</line>
++-          <option name="timeStamp" value="133" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test.py</url>
++-          <line>18</line>
++-          <option name="timeStamp" value="135" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>
++-          <line>44</line>
++-          <option name="timeStamp" value="138" />
++-        </line-breakpoint>
++-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/Test2.py</url>
++-          <line>16</line>
++-          <option name="timeStamp" value="144" />
+++          <url>file://$PROJECT_DIR$/training.py</url>
+++          <line>217</line>
+++          <option name="timeStamp" value="1" />
++         </line-breakpoint>
++         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/utilities.py</url>
++-          <line>98</line>
++-          <option name="timeStamp" value="170" />
+++          <url>file://$PROJECT_DIR$/networks.py</url>
+++          <line>373</line>
+++          <option name="timeStamp" value="5" />
++         </line-breakpoint>
++         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
++-          <url>file://$PROJECT_DIR$/main.py</url>
++-          <line>157</line>
++-          <option name="timeStamp" value="177" />
+++          <url>file://$PROJECT_DIR$/networks.py</url>
+++          <line>252</line>
+++          <option name="timeStamp" value="6" />
++         </line-breakpoint>
++       </breakpoints>
++-      <default-breakpoints>
++-        <breakpoint type="python-exception">
++-          <properties notifyOnTerminate="true" exception="BaseException">
++-            <option name="notifyOnTerminate" value="true" />
++-          </properties>
++-        </breakpoint>
++-      </default-breakpoints>
++     </breakpoint-manager>
++   </component>
++   <component name="com.intellij.coverage.CoverageDataManagerImpl">
++-    <SUITE FILE_PATH="coverage/PhaseField1$Test3.coverage" NAME="Test3 Coverage Results" MODIFIED="1739273938386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO4d.coverage" NAME="SH3D_FNO4d Coverage Results" MODIFIED="1753633990803" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage" NAME="config_AC2D_FNO3d Coverage Results" MODIFIED="1733233385695" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$main.coverage" NAME="main Coverage Results" MODIFIED="1743065376798" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_2.coverage" NAME="AC2D_Net2D_2 Coverage Results" MODIFIED="1732904114403" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_PFC3D_TNO3d.coverage" NAME="config_PFC3D_TNO3d Coverage Results" MODIFIED="1752681001873" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$test2.coverage" NAME="test2 Coverage Results" MODIFIED="1742889074336" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1741561715014" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage" NAME="config_SH3D_TNO3d Coverage Results" MODIFIED="1750254757455" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3D.coverage" NAME="SH3D_TNO3D Coverage Results" MODIFIED="1753359664305" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$networks.coverage" NAME="networks Coverage Results" MODIFIED="1733086051390" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1740088478224" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1741603428589" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3d_TNO3d_hybrid.coverage" NAME="PFC3d_TNO3d_hybrid Coverage Results" MODIFIED="1753174544263" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$main.coverage" NAME="main Coverage Results" MODIFIED="1738663765959" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$post_processing.coverage" NAME="post_processing Coverage Results" MODIFIED="1733557098801" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1751364899601" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_Hybrid.coverage" NAME="SH3D_Hybrid Coverage Results" MODIFIED="1753435630879" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D.coverage" NAME="AC2D Coverage Results" MODIFIED="1733088640665" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Archive_Code" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D.coverage" NAME="AC2D_Net2D Coverage Results" MODIFIED="1732567473230" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1740054182408" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1753174449133" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1737644605063" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1741605347375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$main.coverage" NAME="main Coverage Results" MODIFIED="1736268192289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1741564210973" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage" NAME="config_CH2DNL_TNO2d Coverage Results" MODIFIED="1735052490996" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$Test_Run.coverage" NAME="Test_Run Coverage Results" MODIFIED="1738945320139" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1741561294310" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_Hybrid.coverage" NAME="PFC3D_Hybrid Coverage Results" MODIFIED="1752753153734" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1743081225414" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1752763076697" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$PFC2D.coverage" NAME="PFC2D Coverage Results" MODIFIED="1732278679485" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$CH2D.coverage" NAME="CH2D Coverage Results" MODIFIED="1732347055915" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_FNO3d.coverage" NAME="AC3D_FNO3d Coverage Results" MODIFIED="1741561435127" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_hybrid.coverage" NAME="MBE3D_hybrid Coverage Results" MODIFIED="1753449172728" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741547133078" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_FNO4d.coverage" NAME="PFC3D_FNO4d Coverage Results" MODIFIED="1753634100431" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$AC3D.coverage" NAME="AC3D Coverage Results" MODIFIED="1740041515520" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$Test2.coverage" NAME="Test2 Coverage Results" MODIFIED="1739283715182" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1751535690856" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D.coverage" NAME="config_AC2D Coverage Results" MODIFIED="1733087276180" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_1.coverage" NAME="AC2D_Net2D_1 Coverage Results" MODIFIED="1732535211383" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1736520700819" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$fourier_3d.coverage" NAME="fourier_3d Coverage Results" MODIFIED="1732221600628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_interface3.coverage" NAME="run_interface3 Coverage Results" MODIFIED="1754322866765" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1751390276789" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1753270153654" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1753435969375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$test1.coverage" NAME="test1 Coverage Results" MODIFIED="1733413325318" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_TNO3d_Hybrid.coverage" NAME="PFC3D_TNO3d_Hybrid Coverage Results" MODIFIED="1752850166757" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseField1$Test3.coverage" NAME="Test3 Coverage Results" MODIFIED="1739273938386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_2.coverage" NAME="AC2D_Net2D_2 Coverage Results" MODIFIED="1732904114403" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_MBE3D_TNO3d.coverage" NAME="config_MBE3D_TNO3d Coverage Results" MODIFIED="1753524263103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage" NAME="config_SH3D_TNO3d Coverage Results" MODIFIED="1753348599806" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/PhaseField1$backend_interagg.coverage" NAME="backend_interagg Coverage Results" MODIFIED="1737630366471" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript3.coverage" NAME="RunScript3 Coverage Results" MODIFIED="1736368081257" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_2.coverage" NAME="AC2D_2 Coverage Results" MODIFIED="1732483323689" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$networks.coverage" NAME="networks Coverage Results" MODIFIED="1733086051390" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField1$main_TF.coverage" NAME="main_TF Coverage Results" MODIFIED="1738704014479" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1741538869064" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$THFNO.coverage" NAME="THFNO Coverage Results" MODIFIED="1732911474644" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/networks" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1740088478224" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$PFC3D.coverage" NAME="PFC3D Coverage Results" MODIFIED="1740083613128" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1741603428589" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_inference.coverage" NAME="run_inference Coverage Results" MODIFIED="1750323709039" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$main.coverage" NAME="main Coverage Results" MODIFIED="1738663765959" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$post_processing.coverage" NAME="post_processing Coverage Results" MODIFIED="1733557098801" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$CH3D_FNO4d.coverage" NAME="CH3D_FNO4d Coverage Results" MODIFIED="1754322861793" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_AC3D_FNO3d.coverage" NAME="config_AC3D_FNO3d Coverage Results" MODIFIED="1751958646687" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_inference.coverage" NAME="run_inference Coverage Results" MODIFIED="1751264322005" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage" NAME="config_CH2D_TNO2d Coverage Results" MODIFIED="1734086207850" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++     <SUITE FILE_PATH="coverage/phase_field_equations_4d$networks.coverage" NAME="networks Coverage Results" MODIFIED="1748933697533" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1750255151255" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript2.coverage" NAME="RunScript2 Coverage Results" MODIFIED="1736369209710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1742215946758" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_3.coverage" NAME="AC2D_Net2D_3 Coverage Results" MODIFIED="1732974697103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_FNO3d.coverage" NAME="AC3d_FNO3d Coverage Results" MODIFIED="1749017845623" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D.coverage" NAME="AC2D Coverage Results" MODIFIED="1733088640665" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Archive_Code" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D.coverage" NAME="AC2D_Net2D Coverage Results" MODIFIED="1732567473230" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1740054182408" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$utilities.coverage" NAME="utilities Coverage Results" MODIFIED="1752595653294" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_FNO3d.coverage" NAME="AC3d_FNO3d Coverage Results" MODIFIED="1751961986602" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1741562061391" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1737644605063" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_TNO.coverage" NAME="MBE3D_TNO Coverage Results" MODIFIED="1753438703018" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$MBE3D.coverage" NAME="MBE3D Coverage Results" MODIFIED="1739283566145" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1741605347375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1743071672425" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$main.coverage" NAME="main Coverage Results" MODIFIED="1736268192289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1741564210973" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage" NAME="config_CH2DNL_TNO2d Coverage Results" MODIFIED="1735052490996" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FO.coverage" NAME="SH3D_FO Coverage Results" MODIFIED="1753438614882" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$MBE2D.coverage" NAME="MBE2D Coverage Results" MODIFIED="1732278526731" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField1$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1739914172084" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$Test_Run.coverage" NAME="Test_Run Coverage Results" MODIFIED="1738945320139" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1741561294310" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3d_hybrid.coverage" NAME="MBE3d_hybrid Coverage Results" MODIFIED="1753458461671" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741861381348" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1743081225414" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage" NAME="PFV3D_FNO3d Coverage Results" MODIFIED="1741564487710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$training.coverage" NAME="training Coverage Results" MODIFIED="1751968651692" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_Hybrid.coverage" NAME="MBE3D_Hybrid Coverage Results" MODIFIED="1753516430619" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript1.coverage" NAME="RunScript1 Coverage Results" MODIFIED="1736368790622" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$SH2D.coverage" NAME="SH2D Coverage Results" MODIFIED="1732347080402" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$PFC2D.coverage" NAME="PFC2D Coverage Results" MODIFIED="1732278679485" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$CH2D.coverage" NAME="CH2D Coverage Results" MODIFIED="1732347055915" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_FNO3d.coverage" NAME="AC3D_FNO3d Coverage Results" MODIFIED="1741561435127" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_FNO3d.coverage" NAME="PFC3D_FNO3d Coverage Results" MODIFIED="1753174772461" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$SH3D.coverage" NAME="SH3D Coverage Results" MODIFIED="1739044808411" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$Test.coverage" NAME="Test Coverage Results" MODIFIED="1739459206236" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741547133078" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$CH3D_TNO3d_Hybrid.coverage" NAME="CH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1752411744994" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage" NAME="config_AC2D_FNO2d Coverage Results" MODIFIED="1733393903488" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$AC3D.coverage" NAME="AC3D Coverage Results" MODIFIED="1740041515520" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$config_CH3D_TNO3d.coverage" NAME="config_CH3D_TNO3d Coverage Results" MODIFIED="1738089807566" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++-    <SUITE FILE_PATH="coverage/PhaseField1$Test2.coverage" NAME="Test2 Coverage Results" MODIFIED="1739283715182" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_FNO3d.coverage" NAME="CH3D_FNO3d Coverage Results" MODIFIED="1741628529142" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage" NAME="AC3d_TNO3d_hybrid Coverage Results" MODIFIED="1748989478372" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage" NAME="AC3d_TNO3d_hybrid Coverage Results" MODIFIED="1751963486807" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseField1$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1737899062785" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D.coverage" NAME="config_AC2D Coverage Results" MODIFIED="1733087276180" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_1.coverage" NAME="AC2D_Net2D_1 Coverage Results" MODIFIED="1732535211383" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1736520700819" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$fourier_3d.coverage" NAME="fourier_3d Coverage Results" MODIFIED="1732221600628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1750254767095" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1749216389646" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1748990262244" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/PhaseFieldNet$test1.coverage" NAME="test1 Coverage Results" MODIFIED="1733413325318" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1753977480601" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+++    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main1.coverage" NAME="main1 Coverage Results" MODIFIED="1753709191839" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
++     <SUITE FILE_PATH="coverage/PhaseField1$CH3D_2.coverage" NAME="CH3D_2 Coverage Results" MODIFIED="1739918355289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1750254975290" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
++     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage" NAME="config_MBE2D_TNO2d Coverage Results" MODIFIED="1736261397712" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
++   </component>
++ </project>
++\ No newline at end of file
++Index: MatlabCode/AC3D.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>clear;\nNx=128; Ny=128; Nz=128; Lx=1.2; Ly=1.2; Lz=1.2; hx=Lx/Nx; hy=Ly/Ny; hz=Lz/Nz;\nx=linspace(-0.5*Lx+hx,0.5*Lx,Nx);\ny=linspace(-0.5*Ly+hy,0.5*Ly,Ny);\nz=linspace(-0.5*Lz+hz,0.5*Lz,Nz);\n[xx,yy,zz]=ndgrid(x,y,z); epsilon=hx; Cahn=epsilon^2;\nu=rand(Nx,Ny,Nz)-0.5;\nkx=2*pi/Lx*[0:Nx/2 -Nx/2+1:-1];\nky=2*pi/Ly*[0:Ny/2 -Ny/2+1:-1];\nkz=2*pi/Lz*[0:Nz/2 -Nz/2+1:-1];\nk2x = kx.^2; k2y = ky.^2; k2z = kz.^2;\n[kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);\ndt=0.01; T=0.5; Nt=round(T/dt); ns=Nt/10;\nfor iter=1:Nt\n    disp(['iteration = ', num2str(iter)])\n    u=real(u);\n    s_hat=fftn(Cahn*u-dt*(u.^3-3*u));\n    v_hat=s_hat./(Cahn+dt*(2+Cahn*(kxx+kyy+kzz)));\n    u=ifftn(v_hat);\n    if mod(iter, ns) == 0\n        if isempty(p1)\n            % First-time setup\n            p1 = patch(isosurface(xx, yy, zz, real(u), 0.));\n            set(p1, 'FaceColor', 'g', 'EdgeColor', 'none');\n            daspect([1 1 1]); \n            camlight; lighting flat; % Simplified lighting\n            box on; axis image;\n            view(45, 45);\n        else\n            % Update isosurface data\n            iso = isosurface(xx, yy, zz, real(u), 0.);\n            set(p1, 'Vertices', iso.vertices, 'Faces', iso.faces);\n        end\n    end\nend
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/AC3D.m b/MatlabCode/AC3D.m
++--- a/MatlabCode/AC3D.m	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/MatlabCode/AC3D.m	(date 1751699238223)
++@@ -1,35 +1,169 @@
+++clc;
++ clear;
++-Nx=128; Ny=128; Nz=128; Lx=1.2; Ly=1.2; Lz=1.2; hx=Lx/Nx; hy=Ly/Ny; hz=Lz/Nz;
++-x=linspace(-0.5*Lx+hx,0.5*Lx,Nx);
++-y=linspace(-0.5*Ly+hy,0.5*Ly,Ny);
++-z=linspace(-0.5*Lz+hz,0.5*Lz,Nz);
++-[xx,yy,zz]=ndgrid(x,y,z); epsilon=hx; Cahn=epsilon^2;
++-u=rand(Nx,Ny,Nz)-0.5;
++-kx=2*pi/Lx*[0:Nx/2 -Nx/2+1:-1];
++-ky=2*pi/Ly*[0:Ny/2 -Ny/2+1:-1];
++-kz=2*pi/Lz*[0:Nz/2 -Nz/2+1:-1];
++-k2x = kx.^2; k2y = ky.^2; k2z = kz.^2;
++-[kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);
++-dt=0.01; T=0.5; Nt=round(T/dt); ns=Nt/10;
++-for iter=1:Nt
++-    disp(['iteration = ', num2str(iter)])
++-    u=real(u);
++-    s_hat=fftn(Cahn*u-dt*(u.^3-3*u));
++-    v_hat=s_hat./(Cahn+dt*(2+Cahn*(kxx+kyy+kzz)));
++-    u=ifftn(v_hat);
++-    if mod(iter, ns) == 0
++-        if isempty(p1)
++-            % First-time setup
++-            p1 = patch(isosurface(xx, yy, zz, real(u), 0.));
++-            set(p1, 'FaceColor', 'g', 'EdgeColor', 'none');
++-            daspect([1 1 1]); 
++-            camlight; lighting flat; % Simplified lighting
++-            box on; axis image;
++-            view(45, 45);
++-        else
++-            % Update isosurface data
++-            iso = isosurface(xx, yy, zz, real(u), 0.);
++-            set(p1, 'Vertices', iso.vertices, 'Faces', iso.faces);
++-        end
++-    end
++-end
++\ No newline at end of file
+++
+++%% Parameter Initialization
+++
+++FigDraw = 0; % Set to 1 to enable visualization, 0 to disable
+++
+++% Spatial Parameters
+++Nx = 32;
+++Ny = Nx;
+++Nz = Nx;
+++Lx = 5;
+++Ly = Lx;
+++Lz = Lx;
+++hx = Lx / Nx;
+++hy = Ly / Ny;
+++hz = Lz / Nz;
+++
+++x = linspace(-0.5 * Lx + hx, 0.5 * Lx, Nx);
+++y = linspace(-0.5 * Ly + hy, 0.5 * Ly, Ny);
+++z = linspace(-0.5 * Lz + hz, 0.5 * Lz, Nz);
+++
+++[xx, yy, zz] = ndgrid(x, y, z);
+++
+++% Interfacial energy constant
+++epsilon = 0.1;
+++Cahn = epsilon^2;
+++
+++% Discrete Fourier Transform
+++kx = 2 * pi / Lx * [0:Nx / 2 -Nx / 2 + 1:-1];
+++ky = 2 * pi / Ly * [0:Ny / 2 -Ny / 2 + 1:-1];
+++kz = 2 * pi / Lz * [0:Nz / 2 -Nz / 2 + 1:-1];
+++k2x = kx.^2;
+++k2y = ky.^2;
+++k2z = kz.^2;
+++[kxx, kyy, kzz] = ndgrid(k2x, k2y, k2z);
+++
+++% Time Discretization
+++dt = 0.0005; % Time step
+++Nt = 100; % Number of time steps
+++T = Nt * dt; % Total simulation time
+++num_saved_steps = 101;
+++ns = Nt / (num_saved_steps - 1);
+++
+++% Dataset
+++data_size = 1500;
+++num_saved_steps = Nt + 1; % Save all steps
+++binary_filename = "AC3D_" + num2str(Nx) + "_" + num2str(data_size) + "_Augmented.bin";
+++mat_filename = "AC3D_" + num2str(Nx) + "_" + num2str(data_size) + "_Augmented.mat";
+++
+++%% Prepare Binary File
+++fileID = fopen(binary_filename, 'wb');
+++if fileID == -1
+++    error("Cannot open binary file for writing.");
+++end
+++
+++%% Visualization (Plot Section)
+++
+++if FigDraw
+++    figure;
+++end
+++
+++%% Main Data Generation Loop
+++for data_num = 1:data_size
+++    disp("Data number = " + num2str(data_num));
+++    
+++    % Strategy: 75% of the time, generate a GRF. 25% of the time, generate a sphere.
+++    ic_type = rand(); % Generate a random number between 0 and 1
+++
+++    if ic_type < 0.75
+++        % --- Method 1: Original GRF Initial Condition ---
+++        % ==================== MINIMAL CHANGE HERE ====================
+++        if data_num == 1
+++            disp('Generating GRF initial condition...');
+++        end
+++        % =============================================================
+++        tau_min = 290;
+++        tau_max = 320;
+++        alpha_min = 90;
+++        alpha_max = 120;
+++        current_tau = tau_min + (tau_max - tau_min) * rand();
+++        current_alpha = alpha_min + (alpha_max - alpha_min) * rand();
+++        norm_a = GRF3D(current_alpha, current_tau, Nx);
+++        shift_factor = 0.7 - 0.4 * rand();
+++        norm_a = norm_a - shift_factor * std(norm_a(:));
+++        u = ones(Nx,Ny,Nz);
+++        u(norm_a < 0) = -1;
+++    else
+++        % --- Method 2: Geometric (Sphere) Initial Condition ---
+++        % ==================== MINIMAL CHANGE HERE ====================
+++        if data_num == 1
+++            disp('Generating geometric initial condition (sphere)...');
+++        end
+++        % =============================================================
+++        % Random radius (e.g., 20% to 40% of the half-domain size)
+++        radius = (0.2 + 0.2*rand()) * (Lx/2); 
+++        
+++        % Random center offset, ensuring it's not too close to the edge
+++        max_offset = Lx/2 - radius - 2*hx;
+++        center_x = (2*rand() - 1) * max_offset;
+++        center_y = (2*rand() - 1) * max_offset;
+++        center_z = (2*rand() - 1) * max_offset;
+++        
+++        % Calculate distance from the random center for every grid point
+++        sphere_grid = sqrt((xx - center_x).^2 + (yy - center_y).^2 + (zz - center_z).^2);
+++        
+++        % Create a smooth interface using tanh function, which is standard
+++        interface_width = 2*sqrt(2)*epsilon; 
+++        u = tanh((radius - sphere_grid) / interface_width);
+++    end
+++
+++    all_iterations = zeros(num_saved_steps, Nx, Ny, Nz, 'single');
+++
+++    %% Initial Preview
+++    if FigDraw
+++        clf;
+++        p1 = patch(isosurface(xx, yy, zz, real(u), 0));
+++        set(p1, 'FaceColor', 'r', 'EdgeColor', 'none');
+++        daspect([1 1 1]); camlight; lighting phong; box on; axis image;
+++        view(45, 45);
+++        pause(2);
+++    end
+++
+++    %% Update
+++    for iter = 1:Nt
+++        if FigDraw && mod(iter, ns) == 0
+++            figure(1);
+++            clf;
+++            p1 = patch(isosurface(xx, yy, zz, real(u), 0));
+++            set(p1, 'FaceColor', 'r', 'EdgeColor', 'none');
+++            daspect([1 1 1]); camlight; lighting phong; box on; axis image;
+++            view(45, 45);
+++            pause(0.01);
+++        end
+++
+++        all_iterations(iter, :, :, :) = u;
+++        
+++        nonlinear_term_hat = fftn(u.^3 - u);
+++        u_hat = fftn(u);
+++        v_hat = (u_hat - (dt/Cahn) * nonlinear_term_hat) ./ (1 + dt * (kxx + kyy + kzz));
+++        u = ifftn(v_hat);
+++    end
+++
+++    all_iterations(end, :, :, :) = u; % Save final step
+++
+++    % Write data to binary file
+++    fwrite(fileID, all_iterations, 'single');
+++end
+++
+++fclose(fileID);
+++
+++%% Convert Binary Data to MAT File
+++fileID = fopen(binary_filename, 'rb');
+++if fileID == -1
+++    error("Cannot open binary file for reading.");
+++end
+++
+++phi_mat = matfile(mat_filename, 'Writable', true);
+++phi_mat.phi = zeros([data_size, num_saved_steps, Nx, Ny, Nz], 'single');
+++
+++for data_num = 1:data_size
+++    disp("Saving dataset " + num2str(data_num));
+++    data_chunk = fread(fileID, num_saved_steps * Nx * Ny * Nz, 'single');
+++    phi_mat.phi(data_num, :, :, :, :) = reshape(data_chunk, [1, num_saved_steps, Nx, Ny, Nz]);
+++end
+++
+++fclose(fileID);
+++
+++disp("Saving dataset");
++\ No newline at end of file
++Index: MatlabCode/SH3D.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>clc;\nclear;\nclose all\n\n%% Parameter Initialization\n\n% Spatial Parameters\nNx=80; \nNy=80; \nNz=80; \nLx=90; \nLy=90; \nLz=90; \nhx=Lx/Nx; \nhy=Ly/Ny; \nhz=Lz/Nz;\nx=linspace(-0.5*Lx+hx,0.5*Lx,Nx);\ny=linspace(-0.5*Ly+hy,0.5*Ly,Ny);\nz=linspace(-0.5*Lz+hz,0.5*Lz,Nz);\n[xx,yy,zz]=ndgrid(x,y,z); \n\n% constant\nepsilon=0.15;\n\n% Discrete Fourier Transform\nkx=2*pi/Lx*[0:Nx/2 -Nx/2+1:-1];\nky=2*pi/Ly*[0:Ny/2 -Ny/2+1:-1];\nkz=2*pi/Lz*[0:Nz/2 -Nz/2+1:-1];\nk2x = kx.^2; \nk2y = ky.^2; \nk2z = kz.^2;\n[kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);\n\n% Time Discritization\ndt=0.01; \nT=5; \nNt=round(T/dt); \nns=Nt/10; \nt=0;\n\n%% Initial Condition\n% u=rand(Nx,Ny,Nz)-0.5;\n\ntau = 2;\nalpha = 3;\nu = GRF3D(alpha, tau, Nx);\n\n%% Initial Preview\n\nfor iter=1:Nt\n    disp(['Iteration = ' num2str(iter)]);\n    u=real(u);\n    s_hat=fftn(u/dt)-fftn(u.^3)+2*(kxx+kyy+kzz).*fftn(u);\n    v_hat=s_hat./(1.0/dt+(1-epsilon)+(kxx+kyy+kzz).^2);\n    u=ifftn(v_hat);\n    t=t+dt;\n\n    if mod(iter, ns) == 0 \n        % Extract mid-plane slices\n        slice_x = squeeze(u(Nx/2, :, :));\n        slice_y = squeeze(u(:, Ny/2, :));\n        slice_z = squeeze(u(:, :, Nz/2));\n\n        % Plot star layout\n        clf; % Clear current figure\n        hold on;\n        % Midplane along X\n        surf(squeeze(yy(Nx/2, :, :)), squeeze(zz(Nx/2, :, :)), slice_x, 'EdgeColor', 'none');\n        % Midplane along Y\n        surf(squeeze(xx(:, Ny/2, :)), squeeze(zz(:, Ny/2, :)), slice_y, 'EdgeColor', 'none');\n        % Midplane along Z\n        surf(squeeze(xx(:, :, Nz/2)), squeeze(yy(:, :, Nz/2)), slice_z, 'EdgeColor', 'none');\n\n        % Visualization settings\n        view(3); % 3D view\n        axis tight;\n        caxis([-0.6, 0.6]); % Adjust color range\n        colormap(jet);\n        colorbar;\n        title(['Time t = ', num2str(t, '%.2f')]);\n        drawnow; % Update the figure\n\n    end\n\nend
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/SH3D.m b/MatlabCode/SH3D.m
++--- a/MatlabCode/SH3D.m	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/MatlabCode/SH3D.m	(date 1753290810608)
++@@ -1,85 +1,146 @@
++ clc;
++ clear;
++-close all
+++close all;
+++fclose('all');
++ 
++ %% Parameter Initialization
+++FigDraw = 0 ; % Enable/Disable visualization (1 = On, 0 = Off)
++ 
++ % Spatial Parameters
++-Nx=80; 
++-Ny=80; 
++-Nz=80; 
++-Lx=90; 
++-Ly=90; 
++-Lz=90; 
++-hx=Lx/Nx; 
++-hy=Ly/Ny; 
++-hz=Lz/Nz;
++-x=linspace(-0.5*Lx+hx,0.5*Lx,Nx);
++-y=linspace(-0.5*Ly+hy,0.5*Ly,Ny);
++-z=linspace(-0.5*Lz+hz,0.5*Lz,Nz);
++-[xx,yy,zz]=ndgrid(x,y,z); 
+++Nx = 32; %80 % 64; % Grid size in x direction
+++Ny = Nx; %80; % 64; % Grid size in y direction
+++Nz = Nx; %80; % 64; % Grid size in z direction
+++Lx = 15; %90; % 64 % Domain size in x direction
+++Ly = Lx; % 10; %90; % 64; % Domain size in y direction
+++Lz = Lx; %90; % 64; % Domain size in z direction
+++hx = Lx / Nx;
+++hy = Ly / Ny;
+++hz = Lz / Nz;
+++
+++x = linspace(-0.5 * Lx + hx, 0.5 * Lx, Nx);
+++y = linspace(-0.5 * Ly + hy, 0.5 * Ly, Ny);
+++z = linspace(-0.5 * Lz + hz, 0.5 * Lz, Nz);
+++[xx, yy, zz] = ndgrid(x, y, z);
++ 
++-% constant
++-epsilon=0.15;
+++% Constant
+++epsilon = 0.15;
++ 
++ % Discrete Fourier Transform
++-kx=2*pi/Lx*[0:Nx/2 -Nx/2+1:-1];
++-ky=2*pi/Ly*[0:Ny/2 -Ny/2+1:-1];
++-kz=2*pi/Lz*[0:Nz/2 -Nz/2+1:-1];
++-k2x = kx.^2; 
++-k2y = ky.^2; 
+++kx = 2 * pi / Lx * [0:Nx/2, -Nx/2+1:-1];
+++ky = 2 * pi / Ly * [0:Ny/2, -Ny/2+1:-1];
+++kz = 2 * pi / Lz * [0:Nz/2, -Nz/2+1:-1];
+++k2x = kx.^2;
+++k2y = ky.^2;
++ k2z = kz.^2;
++-[kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);
+++[kxx, kyy, kzz] = ndgrid(k2x, k2y, k2z);
++ 
++-% Time Discritization
++-dt=0.01; 
++-T=5; 
++-Nt=round(T/dt); 
++-ns=Nt/10; 
++-t=0;
+++% Time Discretization
+++dt = 0.05; %0.00002; % Time step ******
+++Nt = 100; %1000; % Total number of time steps
+++num_saved_steps = 101; %101; % Number of saved time steps
+++ns = Nt / (num_saved_steps - 1); % Save interval
+++
+++% Dataset
+++data_size = 2000; % 1500; % Number of random datasets
+++binary_filename = "SH3D_grf3d_ff_" + num2str(data_size) + "_Nt_" + num2str(num_saved_steps) + ...
+++                  "_Nx_" + num2str(Nx) + ".bin";
+++mat_filename = "SH3D_grf3d_ff_" + num2str(data_size) + "_Nt_" + num2str(num_saved_steps) + ...
+++               "_Nx_" + num2str(Nx) + ".mat";
+++
+++%% Prepare Binary File
+++fileID = fopen(binary_filename, 'wb');
+++if fileID == -1
+++    error("Cannot open binary file for writing.");
+++end
+++
+++%% Simulation Loop
+++if FigDraw
+++    figure;
+++end
+++
+++for data_num = 1:data_size
+++    disp("Data number = " + num2str(data_num));
+++
+++    % ==================== MODIFIED IC SECTION (AS REQUESTED) ====================
+++    % Strategy: Randomize GRF parameters within the user-specified ranges
+++    % to create a rich and diverse dataset for robust NN training.
+++
+++    % 1. Define the min/max for the random ranges
+++    tau_min = 280;
+++    tau_max = 320;
+++    alpha_min = 80;
+++    alpha_max = 120;
+++    
+++    % 2. Generate a random value for tau and alpha in their respective ranges.
+++    % The formula is: min_val + (max_val - min_val) * rand()
+++    current_tau = tau_min + (tau_max - tau_min) * rand();
+++    current_alpha = alpha_min + (alpha_max - alpha_min) * rand();
++ 
++-%% Initial Condition
++-% u=rand(Nx,Ny,Nz)-0.5;
++-
++-tau = 2;
++-alpha = 3;
++-u = GRF3D(alpha, tau, Nx);
+++    % Generate the continuous random field with these new parameters
+++    norm_a = GRF3D(current_alpha, current_tau, Nx);
+++    
+++    % 3. Randomize the thresholding shift to vary the volume fraction.
+++    shift_factor = 0.6 + 0.5 * rand(); % Range: [0.7, 1.2]
+++    norm_a = norm_a - shift_factor * std(norm_a(:));
+++    
+++    % Threshold the field to create the binary initial condition
+++    u = ones(Nx,Ny,Nz);
+++    u(norm_a < 0) = -1;
+++    % ===================== END OF MODIFIED IC SECTION =====================
++ 
++-%% Initial Preview
+++    % Initialize storage for saving time steps
+++    all_iterations = zeros(num_saved_steps, Nx, Ny, Nz, 'single');
++ 
++-for iter=1:Nt
++-    disp(['Iteration = ' num2str(iter)]);
++-    u=real(u);
++-    s_hat=fftn(u/dt)-fftn(u.^3)+2*(kxx+kyy+kzz).*fftn(u);
++-    v_hat=s_hat./(1.0/dt+(1-epsilon)+(kxx+kyy+kzz).^2);
++-    u=ifftn(v_hat);
++-    t=t+dt;
+++    %% Update Loop
+++    save_idx = 1;
+++    for iter = 1:Nt
+++        if iter == 1 || mod(iter, ns) == 0 || iter == Nt
+++            all_iterations(save_idx, :, :, :) = u;
+++            save_idx = save_idx + 1;
+++        end
+++
+++        %% Visualization (Plot Section) - RESTORED TO ORIGINAL
+++        if FigDraw && mod(iter, ns) == 0
+++            clf;
+++            p1 = patch(isosurface(xx, yy, zz, real(u), 0));
+++            set(p1, 'FaceColor', 'r', 'EdgeColor', 'none'); % Red surface
+++            daspect([1 1 1]);
+++            camlight;
+++            lighting phong;
+++            box on;
+++            axis image;
+++            view(45, 45); % Consistent viewing angle
+++            pause(0.01); % Adjust for rendering speed
+++        end
+++
+++        % Time evolution of the SH3D equation
+++        u = real(u);
+++        s_hat = fftn(u / dt) - fftn(u.^3) + 2 * (kxx + kyy + kzz) .* fftn(u);
+++        v_hat = s_hat ./ (1.0 / dt + (1 - epsilon) + (kxx + kyy + kzz).^2);
+++        u = ifftn(v_hat);
+++    end
++ 
++-    if mod(iter, ns) == 0 
++-        % Extract mid-plane slices
++-        slice_x = squeeze(u(Nx/2, :, :));
++-        slice_y = squeeze(u(:, Ny/2, :));
++-        slice_z = squeeze(u(:, :, Nz/2));
+++    % Write this dataset to binary file
+++    fwrite(fileID, all_iterations, 'single');
+++end
++ 
++-        % Plot star layout
++-        clf; % Clear current figure
++-        hold on;
++-        % Midplane along X
++-        surf(squeeze(yy(Nx/2, :, :)), squeeze(zz(Nx/2, :, :)), slice_x, 'EdgeColor', 'none');
++-        % Midplane along Y
++-        surf(squeeze(xx(:, Ny/2, :)), squeeze(zz(:, Ny/2, :)), slice_y, 'EdgeColor', 'none');
++-        % Midplane along Z
++-        surf(squeeze(xx(:, :, Nz/2)), squeeze(yy(:, :, Nz/2)), slice_z, 'EdgeColor', 'none');
+++fclose(fileID);
++ 
++-        % Visualization settings
++-        view(3); % 3D view
++-        axis tight;
++-        caxis([-0.6, 0.6]); % Adjust color range
++-        colormap(jet);
++-        colorbar;
++-        title(['Time t = ', num2str(t, '%.2f')]);
++-        drawnow; % Update the figure
+++%% Convert Binary Data to MAT File
+++fileID = fopen(binary_filename, 'rb');
+++if fileID == -1
+++    error("Cannot open binary file for reading.");
+++end
++ 
++-    end
+++phi_mat = matfile(mat_filename, 'Writable', true);
+++phi_mat.phi = zeros([data_size, num_saved_steps, Nx, Ny, Nz], 'single');
+++
+++for data_num = 1:data_size
+++    disp("Saving dataset " + num2str(data_num));
+++    data_chunk = fread(fileID, num_saved_steps * Nx * Ny * Nz, 'single');
+++    phi_mat.phi(data_num, :, :, :, :) = reshape(data_chunk, [1, num_saved_steps, Nx, Ny, Nz]);
+++end
++ 
++-end
++\ No newline at end of file
+++fclose(fileID);
+++
+++disp('Simulation complete.');
++\ No newline at end of file
++Index: MatlabCode/CH3D.m
++IDEA additional info:
++Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
++<+>clc;\nclear;\nclose all\n\n%% Parameter Initialization\n\n% Spatial Parameters\nNx=32; \nNy=32; \nNz=32; \nLx=1.0; \nLy=1.0; \nLz=1.0; \nhx=Lx/Nx;\nhy=Ly/Ny;\nhz=Lz/Nz;\nx=linspace(-0.5*Lx+hx,0.5*Lx,Nx);\ny=linspace(-0.5*Ly+hy,0.5*Ly,Ny);\nz=linspace(-0.5*Lz+hz,0.5*Lz,Nz);\n[xx,yy,zz]=ndgrid(x,y,z);\n\n% Interfacial energy constant\n%epsilon=1/128; \nepsilon=0.0125; \nCahn=epsilon^2;\n\n% Discrete Fourier Transform\nkx=2*pi/Lx*[0:Nx/2 -Nx/2+1:-1];\nky=2*pi/Ly*[0:Ny/2 -Ny/2+1:-1];\nkz=2*pi/Lz*[0:Nz/2 -Nz/2+1:-1];\nk2x=kx.^2; \nk2y=ky.^2; \nk2z=kz.^2;\n[kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);\n\n% Time Discritization\ndt=0.001; \nT=10; \nNt=round(T/dt); \nns=100;\n\n%% Initial Condition\n%u=rand(Nx,Ny,Nz)-0.5;\n%u=-0.45 + 0.05*(2*rand(Nx,Ny,Nz)-1);\n%u=0.45 - 0.05*(2*rand(Nx,Ny,Nz)-1);\n\n%tau = 400;\n%alpha = 115;\ntau = 10;\nalpha = 5.5;\nnorm_a = GRF3D(alpha, tau, Nx);\nnorm_a = norm_a + 0.2 * std(norm_a(:));   \nu = ones(Nx,Ny,Nz);\nu(norm_a < 0) = -1;\n%u = GRF3D(alpha, tau, Nx);\n\n%% Initial Preview\n% figure(1);\n% clf;\n% p1=patch(isosurface(xx,yy,zz,real(u),0.));\n% set(p1,'FaceColor','g','EdgeColor','none'); \n% daspect([1 1 1])\n% camlight;\n% lighting phong; \n% box on; \n% axis image;\n% view(45,45);\n% pause(2)\n\n%% Update\nfor iter=1:Nt\n    disp(['Iteration = ' num2str(iter)]);\n    u=real(u);\n    s_hat=fftn(u)-dt*(kxx+kyy+kzz).*fftn(u.^3-3*u);\n    v_hat=s_hat./(1.0+dt*(2.0*(kxx+kyy+kzz)+Cahn*(kxx+kyy+kzz).^2));\n    u=ifftn(v_hat);\n    if (mod(iter,ns)==0)\n        figure(1);\n        clf;\n        p1=patch(isosurface(xx,yy,zz,real(u),0.));\n        set(p1,'FaceColor','g','EdgeColor','none'); \n        daspect([1 1 1])\n        camlight;\n        lighting phong; \n        box on; \n        axis image;\n        view(45,45);\n        pause(0.01)\n    end\nend
++Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
++<+>UTF-8
++===================================================================
++diff --git a/MatlabCode/CH3D.m b/MatlabCode/CH3D.m
++--- a/MatlabCode/CH3D.m	(revision 09d4235b45a23fd92cb4f82a4ac691f47d8b08e7)
+++++ b/MatlabCode/CH3D.m	(date 1752146858155)
++@@ -1,16 +1,22 @@
++ clc;
++ clear;
++ close all
++-
+++fclose('all');
+++disp('CH3D Random New File: ')
++ %% Parameter Initialization
++ 
+++FigDraw = 0; %1; % Set to 1 to enable visualization, 0 disable
+++% Start timing
+++tic;
+++
++ % Spatial Parameters
++-Nx=32; 
++-Ny=32; 
++-Nz=32; 
++-Lx=1.0; 
++-Ly=1.0; 
++-Lz=1.0; 
+++Nx=32; %32; %64; %32;
+++Ny=Nx; 
+++Nz=Nx; 
+++Lx=2; % 1.2; % 3; %1; %1.1;
+++Ly=Lx; % 3; %1; %1.1;
+++Lz=Lx; % 3; %1; %1.1;
+++
++ hx=Lx/Nx;
++ hy=Ly/Ny;
++ hz=Lz/Nz;
++@@ -20,8 +26,8 @@
++ [xx,yy,zz]=ndgrid(x,y,z);
++ 
++ % Interfacial energy constant
++-%epsilon=1/128; 
++-epsilon=0.0125; 
+++epsilon=0.05; % 0.0125; 
+++%epsilon = 2.5 * hx; % Based on photo (2.5h)
++ Cahn=epsilon^2;
++ 
++ % Discrete Fourier Transform
++@@ -33,58 +39,149 @@
++ k2z=kz.^2;
++ [kxx,kyy,kzz]=ndgrid(k2x,k2y,k2z);
++ 
++-% Time Discritization
++-dt=0.001; 
++-T=10; 
++-Nt=round(T/dt); 
++-ns=100;
+++% Time Discretization
+++dt = 0.0005; % Time step
+++Nt = 100; % Number of time steps
+++T = Nt * dt; % Total simulation time
+++num_saved_steps = 101;
+++ns = Nt / (num_saved_steps - 1);
+++
+++% Dataset
+++data_size = 1500;%8000;%5000 %12000; %1500; % 600; %1500; %2000 %8000;
+++binary_filename = "CH3D_" + num2str(data_size) + "_Nt_" + num2str(num_saved_steps) + ...
+++                  "_Nx_" + num2str(Nx) + ".bin";
+++mat_filename = "CH3D_" + num2str(data_size) + "_Nt_" + num2str(num_saved_steps) + ...
+++               "_Nx_" + num2str(Nx) + ".mat";
+++
+++%% Prepare Binary File
+++fileID = fopen(binary_filename, 'wb');
+++if fileID == -1
+++    error("Cannot open binary file for writing.");
+++end
++ 
++ %% Initial Condition
++-%u=rand(Nx,Ny,Nz)-0.5;
++-%u=-0.45 + 0.05*(2*rand(Nx,Ny,Nz)-1);
++-%u=0.45 - 0.05*(2*rand(Nx,Ny,Nz)-1);
+++tau = 65; %91;%141;% 400; %400; % 3.5; %5; %15; %45; % 400;
+++alpha = 9.5; %19%41; %115; %115; %2; %4 %11; %115;
++ 
++-%tau = 400;
++-%alpha = 115;
++-tau = 10;
++-alpha = 5.5;
++-norm_a = GRF3D(alpha, tau, Nx);
++-norm_a = norm_a + 0.2 * std(norm_a(:));   
++-u = ones(Nx,Ny,Nz);
++-u(norm_a < 0) = -1;
++-%u = GRF3D(alpha, tau, Nx);
+++if FigDraw
+++    figure;
+++end
+++
+++for data_num = 1:data_size
+++    disp("data number = " + num2str(data_num))
+++    
+++    
+++    %%%%%
+++    % ==================== MODIFIED IC SECTION (AS REQUESTED) ====================
+++    % Strategy: Randomize GRF parameters within the user-specified ranges
+++    % to create a rich and diverse dataset for robust NN training.
+++
+++    % 1. Define the min/max for the random ranges
+++    tau_min = 50;
+++    tau_max = 80;
+++    alpha_min = 5;
+++    alpha_max = 13;
+++    
+++    % 2. Generate a random value for tau and alpha in their respective ranges.
+++    % The formula is: min_val + (max_val - min_val) * rand()
+++    current_tau = tau_min + (tau_max - tau_min) * rand();
+++    current_alpha = alpha_min + (alpha_max - alpha_min) * rand();
+++
+++    % Generate the continuous random field with these new parameters
+++    norm_a = GRF3D(current_alpha, current_tau, Nx);
+++    
+++    % 3. Randomize the thresholding shift to vary the volume fraction.
+++    shift_factor = 0.7 - 0.4 * rand(); % Range: [0.7, 1.2]
+++    norm_a = norm_a - shift_factor * std(norm_a(:));
+++    
+++    % Threshold the field to create the binary initial condition
+++    u = ones(Nx,Ny,Nz);
+++    u(norm_a < 0) = -1;
+++    % ===================== END OF MODIFIED IC SECTION =====================
+++    %%%%
++ 
++-%% Initial Preview
++-% figure(1);
++-% clf;
++-% p1=patch(isosurface(xx,yy,zz,real(u),0.));
++-% set(p1,'FaceColor','g','EdgeColor','none'); 
++-% daspect([1 1 1])
++-% camlight;
++-% lighting phong; 
++-% box on; 
++-% axis image;
++-% view(45,45);
++-% pause(2)
+++    
+++    %%
+++    %norm_a = GRF3D(alpha, tau, Nx);
+++    %norm_a = norm_a - 0.85* std(norm_a(:));   %
+++    %u = ones(Nx,Ny,Nz);
+++    %u(norm_a < 0) = -1;
+++    %u = norm_a;
+++    %u(:,1,:)=1;
+++    %u(:,end,:)=1;
+++    %u(:,:,1)=1;
+++    %u(:,:,end)=1;
+++
+++    all_iterations = zeros(num_saved_steps, Nx, Ny, Nz, 'single');
+++    
+++    %% Initial Preview
+++    if FigDraw
+++        clf;
+++        p1 = patch(isosurface(xx, yy, zz, real(u), 0));
+++        set(p1, 'FaceColor', 'r', 'EdgeColor', 'none'); % Red color for the surface
+++        daspect([1 1 1]);
+++        camlight;
+++        lighting phong;
+++        box on;
+++        axis image;
+++        view(45, 45); % Set the viewing angle
+++        pause(2);
+++    end
++ 
++-%% Update
++-for iter=1:Nt
++-    disp(['Iteration = ' num2str(iter)]);
++-    u=real(u);
++-    s_hat=fftn(u)-dt*(kxx+kyy+kzz).*fftn(u.^3-3*u);
++-    v_hat=s_hat./(1.0+dt*(2.0*(kxx+kyy+kzz)+Cahn*(kxx+kyy+kzz).^2));
++-    u=ifftn(v_hat);
++-    if (mod(iter,ns)==0)
++-        figure(1);
++-        clf;
++-        p1=patch(isosurface(xx,yy,zz,real(u),0.));
++-        set(p1,'FaceColor','g','EdgeColor','none'); 
++-        daspect([1 1 1])
++-        camlight;
++-        lighting phong; 
++-        box on; 
++-        axis image;
++-        view(45,45);
++-        pause(0.01)
+++    %% Update
+++    save_idx = 1;
+++    for iter = 1:Nt
+++        if iter == 1 || mod(iter, ns) == 0 || iter == Nt
+++            all_iterations(save_idx, :, :, :) = u;
+++            save_idx = save_idx + 1;
+++        end
+++
+++        u = real(u);
+++        s_hat = fftn(u) - dt * (kxx + kyy + kzz) .* fftn(u.^3 - 3 * u);
+++        v_hat = s_hat ./ (1.0 + dt * (2.0 * (kxx + kyy + kzz) + Cahn * (kxx + kyy + kzz).^2));
+++        u = ifftn(v_hat);
+++
+++        % Update Visualization During Simulation
+++        if FigDraw && mod(iter, ns) == 0
+++            figure(1);
+++            clf;
+++            p1 = patch(isosurface(xx, yy, zz, real(u), 0));
+++            set(p1, 'FaceColor', 'r', 'EdgeColor', 'none'); % Red color for the surface
+++            daspect([1 1 1]);
+++            camlight;
+++            lighting phong;
+++            box on;
+++            axis image;
+++            view(45, 45); % Maintain consistent view
+++            pause(0.01);
+++        end
+++    
++     end
++-end
++\ No newline at end of file
+++
+++    fwrite(fileID, all_iterations, 'single');
+++end
+++
+++fclose(fileID);
+++
+++%% Convert Binary Data to MAT File
+++fileID = fopen(binary_filename, 'rb');
+++if fileID == -1
+++    error("Cannot open binary file for reading.");
+++end
+++
+++phi_mat = matfile(mat_filename, 'Writable', true);
+++phi_mat.phi = zeros([data_size, num_saved_steps, Nx, Ny, Nz], 'single');
+++
+++for data_num = 1:data_size
+++    disp("Saving dataset " +  num2str(data_num));
+++    data_chunk = fread(fileID, num_saved_steps * Nx * Ny * Nz, 'single');
+++    phi_mat.phi(data_num, :, :, :, :) = reshape(data_chunk, [1, num_saved_steps, Nx, Ny, Nz]);
+++end
+++
+++fclose(fileID);
+++
+++% End timing
+++elapsed_time_seconds = toc; % Total time in seconds
+++elapsed_time_minutes = elapsed_time_seconds / 60; % Convert to minutes
+++% Display runtime
+++disp(['Elapsed Time: ', num2str(elapsed_time_minutes, '%.2f'), ' minutes']);
++\ No newline at end of file
+Index: configs/config_CH3D_FNO3d.py
+IDEA additional info:
+Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
+<+>import numpy as np\n\n# General Setting\ngpu_number = 'cuda:3'  # 'cuda:1'\ntorch_seed = 0\nnumpy_seed = 0\n\n# Network Parameters\nnTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500\nnTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500\nbatch_size = 2 # 20 # 50 # 3 # 20 # 50 # 5 # 50\nlearning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001\nweight_decay = 1e-4 # 1e-3 # 1e-4\nepochs = 100 # 500 # 1000 # 25 # 100 # 1000\niterations = epochs * (nTrain // batch_size)\nmodes = 14 # 10 #12 # 14 # 16 # 10 # 16\nwidth = 12 # 8 #12 #14 # 12 # 16 # 32\nwidth_q = width # 2 * width #\nwidth_h = width//2 # width//4 # width #\nn_layers = 4 # 4 # 5 # 5 # 8\n\n# Discretization\n\ns = 64 # 32 # 64 #32 # 64\nT_in = 1\nT_out = 20 # 100\n\n# Training Setting\nnormalized = True\ntraining = True # False # True # False  # True\nload_model = False # True # False # False #True\n\n# Database\nparent_dir = './data/'\n\n#matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'\nmatlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'\n\n# Plotting\nindex = 62  # 24 # 62\ndomain = [-np.pi, np.pi]\n# time_steps = [29, 35, 39, 45, 49]\n# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n#time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n#              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]\n#time_steps = [39, 49, 59, 69, 79, 89, 99]\n#time_steps = [39, 59, 79]\ntime_steps = [0, 9, 19]
+Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
+<+>UTF-8
+===================================================================
+diff --git a/configs/config_CH3D_FNO3d.py b/configs/config_CH3D_FNO3d.py
+--- a/configs/config_CH3D_FNO3d.py	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
++++ b/configs/config_CH3D_FNO3d.py	(date 1754547784298)
+@@ -6,24 +6,24 @@
+ numpy_seed = 0
+ 
+ # Network Parameters
+-nTrain = 600 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
++nTrain = 1300 #900 # 500 # 6000 # 8000# 1200 #1200 # 7500
+ nTest =  200 # 300 # 100 # 2000 # 4000 #300 # 300 #500
+-batch_size = 2 # 20 # 50 # 3 # 20 # 50 # 5 # 50
++batch_size = 10 # 20 # 20 # 50 # 3 # 20 # 50 # 5 # 50
+ learning_rate = 0.001 # 0.0001 # 0.001 # 0.005 # 0.001
+ weight_decay = 1e-4 # 1e-3 # 1e-4
+-epochs = 100 # 500 # 1000 # 25 # 100 # 1000
++epochs = 50 # 100 # 500 # 1000 # 25 # 100 # 1000
+ iterations = epochs * (nTrain // batch_size)
+ modes = 14 # 10 #12 # 14 # 16 # 10 # 16
+ width = 12 # 8 #12 #14 # 12 # 16 # 32
+ width_q = width # 2 * width #
+ width_h = width//2 # width//4 # width #
+-n_layers = 4 # 4 # 5 # 5 # 8
++n_layers = 3 # 2 # 4 # 5 # 5 # 8
+ 
+ # Discretization
+ 
+-s = 64 # 32 # 64 #32 # 64
++s = 32 # 64 # 32 # 64 #32 # 64
+ T_in = 1
+-T_out = 20 # 100
++T_out = 91 # 20 # 100
+ 
+ # Training Setting
+ normalized = True
+@@ -34,15 +34,44 @@
+ parent_dir = './data/'
+ 
+ #matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
+-matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
+-
++#matlab_dataset = 'CH3D_800_Nt_101_Nx_64.mat'
++matlab_dataset = 'CH3D_1500_Nt_101_Nx_32.mat'
+ # Plotting
+ index = 62  # 24 # 62
+-domain = [-np.pi, np.pi]
++#domain = [-np.pi, np.pi]
++Lx = 2 # np.pi            # Domain size from MATLAB
++#domain = [-np.pi, np.pi]
++domain = [-Lx/2, Lx/2]
+ # time_steps = [29, 35, 39, 45, 49]
+ # time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
+ #time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
+ #              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
+ #time_steps = [39, 49, 59, 69, 79, 89, 99]
+ #time_steps = [39, 59, 79]
+-time_steps = [0, 9, 19]
+\ No newline at end of file
++time_steps = [0, 50, 90]
++
++
++#############
++
++# Time Discretization Parameters (from AC3D MATLAB)
++dt_sim = 0.0005     # Time step in the MATLAB simulation
++Nt_sim = 50        # Total number of simulation steps in MATLAB
++num_saved_steps_sim = 101 # Number of steps saved in the .mat file (Nt_sim + 1)
++# ns_sim = Nt_sim / (num_saved_steps_sim - 1) if num_saved_steps_sim > 1 else 1.0 # Saving interval in sim steps
++# dt_model = ns_sim * dt_sim # Effective time step between frames in your data/model output
++# For AC3D, MATLAB code saves all Nt+1 steps. So ns_sim = 1.
++dt_model = dt_sim # If T_out steps directly correspond to dt_sim steps after T_in
++# PDE Parameters for Allen-Cahn (AC3D)
++# From your MATLAB: epsilon = 0.1, Cahn = epsilon^2.
++# The PDE implemented in calculate_pde_residual was:
++# du/dt = Cahn_ac * laplacian(u) - (u^3 - u)
++epsilon = 0.05  # The epsilon from your AC3D MATLAB script, PDE parameter
++# PINN Specific Settings (if PINN_MODE is True in main.py)
++pde_weight = 0.5  # Example: 50% physics loss, 70% data loss. Adjust as needed.
++# PDE_LOSS_SCALER will be defined in main.py, but you might note its value here for reference
++
++# Learning Rate Scheduler Parameters (for StepLR)
++scheduler_step = 20  # Decay learning rate every 20 epochs
++scheduler_gamma = 0.5 # Multiply learning rate by 0.5 each time
++
++pde_loss_scaler = 1e-4
+\ No newline at end of file
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"TNO3d vs FNO3d\">\n      <change afterPath=\"$PROJECT_DIR$/run_inference.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/vcs.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/vcs.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/main.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/main.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/networks.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/networks.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/post_processing.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/post_processing.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/training.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/training.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/utilities.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/utilities.py\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <excluded-from-favorite>\n      <branch-storage>\n        <map>\n          <entry type=\"LOCAL\">\n            <value>\n              <list>\n                <branch-info repo=\"$PROJECT_DIR$\" source=\"master\" />\n              </list>\n            </value>\n          </entry>\n        </map>\n      </branch-storage>\n    </excluded-from-favorite>\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\n      <map>\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\n      </map>\n    </option>\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n    <option name=\"ROOT_SYNC\" value=\"DONT_SYNC\" />\n  </component>\n  <component name=\"GitHubPullRequestSearchHistory\">{\n  &quot;lastFilter&quot;: {\n    &quot;state&quot;: &quot;OPEN&quot;,\n    &quot;assignee&quot;: &quot;MBamdad&quot;\n  }\n}</component>\n  <component name=\"GithubPullRequestsUISettings\">{\n  &quot;selectedUrlAndAccountId&quot;: {\n    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,\n    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;\n  }\n}</component>\n  <component name=\"ProjectColorInfo\">{\n  &quot;associatedIndex&quot;: 1\n}</component>\n  <component name=\"ProjectId\" id=\"2p11NySvsgjZ8eu9d53SI84567l\" />\n  <component name=\"ProjectReloadState\">\n    <option name=\"STATE\" value=\"1\" />\n  </component>\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">{\n  &quot;keyToString&quot;: {\n    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.main.executor&quot;: &quot;Run&quot;,\n    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.networks.executor&quot;: &quot;Run&quot;,\n    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,\n    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,\n    &quot;Python.test1.executor&quot;: &quot;Run&quot;,\n    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,\n    &quot;git-widget-placeholder&quot;: &quot;main&quot;,\n    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,\n    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,\n    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,\n    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,\n    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,\n    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,\n    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,\n    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;\n  },\n  &quot;keyToStringList&quot;: {\n    &quot;ChangesTree.GroupingKeys&quot;: [\n      &quot;directory&quot;\n    ]\n  }\n}</component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$/configs\" />\n      <recent name=\"$PROJECT_DIR$/AC2Dtest/models\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code/AC2D\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code\" />\n    </key>\n    <key name=\"MoveFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.AC3D_TNO3d\">\n    <configuration name=\"AC3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_TNO3d_hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"MBE3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d_Hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <list>\n      <item itemvalue=\"Python.AC3D_TNO3d\" />\n      <item itemvalue=\"Python.AC3d_FNO3d\" />\n      <item itemvalue=\"Python.AC3d_TNO3d_hybrid\" />\n      <item itemvalue=\"Python.CH3D_TNO3d\" />\n      <item itemvalue=\"Python.MBE3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_FNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d_Hybrid\" />\n    </list>\n  </component>\n  <component name=\"SharedIndexes\">\n    <attachedChunks>\n      <set>\n        <option value=\"bundled-js-predefined-1d06a55b98c1-0b3e54e931b4-JavaScript-PY-241.18034.82\" />\n        <option value=\"bundled-python-sdk-975db3bf15a3-2767605e8bc2-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-241.18034.82\" />\n      </set>\n    </attachedChunks>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"\" />\n      <created>1731918731711</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1731918731711</updated>\n      <workItem from=\"1731918732726\" duration=\"17070000\" />\n      <workItem from=\"1732010735784\" duration=\"777000\" />\n      <workItem from=\"1732011520582\" duration=\"8000\" />\n      <workItem from=\"1732011538945\" duration=\"13153000\" />\n      <workItem from=\"1732106481018\" duration=\"3721000\" />\n      <workItem from=\"1732480846034\" duration=\"2889000\" />\n      <workItem from=\"1732483872465\" duration=\"14926000\" />\n      <workItem from=\"1732567216112\" duration=\"964000\" />\n      <workItem from=\"1732765090621\" duration=\"5000\" />\n      <workItem from=\"1732765102609\" duration=\"12000\" />\n      <workItem from=\"1732765345288\" duration=\"10000\" />\n      <workItem from=\"1732903897716\" duration=\"3074000\" />\n      <workItem from=\"1732911303920\" duration=\"27201000\" />\n      <workItem from=\"1732999179592\" duration=\"8241000\" />\n      <workItem from=\"1733039613684\" duration=\"6792000\" />\n      <workItem from=\"1733095843263\" duration=\"10000\" />\n      <workItem from=\"1733140600841\" duration=\"6993000\" />\n      <workItem from=\"1733150993229\" duration=\"184000\" />\n      <workItem from=\"1733151279786\" duration=\"6000\" />\n      <workItem from=\"1733151296310\" duration=\"16875000\" />\n      <workItem from=\"1733233230739\" duration=\"5172000\" />\n      <workItem from=\"1733246997923\" duration=\"15986000\" />\n      <workItem from=\"1733349590652\" duration=\"1949000\" />\n      <workItem from=\"1733352121741\" duration=\"6332000\" />\n      <workItem from=\"1733405466233\" duration=\"12731000\" />\n      <workItem from=\"1733557048829\" duration=\"5541000\" />\n      <workItem from=\"1733583489891\" duration=\"16419000\" />\n      <workItem from=\"1733859258781\" duration=\"7356000\" />\n      <workItem from=\"1733995059967\" duration=\"7899000\" />\n      <workItem from=\"1734011167665\" duration=\"991000\" />\n      <workItem from=\"1734029966470\" duration=\"25769000\" />\n      <workItem from=\"1734205412700\" duration=\"7689000\" />\n      <workItem from=\"1734644992163\" duration=\"5017000\" />\n      <workItem from=\"1734788130789\" duration=\"2312000\" />\n      <workItem from=\"1734863751114\" duration=\"9000\" />\n      <workItem from=\"1734863775073\" duration=\"9221000\" />\n      <workItem from=\"1734880034791\" duration=\"57000\" />\n      <workItem from=\"1734880213539\" duration=\"15000\" />\n      <workItem from=\"1734880329890\" duration=\"30000\" />\n      <workItem from=\"1734880369064\" duration=\"31312000\" />\n      <workItem from=\"1734983129135\" duration=\"55000\" />\n      <workItem from=\"1735034212628\" duration=\"2274000\" />\n      <workItem from=\"1735049036048\" duration=\"5309000\" />\n      <workItem from=\"1735126261413\" duration=\"75000\" />\n      <workItem from=\"1735356723104\" duration=\"1208000\" />\n      <workItem from=\"1735422837186\" duration=\"1387000\" />\n      <workItem from=\"1735719009558\" duration=\"561000\" />\n      <workItem from=\"1736101930735\" duration=\"570000\" />\n      <workItem from=\"1736102511675\" duration=\"4000\" />\n      <workItem from=\"1736161159525\" duration=\"7670000\" />\n      <workItem from=\"1736237907904\" duration=\"111000\" />\n      <workItem from=\"1736519480236\" duration=\"1867000\" />\n      <workItem from=\"1737577034938\" duration=\"3945000\" />\n      <workItem from=\"1737590448155\" duration=\"6145000\" />\n      <workItem from=\"1738310597042\" duration=\"2502000\" />\n      <workItem from=\"1738316162773\" duration=\"726000\" />\n      <workItem from=\"1738326887364\" duration=\"4500000\" />\n      <workItem from=\"1738586797583\" duration=\"600000\" />\n      <workItem from=\"1738663690532\" duration=\"4505000\" />\n      <workItem from=\"1738668267214\" duration=\"5368000\" />\n      <workItem from=\"1738685509837\" duration=\"74000\" />\n      <workItem from=\"1738703726377\" duration=\"1677000\" />\n      <workItem from=\"1738774383038\" duration=\"2249000\" />\n      <workItem from=\"1738787637783\" duration=\"7013000\" />\n      <workItem from=\"1738962434877\" duration=\"1153000\" />\n      <workItem from=\"1738967049524\" duration=\"782000\" />\n      <workItem from=\"1739275350614\" duration=\"312000\" />\n      <workItem from=\"1739464522072\" duration=\"12498000\" />\n      <workItem from=\"1739572784568\" duration=\"1228000\" />\n      <workItem from=\"1739626528163\" duration=\"5778000\" />\n      <workItem from=\"1739689815626\" duration=\"10399000\" />\n      <workItem from=\"1739812786805\" duration=\"48519000\" />\n      <workItem from=\"1740212626723\" duration=\"1263000\" />\n      <workItem from=\"1740213932190\" duration=\"644000\" />\n      <workItem from=\"1741475492994\" duration=\"40894000\" />\n      <workItem from=\"1741690305204\" duration=\"339000\" />\n      <workItem from=\"1741705983516\" duration=\"604000\" />\n      <workItem from=\"1741713165753\" duration=\"1198000\" />\n      <workItem from=\"1741861318912\" duration=\"2286000\" />\n      <workItem from=\"1742201562752\" duration=\"618000\" />\n      <workItem from=\"1742209067924\" duration=\"383000\" />\n      <workItem from=\"1742226300133\" duration=\"2432000\" />\n      <workItem from=\"1743071528350\" duration=\"9513000\" />\n      <workItem from=\"1743490058046\" duration=\"9000\" />\n      <workItem from=\"1743587112942\" duration=\"1188000\" />\n      <workItem from=\"1748900986740\" duration=\"1771000\" />\n      <workItem from=\"1748931928220\" duration=\"446000\" />\n      <workItem from=\"1748932436127\" duration=\"20890000\" />\n      <workItem from=\"1748970706276\" duration=\"3719000\" />\n      <workItem from=\"1748988822181\" duration=\"59000\" />\n      <workItem from=\"1749200290051\" duration=\"680000\" />\n      <workItem from=\"1749203502833\" duration=\"1349000\" />\n      <workItem from=\"1749213099437\" duration=\"3082000\" />\n      <workItem from=\"1750057109660\" duration=\"10453000\" />\n      <workItem from=\"1750070416210\" duration=\"46415000\" />\n    </task>\n    <task id=\"LOCAL-00001\" summary=\"Initial Commit\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732484343908</created>\n      <option name=\"number\" value=\"00001\" />\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732484343908</updated>\n    </task>\n    <task id=\"LOCAL-00002\" summary=\"added TransformerFNO\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732497990642</created>\n      <option name=\"number\" value=\"00002\" />\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732497990642</updated>\n    </task>\n    <task id=\"LOCAL-00003\" summary=\"added the connection between time steps - the model development is finished\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732910153380</created>\n      <option name=\"number\" value=\"00003\" />\n      <option name=\"presentableId\" value=\"LOCAL-00003\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732910153380</updated>\n    </task>\n    <task id=\"LOCAL-00004\" summary=\"Finished Allen-Cahn Problem\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733176021525</created>\n      <option name=\"number\" value=\"00004\" />\n      <option name=\"presentableId\" value=\"LOCAL-00004\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733176021525</updated>\n    </task>\n    <task id=\"LOCAL-00005\" summary=\"Added Allen-Cahn 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733583274023</created>\n      <option name=\"number\" value=\"00005\" />\n      <option name=\"presentableId\" value=\"LOCAL-00005\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733583274023</updated>\n    </task>\n    <task id=\"LOCAL-00006\" summary=\"added save_vtk\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733995237535</created>\n      <option name=\"number\" value=\"00006\" />\n      <option name=\"presentableId\" value=\"LOCAL-00006\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733995237535</updated>\n    </task>\n    <task id=\"LOCAL-00007\" summary=\"added MATLAB codes for creating database\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1734788540933</created>\n      <option name=\"number\" value=\"00007\" />\n      <option name=\"presentableId\" value=\"LOCAL-00007\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1734788540933</updated>\n    </task>\n    <task id=\"LOCAL-00008\" summary=\"added CH2DNL\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735126332032</created>\n      <option name=\"number\" value=\"00008\" />\n      <option name=\"presentableId\" value=\"LOCAL-00008\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735126332032</updated>\n    </task>\n    <task id=\"LOCAL-00009\" summary=\"added SH2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735719422931</created>\n      <option name=\"number\" value=\"00009\" />\n      <option name=\"presentableId\" value=\"LOCAL-00009\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735719422931</updated>\n    </task>\n    <task id=\"LOCAL-00010\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1736237977029</created>\n      <option name=\"number\" value=\"00010\" />\n      <option name=\"presentableId\" value=\"LOCAL-00010\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1736237977029</updated>\n    </task>\n    <task id=\"LOCAL-00011\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738788849261</created>\n      <option name=\"number\" value=\"00011\" />\n      <option name=\"presentableId\" value=\"LOCAL-00011\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738788849261</updated>\n    </task>\n    <task id=\"LOCAL-00012\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738789326593</created>\n      <option name=\"number\" value=\"00012\" />\n      <option name=\"presentableId\" value=\"LOCAL-00012\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738789326593</updated>\n    </task>\n    <task id=\"LOCAL-00013\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738796104012</created>\n      <option name=\"number\" value=\"00013\" />\n      <option name=\"presentableId\" value=\"LOCAL-00013\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738796104012</updated>\n    </task>\n    <task id=\"LOCAL-00014\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962464719</created>\n      <option name=\"number\" value=\"00014\" />\n      <option name=\"presentableId\" value=\"LOCAL-00014\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962464719</updated>\n    </task>\n    <task id=\"LOCAL-00015\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962748829</created>\n      <option name=\"number\" value=\"00015\" />\n      <option name=\"presentableId\" value=\"LOCAL-00015\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962748829</updated>\n    </task>\n    <task id=\"LOCAL-00016\" summary=\"Turn Nx to 64\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738967163754</created>\n      <option name=\"number\" value=\"00016\" />\n      <option name=\"presentableId\" value=\"LOCAL-00016\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738967163754</updated>\n    </task>\n    <task id=\"LOCAL-00017\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275401458</created>\n      <option name=\"number\" value=\"00017\" />\n      <option name=\"presentableId\" value=\"LOCAL-00017\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275401458</updated>\n    </task>\n    <task id=\"LOCAL-00018\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275433418</created>\n      <option name=\"number\" value=\"00018\" />\n      <option name=\"presentableId\" value=\"LOCAL-00018\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275433418</updated>\n    </task>\n    <task id=\"LOCAL-00019\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690373369</created>\n      <option name=\"number\" value=\"00019\" />\n      <option name=\"presentableId\" value=\"LOCAL-00019\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690373369</updated>\n    </task>\n    <task id=\"LOCAL-00020\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690420059</created>\n      <option name=\"number\" value=\"00020\" />\n      <option name=\"presentableId\" value=\"LOCAL-00020\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690420059</updated>\n    </task>\n    <task id=\"LOCAL-00021\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1743587271259</created>\n      <option name=\"number\" value=\"00021\" />\n      <option name=\"presentableId\" value=\"LOCAL-00021\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1743587271259</updated>\n    </task>\n    <option name=\"localTasksCounter\" value=\"22\" />\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"Vcs.Log.Tabs.Properties\">\n    <option name=\"RECENT_FILTERS\">\n      <map>\n        <entry key=\"Branch\">\n          <value>\n            <list>\n              <RecentGroup>\n                <option name=\"FILTER_VALUES\">\n                  <option value=\"main\" />\n                </option>\n              </RecentGroup>\n            </list>\n          </value>\n        </entry>\n      </map>\n    </option>\n    <option name=\"TAB_STATES\">\n      <map>\n        <entry key=\"MAIN\">\n          <value>\n            <State>\n              <option name=\"FILTERS\">\n                <map>\n                  <entry key=\"branch\">\n                    <value>\n                      <list>\n                        <option value=\"main\" />\n                      </list>\n                    </value>\n                  </entry>\n                </map>\n              </option>\n            </State>\n          </value>\n        </entry>\n      </map>\n    </option>\n  </component>\n  <component name=\"VcsManagerConfiguration\">\n    <MESSAGE value=\"Initial Commit\" />\n    <MESSAGE value=\"added TransformerFNO\" />\n    <MESSAGE value=\"added the connection between time steps - the model development is finished\" />\n    <MESSAGE value=\"refactored\" />\n    <MESSAGE value=\"Finished Allen-Cahn Problem\" />\n    <MESSAGE value=\"Added Allen-Cahn 3D\" />\n    <MESSAGE value=\"added save_vtk\" />\n    <MESSAGE value=\"added MATLAB codes for creating database\" />\n    <MESSAGE value=\"seperated the number of layers in fourier part and convolutional part\" />\n    <MESSAGE value=\"added CH2DNL\" />\n    <MESSAGE value=\"added SH2D\" />\n    <MESSAGE value=\"added PFC2D\" />\n    <MESSAGE value=\"Turn Nx to 64\" />\n    <MESSAGE value=\"update to 3D\" />\n    <MESSAGE value=\"TNO3d vs FNO3d\" />\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"TNO3d vs FNO3d\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>142</line>\n          <option name=\"timeStamp\" value=\"17\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>163</line>\n          <option name=\"timeStamp\" value=\"18\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>134</line>\n          <option name=\"timeStamp\" value=\"19\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>327</line>\n          <option name=\"timeStamp\" value=\"20\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>243</line>\n          <option name=\"timeStamp\" value=\"21\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_2.py</url>\n          <line>333</line>\n          <option name=\"timeStamp\" value=\"27\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>\n          <line>371</line>\n          <option name=\"timeStamp\" value=\"44\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>\n          <line>338</line>\n          <option name=\"timeStamp\" value=\"54\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>53</line>\n          <option name=\"timeStamp\" value=\"128\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>30</line>\n          <option name=\"timeStamp\" value=\"129\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>25</line>\n          <option name=\"timeStamp\" value=\"133\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>18</line>\n          <option name=\"timeStamp\" value=\"135\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>\n          <line>44</line>\n          <option name=\"timeStamp\" value=\"138\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test2.py</url>\n          <line>16</line>\n          <option name=\"timeStamp\" value=\"144\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/utilities.py</url>\n          <line>98</line>\n          <option name=\"timeStamp\" value=\"170\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/main.py</url>\n          <line>157</line>\n          <option name=\"timeStamp\" value=\"177\" />\n        </line-breakpoint>\n      </breakpoints>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n  </component>\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test3.coverage\" NAME=\"Test3 Coverage Results\" MODIFIED=\"1739273938386\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage\" NAME=\"config_AC2D_FNO3d Coverage Results\" MODIFIED=\"1733233385695\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1743065376798\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_2.coverage\" NAME=\"AC2D_Net2D_2 Coverage Results\" MODIFIED=\"1732904114403\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$test2.coverage\" NAME=\"test2 Coverage Results\" MODIFIED=\"1742889074336\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1741561715014\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage\" NAME=\"config_SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254757455\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$backend_interagg.coverage\" NAME=\"backend_interagg Coverage Results\" MODIFIED=\"1737630366471\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript3.coverage\" NAME=\"RunScript3 Coverage Results\" MODIFIED=\"1736368081257\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_2.coverage\" NAME=\"AC2D_2 Coverage Results\" MODIFIED=\"1732483323689\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1733086051390\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main_TF.coverage\" NAME=\"main_TF Coverage Results\" MODIFIED=\"1738704014479\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1741538869064\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$THFNO.coverage\" NAME=\"THFNO Coverage Results\" MODIFIED=\"1732911474644\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/networks\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1740088478224\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$PFC3D.coverage\" NAME=\"PFC3D Coverage Results\" MODIFIED=\"1740083613128\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1741603428589\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$run_inference.coverage\" NAME=\"run_inference Coverage Results\" MODIFIED=\"1750323709039\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1738663765959\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$post_processing.coverage\" NAME=\"post_processing Coverage Results\" MODIFIED=\"1733557098801\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage\" NAME=\"config_CH2D_TNO2d Coverage Results\" MODIFIED=\"1734086207850\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1748933697533\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1750255151255\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript2.coverage\" NAME=\"RunScript2 Coverage Results\" MODIFIED=\"1736369209710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1742215946758\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_3.coverage\" NAME=\"AC2D_Net2D_3 Coverage Results\" MODIFIED=\"1732974697103\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_FNO3d.coverage\" NAME=\"AC3d_FNO3d Coverage Results\" MODIFIED=\"1749017845623\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D.coverage\" NAME=\"AC2D Coverage Results\" MODIFIED=\"1733088640665\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/Archive_Code\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D.coverage\" NAME=\"AC2D_Net2D Coverage Results\" MODIFIED=\"1732567473230\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1740054182408\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage\" NAME=\"MBE3D_TNO3d Coverage Results\" MODIFIED=\"1741562061391\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_AC3D_TNO3d.coverage\" NAME=\"config_AC3D_TNO3d Coverage Results\" MODIFIED=\"1737644605063\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D.coverage\" NAME=\"MBE3D Coverage Results\" MODIFIED=\"1739283566145\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1741605347375\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1743071672425\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1736268192289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage\" NAME=\"PFC3D_TNO3d Coverage Results\" MODIFIED=\"1741564210973\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage\" NAME=\"config_CH2DNL_TNO2d Coverage Results\" MODIFIED=\"1735052490996\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$MBE2D.coverage\" NAME=\"MBE2D Coverage Results\" MODIFIED=\"1732278526731\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1739914172084\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test_Run.coverage\" NAME=\"Test_Run Coverage Results\" MODIFIED=\"1738945320139\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1741561294310\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741861381348\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1743081225414\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage\" NAME=\"PFV3D_FNO3d Coverage Results\" MODIFIED=\"1741564487710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript1.coverage\" NAME=\"RunScript1 Coverage Results\" MODIFIED=\"1736368790622\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$SH2D.coverage\" NAME=\"SH2D Coverage Results\" MODIFIED=\"1732347080402\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$PFC2D.coverage\" NAME=\"PFC2D Coverage Results\" MODIFIED=\"1732278679485\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$CH2D.coverage\" NAME=\"CH2D Coverage Results\" MODIFIED=\"1732347055915\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_FNO3d.coverage\" NAME=\"AC3D_FNO3d Coverage Results\" MODIFIED=\"1741561435127\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D.coverage\" NAME=\"SH3D Coverage Results\" MODIFIED=\"1739044808411\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test.coverage\" NAME=\"Test Coverage Results\" MODIFIED=\"1739459206236\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741547133078\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage\" NAME=\"config_AC2D_FNO2d Coverage Results\" MODIFIED=\"1733393903488\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$AC3D.coverage\" NAME=\"AC3D Coverage Results\" MODIFIED=\"1740041515520\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_CH3D_TNO3d.coverage\" NAME=\"config_CH3D_TNO3d Coverage Results\" MODIFIED=\"1738089807566\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test2.coverage\" NAME=\"Test2 Coverage Results\" MODIFIED=\"1739283715182\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_FNO3d.coverage\" NAME=\"CH3D_FNO3d Coverage Results\" MODIFIED=\"1741628529142\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage\" NAME=\"AC3d_TNO3d_hybrid Coverage Results\" MODIFIED=\"1748989478372\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1737899062785\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D.coverage\" NAME=\"config_AC2D Coverage Results\" MODIFIED=\"1733087276180\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_1.coverage\" NAME=\"AC2D_Net2D_1 Coverage Results\" MODIFIED=\"1732535211383\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1736520700819\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$fourier_3d.coverage\" NAME=\"fourier_3d Coverage Results\" MODIFIED=\"1732221600628\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1750254767095\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage\" NAME=\"SH3D_TNO3d_Hybrid Coverage Results\" MODIFIED=\"1749216389646\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1748990262244\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$test1.coverage\" NAME=\"test1 Coverage Results\" MODIFIED=\"1733413325318\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_2.coverage\" NAME=\"CH3D_2 Coverage Results\" MODIFIED=\"1739918355289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254975290\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage\" NAME=\"config_MBE2D_TNO2d Coverage Results\" MODIFIED=\"1736261397712\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision 220974c4665130a29207d2b020fbea2fd7734cf2)
+++ b/.idea/workspace.xml	(date 1754642309795)
@@ -4,31 +4,18 @@
     <option name="autoReloadType" value="SELECTIVE" />
   </component>
   <component name="ChangeListManager">
-    <list default="true" id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="TNO3d vs FNO3d">
-      <change afterPath="$PROJECT_DIR$/run_inference.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/vcs.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />
+    <list default="true" id="4e84c369-97f3-4301-a9fc-5fc5327e1a8a" name="Changes" comment="3d_phase_evolution">
+      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_10_09_AM_[Changes]/shelved.patch" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/MBE3D_Hybrid.jpg" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/MBE3D_Hybrid1.jpg" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/MBE3D_Hybrid2.jpg" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/MBE3D_Hybrid3.jpg" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results.h5" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25,_9_52_AM_[Changes]/shelved.patch" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25__10_09_AM__Changes_.xml" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_8_8_25__9_52_AM__Changes_.xml" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/PFC3D/.idea/workspace.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/main.py" beforeDir="false" afterPath="$PROJECT_DIR$/main.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/networks.py" beforeDir="false" afterPath="$PROJECT_DIR$/networks.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/post_processing.py" beforeDir="false" afterPath="$PROJECT_DIR$/post_processing.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/training.py" beforeDir="false" afterPath="$PROJECT_DIR$/training.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/utilities.py" beforeDir="false" afterPath="$PROJECT_DIR$/utilities.py" afterDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
@@ -43,31 +30,18 @@
     </option>
   </component>
   <component name="Git.Settings">
-    <excluded-from-favorite>
-      <branch-storage>
-        <map>
-          <entry type="LOCAL">
-            <value>
-              <list>
-                <branch-info repo="$PROJECT_DIR$" source="master" />
-              </list>
-            </value>
-          </entry>
-        </map>
-      </branch-storage>
-    </excluded-from-favorite>
-    <option name="RECENT_BRANCH_BY_REPOSITORY">
-      <map>
-        <entry key="$PROJECT_DIR$" value="main" />
-      </map>
-    </option>
     <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
-    <option name="ROOT_SYNC" value="DONT_SYNC" />
   </component>
   <component name="GitHubPullRequestSearchHistory">{
+  &quot;history&quot;: [
+    {
+      &quot;state&quot;: &quot;OPEN&quot;,
+      &quot;author&quot;: &quot;MBamdad&quot;
+    }
+  ],
   &quot;lastFilter&quot;: {
     &quot;state&quot;: &quot;OPEN&quot;,
-    &quot;assignee&quot;: &quot;MBamdad&quot;
+    &quot;author&quot;: &quot;MBamdad&quot;
   }
 }</component>
   <component name="GithubPullRequestsUISettings">{
@@ -77,129 +51,46 @@
   }
 }</component>
   <component name="ProjectColorInfo">{
+  &quot;customColor&quot;: &quot;&quot;,
   &quot;associatedIndex&quot;: 1
 }</component>
-  <component name="ProjectId" id="2p11NySvsgjZ8eu9d53SI84567l" />
-  <component name="ProjectReloadState">
-    <option name="STATE" value="1" />
-  </component>
+  <component name="ProjectId" id="30Ji1A2o7U8uDkwC8cwxQfRFc4k" />
   <component name="ProjectViewState">
     <option name="hideEmptyMiddlePackages" value="true" />
     <option name="showLibraryContents" value="true" />
   </component>
   <component name="PropertiesComponent">{
   &quot;keyToString&quot;: {
-    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,
-    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,
-    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,
-    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,
-    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,
-    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,
-    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,
-    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,
-    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,
-    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,
-    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,
-    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,
-    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,
-    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,
-    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,
-    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,
-    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,
-    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,
-    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,
-    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,
-    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,
-    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,
-    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,
-    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,
-    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,
-    &quot;Python.Test.executor&quot;: &quot;Run&quot;,
-    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,
-    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,
-    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,
-    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,
-    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,
-    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,
-    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,
+    &quot;Python.CH3D_FNO4d.executor&quot;: &quot;Run&quot;,
+    &quot;Python.PFC3D_FNO4d.executor&quot;: &quot;Run&quot;,
+    &quot;Python.SH3D_FNO4d.executor&quot;: &quot;Run&quot;,
+    &quot;Python.SH3D_Hybrid.executor&quot;: &quot;Run&quot;,
+    &quot;Python.SH3D_TNO3D.executor&quot;: &quot;Run&quot;,
     &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,
-    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,
     &quot;Python.main.executor&quot;: &quot;Run&quot;,
-    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,
-    &quot;Python.networks.executor&quot;: &quot;Run&quot;,
-    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,
-    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,
-    &quot;Python.test1.executor&quot;: &quot;Run&quot;,
+    &quot;Python.main1.executor&quot;: &quot;Run&quot;,
+    &quot;Python.run_interface3.executor&quot;: &quot;Run&quot;,
     &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
     &quot;git-widget-placeholder&quot;: &quot;main&quot;,
-    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,
+    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/MatlabCode/Out_Distribution&quot;,
     &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
-    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,
     &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
     &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,
     &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,
-    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,
     &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;
-  },
-  &quot;keyToStringList&quot;: {
-    &quot;ChangesTree.GroupingKeys&quot;: [
-      &quot;directory&quot;
-    ]
   }
 }</component>
   <component name="RecentsManager">
     <key name="CopyFile.RECENT_KEYS">
-      <recent name="$PROJECT_DIR$/data" />
-      <recent name="$PROJECT_DIR$/configs" />
-      <recent name="$PROJECT_DIR$/AC2Dtest/models" />
-      <recent name="$PROJECT_DIR$/Archive_Code/AC2D" />
-      <recent name="$PROJECT_DIR$/Archive_Code" />
-    </key>
-    <key name="MoveFile.RECENT_KEYS">
-      <recent name="$PROJECT_DIR$/data" />
-      <recent name="$PROJECT_DIR$" />
+      <recent name="$PROJECT_DIR$/MatlabCode/Out_Distribution" />
+      <recent name="$PROJECT_DIR$/PFC3D/plots_Data_Physics_TNO3d" />
+      <recent name="$PROJECT_DIR$/PFC3D/plots_TNO3d" />
+      <recent name="$PROJECT_DIR$/MBE3D/plots_Data_Physics_TNO3d" />
+      <recent name="$PROJECT_DIR$/MBE3D/plots_TNO3d" />
     </key>
   </component>
-  <component name="RunManager" selected="Python.AC3D_TNO3d">
-    <configuration name="AC3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
-      <module name="PhaseFieldNet" />
-      <option name="ENV_FILES" value="" />
-      <option name="INTERPRETER_OPTIONS" value="" />
-      <option name="PARENT_ENVS" value="true" />
-      <envs>
-        <env name="PYTHONUNBUFFERED" value="1" />
-      </envs>
-      <option name="SDK_HOME" value="" />
-      <option name="SDK_NAME" value="torch_env (2)" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
-      <option name="ADD_CONTENT_ROOTS" value="true" />
-      <option name="ADD_SOURCE_ROOTS" value="true" />
-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
-      <option name="PARAMETERS" value="" />
-      <option name="SHOW_COMMAND_LINE" value="false" />
-      <option name="EMULATE_TERMINAL" value="false" />
-      <option name="MODULE_MODE" value="false" />
-      <option name="REDIRECT_INPUT" value="false" />
-      <option name="INPUT_FILE" value="" />
-      <method v="2" />
-    </configuration>
-    <configuration name="AC3d_FNO3d" type="PythonConfigurationType" factoryName="Python">
+  <component name="RunManager" selected="Python.SH3D_FNO4d">
+    <configuration name="CH3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
       <module name="PhaseFieldNet" />
       <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
@@ -223,7 +114,7 @@
       <option name="INPUT_FILE" value="" />
       <method v="2" />
     </configuration>
-    <configuration name="AC3d_TNO3d_hybrid" type="PythonConfigurationType" factoryName="Python">
+    <configuration name="PFC3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
       <module name="PhaseFieldNet" />
       <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
@@ -247,55 +138,7 @@
       <option name="INPUT_FILE" value="" />
       <method v="2" />
     </configuration>
-    <configuration name="CH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
-      <module name="PhaseFieldNet" />
-      <option name="ENV_FILES" value="" />
-      <option name="INTERPRETER_OPTIONS" value="" />
-      <option name="PARENT_ENVS" value="true" />
-      <envs>
-        <env name="PYTHONUNBUFFERED" value="1" />
-      </envs>
-      <option name="SDK_HOME" value="" />
-      <option name="SDK_NAME" value="torch_env (2)" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
-      <option name="ADD_CONTENT_ROOTS" value="true" />
-      <option name="ADD_SOURCE_ROOTS" value="true" />
-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
-      <option name="PARAMETERS" value="" />
-      <option name="SHOW_COMMAND_LINE" value="false" />
-      <option name="EMULATE_TERMINAL" value="false" />
-      <option name="MODULE_MODE" value="false" />
-      <option name="REDIRECT_INPUT" value="false" />
-      <option name="INPUT_FILE" value="" />
-      <method v="2" />
-    </configuration>
-    <configuration name="CH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
-      <module name="PhaseFieldNet" />
-      <option name="ENV_FILES" value="" />
-      <option name="INTERPRETER_OPTIONS" value="" />
-      <option name="PARENT_ENVS" value="true" />
-      <envs>
-        <env name="PYTHONUNBUFFERED" value="1" />
-      </envs>
-      <option name="SDK_HOME" value="" />
-      <option name="SDK_NAME" value="torch_env (2)" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
-      <option name="ADD_CONTENT_ROOTS" value="true" />
-      <option name="ADD_SOURCE_ROOTS" value="true" />
-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
-      <option name="PARAMETERS" value="" />
-      <option name="SHOW_COMMAND_LINE" value="false" />
-      <option name="EMULATE_TERMINAL" value="false" />
-      <option name="MODULE_MODE" value="false" />
-      <option name="REDIRECT_INPUT" value="false" />
-      <option name="INPUT_FILE" value="" />
-      <method v="2" />
-    </configuration>
-    <configuration name="MBE3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
+    <configuration name="SH3D_FNO4d" type="PythonConfigurationType" factoryName="Python">
       <module name="PhaseFieldNet" />
       <option name="ENV_FILES" value="" />
       <option name="INTERPRETER_OPTIONS" value="" />
@@ -304,79 +147,7 @@
         <env name="PYTHONUNBUFFERED" value="1" />
       </envs>
       <option name="SDK_HOME" value="" />
-      <option name="SDK_NAME" value="torch_env (2)" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
-      <option name="ADD_CONTENT_ROOTS" value="true" />
-      <option name="ADD_SOURCE_ROOTS" value="true" />
-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
-      <option name="PARAMETERS" value="" />
-      <option name="SHOW_COMMAND_LINE" value="false" />
-      <option name="EMULATE_TERMINAL" value="false" />
-      <option name="MODULE_MODE" value="false" />
-      <option name="REDIRECT_INPUT" value="false" />
-      <option name="INPUT_FILE" value="" />
-      <method v="2" />
-    </configuration>
-    <configuration name="SH3D_FNO3d" type="PythonConfigurationType" factoryName="Python">
-      <module name="PhaseFieldNet" />
-      <option name="ENV_FILES" value="" />
-      <option name="INTERPRETER_OPTIONS" value="" />
-      <option name="PARENT_ENVS" value="true" />
-      <envs>
-        <env name="PYTHONUNBUFFERED" value="1" />
-      </envs>
-      <option name="SDK_HOME" value="" />
-      <option name="SDK_NAME" value="torch_env (2)" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
-      <option name="ADD_CONTENT_ROOTS" value="true" />
-      <option name="ADD_SOURCE_ROOTS" value="true" />
-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
-      <option name="PARAMETERS" value="" />
-      <option name="SHOW_COMMAND_LINE" value="false" />
-      <option name="EMULATE_TERMINAL" value="false" />
-      <option name="MODULE_MODE" value="false" />
-      <option name="REDIRECT_INPUT" value="false" />
-      <option name="INPUT_FILE" value="" />
-      <method v="2" />
-    </configuration>
-    <configuration name="SH3D_TNO3d" type="PythonConfigurationType" factoryName="Python">
-      <module name="PhaseFieldNet" />
-      <option name="ENV_FILES" value="" />
-      <option name="INTERPRETER_OPTIONS" value="" />
-      <option name="PARENT_ENVS" value="true" />
-      <envs>
-        <env name="PYTHONUNBUFFERED" value="1" />
-      </envs>
-      <option name="SDK_HOME" value="" />
-      <option name="SDK_NAME" value="torch_env (2)" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
-      <option name="ADD_CONTENT_ROOTS" value="true" />
-      <option name="ADD_SOURCE_ROOTS" value="true" />
-      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/main.py" />
-      <option name="PARAMETERS" value="" />
-      <option name="SHOW_COMMAND_LINE" value="false" />
-      <option name="EMULATE_TERMINAL" value="false" />
-      <option name="MODULE_MODE" value="false" />
-      <option name="REDIRECT_INPUT" value="false" />
-      <option name="INPUT_FILE" value="" />
-      <method v="2" />
-    </configuration>
-    <configuration name="SH3D_TNO3d_Hybrid" type="PythonConfigurationType" factoryName="Python">
-      <module name="PhaseFieldNet" />
-      <option name="ENV_FILES" value="" />
-      <option name="INTERPRETER_OPTIONS" value="" />
-      <option name="PARENT_ENVS" value="true" />
-      <envs>
-        <env name="PYTHONUNBUFFERED" value="1" />
-      </envs>
-      <option name="SDK_HOME" value="" />
-      <option name="SDK_NAME" value="torch_env (2)" />
+      <option name="SDK_NAME" value="torch_env" />
       <option name="WORKING_DIRECTORY" value="" />
       <option name="IS_MODULE_SDK" value="false" />
       <option name="ADD_CONTENT_ROOTS" value="true" />
@@ -392,14 +163,9 @@
       <method v="2" />
     </configuration>
     <list>
-      <item itemvalue="Python.AC3D_TNO3d" />
-      <item itemvalue="Python.AC3d_FNO3d" />
-      <item itemvalue="Python.AC3d_TNO3d_hybrid" />
-      <item itemvalue="Python.CH3D_TNO3d" />
-      <item itemvalue="Python.MBE3D_TNO3d" />
-      <item itemvalue="Python.SH3D_FNO3d" />
-      <item itemvalue="Python.SH3D_TNO3d" />
-      <item itemvalue="Python.SH3D_TNO3d_Hybrid" />
+      <item itemvalue="Python.CH3D_FNO4d" />
+      <item itemvalue="Python.PFC3D_FNO4d" />
+      <item itemvalue="Python.SH3D_FNO4d" />
     </list>
   </component>
   <component name="SharedIndexes">
@@ -413,334 +179,276 @@
   <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
   <component name="TaskManager">
     <task active="true" id="Default" summary="Default task">
-      <changelist id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="" />
-      <created>1731918731711</created>
+      <changelist id="4e84c369-97f3-4301-a9fc-5fc5327e1a8a" name="Changes" comment="3d_phase_evolution" />
+      <created>1753351859462</created>
       <option name="number" value="Default" />
       <option name="presentableId" value="Default" />
-      <updated>1731918731711</updated>
-      <workItem from="1731918732726" duration="17070000" />
-      <workItem from="1732010735784" duration="777000" />
-      <workItem from="1732011520582" duration="8000" />
-      <workItem from="1732011538945" duration="13153000" />
-      <workItem from="1732106481018" duration="3721000" />
-      <workItem from="1732480846034" duration="2889000" />
-      <workItem from="1732483872465" duration="14926000" />
-      <workItem from="1732567216112" duration="964000" />
-      <workItem from="1732765090621" duration="5000" />
-      <workItem from="1732765102609" duration="12000" />
-      <workItem from="1732765345288" duration="10000" />
-      <workItem from="1732903897716" duration="3074000" />
-      <workItem from="1732911303920" duration="27201000" />
-      <workItem from="1732999179592" duration="8241000" />
-      <workItem from="1733039613684" duration="6792000" />
-      <workItem from="1733095843263" duration="10000" />
-      <workItem from="1733140600841" duration="6993000" />
-      <workItem from="1733150993229" duration="184000" />
-      <workItem from="1733151279786" duration="6000" />
-      <workItem from="1733151296310" duration="16875000" />
-      <workItem from="1733233230739" duration="5172000" />
-      <workItem from="1733246997923" duration="15986000" />
-      <workItem from="1733349590652" duration="1949000" />
-      <workItem from="1733352121741" duration="6332000" />
-      <workItem from="1733405466233" duration="12731000" />
-      <workItem from="1733557048829" duration="5541000" />
-      <workItem from="1733583489891" duration="16419000" />
-      <workItem from="1733859258781" duration="7356000" />
-      <workItem from="1733995059967" duration="7899000" />
-      <workItem from="1734011167665" duration="991000" />
-      <workItem from="1734029966470" duration="25769000" />
-      <workItem from="1734205412700" duration="7689000" />
-      <workItem from="1734644992163" duration="5017000" />
-      <workItem from="1734788130789" duration="2312000" />
-      <workItem from="1734863751114" duration="9000" />
-      <workItem from="1734863775073" duration="9221000" />
-      <workItem from="1734880034791" duration="57000" />
-      <workItem from="1734880213539" duration="15000" />
-      <workItem from="1734880329890" duration="30000" />
-      <workItem from="1734880369064" duration="31312000" />
-      <workItem from="1734983129135" duration="55000" />
-      <workItem from="1735034212628" duration="2274000" />
-      <workItem from="1735049036048" duration="5309000" />
-      <workItem from="1735126261413" duration="75000" />
-      <workItem from="1735356723104" duration="1208000" />
-      <workItem from="1735422837186" duration="1387000" />
-      <workItem from="1735719009558" duration="561000" />
-      <workItem from="1736101930735" duration="570000" />
-      <workItem from="1736102511675" duration="4000" />
-      <workItem from="1736161159525" duration="7670000" />
-      <workItem from="1736237907904" duration="111000" />
-      <workItem from="1736519480236" duration="1867000" />
-      <workItem from="1737577034938" duration="3945000" />
-      <workItem from="1737590448155" duration="6145000" />
-      <workItem from="1738310597042" duration="2502000" />
-      <workItem from="1738316162773" duration="726000" />
-      <workItem from="1738326887364" duration="4500000" />
-      <workItem from="1738586797583" duration="600000" />
-      <workItem from="1738663690532" duration="4505000" />
-      <workItem from="1738668267214" duration="5368000" />
-      <workItem from="1738685509837" duration="74000" />
-      <workItem from="1738703726377" duration="1677000" />
-      <workItem from="1738774383038" duration="2249000" />
-      <workItem from="1738787637783" duration="7013000" />
-      <workItem from="1738962434877" duration="1153000" />
-      <workItem from="1738967049524" duration="782000" />
-      <workItem from="1739275350614" duration="312000" />
-      <workItem from="1739464522072" duration="12498000" />
-      <workItem from="1739572784568" duration="1228000" />
-      <workItem from="1739626528163" duration="5778000" />
-      <workItem from="1739689815626" duration="10399000" />
-      <workItem from="1739812786805" duration="48519000" />
-      <workItem from="1740212626723" duration="1263000" />
-      <workItem from="1740213932190" duration="644000" />
-      <workItem from="1741475492994" duration="40894000" />
-      <workItem from="1741690305204" duration="339000" />
-      <workItem from="1741705983516" duration="604000" />
-      <workItem from="1741713165753" duration="1198000" />
-      <workItem from="1741861318912" duration="2286000" />
-      <workItem from="1742201562752" duration="618000" />
-      <workItem from="1742209067924" duration="383000" />
-      <workItem from="1742226300133" duration="2432000" />
-      <workItem from="1743071528350" duration="9513000" />
-      <workItem from="1743490058046" duration="9000" />
-      <workItem from="1743587112942" duration="1188000" />
-      <workItem from="1748900986740" duration="1771000" />
-      <workItem from="1748931928220" duration="446000" />
-      <workItem from="1748932436127" duration="20890000" />
-      <workItem from="1748970706276" duration="3719000" />
-      <workItem from="1748988822181" duration="59000" />
-      <workItem from="1749200290051" duration="680000" />
-      <workItem from="1749203502833" duration="1349000" />
-      <workItem from="1749213099437" duration="3082000" />
-      <workItem from="1750057109660" duration="10453000" />
-      <workItem from="1750070416210" duration="46415000" />
+      <updated>1753351859462</updated>
+      <workItem from="1753351861131" duration="6344000" />
+      <workItem from="1753438320712" duration="13353000" />
+      <workItem from="1753603965993" duration="23907000" />
+      <workItem from="1753709105378" duration="8957000" />
+      <workItem from="1753783502864" duration="521000" />
+      <workItem from="1753784038079" duration="2184000" />
+      <workItem from="1753792651870" duration="5722000" />
+      <workItem from="1753867421329" duration="923000" />
+      <workItem from="1753871809956" duration="11925000" />
+      <workItem from="1754025478167" duration="1649000" />
+      <workItem from="1754054724448" duration="1159000" />
+      <workItem from="1754317580682" duration="1098000" />
+      <workItem from="1754384107227" duration="613000" />
+      <workItem from="1754485399433" duration="303000" />
+      <workItem from="1754503724767" duration="4050000" />
+      <workItem from="1754547605829" duration="4804000" />
     </task>
-    <task id="LOCAL-00001" summary="Initial Commit">
+    <task id="LOCAL-00001" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1732484343908</created>
+      <created>1753438388631</created>
       <option name="number" value="00001" />
       <option name="presentableId" value="LOCAL-00001" />
       <option name="project" value="LOCAL" />
-      <updated>1732484343908</updated>
+      <updated>1753438388631</updated>
     </task>
-    <task id="LOCAL-00002" summary="added TransformerFNO">
+    <task id="LOCAL-00002" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1732497990642</created>
+      <created>1753444583988</created>
       <option name="number" value="00002" />
       <option name="presentableId" value="LOCAL-00002" />
       <option name="project" value="LOCAL" />
-      <updated>1732497990642</updated>
+      <updated>1753444583988</updated>
     </task>
-    <task id="LOCAL-00003" summary="added the connection between time steps - the model development is finished">
+    <task id="LOCAL-00003" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1732910153380</created>
+      <created>1753529013551</created>
       <option name="number" value="00003" />
       <option name="presentableId" value="LOCAL-00003" />
       <option name="project" value="LOCAL" />
-      <updated>1732910153380</updated>
+      <updated>1753529013551</updated>
     </task>
-    <task id="LOCAL-00004" summary="Finished Allen-Cahn Problem">
+    <task id="LOCAL-00004" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1733176021525</created>
+      <created>1753539586020</created>
       <option name="number" value="00004" />
       <option name="presentableId" value="LOCAL-00004" />
       <option name="project" value="LOCAL" />
-      <updated>1733176021525</updated>
+      <updated>1753539586020</updated>
     </task>
-    <task id="LOCAL-00005" summary="Added Allen-Cahn 3D">
+    <task id="LOCAL-00005" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1733583274023</created>
+      <created>1753640098974</created>
       <option name="number" value="00005" />
       <option name="presentableId" value="LOCAL-00005" />
       <option name="project" value="LOCAL" />
-      <updated>1733583274023</updated>
+      <updated>1753640098974</updated>
     </task>
-    <task id="LOCAL-00006" summary="added save_vtk">
+    <task id="LOCAL-00006" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1733995237535</created>
+      <created>1753713910794</created>
       <option name="number" value="00006" />
       <option name="presentableId" value="LOCAL-00006" />
       <option name="project" value="LOCAL" />
-      <updated>1733995237535</updated>
+      <updated>1753713910794</updated>
     </task>
-    <task id="LOCAL-00007" summary="added MATLAB codes for creating database">
+    <task id="LOCAL-00007" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1734788540933</created>
+      <created>1753722333819</created>
       <option name="number" value="00007" />
       <option name="presentableId" value="LOCAL-00007" />
       <option name="project" value="LOCAL" />
-      <updated>1734788540933</updated>
+      <updated>1753722333819</updated>
     </task>
-    <task id="LOCAL-00008" summary="added CH2DNL">
+    <task id="LOCAL-00008" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1735126332032</created>
+      <created>1753789147535</created>
       <option name="number" value="00008" />
       <option name="presentableId" value="LOCAL-00008" />
       <option name="project" value="LOCAL" />
-      <updated>1735126332032</updated>
+      <updated>1753789147535</updated>
     </task>
-    <task id="LOCAL-00009" summary="added SH2D">
+    <task id="LOCAL-00009" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1735719422931</created>
+      <created>1753867478797</created>
       <option name="number" value="00009" />
       <option name="presentableId" value="LOCAL-00009" />
       <option name="project" value="LOCAL" />
-      <updated>1735719422931</updated>
+      <updated>1753867478797</updated>
     </task>
-    <task id="LOCAL-00010" summary="added PFC2D">
+    <task id="LOCAL-00010" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1736237977029</created>
+      <created>1753872227989</created>
       <option name="number" value="00010" />
       <option name="presentableId" value="LOCAL-00010" />
       <option name="project" value="LOCAL" />
-      <updated>1736237977029</updated>
+      <updated>1753872227989</updated>
     </task>
-    <task id="LOCAL-00011" summary="added PFC2D">
+    <task id="LOCAL-00011" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1738788849261</created>
+      <created>1753974441825</created>
       <option name="number" value="00011" />
       <option name="presentableId" value="LOCAL-00011" />
       <option name="project" value="LOCAL" />
-      <updated>1738788849261</updated>
+      <updated>1753974441825</updated>
     </task>
-    <task id="LOCAL-00012" summary="added PFC2D">
+    <task id="LOCAL-00012" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1738789326593</created>
+      <created>1753976447489</created>
       <option name="number" value="00012" />
       <option name="presentableId" value="LOCAL-00012" />
       <option name="project" value="LOCAL" />
-      <updated>1738789326593</updated>
+      <updated>1753976447489</updated>
     </task>
-    <task id="LOCAL-00013" summary="added PFC2D">
+    <task id="LOCAL-00013" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1738796104012</created>
+      <created>1753976663822</created>
       <option name="number" value="00013" />
       <option name="presentableId" value="LOCAL-00013" />
       <option name="project" value="LOCAL" />
-      <updated>1738796104012</updated>
+      <updated>1753976663822</updated>
     </task>
-    <task id="LOCAL-00014" summary="added PFC2D">
+    <task id="LOCAL-00014" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1738962464719</created>
+      <created>1753984140485</created>
       <option name="number" value="00014" />
       <option name="presentableId" value="LOCAL-00014" />
       <option name="project" value="LOCAL" />
-      <updated>1738962464719</updated>
+      <updated>1753984140485</updated>
     </task>
-    <task id="LOCAL-00015" summary="added PFC2D">
+    <task id="LOCAL-00015" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1738962748829</created>
+      <created>1754027236458</created>
       <option name="number" value="00015" />
       <option name="presentableId" value="LOCAL-00015" />
       <option name="project" value="LOCAL" />
-      <updated>1738962748829</updated>
+      <updated>1754027236458</updated>
     </task>
-    <task id="LOCAL-00016" summary="Turn Nx to 64">
+    <task id="LOCAL-00016" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1738967163754</created>
+      <created>1754056009830</created>
       <option name="number" value="00016" />
       <option name="presentableId" value="LOCAL-00016" />
       <option name="project" value="LOCAL" />
-      <updated>1738967163754</updated>
+      <updated>1754056009830</updated>
     </task>
-    <task id="LOCAL-00017" summary="update to 3D">
+    <task id="LOCAL-00017" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1739275401458</created>
+      <created>1754317665438</created>
       <option name="number" value="00017" />
       <option name="presentableId" value="LOCAL-00017" />
       <option name="project" value="LOCAL" />
-      <updated>1739275401458</updated>
+      <updated>1754317665438</updated>
     </task>
-    <task id="LOCAL-00018" summary="update to 3D">
+    <task id="LOCAL-00018" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1739275433418</created>
+      <created>1754320089838</created>
       <option name="number" value="00018" />
       <option name="presentableId" value="LOCAL-00018" />
       <option name="project" value="LOCAL" />
-      <updated>1739275433418</updated>
+      <updated>1754320089838</updated>
     </task>
-    <task id="LOCAL-00019" summary="TNO3d vs FNO3d">
+    <task id="LOCAL-00019" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1741690373369</created>
+      <created>1754320859423</created>
       <option name="number" value="00019" />
       <option name="presentableId" value="LOCAL-00019" />
       <option name="project" value="LOCAL" />
-      <updated>1741690373369</updated>
+      <updated>1754320859423</updated>
     </task>
-    <task id="LOCAL-00020" summary="TNO3d vs FNO3d">
+    <task id="LOCAL-00020" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1741690420059</created>
+      <created>1754323071886</created>
       <option name="number" value="00020" />
       <option name="presentableId" value="LOCAL-00020" />
       <option name="project" value="LOCAL" />
-      <updated>1741690420059</updated>
+      <updated>1754323071886</updated>
     </task>
-    <task id="LOCAL-00021" summary="TNO3d vs FNO3d">
+    <task id="LOCAL-00021" summary="3d_phase_evolution">
       <option name="closed" value="true" />
-      <created>1743587271259</created>
+      <created>1754486043769</created>
       <option name="number" value="00021" />
       <option name="presentableId" value="LOCAL-00021" />
       <option name="project" value="LOCAL" />
-      <updated>1743587271259</updated>
+      <updated>1754486043769</updated>
     </task>
-    <option name="localTasksCounter" value="22" />
+    <task id="LOCAL-00022" summary="3d_phase_evolution">
+      <option name="closed" value="true" />
+      <created>1754486850188</created>
+      <option name="number" value="00022" />
+      <option name="presentableId" value="LOCAL-00022" />
+      <option name="project" value="LOCAL" />
+      <updated>1754486850188</updated>
+    </task>
+    <task id="LOCAL-00023" summary="3d_phase_evolution">
+      <option name="closed" value="true" />
+      <created>1754494436539</created>
+      <option name="number" value="00023" />
+      <option name="presentableId" value="LOCAL-00023" />
+      <option name="project" value="LOCAL" />
+      <updated>1754494436539</updated>
+    </task>
+    <task id="LOCAL-00024" summary="3d_phase_evolution">
+      <option name="closed" value="true" />
+      <created>1754512595519</created>
+      <option name="number" value="00024" />
+      <option name="presentableId" value="LOCAL-00024" />
+      <option name="project" value="LOCAL" />
+      <updated>1754512595519</updated>
+    </task>
+    <task id="LOCAL-00025" summary="3d_phase_evolution">
+      <option name="closed" value="true" />
+      <created>1754512937472</created>
+      <option name="number" value="00025" />
+      <option name="presentableId" value="LOCAL-00025" />
+      <option name="project" value="LOCAL" />
+      <updated>1754512937472</updated>
+    </task>
+    <task id="LOCAL-00026" summary="3d_phase_evolution">
+      <option name="closed" value="true" />
+      <created>1754547763545</created>
+      <option name="number" value="00026" />
+      <option name="presentableId" value="LOCAL-00026" />
+      <option name="project" value="LOCAL" />
+      <updated>1754547763545</updated>
+    </task>
+    <task id="LOCAL-00027" summary="3d_phase_evolution">
+      <option name="closed" value="true" />
+      <created>1754548502963</created>
+      <option name="number" value="00027" />
+      <option name="presentableId" value="LOCAL-00027" />
+      <option name="project" value="LOCAL" />
+      <updated>1754548502963</updated>
+    </task>
+    <task id="LOCAL-00028" summary="3d_phase_evolution">
+      <option name="closed" value="true" />
+      <created>1754548778704</created>
+      <option name="number" value="00028" />
+      <option name="presentableId" value="LOCAL-00028" />
+      <option name="project" value="LOCAL" />
+      <updated>1754548778704</updated>
+    </task>
+    <task id="LOCAL-00029" summary="3d_phase_evolution">
+      <option name="closed" value="true" />
+      <created>1754548850651</created>
+      <option name="number" value="00029" />
+      <option name="presentableId" value="LOCAL-00029" />
+      <option name="project" value="LOCAL" />
+      <updated>1754548850651</updated>
+    </task>
+    <task id="LOCAL-00030" summary="3d_phase_evolution">
+      <option name="closed" value="true" />
+      <created>1754551135753</created>
+      <option name="number" value="00030" />
+      <option name="presentableId" value="LOCAL-00030" />
+      <option name="project" value="LOCAL" />
+      <updated>1754551135753</updated>
+    </task>
+    <option name="localTasksCounter" value="31" />
     <servers />
   </component>
   <component name="TypeScriptGeneratedFilesManager">
     <option name="version" value="3" />
-  </component>
-  <component name="Vcs.Log.Tabs.Properties">
-    <option name="RECENT_FILTERS">
-      <map>
-        <entry key="Branch">
-          <value>
-            <list>
-              <RecentGroup>
-                <option name="FILTER_VALUES">
-                  <option value="main" />
-                </option>
-              </RecentGroup>
-            </list>
-          </value>
-        </entry>
-      </map>
-    </option>
-    <option name="TAB_STATES">
-      <map>
-        <entry key="MAIN">
-          <value>
-            <State>
-              <option name="FILTERS">
-                <map>
-                  <entry key="branch">
-                    <value>
-                      <list>
-                        <option value="main" />
-                      </list>
-                    </value>
-                  </entry>
-                </map>
-              </option>
-            </State>
-          </value>
-        </entry>
-      </map>
-    </option>
   </component>
   <component name="VcsManagerConfiguration">
-    <MESSAGE value="Initial Commit" />
-    <MESSAGE value="added TransformerFNO" />
-    <MESSAGE value="added the connection between time steps - the model development is finished" />
-    <MESSAGE value="refactored" />
-    <MESSAGE value="Finished Allen-Cahn Problem" />
-    <MESSAGE value="Added Allen-Cahn 3D" />
-    <MESSAGE value="added save_vtk" />
-    <MESSAGE value="added MATLAB codes for creating database" />
-    <MESSAGE value="seperated the number of layers in fourier part and convolutional part" />
-    <MESSAGE value="added CH2DNL" />
-    <MESSAGE value="added SH2D" />
-    <MESSAGE value="added PFC2D" />
-    <MESSAGE value="Turn Nx to 64" />
-    <MESSAGE value="update to 3D" />
+    <MESSAGE value="3d_phase_evolution" />
     <MESSAGE value="TNO3d vs FNO3d" />
     <option name="LAST_COMMIT_MESSAGE" value="TNO3d vs FNO3d" />
   </component>
@@ -748,166 +456,119 @@
     <breakpoint-manager>
       <breakpoints>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/SH2D.py</url>
-          <line>142</line>
-          <option name="timeStamp" value="17" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/SH2D.py</url>
-          <line>163</line>
-          <option name="timeStamp" value="18" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/SH2D.py</url>
-          <line>134</line>
-          <option name="timeStamp" value="19" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/SH2D.py</url>
-          <line>327</line>
-          <option name="timeStamp" value="20" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/SH2D.py</url>
-          <line>243</line>
-          <option name="timeStamp" value="21" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/AC2D_2.py</url>
-          <line>333</line>
-          <option name="timeStamp" value="27" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>
-          <line>371</line>
-          <option name="timeStamp" value="44" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>
-          <line>338</line>
-          <option name="timeStamp" value="54" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/Test.py</url>
-          <line>53</line>
-          <option name="timeStamp" value="128" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/Test.py</url>
-          <line>30</line>
-          <option name="timeStamp" value="129" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/Test.py</url>
-          <line>25</line>
-          <option name="timeStamp" value="133" />
+          <url>file://$PROJECT_DIR$/training.py</url>
+          <line>217</line>
+          <option name="timeStamp" value="1" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/Test.py</url>
-          <line>18</line>
-          <option name="timeStamp" value="135" />
+          <url>file://$PROJECT_DIR$/networks.py</url>
+          <line>373</line>
+          <option name="timeStamp" value="5" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>
-          <line>44</line>
-          <option name="timeStamp" value="138" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/Test2.py</url>
-          <line>16</line>
-          <option name="timeStamp" value="144" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/utilities.py</url>
-          <line>98</line>
-          <option name="timeStamp" value="170" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/main.py</url>
-          <line>157</line>
-          <option name="timeStamp" value="177" />
+          <url>file://$PROJECT_DIR$/networks.py</url>
+          <line>252</line>
+          <option name="timeStamp" value="6" />
         </line-breakpoint>
       </breakpoints>
-      <default-breakpoints>
-        <breakpoint type="python-exception">
-          <properties notifyOnTerminate="true" exception="BaseException">
-            <option name="notifyOnTerminate" value="true" />
-          </properties>
-        </breakpoint>
-      </default-breakpoints>
     </breakpoint-manager>
   </component>
   <component name="com.intellij.coverage.CoverageDataManagerImpl">
-    <SUITE FILE_PATH="coverage/PhaseField1$Test3.coverage" NAME="Test3 Coverage Results" MODIFIED="1739273938386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage" NAME="config_AC2D_FNO3d Coverage Results" MODIFIED="1733233385695" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO4d.coverage" NAME="SH3D_FNO4d Coverage Results" MODIFIED="1754559003332" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$main.coverage" NAME="main Coverage Results" MODIFIED="1743065376798" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_2.coverage" NAME="AC2D_Net2D_2 Coverage Results" MODIFIED="1732904114403" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_PFC3D_TNO3d.coverage" NAME="config_PFC3D_TNO3d Coverage Results" MODIFIED="1752681001873" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$test2.coverage" NAME="test2 Coverage Results" MODIFIED="1742889074336" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1741561715014" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage" NAME="config_SH3D_TNO3d Coverage Results" MODIFIED="1750254757455" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3D.coverage" NAME="SH3D_TNO3D Coverage Results" MODIFIED="1753359664305" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$networks.coverage" NAME="networks Coverage Results" MODIFIED="1733086051390" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/PhaseField1$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1740088478224" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1741603428589" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3d_TNO3d_hybrid.coverage" NAME="PFC3d_TNO3d_hybrid Coverage Results" MODIFIED="1753174544263" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseField1$main.coverage" NAME="main Coverage Results" MODIFIED="1738663765959" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$post_processing.coverage" NAME="post_processing Coverage Results" MODIFIED="1733557098801" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1751364899601" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_Hybrid.coverage" NAME="SH3D_Hybrid Coverage Results" MODIFIED="1753435630879" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D.coverage" NAME="AC2D Coverage Results" MODIFIED="1733088640665" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Archive_Code" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D.coverage" NAME="AC2D_Net2D Coverage Results" MODIFIED="1732567473230" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/PhaseField1$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1740054182408" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1753174449133" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseField1$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1737644605063" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+    <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1741605347375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$main.coverage" NAME="main Coverage Results" MODIFIED="1736268192289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1741564210973" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage" NAME="config_CH2DNL_TNO2d Coverage Results" MODIFIED="1735052490996" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+    <SUITE FILE_PATH="coverage/PhaseField1$Test_Run.coverage" NAME="Test_Run Coverage Results" MODIFIED="1738945320139" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1741561294310" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1743081225414" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_Hybrid.coverage" NAME="PFC3D_Hybrid Coverage Results" MODIFIED="1752753153734" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1752763076697" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$PFC2D.coverage" NAME="PFC2D Coverage Results" MODIFIED="1732278679485" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$CH2D.coverage" NAME="CH2D Coverage Results" MODIFIED="1732347055915" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_FNO3d.coverage" NAME="AC3D_FNO3d Coverage Results" MODIFIED="1741561435127" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741547133078" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_hybrid.coverage" NAME="MBE3D_hybrid Coverage Results" MODIFIED="1753449172728" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_FNO4d.coverage" NAME="PFC3D_FNO4d Coverage Results" MODIFIED="1753634100431" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseField1$AC3D.coverage" NAME="AC3D Coverage Results" MODIFIED="1740041515520" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseField1$Test2.coverage" NAME="Test2 Coverage Results" MODIFIED="1739283715182" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1751535690856" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D.coverage" NAME="config_AC2D Coverage Results" MODIFIED="1733087276180" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_1.coverage" NAME="AC2D_Net2D_1 Coverage Results" MODIFIED="1732535211383" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$fourier_3d.coverage" NAME="fourier_3d Coverage Results" MODIFIED="1732221600628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1736520700819" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_interface3.coverage" NAME="run_interface3 Coverage Results" MODIFIED="1754551855088" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1751390276789" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1753270153654" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$test1.coverage" NAME="test1 Coverage Results" MODIFIED="1733413325318" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1753435969375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_TNO3d_Hybrid.coverage" NAME="PFC3D_TNO3d_Hybrid Coverage Results" MODIFIED="1752850166757" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseField1$Test3.coverage" NAME="Test3 Coverage Results" MODIFIED="1739273938386" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_2.coverage" NAME="AC2D_Net2D_2 Coverage Results" MODIFIED="1732904114403" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_MBE3D_TNO3d.coverage" NAME="config_MBE3D_TNO3d Coverage Results" MODIFIED="1753524263103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage" NAME="config_SH3D_TNO3d Coverage Results" MODIFIED="1753348599806" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
     <SUITE FILE_PATH="coverage/PhaseField1$backend_interagg.coverage" NAME="backend_interagg Coverage Results" MODIFIED="1737630366471" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript3.coverage" NAME="RunScript3 Coverage Results" MODIFIED="1736368081257" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_2.coverage" NAME="AC2D_2 Coverage Results" MODIFIED="1732483323689" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$networks.coverage" NAME="networks Coverage Results" MODIFIED="1733086051390" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/PhaseField1$main_TF.coverage" NAME="main_TF Coverage Results" MODIFIED="1738704014479" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1741538869064" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$THFNO.coverage" NAME="THFNO Coverage Results" MODIFIED="1732911474644" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/networks" />
-    <SUITE FILE_PATH="coverage/PhaseField1$SH3D_New.coverage" NAME="SH3D_New Coverage Results" MODIFIED="1740088478224" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField1$PFC3D.coverage" NAME="PFC3D Coverage Results" MODIFIED="1740083613128" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1741603428589" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_inference.coverage" NAME="run_inference Coverage Results" MODIFIED="1750323709039" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/PhaseField1$main.coverage" NAME="main Coverage Results" MODIFIED="1738663765959" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$post_processing.coverage" NAME="post_processing Coverage Results" MODIFIED="1733557098801" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$CH3D_FNO4d.coverage" NAME="CH3D_FNO4d Coverage Results" MODIFIED="1754322861793" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$config_AC3D_FNO3d.coverage" NAME="config_AC3D_FNO3d Coverage Results" MODIFIED="1751958646687" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$run_inference.coverage" NAME="run_inference Coverage Results" MODIFIED="1751264322005" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage" NAME="config_CH2D_TNO2d Coverage Results" MODIFIED="1734086207850" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
     <SUITE FILE_PATH="coverage/phase_field_equations_4d$networks.coverage" NAME="networks Coverage Results" MODIFIED="1748933697533" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1750255151255" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript2.coverage" NAME="RunScript2 Coverage Results" MODIFIED="1736369209710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage" NAME="SH3D_FNO3d Coverage Results" MODIFIED="1742215946758" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_3.coverage" NAME="AC2D_Net2D_3 Coverage Results" MODIFIED="1732974697103" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_FNO3d.coverage" NAME="AC3d_FNO3d Coverage Results" MODIFIED="1749017845623" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D.coverage" NAME="AC2D Coverage Results" MODIFIED="1733088640665" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Archive_Code" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D.coverage" NAME="AC2D_Net2D Coverage Results" MODIFIED="1732567473230" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/PhaseField1$MBE3D_New.coverage" NAME="MBE3D_New Coverage Results" MODIFIED="1740054182408" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$utilities.coverage" NAME="utilities Coverage Results" MODIFIED="1752595653294" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_FNO3d.coverage" NAME="AC3d_FNO3d Coverage Results" MODIFIED="1751961986602" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage" NAME="MBE3D_TNO3d Coverage Results" MODIFIED="1741562061391" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseField1$config_AC3D_TNO3d.coverage" NAME="config_AC3D_TNO3d Coverage Results" MODIFIED="1737644605063" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_TNO.coverage" NAME="MBE3D_TNO Coverage Results" MODIFIED="1753438703018" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField1$MBE3D.coverage" NAME="MBE3D Coverage Results" MODIFIED="1739283566145" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1741605347375" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1743071672425" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$main.coverage" NAME="main Coverage Results" MODIFIED="1736268192289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage" NAME="PFC3D_TNO3d Coverage Results" MODIFIED="1741564210973" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage" NAME="config_CH2DNL_TNO2d Coverage Results" MODIFIED="1735052490996" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_FO.coverage" NAME="SH3D_FO Coverage Results" MODIFIED="1753438614882" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$MBE2D.coverage" NAME="MBE2D Coverage Results" MODIFIED="1732278526731" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/PhaseField1$CH3D_TNO3d.coverage" NAME="CH3D_TNO3d Coverage Results" MODIFIED="1739914172084" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseField1$Test_Run.coverage" NAME="Test_Run Coverage Results" MODIFIED="1738945320139" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1741561294310" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3d_hybrid.coverage" NAME="MBE3d_hybrid Coverage Results" MODIFIED="1753458461671" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741861381348" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1743081225414" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage" NAME="PFV3D_FNO3d Coverage Results" MODIFIED="1741564487710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$training.coverage" NAME="training Coverage Results" MODIFIED="1751968651692" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$MBE3D_Hybrid.coverage" NAME="MBE3D_Hybrid Coverage Results" MODIFIED="1753516430619" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript1.coverage" NAME="RunScript1 Coverage Results" MODIFIED="1736368790622" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$SH2D.coverage" NAME="SH2D Coverage Results" MODIFIED="1732347080402" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$PFC2D.coverage" NAME="PFC2D Coverage Results" MODIFIED="1732278679485" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$CH2D.coverage" NAME="CH2D Coverage Results" MODIFIED="1732347055915" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$AC3D_FNO3d.coverage" NAME="AC3D_FNO3d Coverage Results" MODIFIED="1741561435127" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$PFC3D_FNO3d.coverage" NAME="PFC3D_FNO3d Coverage Results" MODIFIED="1753174772461" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField1$SH3D.coverage" NAME="SH3D Coverage Results" MODIFIED="1739044808411" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField1$Test.coverage" NAME="Test Coverage Results" MODIFIED="1739459206236" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseField_SANO3$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741547133078" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$CH3D_TNO3d_Hybrid.coverage" NAME="CH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1752411744994" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage" NAME="config_AC2D_FNO2d Coverage Results" MODIFIED="1733393903488" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
-    <SUITE FILE_PATH="coverage/PhaseField1$AC3D.coverage" NAME="AC3D Coverage Results" MODIFIED="1740041515520" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField1$config_CH3D_TNO3d.coverage" NAME="config_CH3D_TNO3d Coverage Results" MODIFIED="1738089807566" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
-    <SUITE FILE_PATH="coverage/PhaseField1$Test2.coverage" NAME="Test2 Coverage Results" MODIFIED="1739283715182" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3$CH3D_FNO3d.coverage" NAME="CH3D_FNO3d Coverage Results" MODIFIED="1741628529142" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage" NAME="AC3d_TNO3d_hybrid Coverage Results" MODIFIED="1748989478372" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage" NAME="AC3d_TNO3d_hybrid Coverage Results" MODIFIED="1751963486807" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField1$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1737899062785" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$config_AC2D.coverage" NAME="config_AC2D Coverage Results" MODIFIED="1733087276180" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_1.coverage" NAME="AC2D_Net2D_1 Coverage Results" MODIFIED="1732535211383" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1736520700819" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$fourier_3d.coverage" NAME="fourier_3d Coverage Results" MODIFIED="1732221600628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1750254767095" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1749216389646" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1748990262244" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/PhaseFieldNet$test1.coverage" NAME="test1 Coverage Results" MODIFIED="1733413325318" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1754558969424" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main1.coverage" NAME="main1 Coverage Results" MODIFIED="1753709191839" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/PhaseField1$CH3D_2.coverage" NAME="CH3D_2 Coverage Results" MODIFIED="1739918355289" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1750254975290" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage" NAME="config_MBE2D_TNO2d Coverage Results" MODIFIED="1736261397712" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/configs" />
   </component>
 </project>
\ No newline at end of file
