Index: networks.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef get_grid_2d(shape, device):\n    batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n    gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n    gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n    return torch.cat((gridx, gridy), dim=-1).to(device)\n\n\ndef get_grid_3d(shape, device):\n    batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n    gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n    gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n    gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n    return torch.cat((gridx, gridy, gridz), dim=-1).to(device)\n\n\n# Complex multiplication\ndef compl_mul2d(inp, weights):\n    # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n    return torch.einsum(\"bixy,ioxy->boxy\", inp, weights)\n\n\ndef compl_mul3d(inp, weights):\n    # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n    return torch.einsum(\"bixyz,ioxyz->boxyz\", inp, weights)\n\n\nclass SpectralConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, modes1, modes2):\n        super(SpectralConv2d, self).__init__()\n\n        \"\"\"\n        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n        \"\"\"\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n        self.modes2 = modes2\n\n        self.scale = (1 / (in_channels * out_channels))\n        self.weights1 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n        self.weights2 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n\n    def forward(self, x):\n        batchsize = x.shape[0]\n        # Compute Fourier coefficients --  1. Compute Fourier Transform\n        # Now, instead of working with raw pixel/grid values, we work with frequency components\\\n        # Suppose the input x has shape (batch, in_channels, H, W)\n        # x_ft has shape: batch×in_channels×H×(W/2+1)\n        x_ft = torch.fft.rfft2(x) # 2D Fast Fourier Transform (FFT) --> v0 = F(v0)\n\n        # Multiply relevant Fourier modes -- 2. Apply Spectral Convolution\n        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat,\n                             device=x.device)\n        # v1(k1,k2)= W(k1,k2).v0(k1,k2) --> W(k1,k2) are learnable parameters that control how much each frequency mode contributes\n        out_ft[:, :, :self.modes1, :self.modes2] = \\\n            compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n            compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n\n        # Return to physical space\n        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1))) # Apply Inverse Fourier Transform (iFFT) --> v1(x,y) = F^(-1)[v1(k1,k2)]\n        return x\n\n\nclass SpectralConv3d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n        super(SpectralConv3d, self).__init__()\n\n        \"\"\"\n        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n        \"\"\"\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n        self.modes2 = modes2\n        self.modes3 = modes3\n\n        self.scale = (1 / (in_channels * out_channels))\n        self.weights1 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights2 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights3 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n        self.weights4 = nn.Parameter(\n            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3,\n                                    dtype=torch.cfloat))\n\n    def forward(self, x):\n        batchsize = x.shape[0]\n        # Compute Fourier coefficients up to factor of e^(- something constant)\n        x_ft = torch.fft.rfftn(x, dim=[-3, -2, -1])\n\n        # Multiply relevant Fourier modes\n        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1) // 2 + 1,\n                             dtype=torch.cfloat, device=x.device)\n        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n            compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n\n        # Return to physical space\n        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n        return x\n\n\nclass MLP2d(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels, T=1, num_layers=2):\n        \"\"\"\n        Initialize the MLP2d class.\n        Parameters:\n        - in_channels: Number of input channels.\n        - out_channels: Number of output channels.\n        - mid_channels: Number of intermediate channels.\n        - T: Number of blocks (default=1).\n        - num_layers: Number of layers in each block (default=2).\n        \"\"\"\n        super(MLP2d, self).__init__()\n\n        self.num_layers = num_layers\n        self.layers = nn.ModuleList()\n\n        for _ in range(T):\n            self.layers.append(nn.Conv2d(in_channels, mid_channels, 1))\n            for _ in range(self.num_layers - 2):\n                self.layers.append(nn.Conv2d(mid_channels, mid_channels, 1))\n            self.layers.append(nn.Conv2d(mid_channels, out_channels, 1))\n\n    def forward(self, x, t=0):\n        start = t * self.num_layers\n        end = start + self.num_layers\n        for i in range(start, end - 1):\n            x = F.gelu(self.layers[i](x))\n        x = self.layers[end - 1](x)\n        return x\n\n\nclass MLP3d(MLP2d):\n    def __init__(self, in_channels, out_channels, mid_channels, T=1, num_layers=2):\n        super(MLP3d, self).__init__(in_channels, out_channels, mid_channels, T, num_layers)\n\n        self.layers = nn.ModuleList()\n        for _ in range(T):\n            self.layers.append(nn.Conv3d(in_channels, mid_channels, 1))\n            # After (3x3x3 kernel)\n            #self.layers.append(nn.Conv3d(in_channels, mid_channels, 3, padding=1))  ## Changed from 1*1*1 to 3*3*3\n            for _ in range(self.num_layers - 2):\n                self.layers.append(nn.Conv3d(mid_channels, mid_channels, 1))\n                #self.layers.append(nn.Conv3d(mid_channels, mid_channels, 3, padding=1))  ## Changed from 1 to 3\n            self.layers.append(nn.Conv3d(mid_channels, out_channels, 1))\n            #self.layers.append(nn.Conv3d(mid_channels, out_channels, 3, padding=1))  ## Changed from 1 to 3\n\n\nclass FNO2d(nn.Module):\n    def __init__(self, modes1, modes2, width, width_q, T_in, T_out, n_layers):\n        super(FNO2d, self).__init__()\n\n        \"\"\"\n        The overall network. It contains 4 layers of the Fourier layer.\n        1. Lift the input to the desire channel dimension by self.fc0 .\n        2. 4 layers of the integral operators u' = (W + K)(u).\n            W defined by self.w; K defined by self.conv .\n        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n\n        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n        input shape: (batchsize, x=64, y=64, c=12)\n        output: the solution of the next timestep\n        output shape: (batchsize, x=64, y=64, c=1)\n        \"\"\"\n\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.width = width\n        self.width_q = width_q\n        self.T_in = T_in\n        self.T_out = T_out\n        self.padding = 8  # pad the domain if input is non-periodic\n        self.n_layers = n_layers\n\n        self.p = nn.Linear(T_in + 2, self.width)  # We start with an input x == u(x,y) of shape (batch,x,y,c), We lift it to a higher-dimensional space using a linear layer\n        # v0(x,y) = p(x=u)\n        self.convs = nn.ModuleList(\n            [SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(n_layers)]) # 2D Fast Fourier Transform (FFT) --> v0 = F(v0)\n        self.mlps = nn.ModuleList([MLP2d(self.width, self.width, self.width) for _ in range(n_layers)])\n        self.ws = nn.ModuleList([nn.Conv2d(self.width, self.width, 1) for _ in range(n_layers)]) # Pointwise convolution layers\n        self.norm = nn.InstanceNorm2d(self.width)\n        self.q = MLP2d(self.width, 1, self.width_q)  # output channel is 1: u(x, y)\n\n    def forward(self, x):\n        grid = get_grid_2d(x.shape, x.device)\n        x = torch.cat((x, grid), dim=-1)\n        x = self.p(x)\n        x = x.permute(0, 3, 1, 2)\n        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            '''\n            x1 = self.mlps[i](x1): Local Mixing Using MLP: Since the Fourier convolution captures global dependencies,\n             we still need local interactions --> v_i+1 = sigma(W.vi  +  b), \n             which W and b are learnable parameters, and σ is the activation function.\n            '''\n            x2 = self.ws[i](x)\n            '''\n             x2 = self.ws[i](x): applies a pointwise convolution (1×1 convolution) to the input tensor x.\n                self.ws is a list (nn.ModuleList) of 1×1 convolutional layers.\n                Each self.ws[i] is a 2D convolution layer (nn.Conv2d) with a kernel size of 1x1.\n                The purpose of these layers is to perform a linear transformation of the feature maps \n                without mixing spatial locations.\n\n            '''\n            x = x1 + x2 #  Merge Global and Local Representations\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n        x = self.q(x)\n        '''\n         Output Projection back to the desired shape using another MLP\n        v_out = Q.v_final(x,y)\n        Q is a learnable projection.\n\n        '''\n        x = x.permute(0, 2, 3, 1)\n        #The final shape of x is (batch,x,y,1), which represents the predicted function value at each spatial location.\n        return x\n\n\nclass TNO2d(FNO2d):\n    def __init__(self, modes1, modes2, width, width_q, width_h, T_in, T_out, n_layers, n_layers_q=2, n_layers_h=4):\n        super(TNO2d, self).__init__(modes1, modes2, width, width_q, T_in, T_out, n_layers)\n        '''\n         TNO2d extends FNO2d. It introduces temporal modeling by adding two MLP layers:\n        self.q → projects the Fourier features to output over time.\n        self.h → handles temporal dependencies between consecutive time steps.\n        New parameters added:\n        width_h → controls temporal memory features.\n        n_layers_q → depth of self.q (output MLP).\n        n_layers_h → depth of self.h (temporal evolution MLP).\n        '''\n        self.width_h = width_h\n        #self.q = MLP2d(self.width, 1, self.width, T_out) # for AC\n        #self.q2 = MLP2d(1, 1, self.width // 4, T_out - 1)\n        #self.q = MLP2d(self.width, 1, 2 * self.width, T_out)  # for CH\n        #self.q2 = MLP2d(1, 1, self.width, T_out - 1)\n        self.q = MLP2d(self.width, 1, self.width_q, T_out, n_layers_q)  # for CHNL\n        self.h = MLP2d(1, 1, self.width_h, T_out - 1, n_layers_h)\n\n    def forward(self, x):\n        grid = get_grid_2d(x.shape, x.device)\n        x = torch.cat((x, grid), dim=-1) # a(x) or= x : Input function (e.g., initial condition for a PDE)\n        x = self.p(x) # \tLifts input to a high-dimensional space\n        x = x.permute(0, 3, 1, 2)\n        # x = F.pad(x, [0, self.padding, 0, self.padding])\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x # x′=GELU(FourierConv(x)+MLP(x)+PointwiseConv(x)\n\n        # x = x[..., :-self.padding, :-self.padding]\n        '''\n         Temporal Evolution Loop\n        Initial time step prediction:\n        Uses self.q(x) to generate the first time step.\n        Stores result in X[..., 0]\n        '''\n        X = torch.zeros(*grid.shape[:-1], self.T_out, device=x.device)\n        xt = self.q(x)\n        X[..., 0] = xt.permute(0, 2, 3, 1).squeeze(-1)\n\n        for t in range(1, self.T_out):\n            x1 = self.q(x, t) # Predicts the next step using Fourier features.  # Q_n∘(W_L+ K_L )∘...∘P(a(x)), Projects final Fourier features to outpu\n            x2 = self.h(xt, t - 1) # Uses previous output (xt) to refine the next state. # H_n∘G_θ (x,t_(n-1) )(a(x)), Models dependency on past states\n            xt = x1 + x2 #  Solution at time t_n : x_t = G_θ (x,t_n )(a(x))\n            X[..., t] = xt.permute(0, 2, 3, 1).squeeze(-1)\n            '''\n             Uses previous output (xt) to refine the next state.\n            Combines both predictions --> x_t=MLP_q(x)+MLP_h[(x t−1)]\n            Stores result in X[..., t]\n            '''\n        return X\n\n\nclass FNO3d(nn.Module):\n    def __init__(self, modes1, modes2, modes3, width, width_q, T_in, T_out, n_layers, n_layers_q=2, n_layers_h=2):\n        super(FNO3d, self).__init__()\n\n        \"\"\"\n        The FNO3d class is a deep learning model designed for solving spatiotemporal problems. \n        The overall network. It contains 4 layers of the Fourier layer.\n        1. Lift the input to the desire channel dimension by self.fc0 .\n        2. 4 layers of the integral operators u' = (W + K)(u).\n            W defined by self.w; K defined by self.conv .\n        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n\n        input: the solution of the first 10 time_steps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n        input shape: (batchsize, x=64, y=64, t=40, c=13)\n        output: the solution of the next 40 time_steps\n        output shape: (batchsize, x=64, y=64, t=40, c=1)\n        \"\"\"\n\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.modes3 = modes3\n        self.width = width\n        self.width_q = width_q\n        self.T_in = T_in\n        self.T_out = T_out\n        self.padding = 6  # pad the domain if input is non-periodic\n        self.n_layers = n_layers\n\n        self.p = nn.Linear(self.T_in + 3, self.width)  # Lifting Layer: input channel is 12: the solution of the first 10 time_steps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n\n        self.convs = nn.ModuleList(\n            [SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3) for _ in range(n_layers)])\n        self.mlps = nn.ModuleList([MLP3d(self.width, self.width, self.width) for _ in range(n_layers)])\n        self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 1) for _ in range(n_layers)])\n        #self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 3, padding=1) for _ in range(n_layers)])  ## kernel changed\n        #self.q = MLP3d(self.width, 1, self.width)  # output channel is 1: u(x, y)\n        self.q = MLP3d(self.width, 1, self.width_q)  # output channel is 1: u(x, y)\n\n    def forward(self, x):\n        #x = x.unsqueeze(3).repeat([1, 1, 1, self.T_out, 1])\n        grid = get_grid_3d(x.shape, x.device)\n        #print(' x shape:', x.shape)\n        x = torch.cat((x, grid), dim=-1)\n        #print(' x shape after cat:', x.shape)\n        x = self.p(x)\n        x = x.permute(0, 4, 1, 2, 3)\n        #x = F.pad(x, [0, self.padding])  # pad the domain if input is non-periodic\n        #print(' x shape after permute:', x.shape)\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        #x = x[..., :-self.padding]\n        x = self.q(x)\n        #x = x.permute(0, 2, 3, 4, 1)[..., 0]  # pad the domain if input is non-periodic\n        x = x.permute(0, 2, 3, 4, 1)\n        #print('FNO3d return x shape:', x.shape)\n        return x\n\n\nclass TNO3d(FNO3d):\n    def __init__(self, modes1, modes2, modes3, width, width_q, width_h, T_in, T_out, n_layers):\n        super(TNO3d, self).__init__(modes1, modes2, modes3, width, width_q, T_in, T_out, n_layers)\n        \"\"\"\n        The super() function calls the parent class (FNO3d) constructor to initialize \n        the parameters that are inherited from the parent class.\n        input: the initial condition and locations (a(x, y, z), x, y, z)\n        input shape: (batchsize, x=s, y=s, z=s, c=4)\n        output: the solution \n        output shape: (batchsize, x=s, y=s, z=s, t=T)\n        \"\"\"\n        self.width_h = width_h\n\n        #self.q = MLP3d(self.width, 1, self.width, T_out)\n        #self.q2 = MLP3d(1, 1, self.width // 4, T_out - 1)\n        self.q = MLP3d(self.width, 1, self.width_q, T_out)\n        self.h = MLP3d(1, 1, self.width_h, T_out - 1)\n\n    def forward(self, x):\n        grid = get_grid_3d(x.shape, x.device)\n        #print('x shape: ',x.shape)\n        #print('grid shape: ', grid.shape)\n        x = torch.cat((x, grid), dim=-1)\n        x = self.p(x)\n        x = x.permute(0, 4, 1, 2, 3)\n        # x = F.pad(x, [0, self.padding, 0, self.padding])\n\n        for i in range(self.n_layers):\n            x1 = self.convs[i](x)\n            x1 = self.mlps[i](x1)\n            x2 = self.ws[i](x)\n            x = x1 + x2\n            x = F.gelu(x) if i < self.n_layers - 1 else x\n\n        # x = x[..., :-self.padding, :-self.padding]\n        X = torch.zeros(*grid.shape[:-1], self.T_out, device=x.device)\n        xt = self.q(x)\n        X[..., 0] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)\n        for t in range(1, self.T_out):\n            x1 = self.q(x, t)\n            x2 = self.h(xt, t - 1)\n            xt = x1 + x2\n            X[..., t] = xt.permute(0, 2, 3, 4, 1).squeeze(-1)\n\n        #print('shape X for model TNO: ', X.shape)\n        return X\n\n\ndef compute_spatial_derivatives(field, coordinates):\n    \"\"\"\n    Computes first and second spatial derivatives of a field with respect to coordinates\n\n    Args:\n        field: Tensor of shape [batch, x, y, z]\n        coordinates: Tensor of shape [batch, x, y, z, 3] (must require grad)\n\n    Returns:\n        laplacian: Tensor of shape [batch, x, y, z] containing Δϕ\n    \"\"\"\n    # Ensure we can compute gradients\n    field = field.clone().requires_grad_(True)\n    coordinates = coordinates.clone().requires_grad_(True)\n\n    # Compute first derivatives\n    grad_outputs = torch.ones_like(field)\n    grad_x, grad_y, grad_z = torch.autograd.grad(\n        outputs=field,\n        inputs=coordinates,\n        grad_outputs=grad_outputs,\n        create_graph=True,\n        retain_graph=True,\n        allow_unused=False\n    )[0].unbind(dim=-1)\n\n    # Compute second derivatives\n    laplacian = 0.0\n    for grad in [grad_x, grad_y, grad_z]:\n        grad_outputs = torch.ones_like(grad)\n        d2phi = torch.autograd.grad(\n            outputs=grad,\n            inputs=coordinates,\n            grad_outputs=grad_outputs,\n            create_graph=True,\n            retain_graph=True,\n            allow_unused=False\n        )[0].unbind(dim=-1)[0]  # Take derivative along same axis\n        laplacian += d2phi\n\n    return laplacian\ndef compute_allen_cahn_loss(predictions, coordinates, epsilon=0.05, delta_t=0.01):\n    \"\"\"\n    Robust physics loss calculation for Allen-Cahn equation\n\n    Args:\n        predictions: Model outputs [batch, x, y, z, time]\n        coordinates: Spatial coordinates [batch, x, y, z, 3]\n        epsilon: Interface width parameter\n        delta_t: Time step size\n\n    Returns:\n        pde_loss: PDE residual loss\n        bc_loss: Boundary condition loss\n    \"\"\"\n    batch_size = predictions.shape[0]\n    pde_loss = 0.0\n    bc_loss = 0.0\n\n    # Compute for each time step\n    for t in range(predictions.shape[-1]):\n        phi_t = predictions[..., t]\n\n        # Compute Laplacian\n        laplacian = compute_spatial_derivatives(phi_t, coordinates)\n\n        # Compute time derivative (finite difference)\n        if t == 0:\n            dt = (predictions[..., t + 1] - predictions[..., t]) / delta_t\n        elif t == predictions.shape[-1] - 1:\n            dt = (predictions[..., t] - predictions[..., t - 1]) / delta_t\n        else:\n            dt = (predictions[..., t + 1] - predictions[..., t - 1]) / (2 * delta_t)\n\n        # Allen-Cahn residual\n        residual = dt - (laplacian - (1 / epsilon ** 2) * (phi_t ** 3 - phi_t))\n        pde_loss += torch.mean(residual ** 2)\n\n        # Periodic boundary conditions\n        bc_loss += torch.mean((phi_t[..., 0, :, :] - phi_t[..., -1, :, :]) ** 2)\n        bc_loss += torch.mean((phi_t[..., :, 0, :] - phi_t[..., :, -1, :]) ** 2)\n        bc_loss += torch.mean((phi_t[..., :, :, 0] - phi_t[..., :, :, -1]) ** 2)\n\n    return pde_loss / predictions.shape[-1], bc_loss / (3 * predictions.shape[-1])
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/networks.py b/networks.py
--- a/networks.py	(revision 4571b9c99edbe597d7f28792b7cdc66308871464)
+++ b/networks.py	(date 1754659122629)
@@ -2,7 +2,7 @@
 import numpy as np
 import torch.nn as nn
 import torch.nn.functional as F
-
+from timeit import default_timer
 
 def get_grid_2d(shape, device):
     batchsize, size_x, size_y = shape[0], shape[1], shape[2]
@@ -419,87 +419,56 @@
         return X
 
 
-def compute_spatial_derivatives(field, coordinates):
-    """
-    Computes first and second spatial derivatives of a field with respect to coordinates
-
-    Args:
-        field: Tensor of shape [batch, x, y, z]
-        coordinates: Tensor of shape [batch, x, y, z, 3] (must require grad)
+def get_grid_3D(shape, device):
+    batchsize, size_x, size_y, size_z, _ = shape  # Note: last dim is channels, not time
+    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
+    gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])
+    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
+    gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])
+    gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
+    gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])
+    return torch.cat((gridx, gridy, gridz), dim=-1).to(device)  # Returns (batch, x, y, z, 3)
 
-    Returns:
-        laplacian: Tensor of shape [batch, x, y, z] containing Δϕ
-    """
-    # Ensure we can compute gradients
-    field = field.clone().requires_grad_(True)
-    coordinates = coordinates.clone().requires_grad_(True)
 
-    # Compute first derivatives
-    grad_outputs = torch.ones_like(field)
-    grad_x, grad_y, grad_z = torch.autograd.grad(
-        outputs=field,
-        inputs=coordinates,
-        grad_outputs=grad_outputs,
-        create_graph=True,
-        retain_graph=True,
-        allow_unused=False
-    )[0].unbind(dim=-1)
+class FNO4d(nn.Module):
+    def __init__(self, modes1, modes2, modes3, modes4_internal, width, width_q, T_in_channels, n_layers):
+        super(FNO4d, self).__init__()
 
-    # Compute second derivatives
-    laplacian = 0.0
-    for grad in [grad_x, grad_y, grad_z]:
-        grad_outputs = torch.ones_like(grad)
-        d2phi = torch.autograd.grad(
-            outputs=grad,
-            inputs=coordinates,
-            grad_outputs=grad_outputs,
-            create_graph=True,
-            retain_graph=True,
-            allow_unused=False
-        )[0].unbind(dim=-1)[0]  # Take derivative along same axis
-        laplacian += d2phi
+        self.modes1 = modes1
+        self.modes2 = modes2
+        self.modes3 = modes3
+        self.modes4 = modes4_internal
+        self.width = width
+        self.width_q = width_q
+        self.T_in = T_in_channels
+        self.n_layers = n_layers
+        self.padding = 6
 
-    return laplacian
-def compute_allen_cahn_loss(predictions, coordinates, epsilon=0.05, delta_t=0.01):
-    """
-    Robust physics loss calculation for Allen-Cahn equation
+        # Input is (x,y,z) + time channels (t_in_channels) + 3 spatial coordinates
+        self.p = nn.Linear(self.T_in + 3, self.width)  # +3 for (x,y,z) coordinates
 
-    Args:
-        predictions: Model outputs [batch, x, y, z, time]
-        coordinates: Spatial coordinates [batch, x, y, z, 3]
-        epsilon: Interface width parameter
-        delta_t: Time step size
+        self.convs = nn.ModuleList([
+            SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)
+            for _ in range(n_layers)
+        ])
+        self.mlps = nn.ModuleList([MLP3d(self.width, self.width, self.width) for _ in range(n_layers)])
+        self.ws = nn.ModuleList([nn.Conv3d(self.width, self.width, 1) for _ in range(n_layers)])
+        self.q = MLP3d(self.width, 1, self.width_q)  # Output channel is 1
 
-    Returns:
-        pde_loss: PDE residual loss
-        bc_loss: Boundary condition loss
-    """
-    batch_size = predictions.shape[0]
-    pde_loss = 0.0
-    bc_loss = 0.0
+    def forward(self, x):
+        # Input shape: (batch, x, y, z, t_in_channels)
+        grid = get_grid_3D(x.shape, x.device)
+        x = torch.cat((x, grid), dim=-1)  # Now both are 5D: (batch, x, y, z, t_in_channels + 3)
+        x = self.p(x)  # Lift to higher dimension
+        x = x.permute(0, 4, 1, 2, 3)  # (batch, channels, x, y, z)
 
-    # Compute for each time step
-    for t in range(predictions.shape[-1]):
-        phi_t = predictions[..., t]
+        for i in range(self.n_layers):
+            x1 = self.convs[i](x)
+            x1 = self.mlps[i](x1)
+            x2 = self.ws[i](x)
+            x = x1 + x2
+            x = F.gelu(x) if i < self.n_layers - 1 else x
 
-        # Compute Laplacian
-        laplacian = compute_spatial_derivatives(phi_t, coordinates)
-
-        # Compute time derivative (finite difference)
-        if t == 0:
-            dt = (predictions[..., t + 1] - predictions[..., t]) / delta_t
-        elif t == predictions.shape[-1] - 1:
-            dt = (predictions[..., t] - predictions[..., t - 1]) / delta_t
-        else:
-            dt = (predictions[..., t + 1] - predictions[..., t - 1]) / (2 * delta_t)
-
-        # Allen-Cahn residual
-        residual = dt - (laplacian - (1 / epsilon ** 2) * (phi_t ** 3 - phi_t))
-        pde_loss += torch.mean(residual ** 2)
-
-        # Periodic boundary conditions
-        bc_loss += torch.mean((phi_t[..., 0, :, :] - phi_t[..., -1, :, :]) ** 2)
-        bc_loss += torch.mean((phi_t[..., :, 0, :] - phi_t[..., :, -1, :]) ** 2)
-        bc_loss += torch.mean((phi_t[..., :, :, 0] - phi_t[..., :, :, -1]) ** 2)
-
-    return pde_loss / predictions.shape[-1], bc_loss / (3 * predictions.shape[-1])
\ No newline at end of file
+        x = self.q(x)
+        x = x.permute(0, 2, 3, 4, 1)  # (batch, x, y, z, 1)
+        return x
\ No newline at end of file
Index: training.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\nimport torch.nn.functional as F\nfrom timeit import default_timer\nfrom tqdm import tqdm\n\ndef train_fno(model, myloss, epochs, batch_size, train_loader, test_loader,\n              optimizer, scheduler, normalized, normalizer, device):\n    train_mse_log = []\n    train_l2_log = []\n    test_l2_log = []\n\n    if normalized:\n        # a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        # a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n        train_mse = 0\n        train_l2 = 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            #print(\"x shape\", x.shape)\n            out = model(x)\n            #print(f\"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}\")\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            train_mse += mse.item()\n            train_l2 += loss.item()\n\n        model.eval()\n        test_l2 = 0.0\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                #test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n\n        train_mse /= len(train_loader)\n        train_l2 /= (batch_size * len(train_loader))\n        test_l2 /= (batch_size * len(test_loader))\n\n        train_mse_log.append(train_mse)\n        train_l2_log.append(train_l2)\n        test_l2_log.append(test_l2)\n\n        # Update the learning rate based on the test_l2 metric\n        #scheduler.step(test_l2) ##\n\n\n        t2 = default_timer()\n        #print(ep, t2 - t1, train_mse, train_l2, test_l2)\n        if ep == 0:  # Print the header row once\n            print(\"No. Epoch   Time (s)       Train MSE      Train L2       Test L2\")\n\n        print(f\"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}\")\n\n    return model, train_mse_log, train_l2_log, test_l2_log\n\ndef train_fno_time(model, myloss, epochs, batch_size, train_loader, test_loader,\n                   optimizer, scheduler, normalized, normalizer, device):\n    ntrain = len(train_loader) * train_loader.batch_size\n    ntest = len(test_loader) * test_loader.batch_size\n    train_mse_log = []\n    train_l2_log = []\n    test_l2_log = []\n    step = 1\n    if normalized:\n        a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n        train_l2_step = 0\n        train_l2_full = 0\n        for xx, yy in train_loader:\n            loss = 0\n            xx = xx.to(device)\n            yy = yy.to(device)\n            T = yy.shape[-1]\n            #print(f\" T : {T}\")\n            #print(f\"target shape: {yy.shape}\")\n            #print(f\"Input shape: {xx.shape}, y (target): {yy.shape}\")\n            for t in range(0, T, step):\n                y = yy[..., t:t + step]\n                im = model(xx)\n                #print(f\"Input shape: {xx.shape}, y (target): {y.shape}, prediction (model output): {im.shape}\")\n                #print(f\"target shape 2: {yy.shape}\")\n                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n\n                if t == 0:\n                    pred = im\n                else:\n                    pred = torch.cat((pred, im), -1)\n                xx = torch.cat((xx[..., step:], im), dim=-1)\n\n            train_l2_step += loss.item()\n            l2_full = myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1))\n            train_l2_full += l2_full.item()\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n        test_l2_step = 0\n        test_l2_full = 0\n        with torch.no_grad():\n            for xx, yy in test_loader:\n                loss = 0\n                xx = xx.to(device)\n                yy = yy.to(device)\n\n                for t in range(0, T, step):\n                    y = yy[..., t:t + step]\n                    im = model(xx)\n                    loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n\n                    if t == 0:\n                        pred = im\n                    else:\n                        pred = torch.cat((pred, im), -1)\n\n                    xx = torch.cat((xx[..., step:], im), dim=-1)\n\n                test_l2_step += loss.item()\n                test_l2_full += myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1)).item()\n\n        t2 = default_timer()\n        train_mse = train_l2_step / ntrain / (T / step)\n        train_l2 = train_l2_full / ntrain\n        test_l2 = test_l2_full / ntest\n\n        # Log the loss values\n        train_l2_log.append(train_l2_step / ntrain / (T / step))\n        test_l2_log.append(test_l2_step / ntest / (T / step))\n\n        if ep == 0:  # Print the header row once\n            print(\"No. Epoch   Time (s)       Train MSE      Train L2       Test L2\")\n\n        print(f\"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f} {test_l2:<13.10f}\")\n\n    return model, train_l2_log, test_l2_log\n\n\n\n########################\n########################\n\ndef calculate_pde_residual(u_phys, grid_info, epsilon, problem, device):\n    \"\"\"\n    Calculates the residual for a specified 3D PDE on PHYSICAL data.\n    u_phys shape: (batch, Nx, Ny, Nz, T_out) - Denormalized data\n    grid_info: Dictionary containing Nx, Ny, Nz, Lx, Ly, Lz, dt_model, T_out\n    pde_params: Dictionary containing PDE-specific parameters\n    problem_name: String identifier for the PDE (e.g., 'SH3D', 'AC3D', 'CH3D', 'MBE3D', 'PFC3D')\n    device: PyTorch device\n    \"\"\"\n    batch_size, Nx, Ny, Nz, T_out = u_phys.shape\n    Lx, Ly, Lz = grid_info['Lx'], grid_info['Ly'], grid_info['Lz']\n    dt_model = grid_info['dt_model']\n\n    if T_out <= 1:\n        print(f\"Warning: T_out ({T_out}) <= 1 for problem {problem}. PDE loss requires T_out > 1. Returning zero loss.\")\n        return torch.zeros(1, device=device, requires_grad=True)\n\n    # --- Calculate Time Derivative (∂u/∂t) ---\n    du_dt = torch.zeros_like(u_phys)\n    du_dt[..., 0] = (u_phys[..., 1] - u_phys[..., 0]) / dt_model\n    du_dt[..., -1] = (u_phys[..., -1] - u_phys[..., -2]) / dt_model\n    if T_out > 2:\n       du_dt[..., 1:-1] = (u_phys[..., 2:] - u_phys[..., :-2]) / (2 * dt_model)\n\n    # --- Common Spectral Derivative Setup ---\n    _kx = torch.fft.fftfreq(Nx, d=Lx/Nx) * 2 * torch.pi\n    _ky = torch.fft.fftfreq(Ny, d=Ly/Ny) * 2 * torch.pi\n    _kz = torch.fft.fftfreq(Nz, d=Lz/Nz) * 2 * torch.pi\n\n    ikx_m, iky_m, ikz_m = torch.meshgrid(1j * _kx, 1j * _ky, 1j * _kz, indexing='ij')\n    ikx_m = ikx_m.to(device)\n    iky_m = iky_m.to(device)\n    ikz_m = ikz_m.to(device)\n\n    k2x_m, k2y_m, k2z_m = torch.meshgrid(_kx**2, _ky**2, _kz**2, indexing='ij')\n    # k2_m is kx^2 + ky^2 + kz^2. In Fourier space, laplacian is -k2_m\n    k2_m = (k2x_m + k2y_m + k2z_m).to(device)\n\n    u_hat = torch.fft.fftn(u_phys, dim=[1, 2, 3])\n\n    pde_residual = None\n\n    if problem == 'SH3D':\n        epsilon_sh = epsilon # pde_params.get('epsilon_sh')\n        if epsilon_sh is None: raise ValueError(\"Parameter 'epsilon_sh' not provided for SH3D.\")\n        k4_m = k2_m**2\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n        rhs_sh3d = -(u_phys**3) - (1 - epsilon_sh) * u_phys - biharm_u - 2 * lap_u\n        pde_residual = du_dt - rhs_sh3d\n\n    elif problem == 'AC3D':\n        Cahn_ac = epsilon # pde_params.get('Cahn_ac')\n        if Cahn_ac is None: raise ValueError(\"Parameter 'Cahn_ac' not provided for AC3D.\")\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        f_prime_u = u_phys**3 - u_phys\n        rhs_ac3d = Cahn_ac * lap_u - f_prime_u\n        pde_residual = du_dt - rhs_ac3d\n\n    elif problem == 'CH3D':\n        Cahn_ch = epsilon #  pde_params.get('Cahn_ch')\n        if Cahn_ch is None: raise ValueError(\"Parameter 'Cahn_ch' not provided for CH3D.\")\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        #mu_terms = (u_phys**3 - 3 * u_phys) - Cahn_ch * lap_u\n        mu_terms = (u_phys ** 3 -  u_phys) - Cahn_ch * lap_u\n        mu_terms_hat = torch.fft.fftn(mu_terms, dim=[1, 2, 3])\n        lap_mu_terms_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * mu_terms_hat\n        lap_mu_terms = torch.fft.ifftn(lap_mu_terms_hat, dim=[1, 2, 3]).real\n        rhs_ch3d = lap_mu_terms\n        pde_residual = du_dt - rhs_ch3d\n\n    elif problem == 'MBE3D':\n        epsilon_mbe = epsilon #  pde_params.get('epsilon_mbe')\n        if epsilon_mbe is None: raise ValueError(\"Parameter 'epsilon_mbe' not provided for MBE3D.\")\n        du_dx_hat = ikx_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dy_hat = iky_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dz_hat = ikz_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        du_dx = torch.fft.ifftn(du_dx_hat, dim=[1, 2, 3]).real\n        du_dy = torch.fft.ifftn(du_dy_hat, dim=[1, 2, 3]).real\n        du_dz = torch.fft.ifftn(du_dz_hat, dim=[1, 2, 3]).real\n        grad_u_sq = du_dx**2 + du_dy**2 + du_dz**2\n        f1 = grad_u_sq * du_dx\n        f2 = grad_u_sq * du_dy\n        f3 = grad_u_sq * du_dz\n        f1_hat = torch.fft.fftn(f1, dim=[1, 2, 3])\n        f2_hat = torch.fft.fftn(f2, dim=[1, 2, 3])\n        f3_hat = torch.fft.fftn(f3, dim=[1, 2, 3])\n        div_term_hat = (ikx_m.unsqueeze(0).unsqueeze(-1) * f1_hat +\n                        iky_m.unsqueeze(0).unsqueeze(-1) * f2_hat +\n                        ikz_m.unsqueeze(0).unsqueeze(-1) * f3_hat)\n        div_term = torch.fft.ifftn(div_term_hat, dim=[1, 2, 3]).real\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n        k4_m = k2_m**2\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n        rhs_mbe3d = -lap_u + epsilon_mbe * biharm_u - div_term\n        pde_residual = du_dt - rhs_mbe3d\n\n    elif problem == 'PFC3D':\n        epsilon_pfc = epsilon # pde_params.get('epsilon_pfc') # Parameter 'r' in PFC, often -(epsilon)\n        if epsilon_pfc is None: raise ValueError(\"Parameter 'epsilon_pfc' not provided for PFC3D.\")\n\n        # Calculate necessary derivatives\n        # -∇²u  (term1_spatial_operator * u)\n        lap_u_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        lap_u = torch.fft.ifftn(lap_u_hat, dim=[1, 2, 3]).real\n\n        # ∇⁴u   (term2_spatial_operator * u)\n        k4_m = k2_m**2\n        biharm_u_hat = k4_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        biharm_u = torch.fft.ifftn(biharm_u_hat, dim=[1, 2, 3]).real\n\n        # -∇⁶u  (term3_spatial_operator * u)\n        k6_m = k2_m**3 # Be careful with sign if k2_m is just kx^2+ky^2+kz^2\n                      # Since k^6 in Fourier space corresponds to (-∇^2)^3 = -∇^6 if direct multiplication\n                      # Or (i k)^6 = -k^6.\n                      # The MATLAB denominator (1/dt + (1-eps)k^2 + k^6) implies the k^6 term is positive.\n                      # So in real space, this corresponds to -∇⁶u (because -(-∇²)^3 u = ∇⁶u is not what we want)\n                      # A positive k^6 in Fourier space means we multiply by k^6, which is (-(laplacian_operator))^3,\n                      # this will become -laplacian_operator^3 which is -∇⁶.\n                      # The MATLAB form `(pp2+qq2+rr2).^3` is `(k^2)^3 = k^6`.\n                      # So this term becomes `k^6 * u_hat` -> `∇⁶u` (with a negative sign from implicit to explicit)\n        # Or, if (pp2+qq2+rr2) is k^2, then (pp2+qq2+rr2)^3 is k^6.\n        # The term in the denominator is `+ k^6`, so when moved to RHS it's `-k^6 u_hat`.\n        # `-k^6 u_hat` corresponds to `∇⁶u` in real space.\n        triharm_u_hat = -k6_m.unsqueeze(0).unsqueeze(-1) * u_hat\n        triharm_u = torch.fft.ifftn(triharm_u_hat, dim=[1, 2, 3]).real\n\n\n        # ∇²(u³)\n        u_cubed = u_phys**3\n        u_cubed_hat = torch.fft.fftn(u_cubed, dim=[1, 2, 3])\n        lap_u_cubed_hat = -k2_m.unsqueeze(0).unsqueeze(-1) * u_cubed_hat\n        lap_u_cubed = torch.fft.ifftn(lap_u_cubed_hat, dim=[1, 2, 3]).real\n\n        # PDE: ∂u/∂t + (1-ε)∇²u + 2∇⁴u + ∇⁶u + ∇²(u³) = 0\n        # RHS = - ( (1-ε_pfc)∇²u + 2∇⁴u + ∇⁶u + ∇²(u³) )\n        # Let's use the parameter `epsilon` from PFC MATLAB as `r` (undercooling param)\n        # A common PFC form is du/dt = nabla^2 * ( (r)u + u^3 - (1+nabla^2)^2 u )\n        # du/dt = nabla^2 * ( ru + u^3 - (1 + 2 nabla^2 + nabla^4)u )\n        # du/dt = r nabla^2 u + nabla^2(u^3) - nabla^2 u - 2 nabla^4 u - nabla^6 u\n        # du/dt = (r-1) nabla^2 u - 2 nabla^4 u - nabla^6 u + nabla^2(u^3)\n        # Here 'r' from literature is often called 'epsilon' in PFC code.\n        # Let's match the form derived from MATLAB:\n        # ∂u/∂t = -(1-ε)∇²u - 2∇⁴u - ∇⁶u - ∇²(u³)\n        # Residual: du_dt - [-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed]\n\n        term1_spatial = (1 - epsilon_pfc) * lap_u # (1-eps)(-nabla^2 u) -> (eps-1)nabla^2 u\n        term2_spatial = 2 * biharm_u             # 2 nabla^4 u\n        term3_spatial = triharm_u                # nabla^6 u\n        term4_nonlinear = lap_u_cubed            # nabla^2 (u^3)\n\n        # According to the derived form: ∂u/∂t = -(1-ε)∇²u - 2∇⁴u - ∇⁶u - ∇²(u³)\n        # residual = du_dt - (-(1-epsilon_pfc)*lap_u - 2*biharm_u - triharm_u - lap_u_cubed)\n        rhs_pfc3d = -(1 - epsilon_pfc) * lap_u - 2 * biharm_u - triharm_u - lap_u_cubed\n        pde_residual = du_dt - rhs_pfc3d\n\n    else:\n        raise ValueError(f\"Unknown problem_name: {problem}. PDE residual not defined.\")\n\n    if pde_residual is not None:\n        loss_pde = F.mse_loss(pde_residual, torch.zeros_like(pde_residual))\n    else:\n        loss_pde = torch.zeros(1, device=device, requires_grad=True)\n\n    return loss_pde\n\n\ndef train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,\n                    optimizer, scheduler, normalized, normalizer, device, pde_weight, grid_info, epsilon, problem, pde_loss_scaler=1.0, can_compute_pde = True):\n    train_mse_hybrid_log = []\n    train_l2_hybrid_log = []\n\n    test_mse_hybrid_log = []\n    test_loss_hybrid_log = []\n\n\n    train_data_log = []\n    test_data_log = []\n\n    train_pde_scaled_log = []\n    train_pde_raw_log = []\n\n    test_pde_loss_scaled_log = []\n    test_pde_loss_raw_log = []\n\n\n    if normalized:\n        # a_normalizer = normalizer[0].to(device)\n        y_normalizer = normalizer[1].to(device)\n    else:\n        # a_normalizer = None\n        y_normalizer = None\n\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n\n        train_mse_hybrid = 0\n        train_l2_hybrid = 0\n\n        train_data = 0.0\n        train_pde_scaled = 0.0\n        train_pde_raw = 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            # print(\"x shape\", x.shape)\n            out = model(x)\n            # print(f\"Input shape: {x.shape}, y (target): {y.shape}, prediction (model output): {out.shape}\")\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n\n            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n            loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n            # --- PDE Loss Calculation (on physical scale) ---\n            if can_compute_pde:\n                # loss_pde_raw = calculate_pde_residual_sh3d(pred_phys, grid_info, epsilon, device)\n                #loss_pde_raw = calculate_pde_residual_sh3d(out, grid_info, epsilon, device)\n                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                loss_pde_scaled = loss_pde_raw * pde_loss_scaler  # Apply scaling\n\n            loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled\n            mse_hybrid = (1.0 - pde_weight) * mse_data + pde_weight * loss_pde_scaled\n\n\n            loss_hybrid.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # Hybrid\n            train_mse_hybrid += mse_hybrid.item()\n            train_l2_hybrid += loss_hybrid.item()\n            ##\n            train_data += loss_data.item()\n            train_pde_scaled += loss_pde_scaled.item()\n            train_pde_raw += loss_pde_raw.item()\n\n\n        model.eval()\n        test_data= 0.0 # data\n        test_mse_data = 0.0\n        test_pde_loss_scaled = 0.0\n        test_pde_loss_raw = 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                # test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n                test_mse_data += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n                test_data += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n\n                # PDE Loss\n                if can_compute_pde:\n                    #loss_pde_test_raw = calculate_pde_residual_sh3d(out, grid_info, epsilon, device)\n                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n\n                test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()\n                test_pde_loss_raw += loss_pde_test_raw.item()\n\n            test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled\n            test_mse_hybrid = (1.0 - pde_weight) * test_mse_data + pde_weight * test_pde_loss_scaled\n\n        # Train Hybrid\n        train_mse_hybrid /= len(train_loader)\n        train_l2_hybrid /= (batch_size * len(train_loader))\n\n        # Test Hybrid\n        test_mse_hybrid /= len(test_loader)\n        test_loss_hybrid /= (batch_size * len(test_loader))\n\n        # train data\n        train_data /= (batch_size * len(train_loader))\n        # test data\n        test_data /= (batch_size * len(test_loader))\n        # train pde\n        train_pde_scaled /= (batch_size * len(train_loader))\n        train_pde_raw /= (batch_size * len(train_loader))\n        # test pde\n        test_pde_loss_scaled /= (batch_size * len(test_loader))\n        test_pde_loss_raw /= (batch_size * len(test_loader))\n\n\n\n\n        # train Hybrid\n        train_mse_hybrid_log.append(train_mse_hybrid)\n        train_l2_hybrid_log.append(train_l2_hybrid)\n\n        # Test Hybrid\n        test_mse_hybrid_log.append(test_mse_hybrid)\n        test_loss_hybrid_log.append(test_loss_hybrid)\n\n        # train data\n        train_data_log.append(train_data)\n        # test data\n        test_data_log.append(test_data)\n        # train pde\n        train_pde_scaled_log.append(train_pde_scaled)\n        train_pde_raw_log.append(train_pde_raw)\n        # test pde\n        test_pde_loss_scaled_log.append(test_pde_loss_scaled)\n        test_pde_loss_raw_log.append(test_pde_loss_raw)\n\n        # Update the learning rate based on the test_l2 metric\n        # scheduler.step(test_l2) ##\n\n        t2 = default_timer()\n\n        if ep == 0:\n            # Update header to reflect spectral raw PDE loss\n            print(\"No. Epoch | Time (s)   | Train MSE Hyb  | Train L2 Hyb  | test L2 Hyb | Test L2 data        | test_pde scl.   | test_pde_raw \")\n            print(\"---------------------------------------------------------------------------------------------\")\n        # Update print statement\n        print(f\"{ep:<9}  {t2 - t1:<10.4f}   {train_mse_hybrid:<10.6e}     {train_l2_hybrid:<10.6e} {test_loss_hybrid:<10.6e}  {test_data:<24.6e} {test_pde_loss_scaled:<24.6e} {test_pde_loss_raw:<24.6e} \")\n\n    return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log\n\n\ndef compute_initial_loss_scaler(model, loader, myloss, normalized, normalizer, device, grid_info, epsilon, problem):\n    \"\"\"\n    Computes the scaling factor to balance data and PDE losses.\n    \"\"\"\n    model.eval()\n\n    # Get one batch from the loader\n    x, y = next(iter(loader))\n    x, y = x.to(device), y.to(device)\n\n    with torch.no_grad():\n        out = model(x)\n        if normalized:\n            y_normalizer = normalizer[1].to(device)\n            out = y_normalizer.decode(out)\n            y = y_normalizer.decode(y)\n\n        # Calculate initial data loss\n        initial_loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n\n        # Calculate initial raw PDE loss\n        initial_loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n\n        # Handle case where PDE loss is zero to avoid division by zero\n        if initial_loss_pde_raw.item() < 1e-12:\n            scaler = 1.0\n            print(\"Warning: Initial PDE loss is near zero. Setting scaler to 1.0.\")\n        else:\n            # The scaler is the ratio of the two losses\n            scaler = initial_loss_data.item() / initial_loss_pde_raw.item()\n            print(f\"Computed initial loss scaler: {scaler:.4f}\")\n            print(f\"  - Initial Data Loss: {initial_loss_data.item():.6f}\")\n            print(f\"  - Initial PDE Loss (raw): {initial_loss_pde_raw.item():.6f}\")\n\n    model.train()  # Set model back to training mode\n    return scaler\n\n\n''''\ndef train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,\n                 optimizer, scheduler, normalized, normalizer, device, pde_weight,\n                 grid_info, epsilon, problem, pde_loss_scaler='auto', can_compute_pde=True):\n    # --- Logging Lists ---\n    train_mse_hybrid_log, train_l2_hybrid_log = [], []\n    test_mse_hybrid_log, test_loss_hybrid_log = [], []\n    train_data_log, test_data_log = [], []\n    train_pde_scaled_log, train_pde_raw_log = [], []\n    test_pde_loss_scaled_log, test_pde_loss_raw_log = [], []\n\n    if normalized:\n        y_normalizer = normalizer[1].to(device)\n    else:\n        y_normalizer = None\n\n    # ====================================================================================\n    # Automatic PDE Loss Scaler Calculation\n    # ====================================================================================\n    if pde_loss_scaler == 'auto' and can_compute_pde and pde_weight > 0:\n        print(\"--- Calibrating PDE loss scaler automatically ---\")\n        model.eval()\n        total_data_loss_for_scaling = 0.0\n        total_pde_loss_for_scaling = 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n                out = model(x)\n\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                # Calculate data loss for this batch\n                data_loss_batch = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n                total_data_loss_for_scaling += data_loss_batch.item()\n\n                # Calculate raw PDE loss for this batch\n                pde_loss_batch_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                total_pde_loss_for_scaling += pde_loss_batch_raw.item()\n\n        # Calculate the average losses\n        avg_data_loss = total_data_loss_for_scaling / len(test_loader)\n        avg_pde_loss = total_pde_loss_for_scaling / len(test_loader)\n\n        # Compute the scaler\n        if avg_pde_loss > 1e-8:  # Avoid division by zero\n            pde_loss_scaler = avg_data_loss / avg_pde_loss\n        else:\n            pde_loss_scaler = 1.0  # Default to 1 if PDE loss is negligible\n\n        print(f\"Initial Avg Data Loss: {avg_data_loss:.6e}\")\n        print(f\"Initial Avg Raw PDE Loss: {avg_pde_loss:.6e}\")\n        print(f\"Calculated pde_loss_scaler: {pde_loss_scaler:.6f}\")\n        print(\"---------------------------------------------\")\n\n    elif not can_compute_pde or pde_weight == 0:\n        pde_loss_scaler = 0.0  # No scaling needed if PDE is not used\n    elif isinstance(pde_loss_scaler, str):  # Handle cases like 'auto' when PDE is off\n        pde_loss_scaler = 1.0\n\n    # --- Main Training Loop ---\n    for ep in range(epochs):\n        model.train()\n        t1 = default_timer()\n\n        # Initialize epoch-level accumulators\n        train_mse_hybrid, train_l2_hybrid = 0.0, 0.0\n        train_data, train_pde_scaled, train_pde_raw = 0.0, 0.0, 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            optimizer.zero_grad()\n\n            out = model(x)\n            if normalized:\n                out = y_normalizer.decode(out)\n                y = y_normalizer.decode(y)\n\n            # --- Loss Calculation ---\n            loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))\n            mse_data = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')\n\n            loss_pde_scaled = torch.tensor(0.0, device=device)\n            loss_pde_raw = torch.tensor(0.0, device=device)\n\n            if can_compute_pde and pde_weight > 0:\n                loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                loss_pde_scaled = loss_pde_raw * pde_loss_scaler\n\n            # Combine losses\n            loss_hybrid = (1.0 - pde_weight) * loss_data + pde_weight * loss_pde_scaled\n            mse_hybrid = (1.0 - pde_weight) * mse_data + pde_weight * loss_pde_scaled\n\n            loss_hybrid.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # --- Accumulate Metrics ---\n            train_mse_hybrid += mse_hybrid.item()\n            train_l2_hybrid += loss_hybrid.item()\n            train_data += loss_data.item()\n            train_pde_scaled += loss_pde_scaled.item()\n            train_pde_raw += loss_pde_raw.item()\n\n        # --- Evaluation ---\n        model.eval()\n        test_data, test_mse_data = 0.0, 0.0\n        test_pde_loss_scaled, test_pde_loss_raw = 0.0, 0.0\n\n        with torch.no_grad():\n            for x, y in test_loader:\n                x, y = x.to(device), y.to(device)\n\n                out = model(x)\n                if normalized:\n                    out = y_normalizer.decode(out)\n                    y = y_normalizer.decode(y)\n\n                test_data += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()\n                test_mse_data += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean').item()\n\n                if can_compute_pde and pde_weight > 0:\n                    loss_pde_test_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)\n                    test_pde_loss_raw += loss_pde_test_raw.item()\n                    test_pde_loss_scaled += (loss_pde_test_raw * pde_loss_scaler).item()\n\n        # --- Normalize and Log Metrics ---\n        # Note: We divide by len(loader) because item() gives the mean loss for the batch.\n        # This computes the average of the batch means.\n\n        # Averages for training set\n        train_mse_hybrid /= len(train_loader)\n        train_l2_hybrid /= len(train_loader)\n        train_data /= len(train_loader)\n        train_pde_scaled /= len(train_loader)\n        train_pde_raw /= len(train_loader)\n\n        # Averages for test set\n        test_mse_data /= len(test_loader)\n        test_data /= len(test_loader)\n        test_pde_loss_scaled /= len(test_loader)\n        test_pde_loss_raw /= len(test_loader)\n\n        # Calculate final hybrid test losses from averages\n        test_loss_hybrid = (1.0 - pde_weight) * test_data + pde_weight * test_pde_loss_scaled\n        test_mse_hybrid = (1.0 - pde_weight) * test_mse_data + pde_weight * test_pde_loss_scaled\n\n        # Append to logs\n        train_mse_hybrid_log.append(train_mse_hybrid)\n        train_l2_hybrid_log.append(train_l2_hybrid)\n        test_mse_hybrid_log.append(test_mse_hybrid)\n        test_loss_hybrid_log.append(test_loss_hybrid)\n        train_data_log.append(train_data)\n        test_data_log.append(test_data)\n        train_pde_scaled_log.append(train_pde_scaled)\n        train_pde_raw_log.append(train_pde_raw)\n        test_pde_loss_scaled_log.append(test_pde_loss_scaled)\n        test_pde_loss_raw_log.append(test_pde_loss_raw)\n\n        t2 = default_timer()\n\n        if ep == 0:\n            print(\"--- Starting Training ---\")\n            print(f\"PDE Loss Scaler is set to: {pde_loss_scaler:.6f}\")\n            print(\n                \"No. Epoch | Time (s)   | Train MSE Hyb  | Train L2 Hyb   | Test L2 Hyb    | Test L2 data   | Test PDE Scl.  | Test PDE Raw\")\n            print(\n                \"-------------------------------------------------------------------------------------------------------------------------\")\n\n        # CORRECTED PRINT STATEMENT:\n        print(\n            f\"{ep:<9} | {t2 - t1:<10.4f} | {train_mse_hybrid:<14.6e} | {train_l2_hybrid:<14.6e} | {test_loss_hybrid:<14.6e} | {test_data:<14.6e} | {test_pde_loss_scaled:<14.6e} | {test_pde_loss_raw:<14.6e}\")\n\n    return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log\n'''
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/training.py b/training.py
--- a/training.py	(revision 4571b9c99edbe597d7f28792b7cdc66308871464)
+++ b/training.py	(date 1754659024990)
@@ -503,43 +503,6 @@
     return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log
 
 
-def compute_initial_loss_scaler(model, loader, myloss, normalized, normalizer, device, grid_info, epsilon, problem):
-    """
-    Computes the scaling factor to balance data and PDE losses.
-    """
-    model.eval()
-
-    # Get one batch from the loader
-    x, y = next(iter(loader))
-    x, y = x.to(device), y.to(device)
-
-    with torch.no_grad():
-        out = model(x)
-        if normalized:
-            y_normalizer = normalizer[1].to(device)
-            out = y_normalizer.decode(out)
-            y = y_normalizer.decode(y)
-
-        # Calculate initial data loss
-        initial_loss_data = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
-
-        # Calculate initial raw PDE loss
-        initial_loss_pde_raw = calculate_pde_residual(out, grid_info, epsilon, problem, device)
-
-        # Handle case where PDE loss is zero to avoid division by zero
-        if initial_loss_pde_raw.item() < 1e-12:
-            scaler = 1.0
-            print("Warning: Initial PDE loss is near zero. Setting scaler to 1.0.")
-        else:
-            # The scaler is the ratio of the two losses
-            scaler = initial_loss_data.item() / initial_loss_pde_raw.item()
-            print(f"Computed initial loss scaler: {scaler:.4f}")
-            print(f"  - Initial Data Loss: {initial_loss_data.item():.6f}")
-            print(f"  - Initial PDE Loss (raw): {initial_loss_pde_raw.item():.6f}")
-
-    model.train()  # Set model back to training mode
-    return scaler
-
 
 ''''
 def train_hybrid(model, myloss, epochs, batch_size, train_loader, test_loader,
@@ -717,4 +680,85 @@
             f"{ep:<9} | {t2 - t1:<10.4f} | {train_mse_hybrid:<14.6e} | {train_l2_hybrid:<14.6e} | {test_loss_hybrid:<14.6e} | {test_data:<14.6e} | {test_pde_loss_scaled:<14.6e} | {test_pde_loss_raw:<14.6e}")
 
     return model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log
-'''
\ No newline at end of file
+'''
+
+
+
+def train_fno4d(model, myloss, epochs, batch_size, train_loader, test_loader,
+                optimizer, scheduler, normalized, normalizer, device):
+    """Training function for FNO4d model."""
+    ntrain = len(train_loader) * train_loader.batch_size
+    ntest = len(test_loader) * test_loader.batch_size
+
+    train_mse_log = []
+    train_l2_log = []
+    test_l2_log = []
+    test_mse_log = []
+
+    if normalized:
+        y_normalizer = normalizer[1].to(device)
+    else:
+        y_normalizer = None
+
+    for ep in range(epochs):
+        model.train()
+        t1 = default_timer()
+        train_mse = 0
+        train_l2 = 0
+
+        for x, y in train_loader:
+            x, y = x.to(device), y.to(device)
+
+            optimizer.zero_grad()
+            out = model(x)
+
+            if normalized:
+                out = y_normalizer.decode(out)
+                y = y_normalizer.decode(y)
+
+            mse = F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean')
+            loss = myloss(out.flatten(start_dim=1), y.flatten(start_dim=1))
+
+            loss.backward()
+            optimizer.step()
+            scheduler.step()
+
+            train_mse += mse.item()
+            #train_l2 += loss.item()
+            train_l2 += loss.item() / batch_size  # Normalize by batch size
+
+        model.eval()
+        test_l2 = 0
+        test_mse = 0
+        with torch.no_grad():
+            for x, y in test_loader:
+                x, y = x.to(device), y.to(device)
+
+                out = model(x)
+                if normalized:
+                    out = y_normalizer.decode(out)
+                    y = y_normalizer.decode(y)
+
+                test_mse += F.mse_loss(out.flatten(start_dim=1), y.flatten(start_dim=1), reduction='mean').item()
+                test_l2 += myloss(out.flatten(start_dim=1), y.flatten(start_dim=1)).item()
+                test_l2 += test_l2.item() / batch_size
+
+
+        train_mse /= len(train_loader)
+        train_l2 /= len(train_loader)
+        test_mse /= len(test_loader)
+        test_l2 /= len(test_loader)
+
+        train_mse_log.append(train_mse)
+        train_l2_log.append(train_l2)
+        test_l2_log.append(test_l2)
+        test_mse_log.append(test_mse)
+
+        t2 = default_timer()
+
+        if ep == 0:
+            print("No. Epoch   Time (s)       Train MSE      Train L2            Test L2")
+
+        print(f"{ep:<10} {t2 - t1:<13.6f} {train_mse:<13.10f} {train_l2:<13.10f}  {test_l2:<13.10f}")
+
+    return model, train_mse_log, train_l2_log, test_l2_log
\ No newline at end of file
Index: main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import os\nimport importlib\nimport torch\nimport inspect\nimport numpy as np\nimport matplotlib\nimport h5py  # MODIFIED: Added h5py import\nimport scipy.io\n\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom training import train_fno, train_fno_time, train_hybrid, train_fno4d\nfrom torch.utils.data import DataLoader, random_split\nfrom utilities import ImportDataset, count_params, LpLoss, ModelEvaluator, SobolevLoss\nfrom post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \\\n    make_video, save_vtk, plot_xy_plane_subplots\nimport time\nfrom torch_optimizer import Lamb\n\n################################################################\n# Problem Definition\n################################################################\n\n################################################################\n# Problem Definition\n################################################################\n# problem = 'AC2D'\n#problem = 'AC3D'\n# problem = 'CH2DNL'\n# problem = 'SH2D'\nproblem = 'SH3D'\n# problem = 'PFC2D'\n#problem = 'PFC3D'\n# problem = 'MBE2D'\n#problem = 'MBE3D'\n# problem = 'CH2D'\n#problem = 'CH3D'\n\n# network_name = 'TNO2d'\n# network_name = 'FNO2d'\n#network_name = 'FNO3d'\nnetwork_name = 'FNO4d'\n#network_name = 'TNO3d'\n\nPINN_MODE =  False #True #   True #  False #  True #   True #    True #\n#  False #    True # False #  False  # False #\n\nprint(f\"problem = {problem}\")\nprint(f\"network = {network_name}\")\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\")\nnetwork = getattr(importlib.import_module('networks'), network_name)\ntorch.manual_seed(cf.torch_seed)\nnp.random.seed(cf.numpy_seed)\ndevice = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)\n\nPDE_WEIGHT = cf.pde_weight\npde_loss_scaler = cf.pde_loss_scaler\n\nif PINN_MODE:\n    run_descriptor = f\"PINN_w{int(PDE_WEIGHT * 100)}\"\n    output_subdir = f\"plots_Data_Physics_{network_name}\"\n    model_run_name = f'{network_name}_{problem}_Hybrid_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d.pt'\nelse:\n    run_descriptor = \"DataDriven\"\n    output_subdir = f\"plots_{network_name}\"\n    model_run_name = f'{network_name}_{problem}_S{cf.s}_T{cf.T_in}to{cf.T_out}_width{cf.width}_modes{cf.modes}_q{cf.width_q}_h{cf.width_h}_grf3d.pt'\n\nmodel_dir = os.path.join(problem, 'models')\nmodel_name = f'{model_run_name}'\nmodel_path = os.path.join(model_dir, model_name)\nplot_dir = os.path.join(problem, output_subdir)\nos.makedirs(model_dir, exist_ok=True)\nos.makedirs(plot_dir, exist_ok=True)\n\nprint(f\"Model Run Name: {model_run_name}\")\nprint(f\"Model Path: {model_path}\")\nprint(f\"Plot Directory: {plot_dir}\")\n\nstart_time = time.time()\n\n################################################################\n# load data and data normalization\n################################################################\n# MODIFIED: Added special handling for SH3D dataset loading\ntry:\n    dataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n    if problem == 'SH3D':\n        print(\"SH3D dataset detected - applying special handling\")\n        # Verify dataset sizes\n        sample = dataset[0][0]  # Get first sample\n        print(f\"SH3D sample shape: {sample.shape}, dtype: {sample.dtype}\")\n        print(f\"SH3D stats - mean: {sample.mean():.4f}, std: {sample.std():.4f}\")\nexcept Exception as e:\n    print(f\"Error loading dataset: {e}\")\n    raise\n\ntrain_dataset, test_dataset, _ = random_split(dataset, [cf.nTrain, cf.nTest, len(dataset) - cf.nTrain - cf.nTest])\nnormalizers = [dataset.normalizer_x, dataset.normalizer_y] if cf.normalized is True else None\n\ntrain_loader = DataLoader(train_dataset, batch_size=cf.batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=cf.batch_size, shuffle=False)\n\n\n# ==================== CODE TO INSPECT BATCH SHAPE ====================\nprint(\"\\n\" + \"=\"*50)\nprint(\"Inspecting DataLoader Batch Shapes\")\nprint(\"=\"*50)\n# Get one batch of data from the train_loader\ntry:\n    x_batch, y_batch = next(iter(train_loader))\n    # Print the shape of the batch\n    # This will be (batch_size, S, S, S, T_in) for input\n    # and (batch_size, S, S, S, T_out) for target\n    print(f\"Shape of an input batch from DataLoader: {x_batch.shape}\")\n    print(f\"Shape of a target batch from DataLoader: {y_batch.shape}\")\nexcept StopIteration:\n    print(\"Train loader is empty. Cannot retrieve a batch.\")\nprint(\"=\"*50 + \"\\n\")\n# =======================================================================\n\n############AA####################################################\n# training and evaluation\n################################################################\nsig = inspect.signature(network.__init__)\nrequired_args = [param.name for param in sig.parameters.values()\n                 if param.default == inspect.Parameter.empty and param.name != \"self\"]\nif network_name == 'FNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO2d':\n    model = network(cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'FNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.T_in, cf.T_out, cf.n_layers).to(device)\nelif network_name == 'TNO3d':\n    model = network(cf.modes, cf.modes, cf.modes, cf.width, cf.width_q, cf.width_h, cf.T_in, cf.T_out, cf.n_layers).to(\n        device)\nelif network_name == 'FNO4d':\n    model = network(\n        modes1=cf.modes,\n        modes2=cf.modes,\n        modes3=cf.modes,\n        modes4_internal =1, # cf.modes_t, # MUST BE 1\n        width=cf.width,\n        width_q=cf.width_q,\n        T_in_channels=cf.T_in,\n        n_layers=cf.n_layers\n    ).to(device)\n\n\nelse:\n    raise Exception(\"network_name is not correct\")\n\nprint(count_params(model))  # Print model parameters\ntrain_mse_log, train_l2_log, test_l2_log = [], [], []  # Initialize logs\n\n# Load the entire model and logs\nif os.path.exists(model_path) and cf.load_model:\n    print(f\"Loading pre-trained model from {model_path}\")\n    checkpoint = torch.load(model_path, map_location=device)\n    model = checkpoint['model']\n    train_mse_log = checkpoint.get('train_mse_log', [])\n    train_l2_log = checkpoint.get('train_l2_log', [])\n    test_l2_log = checkpoint.get('test_l2_log', [])\nelse:\n    print(\"No pre-trained model loaded. Initializing a new model.\")\n\n# Define optimizer, scheduler, and loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)\nmyloss = LpLoss(p=2, l1_weight=0.1, size_average=False) # size_average=True # False\n# NEW: Instantiate SobolevLoss instead of LpLoss\n# You can tune grad_weight. A good starting point is 0.1 or 1.0.\n#myloss = SobolevLoss(d=3, p=2, grad_weight=0.1)\n\n# COMPUTE THE DYNAMIC SCALER\n# Use the train_loader to get a representative batch\n\n\n# Train the model\nif cf.training:\n    print(\"\\n--- Starting Training ---\")\n    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)\n        grid_info = {\n            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,\n            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,\n            'dt_model': cf.dt_model,\n            'T_out': cf.T_out\n        }\n\n        if PDE_WEIGHT == 0.0:\n            print(\"Running PINN training loop with pde_weight=0 (Data-Driven only loss).\")\n        else:\n            print(\n                f\"Running PINN training loop with pde_weight={PDE_WEIGHT:.2f}, using PDE Scaler: {pde_loss_scaler:.2e}\")\n\n        model, train_mse_hybrid_log, train_l2_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log, train_pde_scaled_log, test_loss_hybrid_log = (\n            train_hybrid(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                         optimizer, scheduler, cf.normalized, normalizers, device,\n                         PDE_WEIGHT, grid_info, cf.epsilon, problem,\n                         pde_loss_scaler=pde_loss_scaler)\n        )\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model': model,\n            'train_mse_log': train_mse_hybrid_log,\n            'train_l2_log': train_l2_hybrid_log,\n            'test_l2_log': test_data_log,\n            'test_pde_scaled_log': test_pde_loss_scaled_log,\n            'train_data_log': train_data_log,\n            'train_pde_scaled_log': train_pde_scaled_log,\n            'test_loss_hybrid_log': test_loss_hybrid_log\n        }, model_path)\n\n    else:  # Original Data-Driven Mode\n        if network_name == 'FNO2d' or network_name == 'FNO3d':\n            model, train_l2_log, test_l2_log = (\n                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                               optimizer, scheduler, cf.normalized, normalizers, device))\n            train_mse_log = []\n        elif network_name == 'FNO4d':\n\n            model, train_mse_log, train_l2_log, test_l2_log = (  # Add val logs\n                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                          optimizer, scheduler, cf.normalized, normalizers, device))\n\n            # train_fno4d = train_fno\n        else:\n            model, train_mse_log, train_l2_log, test_l2_log = (\n                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                          optimizer, scheduler, cf.normalized, normalizers, device))\n\n    print(f\"Saving model and logs to {model_path}\")\n    torch.save({\n        'model': model,\n        'train_mse_log': train_mse_log,\n        'train_l2_log': train_l2_log,\n        'test_l2_log': test_l2_log\n    }, model_path)\n\n\n'''\n# Train the model\nif cf.training:\n    print(\"\\n--- Starting Training ---\")\n    if PINN_MODE:  # Use PINN loop regardless of weight (handles pde_weight=0 case)\n        grid_info = {\n            'Nx': cf.s, 'Ny': cf.s, 'Nz': cf.s,\n            'Lx': cf.Lx, 'Ly': cf.Lx, 'Lz': cf.Lx,\n            'dt_model': cf.dt_model,\n            'T_out': cf.T_out\n        }\n\n        # --- NEW: Define the two stages for the training curriculum ---\n        epochs_stage1 = 10\n        scaler_stage1 = 1e-4\n\n        # Calculate remaining epochs for stage 2\n        epochs_stage2 = cf.epochs - epochs_stage1\n        scaler_stage2 = 1e-6\n\n        # --- Stage 1 Training ---\n        print(\"\\n--- Starting Training Stage 1 ---\")\n        print(f\"Epochs: {epochs_stage1}, PDE Scaler: {scaler_stage1:.2e}, PDE Weight: {PDE_WEIGHT:.2f}\")\n\n        # Note: The 'model' object is updated in-place by the function call\n        model, train_mse_s1, train_l2_s1, test_data_s1, test_pde_s1, train_data_s1, train_pde_scl_s1, test_loss_s1 = (\n            train_hybrid(model, myloss, epochs_stage1, cf.batch_size, train_loader, test_loader,\n                         optimizer, scheduler, cf.normalized, normalizers, device,\n                         PDE_WEIGHT, grid_info, cf.epsilon, problem,\n                         pde_loss_scaler=scaler_stage1)\n        )\n\n        # --- Stage 2 Training (if there are remaining epochs) ---\n        if epochs_stage2 > 0:\n            print(\"\\n--- Starting Training Stage 2 ---\")\n            print(f\"Epochs: {epochs_stage2}, PDE Scaler: {scaler_stage2:.2e}, PDE Weight: {PDE_WEIGHT:.2f}\")\n\n            model, train_mse_s2, train_l2_s2, test_data_s2, test_pde_s2, train_data_s2, train_pde_scl_s2, test_loss_s2 = (\n                train_hybrid(model, myloss, epochs_stage2, cf.batch_size, train_loader, test_loader,\n                             optimizer, scheduler, cf.normalized, normalizers, device,\n                             PDE_WEIGHT, grid_info, cf.epsilon, problem,\n                             pde_loss_scaler=scaler_stage2)\n            )\n\n            # Combine the logs from both stages for plotting and saving\n            train_mse_hybrid_log = train_mse_s1 + train_mse_s2\n            train_l2_hybrid_log = train_l2_s1 + train_l2_s2\n            test_data_log = test_data_s1 + test_data_s2\n            test_pde_loss_scaled_log = test_pde_s1 + test_pde_s2\n            train_data_log = train_data_s1 + train_data_s2\n            train_pde_scaled_log = train_pde_scl_s1 + train_pde_scl_s2\n            test_loss_hybrid_log = test_loss_s1 + test_loss_s2\n        else:\n            # If only stage 1 was run, the final logs are just the stage 1 logs\n            train_mse_hybrid_log = train_mse_s1\n            train_l2_hybrid_log = train_l2_s1\n            test_data_log = test_data_s1\n            test_pde_loss_scaled_log = test_pde_s1\n            train_data_log = train_data_s1\n            train_pde_scaled_log = train_pde_scl_s1\n            test_loss_hybrid_log = test_loss_s1\n\n        print(f\"\\n--- Training Finished. Saving model and logs to {model_path} ---\")\n        # The torch.save call remains the same, as the log variables have been correctly prepared\n        torch.save({\n            'model': model,\n            'train_mse_log': train_mse_hybrid_log,\n            'train_l2_log': train_l2_hybrid_log,\n            'test_l2_log': test_data_log, # 'test_l2_log' is used by evaluator, it should contain data loss\n            'test_pde_scaled_log': test_pde_loss_scaled_log,\n            'train_data_log': train_data_log,\n            'train_pde_scaled_log': train_pde_scaled_log,\n            'test_loss_hybrid_log': test_loss_hybrid_log\n        }, model_path)\n\n    else:  # Original Data-Driven Mode (This part remains unchanged)\n        if network_name == 'FNO2d' or network_name == 'FNO3d':\n            model, train_l2_log, test_l2_log = (\n                train_fno_time(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                               optimizer, scheduler, cf.normalized, normalizers, device))\n            train_mse_log = []\n        else:\n            model, train_mse_log, train_l2_log, test_l2_log = (\n                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,\n                          optimizer, scheduler, cf.normalized, normalizers, device))\n\n        print(f\"Saving model and logs to {model_path}\")\n        torch.save({\n            'model': model,\n            'train_mse_log': train_mse_log,\n            'train_l2_log': train_l2_log,\n            'test_l2_log': test_l2_log\n        }, model_path)\n'''\n\nend_time = time.time()\nFinal_time = round(end_time - start_time, 2)\nprint(f\"Total Execution Time: {Final_time} seconds\")\n\n# ==================== START: CAPTURE PREDICTION AND EXACT SOLUTION TIMES ====================\nprint(\"\\n--- Evaluating Model and Measuring Prediction Time ---\")\nevaluator = ModelEvaluator(model, test_dataset, cf.s, cf.T_in, cf.T_out, device, cf.normalized, normalizers,\n                           time_history=(network_name == 'FNO2d'))\n\n# Measure the time it takes to get predictions for the entire test set\nprediction_start_time = time.time()\nresults = evaluator.evaluate(loss_fn=myloss)\nprediction_end_time = time.time()\n\n# Calculate the model's prediction time\nmodel_prediction_time = prediction_end_time - prediction_start_time\nprint(f\"Model prediction time for the test set: {model_prediction_time:.4f} seconds\")\n\n# IMPORTANT: Placeholder for the exact solution time.\n# This value MUST be updated manually with the time it took the numerical\n# solver to generate the ground truth data for the test set.\n# The value here is just an example.\nexact_solution_time = 3600.0  # Placeholder in seconds (e.g., 1 hour)\nprint(f\"Using placeholder for exact solution time: {exact_solution_time:.2f} seconds. PLEASE UPDATE THIS VALUE.\")\n# ===================== END: CAPTURE PREDICTION AND EXACT SOLUTION TIMES =====================\n\n\ninp = results['input']\npred = results['prediction']\nexact = results['exact']\ntest_l2_avg = results[\"average\"]\n\nif PINN_MODE:\n    losses = [train_l2_hybrid_log, test_loss_hybrid_log, test_data_log, test_pde_loss_scaled_log, train_data_log,\n              train_pde_scaled_log]\n    labels = ['Train L2 Hyb', 'Test L2 Hyb', 'Test L2 data', 'Test pde_scaled', 'Train data', 'Train pde']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\nelse:\n    losses = [train_l2_log, test_l2_log]\n    labels = ['Train L2', 'Test L2']\n    plot_loss_trend(losses, labels, problem, network_name, Final_time, test_l2_avg, plot_dir, PDE_WEIGHT)\n\n################################################################\n# post-processing\n################################################################\na_ind = inp[cf.index]\nu_pred = pred[cf.index]\nu_exact = exact[cf.index]\nerror = u_pred - u_exact\n\nprint(f\"DEBUG: Shape of u_exact passed to plotting function: {u_exact.shape}\")\nprint(f\"DEBUG: Shape of u_pred passed to plotting function: {u_pred.shape}\")\n\nplot_range = [[-1.2, 1.2], [-1.2, 1.2], [-0.6, 0.6]]\n\n# =========================================================================================\n# ===                START OF MODIFIED PLOTTING PREPARATION BLOCK                      ===\n# =========================================================================================\n\n# 1. Get the initial condition (t=0) data for the chosen sample index\na_ind = inp[cf.index]\nprint(f\"Shape of initial condition (t=0) data 'a_ind': {a_ind.shape}\")\n\n# 2. Separate desired times into t=0 vs. future predictions\ndesired_times = cf.time_steps\nfuture_times_to_plot = []\nhas_initial_condition = (0 in desired_times)\nfor t in desired_times:\n    if t > 0:\n        future_times_to_plot.append(t)\n\n# 3. Translate the FUTURE times to array indices\nindices_to_plot = []\nvalid_future_times = []\nfor t in future_times_to_plot:\n    if t <= cf.T_out:\n        indices_to_plot.append(t - 1)\n        valid_future_times.append(t)\n    else:\n        print(f\"Warning: Time t={t} is out of valid prediction range. Skipping.\")\nprint(f\"Plotting for future times: {valid_future_times} --> which correspond to array indices: {indices_to_plot}\")\n\n# 4. MOVE ALL DATA TO THE TARGET DEVICE BEFORE OPERATIONS\nt0_data_cpu = a_ind\nu_exact_cpu = u_exact\nu_pred_cpu = u_pred\nerror_cpu = error\n\nt0_data_gpu = t0_data_cpu.to(device)\nu_exact_gpu = u_exact_cpu.to(device)\nu_pred_gpu = u_pred_cpu.to(device)\nerror_gpu = error_cpu.to(device)\nindices_tensor_gpu = torch.tensor(indices_to_plot, device=device)\n\n# 5. PREPARE COMBINED TENSORS FOR PLOTTING on the GPU\nif has_initial_condition:\n    # --- ### FIXED DIMENSION HANDLING ### ---\n    # `a_ind` has shape (sx, sy, sz, 1) where the last dim is a channel.\n    # `u_exact_gpu` has shape (sx, sy, sz, T) where the last dim is time.\n    # They are both 4D, so we can concatenate them directly if the last dimension is treated as the time dimension.\n    # We don't need to do any reshaping. `t0_data_gpu` is already correct.\n    t0_for_concat = t0_data_gpu\n\n    # Select the future time slices from the GPU tensors\n    u_exact_selected = u_exact_gpu.index_select(-1, indices_tensor_gpu)\n    u_pred_selected = u_pred_gpu.index_select(-1, indices_tensor_gpu)\n    error_selected = error_gpu.index_select(-1, indices_tensor_gpu)\n\n    # Combine t=0 data with the selected future steps\n    u_exact_for_plot = torch.cat((t0_for_concat, u_exact_selected), dim=-1)\n    u_pred_for_plot = torch.cat((t0_for_concat, u_pred_selected), dim=-1)\n\n    # The error for t=0 is zero by definition\n    error_t0 = torch.zeros_like(t0_for_concat)\n    error_for_plot = torch.cat((error_t0, error_selected), dim=-1)\n\n    final_indices = list(range(len(desired_times)))\n    final_labels = desired_times\nelse:\n    u_exact_for_plot = u_exact_gpu\n    u_pred_for_plot = u_pred_gpu\n    error_for_plot = error_gpu\n    final_indices = indices_to_plot\n    final_labels = valid_future_times\n\nprint(f\"Final data prepared for plotting with shape: {u_exact_for_plot.shape}\")\nprint(f\"Final indices for plotting: {final_indices}\")\nprint(f\"Final labels for plotting: {final_labels}\")\n\n\n# =========================================================================================\n# ===                 END OF MODIFIED PLOTTING PREPARATION BLOCK                       ===\n# =========================================================================================\n\n################################################################\n# Save Results to MATLAB .mat file\n################################################################\nprint(\"\\n--- Saving Results to .mat File ---\")\nmat_filename = os.path.join(plot_dir, f'{model_run_name}_results.mat')\n\n# MODIFIED: Enhanced saving logic with fallbacks\ndef save_results(mat_filename, results_dict):\n    try:\n        # First try standard save\n        scipy.io.savemat(mat_filename, results_dict)\n        print(f\"Saved with standard format to {mat_filename}\")\n    except ValueError as e:\n        if \"Format should be '4' or '5'\" in str(e):\n            print(\"Large data detected, trying v7.3 format...\")\n            try:\n                scipy.io.savemat(mat_filename, results_dict, format='v7.3')\n                print(f\"Saved with v7.3 format to {mat_filename}\")\n            except Exception as e:\n                print(f\"v7.3 failed: {e}\")\n                # Fallback to HDF5\n                h5_filename = mat_filename.replace('.mat', '.h5')\n                with h5py.File(h5_filename, 'w') as f:\n                    for k, v in results_dict.items():\n                        f.create_dataset(k, data=v, compression='gzip')\n                print(f\"Saved as HDF5 to {h5_filename}\")\n        else:\n            raise\n\nif PINN_MODE:\n    results_dict = {\n        'train_mse_log': np.array(train_mse_hybrid_log, dtype=np.float32),  # MODIFIED: Added dtype\n        'train_hybrid_loss': np.array(train_l2_hybrid_log, dtype=np.float32),\n        'test_loss_hybrid_log': np.array(test_loss_hybrid_log, dtype=np.float32),\n        'train_data_log': np.array(train_data_log, dtype=np.float32),\n        'test_data_log': np.array(test_data_log, dtype=np.float32),\n        'train_pde_scaled_log': np.array(train_pde_scaled_log, dtype=np.float32),\n        'test_pde_loss_scaled_log': np.array(test_pde_loss_scaled_log, dtype=np.float32),\n        'test_input': inp.cpu().numpy().astype(np.float32),  # MODIFIED: Added astype\n        'test_prediction': pred.cpu().numpy().astype(np.float32),\n        'test_exact': exact.cpu().numpy().astype(np.float32),\n        'config_pde_weight': np.float32(PDE_WEIGHT),\n        'config_pde_loss_scaler': np.float32(pde_loss_scaler),\n        'config_epochs': np.int32(cf.epochs),\n        'config_lr': np.float32(cf.learning_rate),\n        'config_T_in': np.int32(cf.T_in),\n        'config_T_out': np.int32(cf.T_out),\n        'config_s': np.int32(cf.s),\n        'config_Lx': np.float32(cf.Lx),\n        'final_exec_time_s': np.float32(Final_time),\n        'model_prediction_time': np.float32(model_prediction_time),  # ADDED\n        'exact_solution_time': np.float32(exact_solution_time),      # ADDED\n    }\nelse:\n    results_dict = {\n        'train_mse_log': np.array(train_mse_log, dtype=np.float32),\n        'train_l2_log': np.array(train_l2_log, dtype=np.float32),\n        'test_l2_log': np.array(test_l2_log, dtype=np.float32),\n        'test_input': inp.cpu().numpy().astype(np.float32),\n        'test_prediction': pred.cpu().numpy().astype(np.float32),\n        'test_exact': exact.cpu().numpy().astype(np.float32),\n        'config_epochs': np.int32(cf.epochs),\n        'config_lr': np.float32(cf.learning_rate),\n        'config_T_in': np.int32(cf.T_in),\n        'config_T_out': np.int32(cf.T_out),\n        'config_s': np.int32(cf.s),\n        'config_Lx': np.float32(cf.Lx),\n        'final_exec_time_s': np.float32(Final_time),\n        'model_prediction_time': np.float32(model_prediction_time),  # ADDED\n        'exact_solution_time': np.float32(exact_solution_time),      # ADDED\n    }\n\n# MODIFIED: Use the new save function\nsave_results(mat_filename, results_dict)\n\n# Plot XY-plane for the \"Exact\" solution trajectory (includes t=0)\n\n'''\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=u_exact_for_plot,\n                       field_name='Exact Solution',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[0],\n                       problem=problem,\n                       network_name=network_name)\n\n# Plot XY-plane for the \"Predicted\" solution trajectory (includes t=0 from input)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=u_pred_for_plot,\n                       field_name='Predicted Solution',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[1],\n                       problem=problem,\n                       network_name=network_name)\n\n# Plot XY-plane for the \"Error\" (error is 0 at t=0)\nplot_xy_plane_subplots(domain=cf.domain,\n                       field=error_for_plot,\n                       field_name='Error',\n                       time_steps=final_indices,\n                       desired_times=final_labels,\n                       plot_range=plot_range[2],\n                       problem=problem,\n                       network_name=network_name)\n'''\n\n# Calculate L2 norm on original full prediction\nl2_norm_error = torch.norm(u_pred - u_exact, p=2)\nl2_norm_exact = torch.norm(u_exact, p=2)\nepsilon = 1e-8\nif l2_norm_exact.item() > epsilon:\n    relative_l2_error = l2_norm_error / l2_norm_exact\nelse:\n    relative_l2_error = torch.tensor(0.0) if l2_norm_error.item() < epsilon else torch.tensor(float('inf'))\n\nprint(f\"L2 norm of error: {l2_norm_error.item()}\")\nprint(f\"L2 norm of exact solution: {l2_norm_exact.item()}\")\nprint(f\"Relative L2 norm error: {relative_l2_error.item()}\")\nrelative_l2_error_percentage = (relative_l2_error * 100)\nprint(f\"Relative L2 norm error (percentage): {relative_l2_error_percentage.item()}%\")\n\n# Call the combined results plots with the prepared data\nplot_combined_results(\n    domain=cf.domain,\n    u_exact=u_exact_for_plot,\n    u_pred=u_pred_for_plot,\n    error=error_for_plot,\n    plot_ranges=plot_range,\n    problem=problem,\n    network_name=network_name,\n    plot_dir=plot_dir,\n    pde_weight=PDE_WEIGHT,\n    time_steps_indices=final_indices,\n    desired_times=final_labels\n)\n\nplot_combined_results_3d(\n    domain=cf.domain,\n    u_exact=u_exact_for_plot,\n    u_pred=u_pred_for_plot,\n    error=error_for_plot,\n    plot_ranges=plot_range,\n    problem=problem,\n    network_name=network_name,\n    plot_dir=plot_dir,\n    pde_weight=PDE_WEIGHT,\n    time_steps_indices=final_indices,\n    desired_times=final_labels\n)\n\nprint(\"\\n--- Script Finished ---\")
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/main.py b/main.py
--- a/main.py	(revision 4571b9c99edbe597d7f28792b7cdc66308871464)
+++ b/main.py	(date 1754665554837)
@@ -12,7 +12,7 @@
 import torch.nn.functional as F
 from training import train_fno, train_fno_time, train_hybrid, train_fno4d
 from torch.utils.data import DataLoader, random_split
-from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator, SobolevLoss
+from utilities import ImportDataset, count_params, LpLoss, ModelEvaluator #, SobolevLoss
 from post_processing import plot_loss_trend, plot_combined_results_3d, plot_combined_results, plot_field_trajectory, \
     make_video, save_vtk, plot_xy_plane_subplots
 import time
@@ -40,8 +40,8 @@
 # network_name = 'TNO2d'
 # network_name = 'FNO2d'
 #network_name = 'FNO3d'
-network_name = 'FNO4d'
-#network_name = 'TNO3d'
+#network_name = 'FNO4d'
+network_name = 'TNO3d'
 
 PINN_MODE =  False #True #   True #  False #  True #   True #    True #
 #  False #    True # False #  False  # False #
@@ -169,7 +169,7 @@
 # Define optimizer, scheduler, and loss function
 optimizer = torch.optim.Adam(model.parameters(), lr=cf.learning_rate, weight_decay=cf.weight_decay)
 scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cf.iterations)
-myloss = LpLoss(p=2, l1_weight=0.1, size_average=False) # size_average=True # False
+myloss = LpLoss(p=2, l1_weight=0.0, size_average=False) # size_average=True # False
 # NEW: Instantiate SobolevLoss instead of LpLoss
 # You can tune grad_weight. A good starting point is 0.1 or 1.0.
 #myloss = SobolevLoss(d=3, p=2, grad_weight=0.1)
@@ -223,7 +223,7 @@
         elif network_name == 'FNO4d':
 
             model, train_mse_log, train_l2_log, test_l2_log = (  # Add val logs
-                train_fno(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
+                train_fno4d(model, myloss, cf.epochs, cf.batch_size, train_loader, test_loader,
                           optimizer, scheduler, cf.normalized, normalizers, device))
 
             # train_fno4d = train_fno
Index: run_interface3.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\nimport numpy as np\nimport importlib\nfrom utilities import ImportDataset\nimport matplotlib\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom skimage import measure\nfrom matplotlib.colors import LightSource\n\n# Load model\ndevice = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n\n#model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6.pt'\n\nmodel_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'\n\n# Option 1 (Recommended secure approach)\ntry:\n    from networks import TNO3d  # Import your custom network class\n    torch.serialization.add_safe_globals([TNO3d])\n    checkpoint = torch.load(model_path, map_location=device, weights_only=True)\nexcept Exception as e:\n    print(f\"Secure loading failed: {e}\\nFalling back to weights_only=False\")\n    # Option 2 (Less secure fallback)\n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n\nmodel = checkpoint['model']\nmodel.eval()\n\n# Load dataset for normalization\nproblem = 'SH3D'\nnetwork_name = 'TNO3d'\ncf = importlib.import_module(f\"configs.config_{problem}_{network_name}\")\ndataset = ImportDataset(cf.parent_dir, cf.matlab_dataset, cf.normalized, cf.T_in, cf.T_out)\n\n# Move normalizer parameters to device\ndataset.normalizer_x.mean = dataset.normalizer_x.mean.to(device)\ndataset.normalizer_x.std = dataset.normalizer_x.std.to(device)\ndataset.normalizer_y.mean = dataset.normalizer_y.mean.to(device)\ndataset.normalizer_y.std = dataset.normalizer_y.std.to(device)\n\n\n# Create spherical initial condition\ndef create_sharp_sphere_initial_condition(N=32, radius=2, L=10):\n    x = np.linspace(-L / 2, L / 2, N)\n    y = np.linspace(-L / 2, L / 2, N)\n    z = np.linspace(-L / 2, L / 2, N)\n    xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')\n\n    r = np.sqrt(xx ** 2 + yy ** 2 + zz ** 2)\n    sphere = np.ones((N, N, N), dtype=np.float32)  # Use float32 for consistency\n\n    # Perfectly sharp transition (no smoothing)\n    outer_mask = r > radius\n    sphere[outer_mask] = -1.0\n\n    # Force exact values (no floating point artifacts)\n    sphere = np.where(r <= radius, 1.0, -1.0)\n\n    return sphere\n# Create initial condition with perfect sharp interface\nsphere_ic = create_sharp_sphere_initial_condition()\n\ninput_tensor = torch.from_numpy(sphere_ic).float().unsqueeze(0).unsqueeze(-1).to(device)\ninput_tensor = dataset.normalizer_x.encode(input_tensor)\n\n# Run prediction\nwith torch.no_grad():\n    prediction = model(input_tensor)  # Shape [1, 32, 32, 32, 10]\n    prediction = dataset.normalizer_y.decode(prediction)\n\n# Define your custom frames to display\nselected_frames = [0, 50, 90]  # Adjusted for T_out=10\nnum_frames = len(selected_frames)\n\n# Create figure with two subplots: 3D views and 1D profile\nfig = plt.figure(figsize=(20, 10))\ngrid = plt.GridSpec(2, num_frames, hspace=0.3, wspace=0.2)\n\n# 1. Plot 3D isosurfaces for selected frames\nfor i, t in enumerate(selected_frames):\n    ax = fig.add_subplot(grid[0, i], projection='3d')\n    frame_data = prediction[0, ..., t].cpu().numpy()\n\n    # Print data range for debugging\n    print(f\"Frame {t}: min={np.min(frame_data):.3f}, max={np.max(frame_data):.3f}\")\n\n    # Determine appropriate level\n    data_min, data_max = np.min(frame_data), np.max(frame_data)\n    if data_min > 0 or data_max < 0:\n        level = (data_max + data_min) / 2  # Midpoint if zero is outside range\n    else:\n        level = 0.0  # Default level\n\n    try:\n        # Extract smooth isosurface with adjusted level\n        verts, faces, _, _ = measure.marching_cubes(frame_data, level=level)\n\n        # Apply lighting and coloring\n        ls = LightSource(azdeg=135, altdeg=45)\n        rgb = ls.shade_normals(verts[faces], fraction=0.8)\n\n        mesh = Poly3DCollection(verts[faces],\n                                facecolors=rgb,\n                                edgecolor='none',\n                                alpha=0.9)\n\n        ax.add_collection3d(mesh)\n        plot_success = True\n    except ValueError as e:\n        print(f\"Could not generate isosurface for frame {t}: {e}\")\n        plot_success = False\n        # Display empty plot with error message\n        ax.text(0.5, 0.5, 0.5, f\"No isosurface\\nat level={level:.2f}\",\n                ha='center', va='center', fontsize=10)\n\n    # Set viewing parameters\n    ax.set_xlim(0, frame_data.shape[0])\n    ax.set_ylim(0, frame_data.shape[1])\n    ax.set_zlim(0, frame_data.shape[2])\n    ax.set_title(f'Time = {t}\\nLevel = {level:.2f}', pad=10)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_zticks([])\n    if plot_success:\n        ax.view_init(elev=30, azim=45)\n\n# 2. Plot 1D profile through center for all time steps\nax_profile = fig.add_subplot(grid[1, :])\nL = 10  # Domain size\nx = np.linspace(-L / 2, L / 2, prediction.shape[1])\ncenter_idx = prediction.shape[1] // 2  # Middle of the domain\n\n# Plot profiles for the same custom frames in the profile plot\nfor t in selected_frames:\n    profile = prediction[0, :, center_idx, center_idx, t].cpu().numpy()\n    ax_profile.plot(x, profile, label=f't={t}', alpha=0.8, linewidth=1.5)\n\n# Format profile plot\nax_profile.set_xlabel('Position along x-axis', fontsize=12)\nax_profile.set_ylabel('Field value', fontsize=12)\nax_profile.set_title('1D Profile Evolution Through Domain Center', pad=15)\nax_profile.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nax_profile.grid(True, alpha=0.3)\nax_profile.set_ylim([-1.2, 1.5])  # Match MATLAB y-limits\n\nplt.tight_layout()\nplt.show()\n\n# After getting predictions in Python\nprediction_np = prediction.cpu().numpy()  # Convert to numpy array\n\n# Save to .mat file\nfrom scipy.io import savemat\nsavemat('SH3D_python_predictions.mat', {\n    'python_pred': prediction_np,\n    'selected_frames': np.array(selected_frames),\n    'x': x  # Spatial coordinates\n})
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/run_interface3.py b/run_interface3.py
--- a/run_interface3.py	(revision 4571b9c99edbe597d7f28792b7cdc66308871464)
+++ b/run_interface3.py	(date 1754665554846)
@@ -15,7 +15,7 @@
 
 #model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6.pt'
 
-model_path = '/scratch/noqu8762/phase_field_equations_4d/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt'
+model_path = '/SH3D/models/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d_original.pt'
 
 # Option 1 (Recommended secure approach)
 try:
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"TNO3d vs FNO3d\">\n      <change afterPath=\"$PROJECT_DIR$/run_inference.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/vcs.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/vcs.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_AC3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_FNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/configs/config_SH3D_TNO3d.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/main.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/main.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/networks.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/networks.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/post_processing.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/post_processing.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/training.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/training.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/utilities.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/utilities.py\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <excluded-from-favorite>\n      <branch-storage>\n        <map>\n          <entry type=\"LOCAL\">\n            <value>\n              <list>\n                <branch-info repo=\"$PROJECT_DIR$\" source=\"master\" />\n              </list>\n            </value>\n          </entry>\n        </map>\n      </branch-storage>\n    </excluded-from-favorite>\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\n      <map>\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\n      </map>\n    </option>\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n    <option name=\"ROOT_SYNC\" value=\"DONT_SYNC\" />\n  </component>\n  <component name=\"GitHubPullRequestSearchHistory\">{\n  &quot;lastFilter&quot;: {\n    &quot;state&quot;: &quot;OPEN&quot;,\n    &quot;assignee&quot;: &quot;MBamdad&quot;\n  }\n}</component>\n  <component name=\"GithubPullRequestsUISettings\">{\n  &quot;selectedUrlAndAccountId&quot;: {\n    &quot;url&quot;: &quot;https://github.com/MBamdad/PhaseField_SANO3D&quot;,\n    &quot;accountId&quot;: &quot;819f0417-ba46-4324-b18a-a12d153ca697&quot;\n  }\n}</component>\n  <component name=\"ProjectColorInfo\">{\n  &quot;associatedIndex&quot;: 1\n}</component>\n  <component name=\"ProjectId\" id=\"2p11NySvsgjZ8eu9d53SI84567l\" />\n  <component name=\"ProjectReloadState\">\n    <option name=\"STATE\" value=\"1\" />\n  </component>\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">{\n  &quot;keyToString&quot;: {\n    &quot;Python.AC2D.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC2D_Net2D_3.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.AC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.AC3d_TNO3d_hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.MBE2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.MBE3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.PFV3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript0.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript1.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript2.executor&quot;: &quot;Run&quot;,\n    &quot;Python.RunScript3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_New.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.SH3D_TNO3d_Hybrid.executor&quot;: &quot;Run&quot;,\n    &quot;Python.THFNO.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test2.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.Test3.executor&quot;: &quot;Run&quot;,\n    &quot;Python.Test_Run.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.backend_interagg.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC2D_FNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_AC3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2DNL_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_CH3D_TNO3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.config_MBE2D_TNO2d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.config_SH3D_TNO3d.executor&quot;: &quot;Run&quot;,\n    &quot;Python.fourier_3d.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.main.executor&quot;: &quot;Run&quot;,\n    &quot;Python.main_TF.executor&quot;: &quot;Debug&quot;,\n    &quot;Python.networks.executor&quot;: &quot;Run&quot;,\n    &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,\n    &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,\n    &quot;Python.test1.executor&quot;: &quot;Run&quot;,\n    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,\n    &quot;git-widget-placeholder&quot;: &quot;main&quot;,\n    &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,\n    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,\n    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,\n    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,\n    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,\n    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,\n    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,\n    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;\n  },\n  &quot;keyToStringList&quot;: {\n    &quot;ChangesTree.GroupingKeys&quot;: [\n      &quot;directory&quot;\n    ]\n  }\n}</component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$/configs\" />\n      <recent name=\"$PROJECT_DIR$/AC2Dtest/models\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code/AC2D\" />\n      <recent name=\"$PROJECT_DIR$/Archive_Code\" />\n    </key>\n    <key name=\"MoveFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data\" />\n      <recent name=\"$PROJECT_DIR$\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.AC3D_TNO3d\">\n    <configuration name=\"AC3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"AC3d_TNO3d_hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"CH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"MBE3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_FNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"SH3D_TNO3d_Hybrid\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"PhaseFieldNet\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"SDK_NAME\" value=\"torch_env (2)\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <list>\n      <item itemvalue=\"Python.AC3D_TNO3d\" />\n      <item itemvalue=\"Python.AC3d_FNO3d\" />\n      <item itemvalue=\"Python.AC3d_TNO3d_hybrid\" />\n      <item itemvalue=\"Python.CH3D_TNO3d\" />\n      <item itemvalue=\"Python.MBE3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_FNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d\" />\n      <item itemvalue=\"Python.SH3D_TNO3d_Hybrid\" />\n    </list>\n  </component>\n  <component name=\"SharedIndexes\">\n    <attachedChunks>\n      <set>\n        <option value=\"bundled-js-predefined-1d06a55b98c1-0b3e54e931b4-JavaScript-PY-241.18034.82\" />\n        <option value=\"bundled-python-sdk-975db3bf15a3-2767605e8bc2-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-241.18034.82\" />\n      </set>\n    </attachedChunks>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"69f06a2e-e075-4f1f-8925-28211e19f97d\" name=\"Changes\" comment=\"\" />\n      <created>1731918731711</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1731918731711</updated>\n      <workItem from=\"1731918732726\" duration=\"17070000\" />\n      <workItem from=\"1732010735784\" duration=\"777000\" />\n      <workItem from=\"1732011520582\" duration=\"8000\" />\n      <workItem from=\"1732011538945\" duration=\"13153000\" />\n      <workItem from=\"1732106481018\" duration=\"3721000\" />\n      <workItem from=\"1732480846034\" duration=\"2889000\" />\n      <workItem from=\"1732483872465\" duration=\"14926000\" />\n      <workItem from=\"1732567216112\" duration=\"964000\" />\n      <workItem from=\"1732765090621\" duration=\"5000\" />\n      <workItem from=\"1732765102609\" duration=\"12000\" />\n      <workItem from=\"1732765345288\" duration=\"10000\" />\n      <workItem from=\"1732903897716\" duration=\"3074000\" />\n      <workItem from=\"1732911303920\" duration=\"27201000\" />\n      <workItem from=\"1732999179592\" duration=\"8241000\" />\n      <workItem from=\"1733039613684\" duration=\"6792000\" />\n      <workItem from=\"1733095843263\" duration=\"10000\" />\n      <workItem from=\"1733140600841\" duration=\"6993000\" />\n      <workItem from=\"1733150993229\" duration=\"184000\" />\n      <workItem from=\"1733151279786\" duration=\"6000\" />\n      <workItem from=\"1733151296310\" duration=\"16875000\" />\n      <workItem from=\"1733233230739\" duration=\"5172000\" />\n      <workItem from=\"1733246997923\" duration=\"15986000\" />\n      <workItem from=\"1733349590652\" duration=\"1949000\" />\n      <workItem from=\"1733352121741\" duration=\"6332000\" />\n      <workItem from=\"1733405466233\" duration=\"12731000\" />\n      <workItem from=\"1733557048829\" duration=\"5541000\" />\n      <workItem from=\"1733583489891\" duration=\"16419000\" />\n      <workItem from=\"1733859258781\" duration=\"7356000\" />\n      <workItem from=\"1733995059967\" duration=\"7899000\" />\n      <workItem from=\"1734011167665\" duration=\"991000\" />\n      <workItem from=\"1734029966470\" duration=\"25769000\" />\n      <workItem from=\"1734205412700\" duration=\"7689000\" />\n      <workItem from=\"1734644992163\" duration=\"5017000\" />\n      <workItem from=\"1734788130789\" duration=\"2312000\" />\n      <workItem from=\"1734863751114\" duration=\"9000\" />\n      <workItem from=\"1734863775073\" duration=\"9221000\" />\n      <workItem from=\"1734880034791\" duration=\"57000\" />\n      <workItem from=\"1734880213539\" duration=\"15000\" />\n      <workItem from=\"1734880329890\" duration=\"30000\" />\n      <workItem from=\"1734880369064\" duration=\"31312000\" />\n      <workItem from=\"1734983129135\" duration=\"55000\" />\n      <workItem from=\"1735034212628\" duration=\"2274000\" />\n      <workItem from=\"1735049036048\" duration=\"5309000\" />\n      <workItem from=\"1735126261413\" duration=\"75000\" />\n      <workItem from=\"1735356723104\" duration=\"1208000\" />\n      <workItem from=\"1735422837186\" duration=\"1387000\" />\n      <workItem from=\"1735719009558\" duration=\"561000\" />\n      <workItem from=\"1736101930735\" duration=\"570000\" />\n      <workItem from=\"1736102511675\" duration=\"4000\" />\n      <workItem from=\"1736161159525\" duration=\"7670000\" />\n      <workItem from=\"1736237907904\" duration=\"111000\" />\n      <workItem from=\"1736519480236\" duration=\"1867000\" />\n      <workItem from=\"1737577034938\" duration=\"3945000\" />\n      <workItem from=\"1737590448155\" duration=\"6145000\" />\n      <workItem from=\"1738310597042\" duration=\"2502000\" />\n      <workItem from=\"1738316162773\" duration=\"726000\" />\n      <workItem from=\"1738326887364\" duration=\"4500000\" />\n      <workItem from=\"1738586797583\" duration=\"600000\" />\n      <workItem from=\"1738663690532\" duration=\"4505000\" />\n      <workItem from=\"1738668267214\" duration=\"5368000\" />\n      <workItem from=\"1738685509837\" duration=\"74000\" />\n      <workItem from=\"1738703726377\" duration=\"1677000\" />\n      <workItem from=\"1738774383038\" duration=\"2249000\" />\n      <workItem from=\"1738787637783\" duration=\"7013000\" />\n      <workItem from=\"1738962434877\" duration=\"1153000\" />\n      <workItem from=\"1738967049524\" duration=\"782000\" />\n      <workItem from=\"1739275350614\" duration=\"312000\" />\n      <workItem from=\"1739464522072\" duration=\"12498000\" />\n      <workItem from=\"1739572784568\" duration=\"1228000\" />\n      <workItem from=\"1739626528163\" duration=\"5778000\" />\n      <workItem from=\"1739689815626\" duration=\"10399000\" />\n      <workItem from=\"1739812786805\" duration=\"48519000\" />\n      <workItem from=\"1740212626723\" duration=\"1263000\" />\n      <workItem from=\"1740213932190\" duration=\"644000\" />\n      <workItem from=\"1741475492994\" duration=\"40894000\" />\n      <workItem from=\"1741690305204\" duration=\"339000\" />\n      <workItem from=\"1741705983516\" duration=\"604000\" />\n      <workItem from=\"1741713165753\" duration=\"1198000\" />\n      <workItem from=\"1741861318912\" duration=\"2286000\" />\n      <workItem from=\"1742201562752\" duration=\"618000\" />\n      <workItem from=\"1742209067924\" duration=\"383000\" />\n      <workItem from=\"1742226300133\" duration=\"2432000\" />\n      <workItem from=\"1743071528350\" duration=\"9513000\" />\n      <workItem from=\"1743490058046\" duration=\"9000\" />\n      <workItem from=\"1743587112942\" duration=\"1188000\" />\n      <workItem from=\"1748900986740\" duration=\"1771000\" />\n      <workItem from=\"1748931928220\" duration=\"446000\" />\n      <workItem from=\"1748932436127\" duration=\"20890000\" />\n      <workItem from=\"1748970706276\" duration=\"3719000\" />\n      <workItem from=\"1748988822181\" duration=\"59000\" />\n      <workItem from=\"1749200290051\" duration=\"680000\" />\n      <workItem from=\"1749203502833\" duration=\"1349000\" />\n      <workItem from=\"1749213099437\" duration=\"3082000\" />\n      <workItem from=\"1750057109660\" duration=\"10453000\" />\n      <workItem from=\"1750070416210\" duration=\"46415000\" />\n    </task>\n    <task id=\"LOCAL-00001\" summary=\"Initial Commit\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732484343908</created>\n      <option name=\"number\" value=\"00001\" />\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732484343908</updated>\n    </task>\n    <task id=\"LOCAL-00002\" summary=\"added TransformerFNO\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732497990642</created>\n      <option name=\"number\" value=\"00002\" />\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732497990642</updated>\n    </task>\n    <task id=\"LOCAL-00003\" summary=\"added the connection between time steps - the model development is finished\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1732910153380</created>\n      <option name=\"number\" value=\"00003\" />\n      <option name=\"presentableId\" value=\"LOCAL-00003\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1732910153380</updated>\n    </task>\n    <task id=\"LOCAL-00004\" summary=\"Finished Allen-Cahn Problem\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733176021525</created>\n      <option name=\"number\" value=\"00004\" />\n      <option name=\"presentableId\" value=\"LOCAL-00004\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733176021525</updated>\n    </task>\n    <task id=\"LOCAL-00005\" summary=\"Added Allen-Cahn 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733583274023</created>\n      <option name=\"number\" value=\"00005\" />\n      <option name=\"presentableId\" value=\"LOCAL-00005\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733583274023</updated>\n    </task>\n    <task id=\"LOCAL-00006\" summary=\"added save_vtk\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1733995237535</created>\n      <option name=\"number\" value=\"00006\" />\n      <option name=\"presentableId\" value=\"LOCAL-00006\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1733995237535</updated>\n    </task>\n    <task id=\"LOCAL-00007\" summary=\"added MATLAB codes for creating database\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1734788540933</created>\n      <option name=\"number\" value=\"00007\" />\n      <option name=\"presentableId\" value=\"LOCAL-00007\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1734788540933</updated>\n    </task>\n    <task id=\"LOCAL-00008\" summary=\"added CH2DNL\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735126332032</created>\n      <option name=\"number\" value=\"00008\" />\n      <option name=\"presentableId\" value=\"LOCAL-00008\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735126332032</updated>\n    </task>\n    <task id=\"LOCAL-00009\" summary=\"added SH2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1735719422931</created>\n      <option name=\"number\" value=\"00009\" />\n      <option name=\"presentableId\" value=\"LOCAL-00009\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1735719422931</updated>\n    </task>\n    <task id=\"LOCAL-00010\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1736237977029</created>\n      <option name=\"number\" value=\"00010\" />\n      <option name=\"presentableId\" value=\"LOCAL-00010\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1736237977029</updated>\n    </task>\n    <task id=\"LOCAL-00011\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738788849261</created>\n      <option name=\"number\" value=\"00011\" />\n      <option name=\"presentableId\" value=\"LOCAL-00011\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738788849261</updated>\n    </task>\n    <task id=\"LOCAL-00012\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738789326593</created>\n      <option name=\"number\" value=\"00012\" />\n      <option name=\"presentableId\" value=\"LOCAL-00012\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738789326593</updated>\n    </task>\n    <task id=\"LOCAL-00013\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738796104012</created>\n      <option name=\"number\" value=\"00013\" />\n      <option name=\"presentableId\" value=\"LOCAL-00013\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738796104012</updated>\n    </task>\n    <task id=\"LOCAL-00014\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962464719</created>\n      <option name=\"number\" value=\"00014\" />\n      <option name=\"presentableId\" value=\"LOCAL-00014\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962464719</updated>\n    </task>\n    <task id=\"LOCAL-00015\" summary=\"added PFC2D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738962748829</created>\n      <option name=\"number\" value=\"00015\" />\n      <option name=\"presentableId\" value=\"LOCAL-00015\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738962748829</updated>\n    </task>\n    <task id=\"LOCAL-00016\" summary=\"Turn Nx to 64\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1738967163754</created>\n      <option name=\"number\" value=\"00016\" />\n      <option name=\"presentableId\" value=\"LOCAL-00016\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1738967163754</updated>\n    </task>\n    <task id=\"LOCAL-00017\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275401458</created>\n      <option name=\"number\" value=\"00017\" />\n      <option name=\"presentableId\" value=\"LOCAL-00017\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275401458</updated>\n    </task>\n    <task id=\"LOCAL-00018\" summary=\"update to 3D\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1739275433418</created>\n      <option name=\"number\" value=\"00018\" />\n      <option name=\"presentableId\" value=\"LOCAL-00018\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1739275433418</updated>\n    </task>\n    <task id=\"LOCAL-00019\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690373369</created>\n      <option name=\"number\" value=\"00019\" />\n      <option name=\"presentableId\" value=\"LOCAL-00019\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690373369</updated>\n    </task>\n    <task id=\"LOCAL-00020\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741690420059</created>\n      <option name=\"number\" value=\"00020\" />\n      <option name=\"presentableId\" value=\"LOCAL-00020\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741690420059</updated>\n    </task>\n    <task id=\"LOCAL-00021\" summary=\"TNO3d vs FNO3d\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1743587271259</created>\n      <option name=\"number\" value=\"00021\" />\n      <option name=\"presentableId\" value=\"LOCAL-00021\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1743587271259</updated>\n    </task>\n    <option name=\"localTasksCounter\" value=\"22\" />\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"Vcs.Log.Tabs.Properties\">\n    <option name=\"RECENT_FILTERS\">\n      <map>\n        <entry key=\"Branch\">\n          <value>\n            <list>\n              <RecentGroup>\n                <option name=\"FILTER_VALUES\">\n                  <option value=\"main\" />\n                </option>\n              </RecentGroup>\n            </list>\n          </value>\n        </entry>\n      </map>\n    </option>\n    <option name=\"TAB_STATES\">\n      <map>\n        <entry key=\"MAIN\">\n          <value>\n            <State>\n              <option name=\"FILTERS\">\n                <map>\n                  <entry key=\"branch\">\n                    <value>\n                      <list>\n                        <option value=\"main\" />\n                      </list>\n                    </value>\n                  </entry>\n                </map>\n              </option>\n            </State>\n          </value>\n        </entry>\n      </map>\n    </option>\n  </component>\n  <component name=\"VcsManagerConfiguration\">\n    <MESSAGE value=\"Initial Commit\" />\n    <MESSAGE value=\"added TransformerFNO\" />\n    <MESSAGE value=\"added the connection between time steps - the model development is finished\" />\n    <MESSAGE value=\"refactored\" />\n    <MESSAGE value=\"Finished Allen-Cahn Problem\" />\n    <MESSAGE value=\"Added Allen-Cahn 3D\" />\n    <MESSAGE value=\"added save_vtk\" />\n    <MESSAGE value=\"added MATLAB codes for creating database\" />\n    <MESSAGE value=\"seperated the number of layers in fourier part and convolutional part\" />\n    <MESSAGE value=\"added CH2DNL\" />\n    <MESSAGE value=\"added SH2D\" />\n    <MESSAGE value=\"added PFC2D\" />\n    <MESSAGE value=\"Turn Nx to 64\" />\n    <MESSAGE value=\"update to 3D\" />\n    <MESSAGE value=\"TNO3d vs FNO3d\" />\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"TNO3d vs FNO3d\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>142</line>\n          <option name=\"timeStamp\" value=\"17\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>163</line>\n          <option name=\"timeStamp\" value=\"18\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>134</line>\n          <option name=\"timeStamp\" value=\"19\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>327</line>\n          <option name=\"timeStamp\" value=\"20\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/SH2D.py</url>\n          <line>243</line>\n          <option name=\"timeStamp\" value=\"21\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_2.py</url>\n          <line>333</line>\n          <option name=\"timeStamp\" value=\"27\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_2.py</url>\n          <line>371</line>\n          <option name=\"timeStamp\" value=\"44\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/AC2D_Net2D_3.py</url>\n          <line>338</line>\n          <option name=\"timeStamp\" value=\"54\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>53</line>\n          <option name=\"timeStamp\" value=\"128\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>30</line>\n          <option name=\"timeStamp\" value=\"129\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>25</line>\n          <option name=\"timeStamp\" value=\"133\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test.py</url>\n          <line>18</line>\n          <option name=\"timeStamp\" value=\"135\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>\n          <line>44</line>\n          <option name=\"timeStamp\" value=\"138\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Test2.py</url>\n          <line>16</line>\n          <option name=\"timeStamp\" value=\"144\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/utilities.py</url>\n          <line>98</line>\n          <option name=\"timeStamp\" value=\"170\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/main.py</url>\n          <line>157</line>\n          <option name=\"timeStamp\" value=\"177\" />\n        </line-breakpoint>\n      </breakpoints>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n  </component>\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test3.coverage\" NAME=\"Test3 Coverage Results\" MODIFIED=\"1739273938386\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO3d.coverage\" NAME=\"config_AC2D_FNO3d Coverage Results\" MODIFIED=\"1733233385695\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1743065376798\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_2.coverage\" NAME=\"AC2D_Net2D_2 Coverage Results\" MODIFIED=\"1732904114403\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$test2.coverage\" NAME=\"test2 Coverage Results\" MODIFIED=\"1742889074336\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1741561715014\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$config_SH3D_TNO3d.coverage\" NAME=\"config_SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254757455\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$backend_interagg.coverage\" NAME=\"backend_interagg Coverage Results\" MODIFIED=\"1737630366471\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$APPLICATION_HOME_DIR$/plugins/python/helpers/pycharm_matplotlib_backend\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript3.coverage\" NAME=\"RunScript3 Coverage Results\" MODIFIED=\"1736368081257\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_2.coverage\" NAME=\"AC2D_2 Coverage Results\" MODIFIED=\"1732483323689\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1733086051390\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main_TF.coverage\" NAME=\"main_TF Coverage Results\" MODIFIED=\"1738704014479\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1741538869064\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$THFNO.coverage\" NAME=\"THFNO Coverage Results\" MODIFIED=\"1732911474644\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/networks\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D_New.coverage\" NAME=\"SH3D_New Coverage Results\" MODIFIED=\"1740088478224\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$PFC3D.coverage\" NAME=\"PFC3D Coverage Results\" MODIFIED=\"1740083613128\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1741603428589\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$run_inference.coverage\" NAME=\"run_inference Coverage Results\" MODIFIED=\"1750323709039\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1738663765959\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$post_processing.coverage\" NAME=\"post_processing Coverage Results\" MODIFIED=\"1733557098801\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2D_TNO2d.coverage\" NAME=\"config_CH2D_TNO2d Coverage Results\" MODIFIED=\"1734086207850\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$networks.coverage\" NAME=\"networks Coverage Results\" MODIFIED=\"1748933697533\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1750255151255\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript2.coverage\" NAME=\"RunScript2 Coverage Results\" MODIFIED=\"1736369209710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$SH3D_FNO3d.coverage\" NAME=\"SH3D_FNO3d Coverage Results\" MODIFIED=\"1742215946758\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_3.coverage\" NAME=\"AC2D_Net2D_3 Coverage Results\" MODIFIED=\"1732974697103\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_FNO3d.coverage\" NAME=\"AC3d_FNO3d Coverage Results\" MODIFIED=\"1749017845623\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D.coverage\" NAME=\"AC2D Coverage Results\" MODIFIED=\"1733088640665\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/Archive_Code\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D.coverage\" NAME=\"AC2D_Net2D Coverage Results\" MODIFIED=\"1732567473230\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D_New.coverage\" NAME=\"MBE3D_New Coverage Results\" MODIFIED=\"1740054182408\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$MBE3D_TNO3d.coverage\" NAME=\"MBE3D_TNO3d Coverage Results\" MODIFIED=\"1741562061391\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_AC3D_TNO3d.coverage\" NAME=\"config_AC3D_TNO3d Coverage Results\" MODIFIED=\"1737644605063\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$MBE3D.coverage\" NAME=\"MBE3D Coverage Results\" MODIFIED=\"1739283566145\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1741605347375\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1743071672425\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1736268192289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFC3D_TNO3d.coverage\" NAME=\"PFC3D_TNO3d Coverage Results\" MODIFIED=\"1741564210973\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_CH2DNL_TNO2d.coverage\" NAME=\"config_CH2DNL_TNO2d Coverage Results\" MODIFIED=\"1735052490996\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$MBE2D.coverage\" NAME=\"MBE2D Coverage Results\" MODIFIED=\"1732278526731\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_TNO3d.coverage\" NAME=\"CH3D_TNO3d Coverage Results\" MODIFIED=\"1739914172084\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test_Run.coverage\" NAME=\"Test_Run Coverage Results\" MODIFIED=\"1738945320139\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1741561294310\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741861381348\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1743081225414\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage\" NAME=\"PFV3D_FNO3d Coverage Results\" MODIFIED=\"1741564487710\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript1.coverage\" NAME=\"RunScript1 Coverage Results\" MODIFIED=\"1736368790622\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$SH2D.coverage\" NAME=\"SH2D Coverage Results\" MODIFIED=\"1732347080402\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$PFC2D.coverage\" NAME=\"PFC2D Coverage Results\" MODIFIED=\"1732278679485\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$CH2D.coverage\" NAME=\"CH2D Coverage Results\" MODIFIED=\"1732347055915\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$AC3D_FNO3d.coverage\" NAME=\"AC3D_FNO3d Coverage Results\" MODIFIED=\"1741561435127\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$SH3D.coverage\" NAME=\"SH3D Coverage Results\" MODIFIED=\"1739044808411\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test.coverage\" NAME=\"Test Coverage Results\" MODIFIED=\"1739459206236\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1741547133078\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D_FNO2d.coverage\" NAME=\"config_AC2D_FNO2d Coverage Results\" MODIFIED=\"1733393903488\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$AC3D.coverage\" NAME=\"AC3D Coverage Results\" MODIFIED=\"1740041515520\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$config_CH3D_TNO3d.coverage\" NAME=\"config_CH3D_TNO3d Coverage Results\" MODIFIED=\"1738089807566\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$Test2.coverage\" NAME=\"Test2 Coverage Results\" MODIFIED=\"1739283715182\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField_SANO3$CH3D_FNO3d.coverage\" NAME=\"CH3D_FNO3d Coverage Results\" MODIFIED=\"1741628529142\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3d_TNO3d_hybrid.coverage\" NAME=\"AC3d_TNO3d_hybrid Coverage Results\" MODIFIED=\"1748989478372\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1737899062785\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_AC2D.coverage\" NAME=\"config_AC2D Coverage Results\" MODIFIED=\"1733087276180\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$AC2D_Net2D_1.coverage\" NAME=\"AC2D_Net2D_1 Coverage Results\" MODIFIED=\"1732535211383\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$RunScript0.coverage\" NAME=\"RunScript0 Coverage Results\" MODIFIED=\"1736520700819\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$fourier_3d.coverage\" NAME=\"fourier_3d Coverage Results\" MODIFIED=\"1732221600628\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1750254767095\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage\" NAME=\"SH3D_TNO3d_Hybrid Coverage Results\" MODIFIED=\"1749216389646\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$AC3D_TNO3d.coverage\" NAME=\"AC3D_TNO3d Coverage Results\" MODIFIED=\"1748990262244\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$test1.coverage\" NAME=\"test1 Coverage Results\" MODIFIED=\"1733413325318\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/PhaseField1$CH3D_2.coverage\" NAME=\"CH3D_2 Coverage Results\" MODIFIED=\"1739918355289\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/phase_field_equations_4d$SH3D_TNO3d.coverage\" NAME=\"SH3D_TNO3d Coverage Results\" MODIFIED=\"1750254975290\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"\" />\n    <SUITE FILE_PATH=\"coverage/PhaseFieldNet$config_MBE2D_TNO2d.coverage\" NAME=\"config_MBE2D_TNO2d Coverage Results\" MODIFIED=\"1736261397712\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"false\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/configs\" />\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision 4571b9c99edbe597d7f28792b7cdc66308871464)
+++ b/.idea/workspace.xml	(date 1754669330864)
@@ -5,30 +5,17 @@
   </component>
   <component name="ChangeListManager">
     <list default="true" id="69f06a2e-e075-4f1f-8925-28211e19f97d" name="Changes" comment="TNO3d vs FNO3d">
-      <change afterPath="$PROJECT_DIR$/run_inference.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/vcs.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Error_subplots.png" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" afterPath="$PROJECT_DIR$/AC3D/plots_TNO3d/Predicted Solution_subplots.png" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/3d_phase_evolution.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Error_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Exact Solution_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/LossTrend.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_FNO3d/Predicted Solution_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/3d_phase_evolution.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Error_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Exact Solution_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/LossTrend.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/Predicted Solution_subplots.png" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_FNO3d.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_AC3D_TNO3d.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_FNO3d.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" beforeDir="false" afterPath="$PROJECT_DIR$/configs/config_SH3D_TNO3d.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_Comparison_Plot_Modified.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_SANO_field_comparison.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_SANO_field_comparison_FINAL.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/SH3D_SANO_loss_curve.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_field_comparison.png" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/SH3D/plots_TNO3d/TNO3d_SH3D_S32_T1to100_width12_modes14_q12_h6_grf3d.pt_results_loss_curve.png" beforeDir="false" />
       <change beforePath="$PROJECT_DIR$/main.py" beforeDir="false" afterPath="$PROJECT_DIR$/main.py" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/networks.py" beforeDir="false" afterPath="$PROJECT_DIR$/networks.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/post_processing.py" beforeDir="false" afterPath="$PROJECT_DIR$/post_processing.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/run_interface3.py" beforeDir="false" afterPath="$PROJECT_DIR$/run_interface3.py" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/training.py" beforeDir="false" afterPath="$PROJECT_DIR$/training.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/utilities.py" beforeDir="false" afterPath="$PROJECT_DIR$/utilities.py" afterDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
@@ -144,6 +131,7 @@
     &quot;Python.post_processing.executor&quot;: &quot;Run&quot;,
     &quot;Python.run_inference.executor&quot;: &quot;Run&quot;,
     &quot;Python.test1.executor&quot;: &quot;Run&quot;,
+    &quot;Python.training.executor&quot;: &quot;Run&quot;,
     &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
     &quot;git-widget-placeholder&quot;: &quot;main&quot;,
     &quot;last_opened_file_path&quot;: &quot;/scratch/noqu8762/phase_field_equations_4d/data&quot;,
@@ -513,6 +501,8 @@
       <workItem from="1749213099437" duration="3082000" />
       <workItem from="1750057109660" duration="10453000" />
       <workItem from="1750070416210" duration="46415000" />
+      <workItem from="1754657873054" duration="7705000" />
+      <workItem from="1754666353144" duration="2006000" />
     </task>
     <task id="LOCAL-00001" summary="Initial Commit">
       <option name="closed" value="true" />
@@ -806,11 +796,6 @@
           <url>file://$PROJECT_DIR$/Test.py</url>
           <line>18</line>
           <option name="timeStamp" value="135" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/configs/config_PFC3D_TNO3d.py</url>
-          <line>44</line>
-          <option name="timeStamp" value="138" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/Test2.py</url>
@@ -883,6 +868,7 @@
     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$CH3D_FNO3d.coverage" NAME="SH3D_TNO3d Coverage Results" MODIFIED="1741861381348" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3D$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1743081225414" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseField_SANO3$PFV3D_FNO3d.coverage" NAME="PFV3D_FNO3d Coverage Results" MODIFIED="1741564487710" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$training.coverage" NAME="training Coverage Results" MODIFIED="1754658751617" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript1.coverage" NAME="RunScript1 Coverage Results" MODIFIED="1736368790622" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$SH2D.coverage" NAME="SH2D Coverage Results" MODIFIED="1732347080402" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$PFC2D.coverage" NAME="PFC2D Coverage Results" MODIFIED="1732278679485" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
@@ -902,7 +888,7 @@
     <SUITE FILE_PATH="coverage/PhaseFieldNet$AC2D_Net2D_1.coverage" NAME="AC2D_Net2D_1 Coverage Results" MODIFIED="1732535211383" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$RunScript0.coverage" NAME="RunScript0 Coverage Results" MODIFIED="1736520700819" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$fourier_3d.coverage" NAME="fourier_3d Coverage Results" MODIFIED="1732221600628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
-    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1750254767095" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/phase_field_equations_4d$main.coverage" NAME="main Coverage Results" MODIFIED="1754665554880" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/phase_field_equations_4d$SH3D_TNO3d_Hybrid.coverage" NAME="SH3D_TNO3d_Hybrid Coverage Results" MODIFIED="1749216389646" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/phase_field_equations_4d$AC3D_TNO3d.coverage" NAME="AC3D_TNO3d Coverage Results" MODIFIED="1748990262244" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
     <SUITE FILE_PATH="coverage/PhaseFieldNet$test1.coverage" NAME="test1 Coverage Results" MODIFIED="1733413325318" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
