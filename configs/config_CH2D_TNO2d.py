# T_out = 10 , width = 32, modes = 12, batch_size = 100, epochs = 100 , param num = 2383211, nTrain = 1000, nTest = 100
# The average testing error is 0.04354054480791092
# Std. deviation of testing error is 0.0035996802616864443
# Min testing error is 0.03741595521569252 at index 92
# Max testing error is 0.05916225165128708 at index 24
# Mode of testing errors is 0.03741595521569252 appearing 92 times at indices 92
# T_out = 10 , width = 32, modes = 12, batch_size = 100, epochs = 100 , param num = 2395603, nTrain = 4000, nTest = 400
# n_layers = 4
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, 2 * self.width, T_out - 1)
# The average testing error is 0.022000467404723167
# Std. deviation of testing error is 0.001718668034300208
# Min testing error is 0.01801900938153267 at index 367
# Max testing error is 0.027704166248440742 at index 78
# Mode of testing errors is 0.01801900938153267 appearing 367 times at indices 367
# T_out = 10 , width = 32, modes = 12, batch_size = 100, epochs = 100 , param num = 2394739, nTrain = 4000, nTest = 400
# n_layers = 4
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.021649334579706192
# Std. deviation of testing error is 0.0017050061142072082
# Min testing error is 0.018064891919493675 at index 150
# Max testing error is 0.028213392943143845 at index 78
# Mode of testing errors is 0.018064891919493675 appearing 150 times at indices 150



# T_out = 50 , width = 32, modes = 12, batch_size = 100, epochs = 500 , param num = 2427771, nTrain = 2000, nTest = 200
# The average testing error is 0.06233977898955345
# T_out = 50 , width = 32, modes = 12, batch_size = 50, epochs = 500 , param num = 2485699, nTrain = 2000, nTest = 200
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.05317488685250282
# T_out = 50 , width = 32, modes = 12, batch_size = 50, epochs = 500 , param num = 2599203, nTrain = 2000, nTest = 200
# self.q = MLP2d(self.width, 1, 4 * self.width, T_out)
# self.q2 = MLP2d(1, 1, 2 * self.width, T_out - 1)
# The average testing error is 0.05360465869307518
# T_out = 50 , width = 32, modes = 14, batch_size = 50, epochs = 1000 , param num = 3279739, nTrain = 2000, nTest = 200
# The average testing error is 0.04978344589471817
# T_out = 50 , width = 32, modes = 14, batch_size = 50, epochs = 1000 , param num = 3337667, nTrain = 2000, nTest = 200
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.04655471816658974


# T_out = 100, width = 32, modes = 12, batch_size = 50, epochs = 500, param num = 2483471, nTrain = 2800, nTest = 200
# The average testing error is about 0.08
# T_out = 100, width = 32, modes = 14, batch_size = 50, epochs = 1500, param num = 3451367, nTrain = 2800, nTest = 200
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.08574927598237991
# T_out = 100, width = 40, modes = 20, batch_size = 50, epochs = 1500, param num = 10607919, nTrain = 2800, nTest = 200
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.08018164336681366
# T_out = 100, width = 42, modes = 8, batch_size = 50, epochs = 1500, param num = 2210449, nTrain = 2800, nTest = 200
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# Error = 0.11845362663269043
# T_out = 100, width = 40, modes = 16, batch_size = 25, epochs = 1500, param num = 6921519, nTrain = 2800, nTest = 200
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.07591673731803894
# T_out = 100, width = 42, modes = 12, batch_size = 50, epochs = 1500, param num = 4468369, nTrain = 2800, nTest = 200
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.08418522775173187
# T_out = 100, width = 32, modes = 12, batch_size = 50, epochs = 1500, param num = 2599399, nTrain = 4000, nTest = 400
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.07615471631288528
# T_out = 100, width = 40, modes = 16, batch_size = 50, epochs = 1500, param num = 6921519, nTrain = 4000, nTest = 400
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.0664185956120491
# T_out = 100, width = 40, modes = 20, batch_size = 50, epochs = 1500, param num = 10607919, nTrain = 4000, nTest = 400
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.07128896564245224
# T_out = 100, width = 40, modes = 12, batch_size = 25, epochs = 1500, param num = 4054319, nTrain = 4000, nTest = 400
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.06840438395738602
# T_out = 100, width = 32, modes = 12, batch_size = 50, epochs = 1500, param num = 2599399, nTrain = 4000, nTest = 400
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.07615471631288528
# T_out = 100, width = 46, modes = 22, batch_size = 50, epochs = 1500, param num = 16867893, nTrain = 4000, nTest = 400
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.06713391095399857
# T_out = 100, width = 40, modes = 12, batch_size = 25, epochs = 1000, param num = 4425959, nTrain = 4000, nTest = 400
# self.q = MLP2d(self.width, 1, 4 * self.width, T_out)
# self.q2 = MLP2d(1, 1, 4 * self.width, T_out - 1)
# The average testing error is 0.06983762979507446
# T_out = 100, width = 40, modes = 16, batch_size = 25, epochs = 1000, param num = 7293159, nTrain = 4000, nTest = 400
# self.q = MLP2d(self.width, 1, 4 * self.width, T_out)
# self.q2 = MLP2d(1, 1, 4 * self.width, T_out - 1)
# The average testing error is 0.0677800253033638
# T_out = 100, width = 32, modes = 12, batch_size = 25, epochs = 1000, param num = 3785383, nTrain = 4000, nTest = 400
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.04859883338212967
# T_out = 100, width = 32, modes = 12, batch_size = 50, epochs = 1000, param num = 4971367, nTrain = 4000, nTest = 400
# n_layers = 8
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.0459878109395504
# T_out = 100, width = 32, modes = 16, batch_size = 50, epochs = 1000, param num = 8641383, nTrain = 4000, nTest = 400
# n_layers = 8
# self.q = MLP2d(self.width, 1, 2 * self.width, T_out)
# self.q2 = MLP2d(1, 1, self.width, T_out - 1)
# The average testing error is 0.038783442229032516

import numpy as np

# General Setting
gpu_number = 'cuda'  # 'cuda:1'
torch_seed = 0
numpy_seed = 0

# Network Parameters
nTrain = 4000
nTest = 400
batch_size = 50
learning_rate = 0.001
weight_decay = 1e-4
epochs = 1000
iterations = epochs * (nTrain // batch_size)
modes = 16
width = 32
n_layers = 8

# Discretization
s = 64
T_in = 1
T_out = 100

# Training Setting
normalized = True
training = False  # True
load_model = True  # False

# Database
parent_dir = './data/'
matlab_dataset = 'CH2D_4400_Nt_101_Nx_64.mat'

# Plotting
index = 62  # 24 # 62
domain = [-np.pi, np.pi]
# time_steps = [29, 35, 39, 45, 49]
# time_steps = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]
time_steps = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,
              54, 59, 64, 69, 74, 79, 84, 89, 94, 99]
